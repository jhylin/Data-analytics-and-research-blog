{
  "hash": "6226be8fceb7111ef65e0612e91a2209",
  "result": {
    "markdown": "---\ntitle: Small molecules in ChEMBL database\nsubtitle: Series 1.1.4 - Evaluating logistic regression model in *scikit-learn*\nauthor: Jennifer HY Lin\ndate: 2023-1-4\ndate-modified: last-modified\ndraft: false\ncategories:\n  - Machine learning projects\n  - Scikit-learn\n  - Polars\n  - Python\n  - Jupyter\n  - ChEMBL database\n  - Cheminformatics\nbibliography: references.bib\n---\n\n##### **Import libraries**\n\nIn this fourth post and likely the last post of the logistic regression (LR) series, we're still going to begin with importing all the libraries needed for the following work on model evaluations.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport sklearn\nprint(f\"scikit-learn version used is: {sklearn.__version__}\")\nfrom sklearn.model_selection import train_test_split\nimport polars as pl\nprint(f\"polars version used is: {pl.__version__}\")\nimport pickle\nimport matplotlib.pyplot as plt\nfrom sklearn import metrics\n# For model evaluations\nfrom sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report, RocCurveDisplay, roc_curve, log_loss\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nscikit-learn version used is: 1.5.0\npolars version used is: 1.9.0\n```\n:::\n:::\n\n\n<br>\n\n##### **Import logistic regression pipeline/model**\n\nNext, we need to load the pickled file so we can evaluate the same LR pipeline used last time.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nLR = pickle.load(open(\"LR.pkl\", \"rb\"))\nLR\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<style>#sk-container-id-1 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-1 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-1 pre {\n  padding: 0;\n}\n\n#sk-container-id-1 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-1 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-1 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-1 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-1 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-1 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-1 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-1 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-1 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-1 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n#sk-container-id-1 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-1 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-1 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-1 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-1 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-1 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-1 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;StandardScaler&#x27;, StandardScaler()),\n                (&#x27;LogR&#x27;,\n                 LogisticRegression(random_state=50, solver=&#x27;liblinear&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;StandardScaler&#x27;, StandardScaler()),\n                (&#x27;LogR&#x27;,\n                 LogisticRegression(random_state=50, solver=&#x27;liblinear&#x27;))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(random_state=50, solver=&#x27;liblinear&#x27;)</pre></div> </div></div></div></div></div></div>\n```\n:::\n:::\n\n\n<br>\n\n##### **Evaluations of the logistic regression model**\n\nThis part will involve using accuracy scores, confusion matrix, receiver operating characteristic (ROC) curve, classification report and log loss to evaluate the LR model. The main statistical principles and concepts being referred to here are mostly from this reference textbook [@bruce2020], and a lot of native built-in functions from scikit-learn [@pedregosa2011] are used to generate the results.\n\n###### **Accuracy scores**\n\nThe easiest one to understand will be accuracy score, which can be calculated using predicted y outcome and actual or true y outcome in scikit-learn as shown below.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\n## Read in data & split into training & testing sets\ndf = pl.read_csv(\"df_ml.csv\")\nX = df[\"#RO5 Violations\", \"Polar Surface Area\", \"HBA\", \"HBD\", \"QED Weighted\", \"CX LogP\", \"CX LogD\", \"Heavy Atoms\"]\ny = df[\"Max_Phase\"]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 50)\nLR.fit(X_train, y_train)\ny_mp = LR.predict(X_test)\naccuracy_score(y_mp, y_test)\n\n## getting a warning message after accuracy score generated earlier \n# \"UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\" \n# - resolved, missed the fitting step first (my bad) before predict()\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\n0.689594356261023\n```\n:::\n:::\n\n\nThe accuracy score is 0.69 (after rounding up) which means that there are around 70% of the cases or compounds classified correctly by using the LR classifier. This score is also the same as the one shown from the previous post using `score()` instead of `accuracy_score()`.\n\nAccuracy score gives an idea about how close the predicted samples are to the true values. One caveat to note is that for imbalanced dataset, accuracy score might not be very informative and other evaluation metrics will be needed as well.\n\n<br>\n\n###### **Confusion matrix**\n\nA confusion matrix is built below based on the model in order to visualise the counts of correct and incorrect predictions. Previous code used to plot confusion matrix is shown below:\n\n::: {.cell execution_count=4}\n``` {.python .cell-code code-fold=\"true\"}\n## Function to print and plot confusion matrix\n## The function code below was adapted from the IBM data science course I've taken previously\n\n# # to create iterators for efficient looping\n# import itertools\n# import numpy as np\n\n# def plot_confusion_matrix(# Sets a cm object (cm = confusion matrix)\n#                           cm, \n#                           # Sets classes of '1s' (Successes) & '0s' (Non-successes) for the cm\n#                           classes,\n#                           # If setting normalize = true, reports in ratios instead of counts\n#                           normalize,\n#                           title = 'Confusion matrix',\n#                           # Choose colour of the cm (using colourmap recognised by matplotlib)\n#                           cmap = plt.cm.Reds):\n    \n    # if normalize:\n    #     cm = cm.astype('float') / cm.sum(axis = 1)[:, np.newaxis]\n    #     print(\"Normalized confusion matrix\")\n    # else:\n    #     print('Confusion matrix, without normalization')\n\n    # print(cm)\n\n    # # Plot the confusion matrix \n    # plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n    # plt.title(title)\n    # plt.colorbar()\n    # tick_marks = np.arange(len(classes))\n    # plt.xticks(tick_marks, classes, rotation = 45)\n    # plt.yticks(tick_marks, classes)\n\n    # # Floats to be round up to two decimal places if using normalize = True\n    # # or else use integers\n    # fmt = '.2f' if normalize else 'd'\n    # # Sets threshold of 0.5\n    # thresh = cm.max() / 2.\n    # # Iterate through the results and differentiate between two text colours \n    # # by using the threshold as a cut-off\n    # for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    #     plt.text(j, i, format(cm[i, j], fmt),\n    #              horizontalalignment = \"center\",\n    #              color = \"white\" if cm[i, j] > thresh else \"black\")\n\n    # plt.tight_layout()\n    # plt.ylabel('True label')\n    # plt.xlabel('Predicted label')\n\n# # Compute confusion matrix\n# matrix = confusion_matrix(y_test, y_mp, labels = [0,1])\n# np.set_printoptions(precision = 2)\n\n# # Plot confusion matrix without normalisation\n# plt.figure()\n# plot_confusion_matrix(matrix, \n#                       # Define classes of outcomes\n#                       classes = ['Max_Phase = 0','Max_Phase = 1'], \n#                       # Set normalize = True if wanting ratios instead\n#                       normalize = False, \n#                       title = \"Confusion matrix without normalisation\"\n#                      )\n```\n:::\n\n\nThere is actually an alternative and probably a better way (that uses less code) to plot confusion matrix using scikit-learn's code as shown here:\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nConfusionMatrixDisplay.from_estimator(LR, X_test, y_test)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](ML1-1-4_chembl_cpds_evaluate_files/figure-html/cell-6-output-1.png){width=504 height=429}\n:::\n:::\n\n\nA common rule of thumb for confusion matrix is that all predicted outcomes are columns and all the true outcomes are rows. However, there might be exceptions where this would be the other way round. \n\nFour different categories can be seen in the confusion matrix:\n\n-   True positive - Predicted Max_Phase = 1 & True Max_Phase = 1 (391) - *interested in this*\n-   True negative - Predicted Max_Phase = 0 & True Max_Phase = 0 (391)\n-   False positive - Predicted Max_Phase = 1 & True Max_Phase = 0 (167)\n-   False negative - Predicted Max_Phase = 0 & True Max_Phase = 1 (185)\n\n<br>\n\n###### **Receiver operating characteristic (ROC) curve**\n\nMy [old post](https://jhylin.github.io/Data_in_life_blog/posts/17_ML2-2_Random_forest/2_random_forest_classifier.html#brief-introduction) about random forest classifier has already explained what an area under the ROC curve is (I'm just going to quote myself...):\n\n> Area under the ROC curve: [reference](https://scikit-learn.org/stable/modules/model_evaluation.html#receiver-operating-characteristic-roc) - the area under a curve plot between sensitivity or recall (percent of all 1s classified correctly by a classifier or true positive rate) and specificity (percent of all 0s classified correctly by a classifier, or equivalent to 1 - false positive rate or true negative rate) (Bruce, Bruce, and Gedeck 2020). It is useful for evaluating the performance of a classification model via comparing the true positive rate and false positive rate which are influenced by shifting the decision threshold. Area under the ROC is usually represented as a number ranging from 0 to 1 (1 being a perfect classifier, 0.5 or below meaning a poor, ineffective classifier)\n\nIn this case, we can also apply ROC curve to the LR model and its predicted outcomes.\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n# get the predicted probabilities of outcome = 1 (approved drugs)\ny_mp_probs = LR.predict_proba(X_test)[:, 1]\nRocCurveDisplay.from_predictions(y_test, y_mp_probs, plot_chance_level = True)\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\n<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x106021d50>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](ML1-1-4_chembl_cpds_evaluate_files/figure-html/cell-7-output-2.png){width=445 height=431}\n:::\n:::\n\n\n<br>\n\n###### **Classification report**\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nprint(classification_report(y_test, y_mp))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              precision    recall  f1-score   support\n\n           0       0.68      0.70      0.69       558\n           1       0.70      0.68      0.69       576\n\n    accuracy                           0.69      1134\n   macro avg       0.69      0.69      0.69      1134\nweighted avg       0.69      0.69      0.69      1134\n\n```\n:::\n:::\n\n\n***Precision*** is a measure of the accuracy of a predicted outcome, where a class label has been predicted by the classifier. In this case, we can see that for class label 1, the precision is 0.70, which corresponds to the true positive result of 391 out of 558 samples (= 0.70, for true predicted Max_Phase = 1 column). It is defined by:\n\n$$\n\\text{Precision} = \\frac{\\Sigma\\ True\\ Positive}{(\\Sigma\\ True\\ Positive + \\Sigma\\ False\\ Positive)}\n$$\n\n***Recall***, also known as sensitivity (especially widely used in biostatistics and medical diagnostic fields), is a measure of the strength of the classifier to predict a positive outcome. In simple words, it measures the true positive rate. In this example, there is a total of 391 out of 576 samples (which = 0.68, for true Max_Phase = 1 row). It is defined by:\n\n$$\n\\text{Recall} = \\frac{\\Sigma\\ True\\ Positive}{(\\Sigma\\ True\\ Positive + \\Sigma\\ False\\ Negative)}\n$$\n\nThe precision and recall metrics are also calculated and shown for row 0 in the classification report.\n\n***f1-score***, or also known as balanced F-score or F-measure, denoted the harmonic average of both precision and recall metrics. This metric will also give another indication about whether this model performed well on outcome predictions. Its range is normally from 0 (worst precision and recall) to 1 (perfect precision and recall). For this particular classifier, f1-score was at 0.69 (for class label = 1). It is defined as:\n\n$$\n\\text{F1-score} = \\frac{2 \\times (Precision \\times Recall)}{(Precision + Recall)}\n$$\n\n***Support*** is the total number of true samples in each class label (reading row-wise from the confusion matrix). The main purpose of showing this metric is to help clarifying whether the model has had a reasonably balanced dataset for each class (and also helped to check the precision and recall values if needed).\n\n<br>\n\n###### **Log loss**\n\nLog loss can be used as another metric to show how good the classifier is at making the predictions. The further apart the predicted probability is from the true value, the larger the log loss, which is also ranging from 0 to 1. Ideally, the smaller the log loss the better the model will be. Here, we have a log loss of 0.61 (after rounding up) for this particular model.\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nlog_loss(y_test, y_mp_probs)\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\n0.6097696128595831\n```\n:::\n:::\n\n\n<br>\n\n#### **Thoughts**\n\nSo here I've completed a very basic LR classifier model for ChEMBL small molecules dataset. This is certainly not the most optimal machine learning model as I've only wanted to show how a baseline LR model can be built. This post update has added a molecular features versus coefficients plot (in the previous post) which shows the different weightings of the features used to train the dataset, ideally I should include more to provide a better overview of how the physicochemical properties will influence the prediction outcomes, but potentially this plot sort of answers the main goal of the post - which molecular properties might influence max phase outcomes. This last post here is really to show all the different evaluation metrics for the LR model, and I've added a ROC curve this time.\n\nTo further improve this model, I could possibly try hyperparameter tuning although I've come across comments from others in the past that it might not improve LR model that much once it's done. Originally I do have two other posts following on from the first one (which is currently splitted into four smaller posts), and one of them is about hyperparameter tuning. My possible plan at the moment is to maybe update these other two posts further down the line and I may decide to condense or remove them if it's not really going to make much difference or impact, I'll see...\n\n<br>\n\n#### **Acknowledgements**\n\nHuge thanks to our online open-source communities, libraries, and also all the references used in this series of posts.\n\n<br>\n\n#### **Online references**\n\nI've listed below all the online references used throughout this project. All the other journal paper or text book references used should be cited in the post already or listed below. \n\n-   [scikit-learn](https://scikit-learn.org/stable/index.html)\n-   [Stack Overflow](https://stackoverflow.com)\n-   Polars references:\n    1.  [Polars - User Guide](https://docs.pola.rs/) - https://docs.pola.rs/\n    2.  [Polars API reference](https://pola-rs.github.io/polars/py-polars/html/index.html#) - https://pola-rs.github.io/polars/py-polars/html/index.html#\n    3.  [Polars GitHub repository](https://github.com/pola-rs/polars) - https://github.com/pola-rs/polars\n\n",
    "supporting": [
      "ML1-1-4_chembl_cpds_evaluate_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}