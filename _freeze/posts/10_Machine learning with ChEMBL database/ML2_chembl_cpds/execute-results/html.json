{
  "hash": "8a8ebc6b5c7980ba35d1a1ca8230173d",
  "result": {
    "markdown": "---\ntitle: Machine learning with small molecules in ChEMBL database\nsubtitle: Cross-validation & hyper-parameter tuning with *scikit-learn*\nauthor: Jennifer HY Lin\ndate: 2023-2-27\ndraft: true\ncategories:\n  - Machine learning projects\n  - Scikit-learn\n  - Python\n  - ChEMBL database\n  - Cheminformatics\n---\n\n##### ***Machine learning in drug discovery - series 2***\n\n<br>\n\n##### **Review of ML series 1 and quick intro of series 2**\n\nThis post was really a continuation of the first ML series - \"Small molecules in ChEMBL database\". In particular, I wanted to work on the logistics regression (LR) model, and look into other strategies that I could use to improve it. Last time, I used LogisticRegression() method on the df_ml dataframe (df_ml_pd was the actual dataframe name used in ML series 1, to denote a conversion from a Polars to Pandas dataframe). I've not changed any parameters for the LR estimator, which meant everything was kept at default settings. Overall, this was an example of a default prototype of a LR classifer, which most likely would be too simplistic and not really reflecting real-world equivalents, but it sort of helped me to think in terms of a LR context.\n\nThis time, with a goal of trying to improve the model, I've planned to use cross-validation and hyper-parameter tuning at least to evaluate the estimator performance. It was also worth evaluating whether LR was the best ML approach for the df_ml dataset, which would likely need to be kept as a separate post to avoid another lengthy read. I also, on the other hand, have had an idea in mind of doing a ML series 3 looking at re-training the model and a final evaluation, which would keep me busy in the coming weeks or months.\n\n::: callout-note\nIn *scikit-learn*, an estimator is often referring to the different ML approaches, which are usually grouped into classification (e.g. naive Bayes, logistic regression), regression (e.g. support vector regression), clustering (e.g. K-means clustering) and dimensionality reduction (e.g. principal component analysis). A useful guide to help with choosing the right estimator can be found [here](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)\n:::\n\n<br>\n\n##### **Import dataframe from ML series 1**\n\nSince *scikit-learn* mainly supports Pandas dataframes for ML, I've opted to use Pandas instead of Polars dataframe library this time, to avoid the extra step of converting a Polars dataframe into a Pandas one.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\n```\n:::\n\n\nI've exported the final dataframe from ML series 1 as a .csv file, so that we could continue on this ML series and work on the logistic regression model further. For this ML series 2, the .csv file was imported as shown below.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\ndf_ml = pd.read_csv(\"df_ml.csv\")\ndf_ml.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Max_Phase</th>\n      <th>#RO5 Violations</th>\n      <th>QED Weighted</th>\n      <th>CX LogP</th>\n      <th>CX LogD</th>\n      <th>Heavy Atoms</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0.91</td>\n      <td>2.05</td>\n      <td>0.62</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>2</td>\n      <td>0.16</td>\n      <td>1.51</td>\n      <td>-0.41</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>2</td>\n      <td>0.20</td>\n      <td>5.05</td>\n      <td>3.27</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0.53</td>\n      <td>3.21</td>\n      <td>3.21</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0.14</td>\n      <td>2.80</td>\n      <td>2.80</td>\n      <td>37</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n<br>\n\n##### **Import libraries for machine learning**\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\n# Install scikit-learn - an open-source ML library\n# Uncomment the line below if needing to install this library\n#!pip install -U scikit-learn\n```\n:::\n\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\n# Import scikit-learn\nimport sklearn\n\n# Check version of scikit-learn \nprint(sklearn.__version__)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1.2.0\n```\n:::\n:::\n\n\nOther libraries needed to generate ML model were imported as below.\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\n# To use NumPy arrays to prepare X & y variables\nimport numpy as np\n\n# To normalise dataset prior to running ML\nfrom sklearn import preprocessing\n# To split dataset into training & testing sets\nfrom sklearn.model_selection import train_test_split\n\n# For data visualisations\n# Uncomment line below if requiring to install matplotlib\n#!pip install matplotlib\nimport matplotlib.pyplot as plt\n```\n:::\n\n\n<br>\n\n##### **Logistic regression**\n\nTo get the LR model ready, we needed to define our X and y variables from the df_ml dataset.\n\n<br>\n\n###### **Defining X and y variables**\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n# Define X variables from df_ml dataset\nX = np.asarray(df_ml[[\"#RO5 Violations\", \n                      \"QED Weighted\", \n                      \"CX LogP\", \n                      \"CX LogD\", \n                      \"Heavy Atoms\"]]\n              )\nX[0:5]\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\narray([[ 0.  ,  0.91,  2.05,  0.62, 21.  ],\n       [ 2.  ,  0.16,  1.51, -0.41, 48.  ],\n       [ 2.  ,  0.2 ,  5.05,  3.27, 46.  ],\n       [ 0.  ,  0.53,  3.21,  3.21, 24.  ],\n       [ 1.  ,  0.14,  2.8 ,  2.8 , 37.  ]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\n# Define y variable\ny = np.asarray(df_ml[\"Max_Phase\"])\ny[0:5]\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\narray([0, 0, 0, 0, 0])\n```\n:::\n:::\n\n\n<br>\n\n###### **Training and testing sets**\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\n# Split dataset into training & testing sets\nrng = np.random.RandomState(0)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = rng)\nprint('Training set:', X_train.shape, y_train.shape)\nprint('Testing set:', X_test.shape, y_test.shape)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTraining set: (1515, 5) (1515,)\nTesting set: (379, 5) (379,)\n```\n:::\n:::\n\n\n<br>\n\n###### **Preprocessing data**\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\n# Normalise & clean the dataset\n# Fit on the training set - not on testing set as this might lead to data leakage\n# Transform on the testing set\nX = preprocessing.StandardScaler().fit(X_train).transform(X_test)\nX[0:5]\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\narray([[-0.61683613,  0.76594864,  0.29675851,  0.52596937, -0.79684902],\n       [ 0.61602236,  0.45724627,  1.96615599,  1.92002856, -0.11325544],\n       [ 1.84888085, -1.43906824, -2.1393532 , -3.75082759,  0.37502569],\n       [ 0.61602236, -0.73346284, -2.1166917 , -1.56196543,  0.27736946],\n       [-0.61683613, -0.07195778, -1.5954771 , -1.05417464, -0.99216147]])\n```\n:::\n:::\n\n\n<br>\n\n###### **Fitting LR classifier on training set**\n\nOne major difference to this LR classifier this time was that cross-validation was included, via using the LogisticRegressionCV model, when creating and fitting the training data.\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\n# Import logistic regression CV estimator\nfrom sklearn.linear_model import LogisticRegressionCV\n\n# Change to LogisticRegressionCV() - LR with built-in cross validation\n# Create an instance of logistic regression CV classifier and fit the data\nLogR = LogisticRegressionCV().fit(X_train, y_train)\nLogR\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```{=html}\n<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegressionCV()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegressionCV</label><div class=\"sk-toggleable__content\"><pre>LogisticRegressionCV()</pre></div></div></div></div></div>\n```\n:::\n:::\n\n\n<br>\n\n###### **Applying LR classifier on testing set for prediction**\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\ny_mp = LogR.predict(X_test)\ny_mp\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```\narray([0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n       0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1,\n       0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n       0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n       1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n       0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n       1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n       1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n       0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n       1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n       0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n       0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n       0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n       0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n       0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n       0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n       0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n       0, 0, 0, 0, 1])\n```\n:::\n:::\n\n\n<br>\n\n###### **Converting predicted values into a dataframe**\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\n# Predicted values were based on log odds\n# Use describe() method to get characteristics of the distribution\npred = pd.DataFrame(LogR.predict_log_proba(X))\npred.describe()\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>379.000000</td>\n      <td>379.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>-1.068289</td>\n      <td>-0.441525</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.260589</td>\n      <td>0.107720</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-2.647965</td>\n      <td>-0.877546</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-1.146726</td>\n      <td>-0.504220</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>-1.034054</td>\n      <td>-0.439378</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>-0.926282</td>\n      <td>-0.382250</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>-0.537515</td>\n      <td>-0.073426</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nAlternatively, a quicker way to get predicted probabilities was via predict_proba() method in *scikit-learn*.\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\ny_mp_proba = LogR.predict_proba(X_test)\n# Uncomment below to see the predicted probabilities printed\n#print(y_mp_proba)\n```\n:::\n\n\n<br>\n\n###### **Converting predicted probabilities into a dataframe**\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\n# Use describe() to show distributions\ny_mp_prob = pd.DataFrame(y_mp_proba)\ny_mp_prob.describe()\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>379.000000</td>\n      <td>379.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.497894</td>\n      <td>0.502106</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.170176</td>\n      <td>0.170176</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.006039</td>\n      <td>0.148340</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.404873</td>\n      <td>0.382908</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.521389</td>\n      <td>0.478611</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.617092</td>\n      <td>0.595127</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.851660</td>\n      <td>0.993961</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n<br>\n\n###### **Pipeline method for LR**\n\nA quick trial of applying pipeline method with LogisticRegressionCV was done as shown below.\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\n# Test pipline from scikit-Learn\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nLogReg = make_pipeline(StandardScaler(), LogisticRegressionCV())\nLogReg.fit(X_train, y_train)\n```\n\n::: {.cell-output .cell-output-display execution_count=15}\n```{=html}\n<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n                (&#x27;logisticregressioncv&#x27;, LogisticRegressionCV())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n                (&#x27;logisticregressioncv&#x27;, LogisticRegressionCV())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegressionCV</label><div class=\"sk-toggleable__content\"><pre>LogisticRegressionCV()</pre></div></div></div></div></div></div></div>\n```\n:::\n:::\n\n\n<br>\n\n##### **Cross-validation & hyper-parameter tuning**\n\n<br>\n\n###### **Cross-validation**\n\nCross-validation was designed to minimise the amount of samples lost if we were to always partition all of our datasets into three lots for training, testing and validation. Readers with eagle eyes might notice a new set of data named validation set here. One of the biggest reasons to add this validation set was that often overfitting could happen on testing set with testing data being leaked into the model, which most likely would occur because all the parameters could be edited until the model performs optimally. By having a validation set of the data, this overfitting problem would be avoided. \n\nIn general, model training could take place initially on the training set, with the validation set used for first evaluation, which would be followed by a final evaluation on the testing set if the model testing worked as expected. The \"cross\" part of the cross-validation was the part that described the process of splitting the training data into many smaller number (*k*) of sets, which was also why cross-validation was also often known as \"*k*-fold cross-validation\" as well. With the use of *k*-fold cross-validation, the training set was essentially equivalent to *k*-1 of the folds of training data. The trained model would then be validated by using the remaining parts of the training data, which was almost like being used as a testing data to measure the performance of the trained model.\n\n::: callout-note\nIn short, cross-validation was simply a commonly used out-of-sample evaluation metric with effective use of data, where each observation was used for both training and testing.\n:::\n\n<br>\n\n###### **Decoding LogisticRegressionCV classifier**\n\nSince we've used LogisticRegressionCV classifier for the LR models, this meant it would be unnecessary to use GridSearchCV again if we read the definition of the estimatorCV closely, as shown below.\n\nAs quoted from *scikit-learn* on [cross-validation estimator](https://scikit-learn.org/stable/glossary.html#term-cross-validation-estimator):\n\n<q>An estimator that has built-in cross-validation capabilities to automatically select the best hyper-parameters (see the User Guide). Some example of cross-validation estimators are ElasticNetCV and LogisticRegressionCV. Cross-validation estimators are named EstimatorCV and tend to be roughly equivalent to GridSearchCV(Estimator(), ...). The advantage of using a cross-validation estimator over the canonical estimator class along with grid search is that they can take advantage of warm-starting by reusing precomputed results in the previous steps of the cross-validation process. This generally leads to speed improvements. An exception is the RidgeCV class, which can instead perform efficient Leave-One-Out (LOO) CV. By default, all these estimators, apart from RidgeCV with an LOO-CV, will be refitted on the full training dataset after finding the best combination of hyper-parameters.\n\nTherefore, the cross validation part for the LR model was taken care of by the LogisticRegressionCV() classifier. However, I wanted to find out more about this particular estimator, so to further dissect LogisticRegressionCV classifer, I looked into the documentation in *scikit-learn*, in that Stratified K-Folds cross-validator was used specifically at the default setting. One of the parameters in the classifier that was closely related to the Stratified K-Folds was the cv parameter, which was the cross-validation generator that could be tuned by providing integers as its equivalent number of folds used. Its default value for LogisticRegressionCV was set as \"None\", which was changed from 3-fold to 5-fold in version 0.22.\n\n<br>\n\n###### **Best parameters**\n\nTo explicitly see the details of all the parameters after cross-validation and/or hyper-parameter tuning, we could find the names and values of these parameters for the estimator by using the code below.\n\nTo find the parameters of any ML estimator, use code as suggested by *scikit-learn* as shown here.\n\n```{{python}}\nestimator.get_params()\n```\n\nIn this example, the first LR model built was named LogR.\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\nLogR.get_params()\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```\n{'Cs': 10,\n 'class_weight': None,\n 'cv': None,\n 'dual': False,\n 'fit_intercept': True,\n 'intercept_scaling': 1.0,\n 'l1_ratios': None,\n 'max_iter': 100,\n 'multi_class': 'auto',\n 'n_jobs': None,\n 'penalty': 'l2',\n 'random_state': None,\n 'refit': True,\n 'scoring': None,\n 'solver': 'lbfgs',\n 'tol': 0.0001,\n 'verbose': 0}\n```\n:::\n:::\n\n\nThe second LR model built using pipeline method was called LogReg.\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\nLogReg.get_params()\n```\n\n::: {.cell-output .cell-output-display execution_count=17}\n```\n{'memory': None,\n 'steps': [('standardscaler', StandardScaler()),\n  ('logisticregressioncv', LogisticRegressionCV())],\n 'verbose': False,\n 'standardscaler': StandardScaler(),\n 'logisticregressioncv': LogisticRegressionCV(),\n 'standardscaler__copy': True,\n 'standardscaler__with_mean': True,\n 'standardscaler__with_std': True,\n 'logisticregressioncv__Cs': 10,\n 'logisticregressioncv__class_weight': None,\n 'logisticregressioncv__cv': None,\n 'logisticregressioncv__dual': False,\n 'logisticregressioncv__fit_intercept': True,\n 'logisticregressioncv__intercept_scaling': 1.0,\n 'logisticregressioncv__l1_ratios': None,\n 'logisticregressioncv__max_iter': 100,\n 'logisticregressioncv__multi_class': 'auto',\n 'logisticregressioncv__n_jobs': None,\n 'logisticregressioncv__penalty': 'l2',\n 'logisticregressioncv__random_state': None,\n 'logisticregressioncv__refit': True,\n 'logisticregressioncv__scoring': None,\n 'logisticregressioncv__solver': 'lbfgs',\n 'logisticregressioncv__tol': 0.0001,\n 'logisticregressioncv__verbose': 0}\n```\n:::\n:::\n\n\nBoth models provided exactly the same set of parameters when LogisticRegressionCV classifier was used.\n\n<br>\n\n***To evaluate both LogR & LogReg models - perhaps keep it small e.g. only accuracy scores & confusion matrix, so can leave retraining model and final evaluation (full set of evaluation metrics) of model for ML series 3***\n\n#### **Evaluation of the logistic regression model**\n\n###### **Accuracy scores**\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\n#from sklearn.metrics import accuracy_score\n#accuracy_score(y_mp, y_test)\n```\n:::\n\n\nThe accuracy score was 0.7 based on the original data preprocessing method, which meant that there were around 70% of the cases (or compounds) classified correctly by using this LR classifier. Accuracy literally provided a measure of how close the predicted samples were to the true values. One caveat to note was that for imbalanced dataset, accuracy score might not be very informative, and other evaluation metrics would need to be considered instead.\n\nThe accuracy score shown below was from the pipeline method used previously, which showed a very similar accuracy score of 0.6965699 (close to 0.7), confirming the method was in line with the original preprocessing method.\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\n#LR.score(X_test, y_test)\n```\n:::\n\n\n<br>\n\n###### **Confusion matrix**\n\nNext, I've built a confusion matrix based on the model in order to visualise the counts of correct and incorrect predictions. The function code used below was adapted from the IBM data science course I've taken around the end of last year. I've added comments to try and explain what each section of the codes meant.\n\n```{{python}}\n# Import confusion matrix from scikit-learn\nfrom sklearn.metrics import confusion_matrix\n# Import itertools - functions to create iterators for efficient looping\nimport itertools\n\n# Function to print and plot confusion matrix\ndef plot_confusion_matrix(# Sets a cm object (cm = confusion matrix)\n                          cm, \n                          # Sets classes of '1s' (Successes) & '0s' (Non-successes) for the cm\n                          classes,\n                          # If setting normalize = true, reports in ratios instead of counts\n                          normalize,\n                          title = 'Confusion matrix',\n                          # Choose colour of the cm (using colourmap recognised by matplotlib)\n                          cmap = plt.cm.Reds):\n    \n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis = 1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    # Plot the confusion matrix \n    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation = 45)\n    plt.yticks(tick_marks, classes)\n\n    # Floats to be round up to two decimal places if using normalize = True\n    # or else use integers\n    fmt = '.2f' if normalize else 'd'\n    # Sets threshold of 0.5\n    thresh = cm.max() / 2.\n    # Iterate through the results and differentiate between two text colours \n    # by using the threshold as a cut-off\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment = \"center\",\n                 color = \"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n```\n\n```{{python}}\n# Compute confusion matrix\nmatrix = confusion_matrix(y_test, y_mp, labels = [0,1])\nnp.set_printoptions(precision = 2)\n\n# Plot confusion matrix without normalisation\nplt.figure()\nplot_confusion_matrix(matrix, \n                      # Define classes of outcomes\n                      classes = ['Max_Phase = 0','Max_Phase = 1'], \n                      # Set normalize = True if wanting ratios instead\n                      normalize = False, \n                      title = \"Confusion matrix without normalisation\"\n                     )\n```\n\nA common rule of thumb for confusion matrix was that all predicted outcomes were columns and all the true outcomes were rows. However, there might be exceptions where this was the other way round. Four different categories could be seen in the confusion matrix which were:\n\n-   True positive - Predicted Max_Phase = 1 & True Max_Phase = 1 (128 out of 179 samples)\n-   True negative - Predicted Max_Phase = 0 & True Max_Phase = 0 (138 out of 200 samples)\n-   False positive - Predicted Max_Phase = 1 & True Max_Phase = 0 (51 out of 179 samples)\n-   False negative - Predicted Max_Phase = 0 & True Max_Phase = 1 (62 out of 200 samples)\n\nBy having these four categories known would then lead us to the next section about classification report, which showed all the precision, recall, f1-score and support metrics to evaluate the performance of this classifier.\n\n<br>\n\n###### **Classification report**\n\n```{{python}}\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, y_mp))\n```\n\n*Precision* was a measure of the accuracy of a predicted outcome, where a class label had been predicted by the classifier. So in this case, we could see that for class label 1, the precision was 0.72, which corresponded to the true positive result of 128 out of 179 samples (= 0.715). It was defined by:\n\n$$\n\\text{Precision} = \\frac{\\Sigma\\ True\\ Positive}{(\\Sigma\\ True\\ Positive + \\Sigma\\ False\\ Positive)}\n$$\n\n*Recall*, also known as sensitivity (especially widely used in biostatistics and medical diagnostic fields), was a measure of the strength of the classifier to predict a positive outcome. In simple words, it measured the true positive rate. In this example, there was a total of 128 out of 190 samples (which = 0.674, for True Max_Phase = 1 row) that had a true positive outcome of having a max phase of 1. It was defined by:\n\n$$\n\\text{Recall} = \\frac{\\Sigma\\ True\\ Positive}{(\\Sigma\\ True\\ Positive + \\Sigma\\ False\\ Negative)}\n$$\n\nThe precision and recall metrics could also be calculated for class label = 0, which were shown for the row 0 in the classification report.\n\n*f1-score*, or also known as balanced F-score or F-measure, denoted the harmonic average of both precision and recall metrics. This metric would also give another indication about whether this model performed well on outcome predictions. It normally ranged from 0 (worst precision and recall) to 1 (perfect precision and recall). For this particular classifier, f1-score was at 0.7, which was definitely not at its worst, but also could be further improved. It was defined as:\n\n$$\n\\text{F1-score} = \\frac{2 \\times (Precision \\times Recall)}{(Precision + Recall)}\n$$\n\n*Support*, which some readers might have already worked out how the numbers were derived, was the total number of true samples in each class label (read row-wise from the confusion matrix). The main purpose of showing this metric was to help clarifying whether the model or classifier had a reasonably balanced dataset for each class or otherwise.\n\n<br>\n\n###### **Log loss**\n\nLog loss could be used as another gauge to show how good the classifier was at making the outcome predictions. The further the predicted probability was from the true value, the larger the log loss, which was also ranged from 0 to 1. Ideally, the smaller the log loss the better the model would be. Here, we had a log loss of 0.61 for this particular model.\n\n```{{python}}\n# Log loss\nfrom sklearn.metrics import log_loss\nlog_loss(y_test, y_mp_proba)\n```\n\n<br>\n\n#### **Discussions and conclusion**\n\n\n\n<br>\n\n#### **Final words**\n\n::: callout-note\nFeel free to skip this part as this is really me speaking my thoughts out loud about my situation lately.\n:::\n\nAfter encountering several hiccups during my job hunt in data analytics lately (mainly domestic jobs in NZ), I think I need to make up my mind on which field I'm going for (I might be over-qualified for being a general health data analyst... this was the latest impression/feedback I've received). So here it is, I'm going to concentrate on using machine learning (ML) in Python, specifically in drug discovery field for a while. I'll continue improving the data analytics aspect, but I'll be placing more emphasis on ML so that I can somehow create some ML experiences for myself, while trying to find a good match in the research data science job market in the pharmaceutical field. I also have a feeling that I may need to venture out into overseas roles in the near future, as these types of roles involving ML and pharmaceuticals are just too difficult to spot domestically.\n\nI once read a [blog post on learning ML](https://vickiboykis.com/2022/11/10/how-i-learn-machine-learning/) by V. Boykis, who has suggested to go broadly in topics, then go deep in one of them, which I've agreed wholeheartedly as the approach to go about in the tech world, since there is no way on earth that I will be able to learn everything completely (even OpenAI's ChatGPT has limits - being restricted by the amount and types of input data being fed into the GPT). So since I've branched into 3 programming languages so far, I've decided not to expand further into new programming languages for now, to avoid being \"half-bucket-full\" for everything, I should really narrow down my focus now. To name the 3 programming languages in the order I've learnt them, they are Python, R and Rust. In that, I'm most comfortable with Python as that is my first language, then it's R, followed by Rust, which is almost brand new. I think right now is a good time for me to go deep into an area that has always caught my attentions.\n\n<br>\n\n#### **References**\n\nI've listed below most of the references used throughout this project. Again, huge thanks could not be forgotten for our online communities, and definitely also towards the references I've used here.\n\n-   [scikit-learn documentation](https://scikit-learn.org/stable/index.html)\n-   [Scikit-learn: Machine Learning in Python](https://jmlr.csail.mit.edu/papers/v12/pedregosa11a.html), Pedregosa *et al.*, JMLR 12, pp. 2825-2830, 2011.\n-   Bruce, P., Bruce, A. & Gedeck P. (2020). Practical statistics for data scientists. O'Reilly.\n-   [Stack Overflow](https://stackoverflow.com)\n-   Polars references:\n    1.  [Polars - User Guide](https://pola-rs.github.io/polars-book/user-guide/introduction.html) - https://pola-rs.github.io/polars-book/user-guide/introduction.html\n    2.  [Polars documentation](https://pola-rs.github.io/polars/py-polars/html/index.html#) - https://pola-rs.github.io/polars/py-polars/html/index.html#\n    3.  [Polars GitHub repository](https://github.com/pola-rs/polars) - https://github.com/pola-rs/polars\n\n",
    "supporting": [
      "ML2_chembl_cpds_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}