---
title: "Table scraping from PDF"
subtitle: "Using tabula-py in Python"
author: "Jennifer HY Lin"
date: 2022-09-15
categories: [Data analytics projects, Python, Long COVID]
jupyter: python3
---

##### **Quick introduction**

Recently I had the idea of continuing the long COVID exploration and thought that I've never tried scraping a PDF before, so by combining these two ideas together, I ended up with this little piece of work as another post. 

A quick heads up: Java should be installed in order for tabula-py to work seamlessly, since tabula-py is actually a Python wrapper for tabula-java. In this case, I've relied on Homebrew to install Java, but there are several other different options available online and I'll leave this open for people who're interested to explore themselves. Once it's installed, we can then check for the Java version to ensure it's installed properly.
```{python}
# Check the version of Java
!java -version
```

##### **Installing and importing libraries**

Then we would install any libraries needed for scraping table data from PDF, which in this case, I ended up using only one library.

```{python}
!pip install -q tabula-py
```

```{python}
# import read_pdf from the tabula library
from tabula import read_pdf
```

##### **Data source**

Source of the table was from this journal paper by Healey Q, Sheikh A, Daines L, Vasileiou E. Symptoms and signs of long COVID: A rapid review and meta-analysis. J Glob Health 2022;12:05014. Creative Commons Attribution 4.0 International Public License

##### **Table scraping**

Firstly, I trialled scraping the table from page 4 of the journal paper, which only really scraped about half of the table. I then went on to add in another line of code to specify the scraping area[^1] on the PDF page in inches (this part could be deduced by using the in-built PDF tool).

[^1]: Thanks to Stack Overflow as I've managed to find this solution from several different scenarios and comments.

One thing I wasn't too sure about was that the tabula-py documentation did state that the default = full page, but in fact, it appeared to be not the case (only half of the table showed up). Also, the journal paper I was using had the tables printed in landscape layout (rather than the more common portrait style), so it wasn't completely clear if landscape version was making this harder or the other way.

```{python}
#specify the scraping area (top, left, bottom, right)
test_area = "10.05,6.60,10.05,6.60" 
df = read_pdf("Journal.pdf", pages = "4", area = test_area, guess = False, stream = True, pandas_options={'header':None})
df
```

Once above worked, I moved onto scraping the whole table across pages 4 to 6 of the PDF, and then saved the scraped table into a .csv file, which appeared automatically in the working directory.

```{python}
import tabula
test_area = "10.05,6.60,10.05,6.60"
# Convert and save scraped data into specified file format
tabula.convert_into("Journal.pdf", "Full_table_scraped.csv", output_format = "csv", pages = "4-6", area = test_area, guess = False, stream = True)
!cat Full_table_scraped.csv
```

##### **Short summary**

The PDF scraping exercise only worked to a certain degree[^2], as the data did not arrive in a proper tabular format. I've also gone on to read several online resources and looked into tabula-py and tabula-java, it was clearly shown in their GitHub repo that there were existing issues for tables that have merged cells, empty cells or no column lines (which was what I had in this case). All of them tend to result in jumbled or merged rows or columns. It tends to work better if the tables in the PDFs are already in a proper table format i.e. columns and rows marked by lines. Nevertheless, the purpose of scraping the table data was achieved as full data were there after checking, but just not in a clean and tidy state so the next post named, "Long COVID - an update" would take us into the next stage to see what this tabular data would tell us about long COVID (all done in R).

[^2]: or it could be my ignorance to other better methods - please leave a comment as I'd like to learn!
