<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.280">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Jennifer HY Lin">
<meta name="dcterms.date" content="2023-02-28">

<title>Home - Machine learning with small molecules in ChEMBL database</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-5CHVP3K63C"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-5CHVP3K63C', { 'anonymize_ip': true});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Home</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html">
 <span class="menu-text">Jennifer HY Lin</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/jhylin"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/jenhylin"><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://www.datascienceportfol.io/jhylin">
 <span class="menu-text">Portfolio</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://jhylin.github.io/CV_resume_quarto/">
 <span class="menu-text">CV</span></a>
  </li>  
</ul>
              <div class="quarto-toggle-container">
                  <a href="" class="quarto-color-scheme-toggle nav-link" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
              </div>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Machine learning with small molecules in ChEMBL database</h1>
            <p class="subtitle lead">Cross-validation &amp; hyper-parameter tuning with <em>scikit-learn</em></p>
                                <div class="quarto-categories">
                <div class="quarto-category">Machine learning projects</div>
                <div class="quarto-category">Scikit-learn</div>
                <div class="quarto-category">Python</div>
                <div class="quarto-category">ChEMBL database</div>
                <div class="quarto-category">Cheminformatics</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Jennifer HY Lin </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">February 28, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#machine-learning-in-drug-discovery---series-2" id="toc-machine-learning-in-drug-discovery---series-2" class="nav-link active" data-scroll-target="#machine-learning-in-drug-discovery---series-2"><strong><em>Machine learning in drug discovery - series 2</em></strong></a></li>
  <li><a href="#review-of-ml-series-1-introduction-of-series-2" id="toc-review-of-ml-series-1-introduction-of-series-2" class="nav-link" data-scroll-target="#review-of-ml-series-1-introduction-of-series-2"><strong>Review of ML series 1 &amp; introduction of series 2</strong></a></li>
  <li><a href="#import-dataframe-from-ml-series-1" id="toc-import-dataframe-from-ml-series-1" class="nav-link" data-scroll-target="#import-dataframe-from-ml-series-1"><strong>Import dataframe from ML series 1</strong></a></li>
  <li><a href="#import-libraries-for-machine-learning" id="toc-import-libraries-for-machine-learning" class="nav-link" data-scroll-target="#import-libraries-for-machine-learning"><strong>Import libraries for machine learning</strong></a></li>
  <li><a href="#logistic-regression" id="toc-logistic-regression" class="nav-link" data-scroll-target="#logistic-regression"><strong>Logistic regression</strong></a>
  <ul>
  <li><a href="#defining-x-and-y-variables" id="toc-defining-x-and-y-variables" class="nav-link" data-scroll-target="#defining-x-and-y-variables"><strong>Defining X and y variables</strong></a></li>
  <li><a href="#training-and-testing-sets" id="toc-training-and-testing-sets" class="nav-link" data-scroll-target="#training-and-testing-sets"><strong>Training and testing sets</strong></a></li>
  <li><a href="#preprocessing-data" id="toc-preprocessing-data" class="nav-link" data-scroll-target="#preprocessing-data"><strong>Preprocessing data</strong></a></li>
  <li><a href="#fitting-lr-classifier-on-training-set" id="toc-fitting-lr-classifier-on-training-set" class="nav-link" data-scroll-target="#fitting-lr-classifier-on-training-set"><strong>Fitting LR classifier on training set</strong></a></li>
  <li><a href="#applying-lr-classifier-on-testing-set-for-prediction" id="toc-applying-lr-classifier-on-testing-set-for-prediction" class="nav-link" data-scroll-target="#applying-lr-classifier-on-testing-set-for-prediction"><strong>Applying LR classifier on testing set for prediction</strong></a></li>
  <li><a href="#converting-predicted-values-into-a-dataframe" id="toc-converting-predicted-values-into-a-dataframe" class="nav-link" data-scroll-target="#converting-predicted-values-into-a-dataframe"><strong>Converting predicted values into a dataframe</strong></a></li>
  <li><a href="#converting-predicted-probabilities-into-a-dataframe" id="toc-converting-predicted-probabilities-into-a-dataframe" class="nav-link" data-scroll-target="#converting-predicted-probabilities-into-a-dataframe"><strong>Converting predicted probabilities into a dataframe</strong></a></li>
  <li><a href="#pipeline-method-for-lr" id="toc-pipeline-method-for-lr" class="nav-link" data-scroll-target="#pipeline-method-for-lr"><strong>Pipeline method for LR</strong></a></li>
  </ul></li>
  <li><a href="#cross-validation-hyper-parameter-tuning" id="toc-cross-validation-hyper-parameter-tuning" class="nav-link" data-scroll-target="#cross-validation-hyper-parameter-tuning"><strong>Cross-validation &amp; hyper-parameter tuning</strong></a>
  <ul>
  <li><a href="#cross-validation" id="toc-cross-validation" class="nav-link" data-scroll-target="#cross-validation"><strong>Cross-validation</strong></a></li>
  <li><a href="#decoding-logisticregressioncv-classifier" id="toc-decoding-logisticregressioncv-classifier" class="nav-link" data-scroll-target="#decoding-logisticregressioncv-classifier"><strong>Decoding LogisticRegressionCV classifier</strong></a></li>
  <li><a href="#hyper-parameter-tuning---how-parameters-affect-lr-model" id="toc-hyper-parameter-tuning---how-parameters-affect-lr-model" class="nav-link" data-scroll-target="#hyper-parameter-tuning---how-parameters-affect-lr-model"><strong>Hyper-parameter tuning - how parameters affect LR model</strong></a></li>
  </ul></li>
  <li><a href="#evaluation-of-the-logistic-regression-cv-model" id="toc-evaluation-of-the-logistic-regression-cv-model" class="nav-link" data-scroll-target="#evaluation-of-the-logistic-regression-cv-model"><strong>Evaluation of the logistic regression CV model</strong></a>
  <ul>
  <li><a href="#accuracy-scores" id="toc-accuracy-scores" class="nav-link" data-scroll-target="#accuracy-scores"><strong>Accuracy scores</strong></a></li>
  <li><a href="#confusion-matrix" id="toc-confusion-matrix" class="nav-link" data-scroll-target="#confusion-matrix"><strong>Confusion matrix</strong></a></li>
  <li><a href="#classification-report" id="toc-classification-report" class="nav-link" data-scroll-target="#classification-report"><strong>Classification report</strong></a></li>
  <li><a href="#log-loss" id="toc-log-loss" class="nav-link" data-scroll-target="#log-loss"><strong>Log loss</strong></a></li>
  </ul></li>
  <li><a href="#discussions-and-conclusion" id="toc-discussions-and-conclusion" class="nav-link" data-scroll-target="#discussions-and-conclusion"><strong>Discussions and conclusion</strong></a></li>
  <li><a href="#final-words" id="toc-final-words" class="nav-link" data-scroll-target="#final-words"><strong>Final words</strong></a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references"><strong>References</strong></a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/jhylin/Data_in_life_blog/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="machine-learning-in-drug-discovery---series-2" class="level5">
<h5 class="anchored" data-anchor-id="machine-learning-in-drug-discovery---series-2"><strong><em>Machine learning in drug discovery - series 2</em></strong></h5>
<p><br></p>
</section>
<section id="review-of-ml-series-1-introduction-of-series-2" class="level5">
<h5 class="anchored" data-anchor-id="review-of-ml-series-1-introduction-of-series-2"><strong>Review of ML series 1 &amp; introduction of series 2</strong></h5>
<p>This post was really a continuation of the first ML series - “Small molecules in ChEMBL database”. In particular, I wanted to work on the logistics regression (LR) model, and look into other strategies that I could use to improve it. Last time, I used LogisticRegression() method on the df_ml dataframe (df_ml_pd was the actual dataframe name used in ML series 1, to denote a conversion from a Polars to Pandas dataframe). I’ve not changed any parameters for the LR estimator, which meant everything was kept at default settings. Overall, this was an example of a default prototype of a LR classifer, which most likely would be too simplistic and not really reflecting real-world equivalents, but it sort of helped me to think in terms of a LR context.</p>
<p>This time, with a goal of trying to improve the model, I’ve planned to use cross-validation and hyper-parameter tuning at least to evaluate the estimator performance. It was also worth evaluating whether LR was the best ML approach for the df_ml dataset, which would likely need to be kept as a separate post to avoid another lengthy read. I also, on the other hand, have had an idea in mind of doing a ML series 3 looking at re-training the model and a final evaluation, which would keep me busy in the coming weeks or months.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>In <em>scikit-learn</em>, an estimator is often referring to the different ML approaches, which are usually grouped into classification (e.g.&nbsp;naive Bayes, logistic regression), regression (e.g.&nbsp;support vector regression), clustering (e.g.&nbsp;K-means clustering) and dimensionality reduction (e.g.&nbsp;principal component analysis). A useful guide to help with choosing the right estimator can be found <a href="https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html">here</a></p>
</div>
</div>
<p><br></p>
</section>
<section id="import-dataframe-from-ml-series-1" class="level5">
<h5 class="anchored" data-anchor-id="import-dataframe-from-ml-series-1"><strong>Import dataframe from ML series 1</strong></h5>
<p>Since <em>scikit-learn</em> mainly supports Pandas dataframes for ML, I’ve opted to use Pandas instead of Polars dataframe library this time, to avoid the extra step of converting a Polars dataframe into a Pandas one.</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>I’ve exported the final dataframe from ML series 1 as a .csv file, so that we could continue on this ML series and work on the logistic regression model further. For this ML series 2, the .csv file was imported as shown below.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>df_ml <span class="op">=</span> pd.read_csv(<span class="st">"df_ml.csv"</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>df_ml.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Max_Phase</th>
      <th>#RO5 Violations</th>
      <th>QED Weighted</th>
      <th>CX LogP</th>
      <th>CX LogD</th>
      <th>Heavy Atoms</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>0.91</td>
      <td>2.05</td>
      <td>0.62</td>
      <td>21</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>2</td>
      <td>0.16</td>
      <td>1.51</td>
      <td>-0.41</td>
      <td>48</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>2</td>
      <td>0.20</td>
      <td>5.05</td>
      <td>3.27</td>
      <td>46</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
      <td>0.53</td>
      <td>3.21</td>
      <td>3.21</td>
      <td>24</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>1</td>
      <td>0.14</td>
      <td>2.80</td>
      <td>2.80</td>
      <td>37</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>df_ml.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>(1894, 6)</code></pre>
</div>
</div>
<p><br></p>
</section>
<section id="import-libraries-for-machine-learning" class="level5">
<h5 class="anchored" data-anchor-id="import-libraries-for-machine-learning"><strong>Import libraries for machine learning</strong></h5>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Install scikit-learn - an open-source ML library</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Uncomment the line below if needing to install this library</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co">#!pip install -U scikit-learn</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import scikit-learn</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sklearn</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Check version of scikit-learn </span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(sklearn.__version__)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1.2.0</code></pre>
</div>
</div>
<p>Other libraries needed to generate ML model were imported as below.</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># To use NumPy arrays to prepare X &amp; y variables</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># To normalise dataset prior to running ML</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> preprocessing</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="co"># To split dataset into training &amp; testing sets</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="co"># For data visualisations</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Uncomment line below if requiring to install matplotlib</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="co">#!pip install matplotlib</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><br></p>
</section>
<section id="logistic-regression" class="level5">
<h5 class="anchored" data-anchor-id="logistic-regression"><strong>Logistic regression</strong></h5>
<p>To get the LR model ready, we needed to define our X and y variables from the df_ml dataset.</p>
<p><br></p>
<section id="defining-x-and-y-variables" class="level6">
<h6 class="anchored" data-anchor-id="defining-x-and-y-variables"><strong>Defining X and y variables</strong></h6>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define X variables from df_ml dataset</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.asarray(df_ml[[<span class="st">"#RO5 Violations"</span>, </span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>                      <span class="st">"QED Weighted"</span>, </span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>                      <span class="st">"CX LogP"</span>, </span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>                      <span class="st">"CX LogD"</span>, </span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>                      <span class="st">"Heavy Atoms"</span>]]</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>              )</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>X[<span class="dv">0</span>:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>array([[ 0.  ,  0.91,  2.05,  0.62, 21.  ],
       [ 2.  ,  0.16,  1.51, -0.41, 48.  ],
       [ 2.  ,  0.2 ,  5.05,  3.27, 46.  ],
       [ 0.  ,  0.53,  3.21,  3.21, 24.  ],
       [ 1.  ,  0.14,  2.8 ,  2.8 , 37.  ]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define y variable</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.asarray(df_ml[<span class="st">"Max_Phase"</span>])</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>y[<span class="dv">0</span>:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>array([0, 0, 0, 0, 0])</code></pre>
</div>
</div>
<p><br></p>
</section>
<section id="training-and-testing-sets" class="level6">
<h6 class="anchored" data-anchor-id="training-and-testing-sets"><strong>Training and testing sets</strong></h6>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Split dataset into training &amp; testing sets</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Random number generator</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co">#rng = np.random.RandomState(0) - note: this may produce different result each time</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Edited post to use random_state = 250 to show comparison with ML series 1</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="co"># for reproducible result</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size <span class="op">=</span> <span class="fl">0.2</span>, random_state <span class="op">=</span> <span class="dv">250</span>)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Training set:'</span>, X_train.shape, y_train.shape)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Testing set:'</span>, X_test.shape, y_test.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training set: (1515, 5) (1515,)
Testing set: (379, 5) (379,)</code></pre>
</div>
</div>
<p><br></p>
</section>
<section id="preprocessing-data" class="level6">
<h6 class="anchored" data-anchor-id="preprocessing-data"><strong>Preprocessing data</strong></h6>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Normalise &amp; clean the dataset</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit on the training set - not on testing set as this might lead to data leakage</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Transform on the testing set</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> preprocessing.StandardScaler().fit(X_train).transform(X_test)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>X[<span class="dv">0</span>:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>array([[-0.61846489, -0.79518088,  0.57523481,  0.76170581,  0.47638078],
       [-0.61846489, -1.24006401,  1.27389185,  1.25867492,  0.37925834],
       [-0.61846489,  0.4949802 , -0.18352175,  0.12634023, -1.27182321],
       [-0.61846489, -0.79518088,  0.03433905,  0.28360894, -0.68908855],
       [-0.61846489, -0.48376269,  0.61655324,  0.79630492, -0.20347633]])</code></pre>
</div>
</div>
<p><br></p>
</section>
<section id="fitting-lr-classifier-on-training-set" class="level6">
<h6 class="anchored" data-anchor-id="fitting-lr-classifier-on-training-set"><strong>Fitting LR classifier on training set</strong></h6>
<p>One major difference to this LR classifier this time was that cross-validation was included, via using the LogisticRegressionCV model, when creating and fitting the training data.</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import logistic regression CV estimator</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegressionCV</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Change to LogisticRegressionCV() - LR with built-in cross validation</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an instance of logistic regression CV classifier and fit the data</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>LogR <span class="op">=</span> LogisticRegressionCV().fit(X_train, y_train)</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>LogR</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>LogisticRegressionCV()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked=""><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">LogisticRegressionCV</label><div class="sk-toggleable__content"><pre>LogisticRegressionCV()</pre></div></div></div></div></div>
</div>
</div>
<p><br></p>
</section>
<section id="applying-lr-classifier-on-testing-set-for-prediction" class="level6">
<h6 class="anchored" data-anchor-id="applying-lr-classifier-on-testing-set-for-prediction"><strong>Applying LR classifier on testing set for prediction</strong></h6>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>y_mp <span class="op">=</span> LogR.predict(X_test)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>y_mp</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>array([0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0,
       1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,
       1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,
       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1,
       1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,
       1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1,
       0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,
       0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0,
       0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1,
       0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,
       0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,
       1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,
       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,
       0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0,
       1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0,
       1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,
       0, 0, 1, 0, 0])</code></pre>
</div>
</div>
<p><br></p>
</section>
<section id="converting-predicted-values-into-a-dataframe" class="level6">
<h6 class="anchored" data-anchor-id="converting-predicted-values-into-a-dataframe"><strong>Converting predicted values into a dataframe</strong></h6>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicted values were based on log odds</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Use describe() method to get characteristics of the distribution</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>pred <span class="op">=</span> pd.DataFrame(LogR.predict_log_proba(X))</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>pred.describe()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>0</th>
      <th>1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>379.000000</td>
      <td>379.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>-1.062787</td>
      <td>-0.442845</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.235029</td>
      <td>0.109879</td>
    </tr>
    <tr>
      <th>min</th>
      <td>-2.435645</td>
      <td>-0.793868</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>-1.165361</td>
      <td>-0.504319</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>-1.049435</td>
      <td>-0.430992</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>-0.926131</td>
      <td>-0.373691</td>
    </tr>
    <tr>
      <th>max</th>
      <td>-0.601649</td>
      <td>-0.091612</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>Alternatively, a quicker way to get predicted probabilities was via predict_proba() method in <em>scikit-learn</em>.</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>y_mp_proba <span class="op">=</span> LogR.predict_proba(X_test)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Uncomment below to see the predicted probabilities printed</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="co">#print(y_mp_proba)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><br></p>
</section>
<section id="converting-predicted-probabilities-into-a-dataframe" class="level6">
<h6 class="anchored" data-anchor-id="converting-predicted-probabilities-into-a-dataframe"><strong>Converting predicted probabilities into a dataframe</strong></h6>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use describe() to show distributions</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>y_mp_prob <span class="op">=</span> pd.DataFrame(y_mp_proba)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>y_mp_prob.describe()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>0</th>
      <th>1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>379.000000</td>
      <td>379.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.482928</td>
      <td>0.517072</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.172099</td>
      <td>0.172099</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.009285</td>
      <td>0.144482</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>0.372812</td>
      <td>0.391971</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>0.511104</td>
      <td>0.488896</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>0.608029</td>
      <td>0.627188</td>
    </tr>
    <tr>
      <th>max</th>
      <td>0.855518</td>
      <td>0.990715</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p><br></p>
</section>
<section id="pipeline-method-for-lr" class="level6">
<h6 class="anchored" data-anchor-id="pipeline-method-for-lr"><strong>Pipeline method for LR</strong></h6>
<p>A quick trial of applying pipeline method with LogisticRegressionCV was done as shown below.</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Test pipline from scikit-Learn</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> make_pipeline</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>LogReg <span class="op">=</span> make_pipeline(StandardScaler(), LogisticRegressionCV())</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>LogReg.fit(X_train, y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-2" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>Pipeline(steps=[('standardscaler', StandardScaler()),
                ('logisticregressioncv', LogisticRegressionCV())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox"><label for="sk-estimator-id-2" class="sk-toggleable__label sk-toggleable__label-arrow">Pipeline</label><div class="sk-toggleable__content"><pre>Pipeline(steps=[('standardscaler', StandardScaler()),
                ('logisticregressioncv', LogisticRegressionCV())])</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox"><label for="sk-estimator-id-3" class="sk-toggleable__label sk-toggleable__label-arrow">StandardScaler</label><div class="sk-toggleable__content"><pre>StandardScaler()</pre></div></div></div><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-4" type="checkbox"><label for="sk-estimator-id-4" class="sk-toggleable__label sk-toggleable__label-arrow">LogisticRegressionCV</label><div class="sk-toggleable__content"><pre>LogisticRegressionCV()</pre></div></div></div></div></div></div></div>
</div>
</div>
<p><br></p>
</section>
</section>
<section id="cross-validation-hyper-parameter-tuning" class="level5">
<h5 class="anchored" data-anchor-id="cross-validation-hyper-parameter-tuning"><strong>Cross-validation &amp; hyper-parameter tuning</strong></h5>
<p><br></p>
<section id="cross-validation" class="level6">
<h6 class="anchored" data-anchor-id="cross-validation"><strong>Cross-validation</strong></h6>
<p>Cross-validation was designed to minimise the amount of samples lost if we were to always partition all of our datasets into three lots for training, testing and validation. Readers with eagle eyes might notice a new set of data named validation set here. One of the biggest reasons to add this validation set was that often overfitting could happen on testing set with testing data being leaked into the model, which most likely would occur because all the parameters could be edited until the model performs optimally. By having a validation set of the data, this overfitting problem would be avoided.</p>
<p>In general, model training could take place initially on the training set, with the validation set used for first evaluation, which would be followed by a final evaluation on the testing set if the model testing worked as expected. The “cross” part of the cross-validation was the part that described the process of splitting the training data into many smaller number (<em>k</em>) of sets, which was also why cross-validation was also often known as “<em>k</em>-fold cross-validation” as well. With the use of <em>k</em>-fold cross-validation, the training set was essentially equivalent to <em>k</em>-1 of the folds of training data. The trained model would then be validated by using the remaining parts of the training data, which was almost like being used as a testing data to measure the performance of the trained model.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>In short, cross-validation was simply a commonly used out-of-sample evaluation metric with effective use of data, where each observation was used for both training and testing.</p>
</div>
</div>
<p><br></p>
</section>
<section id="decoding-logisticregressioncv-classifier" class="level6">
<h6 class="anchored" data-anchor-id="decoding-logisticregressioncv-classifier"><strong>Decoding LogisticRegressionCV classifier</strong></h6>
<p>Since we’ve used LogisticRegressionCV classifier for the LR models, this meant it would be unnecessary to use GridSearchCV again if we read the definition of the estimatorCV closely, as shown below.</p>
<p>As quoted from <em>scikit-learn</em> on <a href="https://scikit-learn.org/stable/glossary.html#term-cross-validation-estimator">cross-validation estimator</a>:</p>
<p><q>An estimator that has built-in cross-validation capabilities to automatically select the best hyper-parameters (see the User Guide). Some example of cross-validation estimators are ElasticNetCV and LogisticRegressionCV. Cross-validation estimators are named EstimatorCV and tend to be roughly equivalent to GridSearchCV(Estimator(), …). The advantage of using a cross-validation estimator over the canonical estimator class along with grid search is that they can take advantage of warm-starting by reusing precomputed results in the previous steps of the cross-validation process. This generally leads to speed improvements. An exception is the RidgeCV class, which can instead perform efficient Leave-One-Out (LOO) CV. By default, all these estimators, apart from RidgeCV with an LOO-CV, will be refitted on the full training dataset after finding the best combination of hyper-parameters.</q></p>
<p>Therefore, the cross validation part for the LR model was taken care of by the LogisticRegressionCV() classifier. However, I wanted to find out more about this particular estimator, so to further dissect LogisticRegressionCV classifer, I looked into the documentation in <em>scikit-learn</em>, in that Stratified K-Folds cross-validator was used specifically at the default setting. One of the parameters in the classifier that was closely related to the Stratified K-Folds was the cv parameter, which was the cross-validation generator that could be tuned by providing integers as its equivalent number of folds used. Its default value for LogisticRegressionCV was set as “None”, which was changed from 3-fold to 5-fold in version 0.22.</p>
<p><br></p>
</section>
<section id="hyper-parameter-tuning---how-parameters-affect-lr-model" class="level6">
<h6 class="anchored" data-anchor-id="hyper-parameter-tuning---how-parameters-affect-lr-model"><strong>Hyper-parameter tuning - how parameters affect LR model</strong></h6>
<p>To explicitly see the details of all the parameters after cross-validation, we could find the names and values of these parameters for the estimator by using the code below.</p>
<p>To find the parameters of any ML estimator, the code suggested by <em>scikit-learn</em> was shown below.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>estimator.get_params()</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In this example, the first LR model built was named LogR. All the parameters used for LogR could be shown by using the code below.</p>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>LogR.get_params()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>{'Cs': 10,
 'class_weight': None,
 'cv': None,
 'dual': False,
 'fit_intercept': True,
 'intercept_scaling': 1.0,
 'l1_ratios': None,
 'max_iter': 100,
 'multi_class': 'auto',
 'n_jobs': None,
 'penalty': 'l2',
 'random_state': None,
 'refit': True,
 'scoring': None,
 'solver': 'lbfgs',
 'tol': 0.0001,
 'verbose': 0}</code></pre>
</div>
</div>
<p>The second LR model built using pipeline method was called LogReg, and its parameters used were shown below.</p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>LogReg.get_params()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>{'memory': None,
 'steps': [('standardscaler', StandardScaler()),
  ('logisticregressioncv', LogisticRegressionCV())],
 'verbose': False,
 'standardscaler': StandardScaler(),
 'logisticregressioncv': LogisticRegressionCV(),
 'standardscaler__copy': True,
 'standardscaler__with_mean': True,
 'standardscaler__with_std': True,
 'logisticregressioncv__Cs': 10,
 'logisticregressioncv__class_weight': None,
 'logisticregressioncv__cv': None,
 'logisticregressioncv__dual': False,
 'logisticregressioncv__fit_intercept': True,
 'logisticregressioncv__intercept_scaling': 1.0,
 'logisticregressioncv__l1_ratios': None,
 'logisticregressioncv__max_iter': 100,
 'logisticregressioncv__multi_class': 'auto',
 'logisticregressioncv__n_jobs': None,
 'logisticregressioncv__penalty': 'l2',
 'logisticregressioncv__random_state': None,
 'logisticregressioncv__refit': True,
 'logisticregressioncv__scoring': None,
 'logisticregressioncv__solver': 'lbfgs',
 'logisticregressioncv__tol': 0.0001,
 'logisticregressioncv__verbose': 0}</code></pre>
</div>
</div>
<p>Both models acutally, without any surprises, had exactly the same set of parameters when LogisticRegressionCV classifier was used.</p>
<p>However, to find out how the parameters influence the LR model, it was probably best to test a few of the parameters out. I’ve had two parameters in mind that I thought would affect the confusion matrix at least - cv and random_state parameters after doing some manual trial and errors by changing cv and random_state values in the code. However, upon reading and digging more online information and resources, I quickly realised that cv parameter would probably matter more than random_state parameter. This was based this line from <em>scikit-learn</em> on LogisticRegressionCV classifer,</p>
<p><q> For the grid of Cs values and l1_ratios values, the best hyperparameter is selected by the cross-validator StratifiedKFold, but it can be changed using the cv parameter.</q></p>
<p>So it appeared changing cv parameter could affect Cs and l1_ratios values as well. Also from <em>scikit-learn</em> documentation on LR, other parameters that could be tuned were solvers, penalties and C (controls regularisation or penalty strengths, which would be already taken care of if using LogisticRegressionCV classifier). Quite a few other similar online projects using logistic regression in <em>scikit-learn</em> had also mentioned that logistic regression in general did not have a lot of critical hyper-parameters to be tuned (<a href="https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/">one of the examples</a>). Another post I happened to bump into even concluded that better time should be used to link the model results with actual business metrics, rather than trying to use hyper-parameter tuning on LR model. Nevertheless, I still wanted to see how these parameters would affect the LR model in this case, even if it was of minor significance, so that I would fully understand how all of them work together.</p>
<p>Note: only certain penalties and solvers work together.</p>
<p>In order to search and see the variations in the LR parameters, I’ve opted to use RepeatedStratifiedKFold as the cross-validation method (which was also the default cross-validator method used in LogisticRegressionCV classifier). The “repeat” version would repeat Stratified K-Fold at stated (n) times. Because of this, GridSearchCV would be used to exhaustively search for the best parameters in this case, with the aim to see how the changes in parameters would affect the accuracy scores for each model.</p>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Re-sampled y variable so that there were same numbers of samples as X variables</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.asarray(df_ml[<span class="st">"Max_Phase"</span>].sample(n <span class="op">=</span> <span class="dv">379</span>, random_state <span class="op">=</span> <span class="dv">1</span>))</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>y.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>(379,)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># **Draft code only - work-in-progress**</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Idea is to show the variations/trends in cv, C, solvers &amp; penalties</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="co"># when they are used in combinations to fit and evaluate the models</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Code adapted from: https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/</span></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> RepeatedStratifiedKFold</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a><span class="co">#from sklearn.linear_model import LogisticRegression</span></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up model and parameters to test</span></span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LogisticRegressionCV()</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Note: default value for cv = 5-fold</span></span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>cv <span class="op">=</span> [<span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">30</span>]</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Note: default value for Cs = 10 (integers or floats only)</span></span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>Cs <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">10</span>, <span class="dv">50</span>, <span class="dv">100</span>]</span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Note: default solver = "lbfgs"</span></span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>solvers <span class="op">=</span> [<span class="st">"lbfgs"</span>, <span class="st">"liblinear"</span>, <span class="st">"newton-cg"</span>, <span class="st">"newton-cholesky"</span>]</span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a><span class="co">#  removed to test</span></span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a><span class="co"># "sag", "saga" not used as these were faster for large datasets</span></span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a><span class="co"># (the dataset used in this case was small)</span></span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a>penalty <span class="op">=</span> [<span class="st">"l2"</span>]</span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up grid search</span></span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a>grid <span class="op">=</span> <span class="bu">dict</span>(cv <span class="op">=</span> cv, Cs <span class="op">=</span> Cs, solver <span class="op">=</span> solvers, penalty <span class="op">=</span> penalty)</span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a>CV <span class="op">=</span> RepeatedStratifiedKFold(n_splits <span class="op">=</span> <span class="dv">5</span>, n_repeats <span class="op">=</span> <span class="dv">2</span>, random_state <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a>grid_search <span class="op">=</span> GridSearchCV(estimator <span class="op">=</span> model, param_grid <span class="op">=</span> grid, n_jobs <span class="op">=</span> <span class="op">-</span><span class="dv">1</span>, cv <span class="op">=</span> CV, scoring <span class="op">=</span> <span class="st">"accuracy"</span>, error_score <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true" tabindex="-1"></a>grid_result <span class="op">=</span> grid_search.fit(X, y)</span>
<span id="cb31-33"><a href="#cb31-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-34"><a href="#cb31-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Results</span></span>
<span id="cb31-35"><a href="#cb31-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best mean test score: </span><span class="sc">%f</span><span class="st"> using </span><span class="sc">%s</span><span class="st">"</span> <span class="op">%</span> (grid_result.best_score_, grid_result.best_params_))</span>
<span id="cb31-36"><a href="#cb31-36" aria-hidden="true" tabindex="-1"></a>means <span class="op">=</span> grid_result.cv_results_[<span class="st">"mean_test_score"</span>]</span>
<span id="cb31-37"><a href="#cb31-37" aria-hidden="true" tabindex="-1"></a>std <span class="op">=</span> grid_result.cv_results_[<span class="st">"std_test_score"</span>]</span>
<span id="cb31-38"><a href="#cb31-38" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> grid_result.cv_results_[<span class="st">"params"</span>]</span>
<span id="cb31-39"><a href="#cb31-39" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> mean, stdv, param <span class="kw">in</span> <span class="bu">zip</span>(means, std, params):</span>
<span id="cb31-40"><a href="#cb31-40" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="sc">%f</span><span class="st"> (</span><span class="sc">%f</span><span class="st">) with: </span><span class="sc">%r</span><span class="st">"</span> <span class="op">%</span> (mean, stdv, param))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Best mean test score: 0.509228 using {'Cs': 1, 'cv': 5, 'penalty': 'l2', 'solver': 'lbfgs'}
0.509228 (0.005254) with: {'Cs': 1, 'cv': 5, 'penalty': 'l2', 'solver': 'lbfgs'}
0.465772 (0.036237) with: {'Cs': 1, 'cv': 5, 'penalty': 'l2', 'solver': 'liblinear'}
0.509228 (0.005254) with: {'Cs': 1, 'cv': 5, 'penalty': 'l2', 'solver': 'newton-cg'}
0.509228 (0.005254) with: {'Cs': 1, 'cv': 5, 'penalty': 'l2', 'solver': 'newton-cholesky'}
0.509228 (0.005254) with: {'Cs': 1, 'cv': 10, 'penalty': 'l2', 'solver': 'lbfgs'}
0.465772 (0.036237) with: {'Cs': 1, 'cv': 10, 'penalty': 'l2', 'solver': 'liblinear'}
0.509228 (0.005254) with: {'Cs': 1, 'cv': 10, 'penalty': 'l2', 'solver': 'newton-cg'}
0.509228 (0.005254) with: {'Cs': 1, 'cv': 10, 'penalty': 'l2', 'solver': 'newton-cholesky'}
0.509228 (0.005254) with: {'Cs': 1, 'cv': 20, 'penalty': 'l2', 'solver': 'lbfgs'}
0.465772 (0.036237) with: {'Cs': 1, 'cv': 20, 'penalty': 'l2', 'solver': 'liblinear'}
0.509228 (0.005254) with: {'Cs': 1, 'cv': 20, 'penalty': 'l2', 'solver': 'newton-cg'}
0.509228 (0.005254) with: {'Cs': 1, 'cv': 20, 'penalty': 'l2', 'solver': 'newton-cholesky'}
0.509228 (0.005254) with: {'Cs': 1, 'cv': 30, 'penalty': 'l2', 'solver': 'lbfgs'}
0.465772 (0.036237) with: {'Cs': 1, 'cv': 30, 'penalty': 'l2', 'solver': 'liblinear'}
0.509228 (0.005254) with: {'Cs': 1, 'cv': 30, 'penalty': 'l2', 'solver': 'newton-cg'}
0.509228 (0.005254) with: {'Cs': 1, 'cv': 30, 'penalty': 'l2', 'solver': 'newton-cholesky'}
0.490842 (0.028777) with: {'Cs': 10, 'cv': 5, 'penalty': 'l2', 'solver': 'lbfgs'}
0.490842 (0.038995) with: {'Cs': 10, 'cv': 5, 'penalty': 'l2', 'solver': 'liblinear'}
0.490842 (0.028777) with: {'Cs': 10, 'cv': 5, 'penalty': 'l2', 'solver': 'newton-cg'}
0.490842 (0.028777) with: {'Cs': 10, 'cv': 5, 'penalty': 'l2', 'solver': 'newton-cholesky'}
0.496105 (0.028159) with: {'Cs': 10, 'cv': 10, 'penalty': 'l2', 'solver': 'lbfgs'}
0.490842 (0.034269) with: {'Cs': 10, 'cv': 10, 'penalty': 'l2', 'solver': 'liblinear'}
0.496105 (0.028159) with: {'Cs': 10, 'cv': 10, 'penalty': 'l2', 'solver': 'newton-cg'}
0.496105 (0.028159) with: {'Cs': 10, 'cv': 10, 'penalty': 'l2', 'solver': 'newton-cholesky'}
0.490807 (0.027485) with: {'Cs': 10, 'cv': 20, 'penalty': 'l2', 'solver': 'lbfgs'}
0.482947 (0.028791) with: {'Cs': 10, 'cv': 20, 'penalty': 'l2', 'solver': 'liblinear'}
0.490807 (0.027485) with: {'Cs': 10, 'cv': 20, 'penalty': 'l2', 'solver': 'newton-cg'}
0.490807 (0.027485) with: {'Cs': 10, 'cv': 20, 'penalty': 'l2', 'solver': 'newton-cholesky'}
0.492105 (0.025280) with: {'Cs': 10, 'cv': 30, 'penalty': 'l2', 'solver': 'lbfgs'}
0.482930 (0.029669) with: {'Cs': 10, 'cv': 30, 'penalty': 'l2', 'solver': 'liblinear'}
0.492105 (0.025280) with: {'Cs': 10, 'cv': 30, 'penalty': 'l2', 'solver': 'newton-cg'}
0.492105 (0.025280) with: {'Cs': 10, 'cv': 30, 'penalty': 'l2', 'solver': 'newton-cholesky'}
0.493491 (0.032036) with: {'Cs': 50, 'cv': 5, 'penalty': 'l2', 'solver': 'lbfgs'}
0.494807 (0.036552) with: {'Cs': 50, 'cv': 5, 'penalty': 'l2', 'solver': 'liblinear'}
0.493491 (0.032036) with: {'Cs': 50, 'cv': 5, 'penalty': 'l2', 'solver': 'newton-cg'}
0.493491 (0.032036) with: {'Cs': 50, 'cv': 5, 'penalty': 'l2', 'solver': 'newton-cholesky'}
0.502667 (0.051662) with: {'Cs': 50, 'cv': 10, 'penalty': 'l2', 'solver': 'lbfgs'}
0.486877 (0.040474) with: {'Cs': 50, 'cv': 10, 'penalty': 'l2', 'solver': 'liblinear'}
0.502667 (0.051662) with: {'Cs': 50, 'cv': 10, 'penalty': 'l2', 'solver': 'newton-cg'}
0.502667 (0.051662) with: {'Cs': 50, 'cv': 10, 'penalty': 'l2', 'solver': 'newton-cholesky'}
0.485561 (0.032102) with: {'Cs': 50, 'cv': 20, 'penalty': 'l2', 'solver': 'lbfgs'}
0.494789 (0.030606) with: {'Cs': 50, 'cv': 20, 'penalty': 'l2', 'solver': 'liblinear'}
0.485561 (0.032102) with: {'Cs': 50, 'cv': 20, 'penalty': 'l2', 'solver': 'newton-cg'}
0.485561 (0.032102) with: {'Cs': 50, 'cv': 20, 'penalty': 'l2', 'solver': 'newton-cholesky'}
0.494754 (0.042007) with: {'Cs': 50, 'cv': 30, 'penalty': 'l2', 'solver': 'lbfgs'}
0.493421 (0.056290) with: {'Cs': 50, 'cv': 30, 'penalty': 'l2', 'solver': 'liblinear'}
0.494754 (0.042007) with: {'Cs': 50, 'cv': 30, 'penalty': 'l2', 'solver': 'newton-cg'}
0.494754 (0.042007) with: {'Cs': 50, 'cv': 30, 'penalty': 'l2', 'solver': 'newton-cholesky'}
0.493491 (0.033100) with: {'Cs': 100, 'cv': 5, 'penalty': 'l2', 'solver': 'lbfgs'}
0.494807 (0.038848) with: {'Cs': 100, 'cv': 5, 'penalty': 'l2', 'solver': 'liblinear'}
0.493491 (0.033100) with: {'Cs': 100, 'cv': 5, 'penalty': 'l2', 'solver': 'newton-cg'}
0.493491 (0.033100) with: {'Cs': 100, 'cv': 5, 'penalty': 'l2', 'solver': 'newton-cholesky'}
0.492158 (0.034329) with: {'Cs': 100, 'cv': 10, 'penalty': 'l2', 'solver': 'lbfgs'}
0.482930 (0.042174) with: {'Cs': 100, 'cv': 10, 'penalty': 'l2', 'solver': 'liblinear'}
0.492158 (0.034329) with: {'Cs': 100, 'cv': 10, 'penalty': 'l2', 'solver': 'newton-cg'}
0.492158 (0.034329) with: {'Cs': 100, 'cv': 10, 'penalty': 'l2', 'solver': 'newton-cholesky'}
0.493474 (0.029485) with: {'Cs': 100, 'cv': 20, 'penalty': 'l2', 'solver': 'lbfgs'}
0.486877 (0.037845) with: {'Cs': 100, 'cv': 20, 'penalty': 'l2', 'solver': 'liblinear'}
0.493474 (0.029485) with: {'Cs': 100, 'cv': 20, 'penalty': 'l2', 'solver': 'newton-cg'}
0.493474 (0.029485) with: {'Cs': 100, 'cv': 20, 'penalty': 'l2', 'solver': 'newton-cholesky'}
0.497404 (0.042469) with: {'Cs': 100, 'cv': 30, 'penalty': 'l2', 'solver': 'lbfgs'}
0.482895 (0.033960) with: {'Cs': 100, 'cv': 30, 'penalty': 'l2', 'solver': 'liblinear'}
0.497404 (0.042469) with: {'Cs': 100, 'cv': 30, 'penalty': 'l2', 'solver': 'newton-cg'}
0.497404 (0.042469) with: {'Cs': 100, 'cv': 30, 'penalty': 'l2', 'solver': 'newton-cholesky'}</code></pre>
</div>
</div>
<p><br></p>
</section>
</section>
<section id="evaluation-of-the-logistic-regression-cv-model" class="level4">
<h4 class="anchored" data-anchor-id="evaluation-of-the-logistic-regression-cv-model"><strong>Evaluation of the logistic regression CV model</strong></h4>
<section id="accuracy-scores" class="level6">
<h6 class="anchored" data-anchor-id="accuracy-scores"><strong>Accuracy scores</strong></h6>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>accuracy_score(y_mp, y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>0.7150395778364116</code></pre>
</div>
</div>
<p>The accuracy score was still around 0.7 this time for LogR model, but slightly higher at 0.715 as it was 0.6992084 from ML series 1. The accuracy from the pipeline method (LogReg model) was 0.6939314 this time (which was 0.6965699 from ML series 1).</p>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>LogReg.score(X_test, y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>0.6992084432717678</code></pre>
</div>
</div>
<p><br></p>
</section>
<section id="confusion-matrix" class="level6">
<h6 class="anchored" data-anchor-id="confusion-matrix"><strong>Confusion matrix</strong></h6>
<p>Again, to visualise the LR classifer built this time using LogisticRegressionCV estimator in a confusion matrix, the same code was used as previously.</p>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import confusion matrix from scikit-learn</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Import itertools - functions to create iterators for efficient looping</span></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> itertools</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to print and plot confusion matrix</span></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_confusion_matrix(<span class="co"># Sets a cm object (cm = confusion matrix)</span></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>                          cm, </span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>                          <span class="co"># Sets classes of '1s' (Successes) &amp; '0s' (Non-successes) for the cm</span></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>                          classes,</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>                          <span class="co"># If setting normalize = true, reports in ratios instead of counts</span></span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>                          normalize,</span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>                          title <span class="op">=</span> <span class="st">'Confusion matrix'</span>,</span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>                          <span class="co"># Choose colour of the cm (using colourmap recognised by matplotlib)</span></span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a>                          cmap <span class="op">=</span> plt.cm.Reds):</span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> normalize:</span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a>        cm <span class="op">=</span> cm.astype(<span class="st">'float'</span>) <span class="op">/</span> cm.<span class="bu">sum</span>(axis <span class="op">=</span> <span class="dv">1</span>)[:, np.newaxis]</span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Normalized confusion matrix"</span>)</span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'Confusion matrix, without normalization'</span>)</span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(cm)</span>
<span id="cb37-24"><a href="#cb37-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-25"><a href="#cb37-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot the confusion matrix </span></span>
<span id="cb37-26"><a href="#cb37-26" aria-hidden="true" tabindex="-1"></a>    plt.imshow(cm, interpolation <span class="op">=</span> <span class="st">'nearest'</span>, cmap <span class="op">=</span> cmap)</span>
<span id="cb37-27"><a href="#cb37-27" aria-hidden="true" tabindex="-1"></a>    plt.title(title)</span>
<span id="cb37-28"><a href="#cb37-28" aria-hidden="true" tabindex="-1"></a>    plt.colorbar()</span>
<span id="cb37-29"><a href="#cb37-29" aria-hidden="true" tabindex="-1"></a>    tick_marks <span class="op">=</span> np.arange(<span class="bu">len</span>(classes))</span>
<span id="cb37-30"><a href="#cb37-30" aria-hidden="true" tabindex="-1"></a>    plt.xticks(tick_marks, classes, rotation <span class="op">=</span> <span class="dv">45</span>)</span>
<span id="cb37-31"><a href="#cb37-31" aria-hidden="true" tabindex="-1"></a>    plt.yticks(tick_marks, classes)</span>
<span id="cb37-32"><a href="#cb37-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-33"><a href="#cb37-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Floats to be round up to two decimal places if using normalize = True</span></span>
<span id="cb37-34"><a href="#cb37-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># or else use integers</span></span>
<span id="cb37-35"><a href="#cb37-35" aria-hidden="true" tabindex="-1"></a>    fmt <span class="op">=</span> <span class="st">'.2f'</span> <span class="cf">if</span> normalize <span class="cf">else</span> <span class="st">'d'</span></span>
<span id="cb37-36"><a href="#cb37-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sets threshold of 0.5</span></span>
<span id="cb37-37"><a href="#cb37-37" aria-hidden="true" tabindex="-1"></a>    thresh <span class="op">=</span> cm.<span class="bu">max</span>() <span class="op">/</span> <span class="fl">2.</span></span>
<span id="cb37-38"><a href="#cb37-38" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Iterate through the results and differentiate between two text colours </span></span>
<span id="cb37-39"><a href="#cb37-39" aria-hidden="true" tabindex="-1"></a>    <span class="co"># by using the threshold as a cut-off</span></span>
<span id="cb37-40"><a href="#cb37-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, j <span class="kw">in</span> itertools.product(<span class="bu">range</span>(cm.shape[<span class="dv">0</span>]), <span class="bu">range</span>(cm.shape[<span class="dv">1</span>])):</span>
<span id="cb37-41"><a href="#cb37-41" aria-hidden="true" tabindex="-1"></a>        plt.text(j, i, <span class="bu">format</span>(cm[i, j], fmt),</span>
<span id="cb37-42"><a href="#cb37-42" aria-hidden="true" tabindex="-1"></a>                 horizontalalignment <span class="op">=</span> <span class="st">"center"</span>,</span>
<span id="cb37-43"><a href="#cb37-43" aria-hidden="true" tabindex="-1"></a>                 color <span class="op">=</span> <span class="st">"white"</span> <span class="cf">if</span> cm[i, j] <span class="op">&gt;</span> thresh <span class="cf">else</span> <span class="st">"black"</span>)</span>
<span id="cb37-44"><a href="#cb37-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-45"><a href="#cb37-45" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb37-46"><a href="#cb37-46" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'True label'</span>)</span>
<span id="cb37-47"><a href="#cb37-47" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Predicted label'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute confusion matrix</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>matrix <span class="op">=</span> confusion_matrix(y_test, y_mp, labels <span class="op">=</span> [<span class="dv">0</span>,<span class="dv">1</span>])</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>np.set_printoptions(precision <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot confusion matrix without normalisation</span></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>plt.figure()</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>plot_confusion_matrix(matrix, </span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>                      <span class="co"># Define classes of outcomes</span></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>                      classes <span class="op">=</span> [<span class="st">'Max_Phase = 0'</span>,<span class="st">'Max_Phase = 1'</span>], </span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>                      <span class="co"># Set normalize = True if wanting ratios instead</span></span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>                      normalize <span class="op">=</span> <span class="va">False</span>, </span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>                      title <span class="op">=</span> <span class="st">"Confusion matrix without normalisation"</span></span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a>                     )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion matrix, without normalization
[[147  55]
 [ 53 124]]</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="ML2_chembl_cpds_files/figure-html/cell-25-output-2.png" width="570" height="488"></p>
</div>
</div>
<p>The four different categories in the confusion matrix were:</p>
<ul>
<li>True positive - Predicted Max_Phase = 1 &amp; True Max_Phase = 1 ( out of samples)</li>
<li>True negative - Predicted Max_Phase = 0 &amp; True Max_Phase = 0 ( out of samples)</li>
<li>False positive - Predicted Max_Phase = 1 &amp; True Max_Phase = 0 ( out of samples)</li>
<li>False negative - Predicted Max_Phase = 0 &amp; True Max_Phase = 1 ( out of samples)</li>
</ul>
<p><br></p>
</section>
<section id="classification-report" class="level6">
<h6 class="anchored" data-anchor-id="classification-report"><strong>Classification report</strong></h6>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_mp))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              precision    recall  f1-score   support

           0       0.73      0.73      0.73       202
           1       0.69      0.70      0.70       177

    accuracy                           0.72       379
   macro avg       0.71      0.71      0.71       379
weighted avg       0.72      0.72      0.72       379
</code></pre>
</div>
</div>
<p><em>Precision</em> was a measure of the accuracy of a predicted outcome, where a class label had been predicted by the classifier. So in this case, we could see that for class label 1, the precision was 0.72, which corresponded to the true positive result of 128 out of 179 samples (= 0.715). It was defined by:</p>
<p><em>Recall</em>, also known as sensitivity (especially widely used in biostatistics and medical diagnostic fields), was a measure of the strength of the classifier to predict a positive outcome. In simple words, it measured the true positive rate. In this example, there was a total of 128 out of 190 samples (which = 0.674, for True Max_Phase = 1 row) that had a true positive outcome of having a max phase of 1. It was defined by:</p>
<p>The precision and recall metrics could also be calculated for class label = 0, which were shown for the row 0 in the classification report.</p>
<p><em>f1-score</em>, or also known as balanced F-score or F-measure, denoted the harmonic average of both precision and recall metrics. This metric would also give another indication about whether this model performed well on outcome predictions. It normally ranged from 0 (worst precision and recall) to 1 (perfect precision and recall). For this particular classifier, f1-score was at 0.7, which was definitely not at its worst, but also could be further improved. It was defined as:</p>
<p><em>Support</em>, which some readers might have already worked out how the numbers were derived, was the total number of true samples in each class label (read row-wise from the confusion matrix). The main purpose of showing this metric was to help clarifying whether the model or classifier had a reasonably balanced dataset for each class or otherwise.</p>
<p><br></p>
</section>
<section id="log-loss" class="level6">
<h6 class="anchored" data-anchor-id="log-loss"><strong>Log loss</strong></h6>
<p>Log loss could be used as another gauge to show how good the classifier was at making the outcome predictions. The further the predicted probability was from the true value, the larger the log loss, which was also ranged from 0 to 1. Ideally, the smaller the log loss the better the model would be. Here, we had a log loss of 0.61 for this particular model.</p>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Log loss</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> log_loss</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>log_loss(y_test, y_mp_proba)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>0.6115648700062126</code></pre>
</div>
</div>
<p><br></p>
</section>
</section>
<section id="discussions-and-conclusion" class="level4">
<h4 class="anchored" data-anchor-id="discussions-and-conclusion"><strong>Discussions and conclusion</strong></h4>
<p><br></p>
</section>
<section id="final-words" class="level4">
<h4 class="anchored" data-anchor-id="final-words"><strong>Final words</strong></h4>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Feel free to skip this part as this is really me speaking my thoughts out loud about my situation lately.</p>
</div>
</div>
<p>After encountering several hiccups during my job hunt in data analytics lately (mainly domestic jobs in NZ), I think I need to make up my mind on which field I’m going for (I might be over-qualified for being a general health data analyst… this was the latest impression/feedback I’ve received). So here it is, I’m going to concentrate on using machine learning (ML) in Python, specifically in drug discovery field for a while. I’ll continue improving the data analytics aspect, but I’ll be placing more emphasis on ML so that I can somehow create some ML experiences for myself, while trying to find a good match in the research data science job market in the pharmaceutical field. I also have a feeling that I may need to venture out into overseas roles in the near future, as these types of roles involving ML and pharmaceuticals are just too difficult to spot domestically.</p>
<p>I once read a <a href="https://vickiboykis.com/2022/11/10/how-i-learn-machine-learning/">blog post on learning ML</a> by V. Boykis, who has suggested to go broadly in topics, then go deep in one of them, which I’ve agreed wholeheartedly as the approach to go about in the tech world, since there is no way on earth that I will be able to learn everything completely (even OpenAI’s ChatGPT has limits - being restricted by the amount and types of input data being fed into the GPT). So since I’ve branched into 3 programming languages so far, I’ve decided not to expand further into new programming languages for now, to avoid being “half-bucket-full” for everything, I should really narrow down my focus now. To name the 3 programming languages in the order I’ve learnt them, they are Python, R and Rust. In that, I’m most comfortable with Python as that is my first language, then it’s R, followed by Rust, which is almost brand new. I think right now is a good time for me to go deep into an area that has always caught my attentions.</p>
<p><br></p>
</section>
<section id="references" class="level4">
<h4 class="anchored" data-anchor-id="references"><strong>References</strong></h4>
<ul>
<li><a href="https://scikit-learn.org/stable/index.html">scikit-learn documentation</a></li>
<li><a href="https://jmlr.csail.mit.edu/papers/v12/pedregosa11a.html">Scikit-learn: Machine Learning in Python</a>, Pedregosa <em>et al.</em>, JMLR 12, pp.&nbsp;2825-2830, 2011.</li>
<li>Bruce, P., Bruce, A. &amp; Gedeck P. (2020). Practical statistics for data scientists. O’Reilly.</li>
<li><a href="https://stackoverflow.com">Stack Overflow</a></li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="jhylin/Data_in_life_blog" data-repo-id="R_kgDOHw7lGQ" data-category="General" data-category-id="DIC_kwDOHw7lGc4CQzQ_" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
      <div class="nav-footer-center">Blog made with ❤️ in <a href="https://quarto.org/">Quarto</a> by Jennifer HY Lin © 2022 - 2023 📕 Citation as author and blog URL link if used</div>
  </div>
</footer>



</body></html>