[
  {
    "objectID": "posts/Blog-Portfolio_projects/Portfolio_projects.html",
    "href": "posts/Blog-Portfolio_projects/Portfolio_projects.html",
    "title": "Portfolio projects",
    "section": "",
    "text": "To keep myself somewhat occupied, I’m still working on the Tableau project at the moment (while I’m working towards the end of a Tableau course) and have then added two further projects – one a Python one about rare disease drugs and the other one using SQL. I’ve just completed and published the Python one (please see Portfolio section for details) and within this week I’m aiming to start the SQL project. This time I’ll not be using IBM Db2 or SQLite, which was what I’ve used for the course but rather I’ve managed to install MySQL server and also DBeaver GUI to work on the SQL project. The dataset is still to be decided as I sort of want to integrate the SQL one with Tableau and the latest Python project. I’ll have another look again…\n\n\n\nPhoto by Joanna Kosinska on Unsplash"
  },
  {
    "objectID": "posts/03_Long_COVID_data_in_SQL/Long_COVID_SQL.html",
    "href": "posts/03_Long_COVID_data_in_SQL/Long_COVID_SQL.html",
    "title": "Long COVID data in SQL",
    "section": "",
    "text": "Introduction\nFor this SQL project1, I’ve used the same set of data as the Tableau project in order to see if there will be any other new insights when using SQL for data analysis. Dataset is from this paper – Michelen M, Manoharan L, Elkheir N, et al. Characterising long COVID: a living systematic review. BMJ Global Health 2021;6:e005427, which was discovered through PubMed. One other thing of note was that the paper only collected long COVID-related data up until 17th March 2021. All other more recent developments of long COVID will likely require more time before further data are more readily available, for example, the long COVID impact from Omicron variants.\n Image: Rawpixel.com\n\n\nThe process\nMySQL server was installed with DBeaver used as the GUI. Four tables (Continents, Countries, Risk factors and Hospitalisation) in .csv file formats were imported into the newly created database named LongCovid. A series of SQL queries were written and performed. Two views were created so that selected data were stored for future use, such as for data visualisations in Tableau.\n\n\nProject link\nSQL file can be found in my GitHub repository of Portfolio-projects at this URL: https://github.com/jhylin/Portfolio-projects or directly here to view.\n\n\n\n\n\nFootnotes\n\n\nThe published date reflected the most recent date I worked on associated file with the project, prior to the blog move. This work is under CC BY-SA 4.0 International License for anyone interested in exploring the area further.↩︎"
  },
  {
    "objectID": "posts/PhD_projects/PhD_projects.html",
    "href": "posts/PhD_projects/PhD_projects.html",
    "title": "PhD project",
    "section": "",
    "text": "The projects\nMy PhD12 started about 6 months after I’ve finished my MPhil so it was around the beginning of 2015 that I’ve officially begun my PhD and it took a solid 4 years to finish (while working part-time as a hospital pharmacist). In simple words, there were two main research projects going on concurrently in my PhD:\n\nSERCA project (details in a separate post as named)\nFilamenting temperature-sensitive Z protein project (also known as FtsZ project)\n\nFtsZ project was not a new project at the time, but rather a continuation from my previous predecessors in the lab group. Its primary focus was to look for other novel anti-bacterial hit compounds that were different from the ones that were already synthesised and tested in the group. This project was better than the SERCA project in a way that the collaborators were much easier to communicate with even though they were based in India. One down side was that because they’re based overseas, it did take a long time for the compound testing to happen and to have the results returned on time. However, overall, there were much more progress in this project which involved 3 main iterative stages:\nComputational work – involved molecular/homology modelling, virtual compound screening (compound size roughly in several 100,000s, please see below links for details) and compound selection for synthesis (using Schrödinger software mainly for this first stage of work)\nCompound synthesis – this was certainly the part that has painstakingly taken a lot of time in a chemistry lab out of my four years with many failures in between but with some successes in the end obviously…\nCompound testing – it was mainly done by our research collaborators After the completion of these two projects, I was less of a research newbie but I would still humbly call myself a junior researcher, considering how the field of drug discovery can have such an unfathomable depth and breadth…\n\n\n\nImage taken by author\n\n\nThe image above was taken literally when I packed up everything after I’ve completed my PhD, which was physically summed into this little box, but what I’ve gained from the journey was far bigger than this. The two hardcover books on the left hand side were my MPhil and PhD theses (potentially useful as treatment for insomnia due to their lengths and time required to read).\n\n\nPhD thesis link\nPlease visit http://hdl.handle.net/2123/20236 if anyone is even remotely wanting to read the full thesis, for completeness, here it is (beware: very long).\n\n\nAbstract of the projects\nDrug discovery is one of the most challenging research fields that contributes to the birth of novel drugs for therapeutic use. Due to the complexity and intricate nature of the research, lengthy processes are involved in identifying potential hit molecules for a therapeutic target. To shorten the time required to reach the hit-to-lead stage, computer-aided drug design (CADD) has been used to expedite the process and reduce laboratory expenses. Common strategies used within CADD involve structure-based drug design (SBDD) and ligand-based drug design (LBDD). Both strategies were used extensively in two projects showing the complementarity of each strategy throughout the process. In this work, two separate drug discovery projects are detailed: Design, synthesis and molecular docking study of novel tetrahydrocurcumin analogues as potential sarcoplasmic-endoplasmic reticulum calcium ATPases (SERCA) inhibitors – details the identification, synthesis and testing of potential hit candidate(s) targeting SERCA by using SBDD Filamenting temperature-sensitive mutant Z (FtsZ) as therapeutic target in ligand-based drug design – details the identification, synthesis and testing of potential hit molecule(s) targeting FtsZ In the first project, homology modelling and virtual compound library screening were utilised as the SBDD methods to identify potential hit molecules for testing in P-type calcium ATPases such as SERCA. Preliminary results have found compound 20, an analogue of tetrahydrocurcumin, to show some SERCA inhibitory effect at 300µM based on a SERCA-specific calcium signalling assay performed via fluorometric imaging plate reader. Molecular docking study has also reflected this outcome with desirable ligand-protein binding energies found for 20 when compared with other tested ligands. Pharmacophore screening was used as the main LBDD method in the second project to identify probable hit candidates targeting FtsZ. Potential ligands were synthesised, and tested for antibacterial effect in Bacillus Subtilis strain 168 (Bs168) and Streptococcus pneumoniae strain R6 (SpnR6) cells. One of the tetrahydrocurcumin analogues, compound 4, was found to have minimum inhibitory concentration (MIC) ≤ 10 µM in Bs168 cells and ≤ 2 µM in spnR6 cells. The IC50 values for 4 were 9.1 ± 0.01 µM and 1 ± 0.01 µM in Bs168 and SpnR6 cells respectively. The MIC of 4 was found to be very similar to the MIC of compound 1, a known hit compound targeting against Bs168 cells. On the other hand, the MIC of 4 was lower than the MIC (> 64 µg/mL) of a well-known FtsZ inhibitor, PC190723, against S. pneumoniae. Subsequent molecular docking analyses were completed to evaluate the ligand-protein binding energies to correlate against the testing results. Both compounds 20 and 4 possess some structural similarities and differences that may confer their different effects in these protein targets, which render both with potentials to become the next lead molecules for future development.\n\n\nFinal update on FtsZ project\nAs time was ticking along towards the end of 2022, my last attempt to try to get this work published occurred around end of August, where I contacted one of my previous PhD advisers. After that I actually thought there was no way I could carry on in this line of research work, or even think about expanding into cheminformatics for drug discovery and design etc. So in September, I thought about leaving all of this behind and that I need to change direction completely (again), e.g. into health data science or similar. Perhaps it was the universe’s answering or for other unknown reasons, around end of September, an email was sent to me from my previous PhD adviser asking for my help to organise the draft manuscript into the journal template that we were intending to submit. Then in early October, I got another email saying our manuscript was submitted. Then it seemed things started to roll again, after 2019. So this was, indeed, a perfect example showing how a piece of research work was stalled, not only by the commonly known reasons such as delays from collaborating groups, but also by the global-scale pandemic and finally somehow, miraculously, made it to the publication stage.\nIf anyone asked me if I wanted to go through this again, I would firmly say no as it was mentally painful, but on the other hand, I’ve also gained invaluable things like grit and resilience throughout the process. This has, without doubts, influenced on how I want to approach similar research again, which will be in a different way, in a more data-informed way.\n\n\nPublished paper link\nThis will complete the story for the FtsZ project (finally): Discovery of 2′,6-Bis(4-hydroxybenzyl)-2-acetylcyclohexanone, a Novel FtsZ Inhibitor\n\n\n\n\n\nFootnotes\n\n\nI’ve attempted to communicate with both of my PhD advisers and our research collaborators to publish this work, but to no avail due to the severe restrictions imposed by the COVID-19 situation from the beginning of 2020 and basically also in 2021 (our collaborators were unable to perform any experiments during lockdowns…), a direct publication in a scientific journal is not going to happen any time soon so I thought to provide at least my part to showcase what I’ve done at least…↩︎\nUpdates on 31/1/2022 – it appeared that my supervisors are in communications with our overseas research collaborators recently about the manuscript so there is a higher chance now that we may be able to publish this work towards the end of 2022 (fingers-crossed…).↩︎"
  },
  {
    "objectID": "posts/02_Long_COVID_dashboard/Tableau_dashboard.html",
    "href": "posts/02_Long_COVID_dashboard/Tableau_dashboard.html",
    "title": "Long COVID dashboard",
    "section": "",
    "text": "Introduction\nThis project1 was entirely self-motivated and out of personal interests since COVID has widely and deeply affected many people nowadays. I was also learning Tableau while I worked on this project. This has also made me realised that I might have started from the harder end first by learning Python programming language first in 2019 and then picking up the rest of the data analytics tools towards late 2021. It was completely interesting and absolutely fascinating at how different softwares vary but with common themes in mind.\n Image: Rawpixel.com\n\n\nSource of dataset\nThe source of the dataset was from a relatively recent live systemic review paper: Michelen M, Manoharan L, Elkheir N, et al. Characterising long COVID: a living systematic review. BMJ Global Health 2021;6:e005427\n\n\nProject link\nThis project can be accessed at this link from Tableau Public.\n\n\nSummary\nThe data from this paper have shown a very heterogeneous variety of long COVID-related signs and symptoms. Among them, it appeared that female gender had higher risk of suffering from long COVID than the male populations. Other factors that might have contributed to higher risk of suffering from long COVID were people who were above 60-65 years old and also people who have multiple chronic illnesses such as cardiovascular diseases and diabetes. Since this paper only focussed on dataset up until March 2021, more recent variants of COVID would not be covered in the dataset, therefore, more work would be required to look into the long COVID risk inflicted by more recent COVID variants.\n\n\n\n\n\nFootnotes\n\n\nThe published date reflected the last day I worked on the associated files for this project, prior to the blog move. This work is under CC BY-SA 4.0 International License for anyone interested in exploring the topic further.↩︎"
  },
  {
    "objectID": "posts/Blog-Data_analytics/Focussing_on_data_analytics.html",
    "href": "posts/Blog-Data_analytics/Focussing_on_data_analytics.html",
    "title": "Focussing on data analytics",
    "section": "",
    "text": "So after a short period of trials and errors of job applications with serious thoughts into a career change, I’m planning to go for the more practical and realistic approach – starting from an entry-level data analyst role. However, I’m aware that I’ll need to build up a relatively decent portfolio of data analytics work before I’ll even be able to reach that very first stage.\n\n\n\nPhoto by Tobias Fischer on Unsplash\n\n\nSo I’m planning to work on other projects at the moment that are not from my certificate course, but are self-motivated ones which would be more relevant to data science and analytics and the ones that I have personal interests in. New projects will be showcased in the portfolio section when they’re ready. The most current one would be the Tableau project about characterising long COVID symptoms (more on this in portfolio section)."
  },
  {
    "objectID": "posts/Blog-Social_network/Embracing_social_network.html",
    "href": "posts/Blog-Social_network/Embracing_social_network.html",
    "title": "Embracing social network",
    "section": "",
    "text": "I’ve managed to post my first ever tweet on Twitter yesterday on the R project I’ve done recently on rare disease drugs. I’m not used to posting anything on social media as I almost always prefer to stay low-profile, rather than the opposite, and this may not be a good thing especially if I’m trying to transition into a different job field. So I did it finally…\n\n\n\nPhoto by visuals on Unsplash\n\n\nOne of the reasons that I’ve finally decided to post on Twitter is that I’ve heard about the active and friendly R community on Twitter and thought if I could get any feedbacks on my short piece of work in R then that’ll be helpful for me to see if I’ve missed or done anything incorrectly since there’s not really a mentor person around that is able to do this at the moment (I’ve dreadfully taken the self-learning route, rather than attending data science bootcamps or get “another” degree, which is something I’m not really fancied at doing again, after already having MPhil and PhD already…). Luckily, I did get one helpful response and with a small number of likes so perhaps I’m not doing it entirely wrong (hopefully). My future plans will likely be trying to do a #TidyTuesday data visualisation and post whenever I can to learn and grow.\nI’ve also recently edited my rare disease drug projects in R and Python to add summaries of findings from these two projects so it’s easier for anyone to read, especially if there’s not really much time to go through long threads of codes in GitHub. I’m also currently working on another project in the rare diseases series on phenotypes associated with rare diseases from Orphanet. My plan at the moment is to use Python to clean the data (I’ve tried to load it in RStudio via a URL with XML file, it’s >4000 rows and taking quite a long time to run on my laptop, so will stick to Python on Anaconda as it has loaded a lot faster than RStudio, then perhaps once it’s cleaned, I’ll re-import it back into RStudio for analysis and visualisations)."
  },
  {
    "objectID": "posts/05_Phenotypes_associated_with_rare_diseases/Phenotypes_rare_diseases.html",
    "href": "posts/05_Phenotypes_associated_with_rare_diseases/Phenotypes_rare_diseases.html",
    "title": "Phenotypes associated with rare diseases",
    "section": "",
    "text": "Initial data wrangling\nThis dataset was also derived and downloaded from Orphanet, as another part in the “rare diseases” series. It contained 37 columns with 112,243 rows originally, which took quite a long time to load on RStudio (or could be due to my laptop capacity…). It loaded relatively faster on Jupyter notebook from Anaconda, so I then decided to clean it up first using Python1 there. Some columns were removed which reduced the total number of columns from 37 to 13, while not changing any of the rows at all. The columns were also renamed to make it easier to read.\n\n\nSource of dataset\nOrphadata: Free access data from Orphanet. © INSERM 1999. Available on http://www.orphadata.org. Data version (XML data version). Dataset (.xml file) from http://www.orphadata.org/cgi-bin/epidemio.html. Latest date of update for the dataset: 14/6/2022 (last accessed 24/7/2022). Creative Commons Attribution 4.0 International.\n\nPhoto by Sangharsh Lohakare on Unsplash\nThe following libraries were used for the exploratory data analysis:\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(ggplot2)\nlibrary(knitr)\n\nRead imported .csv file after data cleaning in Python.\n\ndf <- read_csv(\"rare_disease_phenotypes.csv\")\n\nRows: 112243 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (10): Disorder group, Disorder type, Diagnostic criteria, HPO frequency...\ndbl   (2): HPO disorder & clinical entity association count, Disorder Orphacode\ndttm  (1): Validation date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nNote: HPO = human phenotype ontology\n\nspec(df)\n\ncols(\n  `Disorder group` = col_character(),\n  `Disorder type` = col_character(),\n  `HPO disorder & clinical entity association count` = col_double(),\n  `Diagnostic criteria` = col_character(),\n  `HPO frequency` = col_character(),\n  `HPO ID` = col_character(),\n  `Preferred HPO term` = col_character(),\n  `Disorder name` = col_character(),\n  `Disorder Orphacode` = col_double(),\n  Online = col_character(),\n  Source = col_character(),\n  `Validation date` = col_datetime(format = \"\"),\n  `Validation status` = col_character()\n)\n\n\n\n\nExploratory data analysis\nSince I wasn’t intending for this project2 to be extremely long (as most people would likely lose interests by then), I’d like to first ask a question about the dataset, in order to keep it at a reasonably short but informative length. So, here’s the question: what are the most common rare disorders and their associated phenotypic features?\nTo answer it, let’s observe the spread of the disorder groups and types first by formulating a contingency table.\n\ndf_type <- df %>% \n  group_by(`Disorder group`,`Disorder type`) %>% \n  summarise(Number = n())\ndf_type\n\n# A tibble: 11 × 3\n# Groups:   Disorder group [3]\n   `Disorder group`    `Disorder type`                                    Number\n   <chr>               <chr>                                               <int>\n 1 Disorder            Biological anomaly                                     41\n 2 Disorder            Clinical syndrome                                     661\n 3 Disorder            Disease                                             57920\n 4 Disorder            Malformation syndrome                               37634\n 5 Disorder            Morphological anomaly                                2644\n 6 Disorder            Particular clinical situation in a disease or syn…    418\n 7 Group of disorders  Category                                              479\n 8 Group of disorders  Clinical group                                        952\n 9 Subtype of disorder Clinical subtype                                     7394\n10 Subtype of disorder Etiological subtype                                  4060\n11 Subtype of disorder Histopathological subtype                              40\n\n\nAfter a quick view on the column of “Disorder group”, it mainly provided different disorder types a group label for each, which to a certain extent, was not necessary at this early stage. So this column was removed for now from the contingency table, in order to focus solely on, “Disorder type” with the number of counts (or times it appeared in the dataset).\n\ndf_type <- df %>% \n  group_by(`Disorder type`) %>% \n  summarise(Number = n())\ndf_type\n\n# A tibble: 11 × 2\n   `Disorder type`                                        Number\n   <chr>                                                   <int>\n 1 Biological anomaly                                         41\n 2 Category                                                  479\n 3 Clinical group                                            952\n 4 Clinical subtype                                         7394\n 5 Clinical syndrome                                         661\n 6 Disease                                                 57920\n 7 Etiological subtype                                      4060\n 8 Histopathological subtype                                  40\n 9 Malformation syndrome                                   37634\n10 Morphological anomaly                                    2644\n11 Particular clinical situation in a disease or syndrome    418\n\n\nThen to visualise this in a graphic way, a lollypop chart was built horizontally, with different types of rare disorders on the y-axis and the number of each type on the x-axis.\n\nggplot(data = df_type, aes(x = `Disorder type`, y = `Number`)) +\n  geom_segment(aes(x = `Disorder type`, xend = `Disorder type`, y = 0, yend = `Number`), colour = \"dark blue\") +\n  geom_point(colour = \"dark green\", size = 2, alpha = 0.6) +\n  theme_light() +\n  coord_flip() \n\n\n\n\nTwo disorder types stood out the most, with “Disease” type appeared 57,920 times and “Malformation syndrome” at 37,634 times. To understand further what each of these two disorder types were, a direct reference3 was used. According to the source of the dataset:\nThe definition of “Disease” in the rare disorder context was “a disorder with homogeneous therapeutic possibilities and an identified physiopathological mechanism…”, one thing also worth noting was that this type did not include any developmental anomalies.\nFor “Malformation syndrome”, this was defined as, “A disorder resulting from a developmental anomaly involving more than one morphogenetic field. Malformative sequences and associations are included.”\nTo demonstrate this in a tabular form, with corresponding proportions of each disorder type in the dataset, the following codes were used:\n\ndf1 <- df %>% \n  group_by(`Disorder type`) %>% \n  summarise(n = n()) %>% \n  mutate(prop = n/sum(n))\ndf1\n\n# A tibble: 11 × 3\n   `Disorder type`                                            n     prop\n   <chr>                                                  <int>    <dbl>\n 1 Biological anomaly                                        41 0.000365\n 2 Category                                                 479 0.00427 \n 3 Clinical group                                           952 0.00848 \n 4 Clinical subtype                                        7394 0.0659  \n 5 Clinical syndrome                                        661 0.00589 \n 6 Disease                                                57920 0.516   \n 7 Etiological subtype                                     4060 0.0362  \n 8 Histopathological subtype                                 40 0.000356\n 9 Malformation syndrome                                  37634 0.335   \n10 Morphological anomaly                                   2644 0.0236  \n11 Particular clinical situation in a disease or syndrome   418 0.00372 \n\n\nThe table was then rearranged with proportions in descending order (from highest to lowest). It also showed the top two were “Disease” (51.6%) and “Malformation syndrome” (33.5%).\n\ndf1 %>% arrange(desc(prop))\n\n# A tibble: 11 × 3\n   `Disorder type`                                            n     prop\n   <chr>                                                  <int>    <dbl>\n 1 Disease                                                57920 0.516   \n 2 Malformation syndrome                                  37634 0.335   \n 3 Clinical subtype                                        7394 0.0659  \n 4 Etiological subtype                                     4060 0.0362  \n 5 Morphological anomaly                                   2644 0.0236  \n 6 Clinical group                                           952 0.00848 \n 7 Clinical syndrome                                        661 0.00589 \n 8 Category                                                 479 0.00427 \n 9 Particular clinical situation in a disease or syndrome   418 0.00372 \n10 Biological anomaly                                        41 0.000365\n11 Histopathological subtype                                 40 0.000356\n\n\n\nDistributions of HPO frequency\nThis was followed by checking out the distributions of HPO frequency to see which categories had the most and least number of counts.\n\ndf_freq <- df %>% \n  count(`HPO frequency`) %>% \n  arrange(desc(n))\ndf_freq\n\n# A tibble: 7 × 2\n  `HPO frequency`            n\n  <chr>                  <int>\n1 Occasional (29-5%)     41140\n2 Frequent (79-30%)      37480\n3 Very frequent (99-80%) 25892\n4 Very rare (<4-1%)       6414\n5 Excluded (0%)            705\n6 Obligate (100%)          610\n7 <NA>                       2\n\n\nResults for rare disorders with obligate or 100% frequency in patient’s populations were then filtered, showing disorder type, HPO frequency and disorder name. Specifically, I wanted to find out the disorder names associated with the “Disease” disorder type with HPO frequency of “Obligate (100%)”.\n\ndf_freq_ob <- df %>% \n  filter(`Disorder type` == \"Disease\", `HPO frequency` == \"Obligate (100%)\") %>% \n  select(`Disorder type`, `HPO frequency`, `Disorder name`)\ndf_freq_ob\n\n# A tibble: 404 × 3\n   `Disorder type` `HPO frequency` `Disorder name`                              \n   <chr>           <chr>           <chr>                                        \n 1 Disease         Obligate (100%) Retinoblastoma                               \n 2 Disease         Obligate (100%) Parathyroid carcinoma                        \n 3 Disease         Obligate (100%) Pituitary carcinoma                          \n 4 Disease         Obligate (100%) Familial hypocalciuric hypercalcemia         \n 5 Disease         Obligate (100%) Familial hypocalciuric hypercalcemia         \n 6 Disease         Obligate (100%) Ravine syndrome                              \n 7 Disease         Obligate (100%) Ravine syndrome                              \n 8 Disease         Obligate (100%) Interstitial granulomatous dermatitis with a…\n 9 Disease         Obligate (100%) Interstitial granulomatous dermatitis with a…\n10 Disease         Obligate (100%) PLIN1-related familial partial lipodystrophy \n# … with 394 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\nI’d then like to look into associated counts of appearance of each disorder name. When I cross-checked with the full dataset in table view, I’ve noted that the number of appearance of each disorder name is linked to the number of preferred HPO phenotype terms for each of these disorder types.\n\ndf2 <- df_freq_ob %>% \n  count(`Disorder name`) \ndf2 %>% arrange(desc(n))\n\n# A tibble: 239 × 2\n   `Disorder name`                                                             n\n   <chr>                                                                   <int>\n 1 Autosomal recessive complex spastic paraplegia due to Kennedy pathway …    10\n 2 STT3A-CDG                                                                   9\n 3 STT3B-CDG                                                                   9\n 4 Spastic paraplegia-Paget disease of bone syndrome                           8\n 5 Oculocutaneous albinism type 5                                              7\n 6 PLIN1-related familial partial lipodystrophy                                7\n 7 Plummer-Vinson syndrome                                                     5\n 8 SSR4-CDG                                                                    5\n 9 Cholesterol-ester transfer protein deficiency                               4\n10 Isolated follicle stimulating hormone deficiency                            4\n# … with 229 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\nTo show this, let’s link preferred HPO terms to a disorder name such as this one, “Autosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction”, which had the “Disease” disorder type with obligate or 100% HPO frequency.\n\ndf_disease <- df %>% \n  filter(`Disorder type` == \"Disease\", `HPO frequency` == \"Obligate (100%)\", `Disorder name` == \"Autosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction\") %>% \n  select(`Disorder type`, `HPO frequency`, `Disorder name`, `Preferred HPO term`)\nkable(df_disease)\n\n\n\n\n\n\n\n\n\n\nDisorder type\nHPO frequency\nDisorder name\nPreferred HPO term\n\n\n\n\nDisease\nObligate (100%)\nAutosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction\nProgressive spastic paraplegia\n\n\nDisease\nObligate (100%)\nAutosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction\nMicrocephaly\n\n\nDisease\nObligate (100%)\nAutosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction\nModerately short stature\n\n\nDisease\nObligate (100%)\nAutosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction\nNasal, dysarthic speech\n\n\nDisease\nObligate (100%)\nAutosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction\nDelayed gross motor development\n\n\nDisease\nObligate (100%)\nAutosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction\nProgressive spasticity\n\n\nDisease\nObligate (100%)\nAutosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction\nLower limb hyperreflexia\n\n\nDisease\nObligate (100%)\nAutosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction\nAnkle clonus\n\n\nDisease\nObligate (100%)\nAutosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction\nRetinal pigment epithelial mottling\n\n\nDisease\nObligate (100%)\nAutosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction\nProgressive spastic paraparesis\n\n\n\n\n\nAs shown in the dataframe above, under the column name, “Preferred HPO term”, there were a total of ten different HPO phenotype terms associated with this particular rare disease with 100% HPO frequency within the patient population for this specific type of spastic paraplegia.\nBy using similar filtering method, we could quickly narrow down any particular rare disease of interest to find out specific phenotype or clinical features, along with associated HPO phenotype frequency, for further investigations.\nFor “Malformation syndrome”, a similar search process was used to find out what was the most common phenotypes associated with it.\n\ndf_freq_ma <- df %>% \n  filter(`Disorder type` == \"Malformation syndrome\", `HPO frequency` == \"Obligate (100%)\") %>%\n  select(`Disorder type`, `HPO frequency`, `Disorder name`)\ndf_freq_ma\n\n# A tibble: 125 × 3\n   `Disorder type`       `HPO frequency` `Disorder name`                  \n   <chr>                 <chr>           <chr>                            \n 1 Malformation syndrome Obligate (100%) CLAPO syndrome                   \n 2 Malformation syndrome Obligate (100%) CLAPO syndrome                   \n 3 Malformation syndrome Obligate (100%) Weaver-Williams syndrome         \n 4 Malformation syndrome Obligate (100%) Weaver-Williams syndrome         \n 5 Malformation syndrome Obligate (100%) Weaver-Williams syndrome         \n 6 Malformation syndrome Obligate (100%) Weaver-Williams syndrome         \n 7 Malformation syndrome Obligate (100%) Weaver-Williams syndrome         \n 8 Malformation syndrome Obligate (100%) Weaver-Williams syndrome         \n 9 Malformation syndrome Obligate (100%) Lethal recessive chondrodysplasia\n10 Malformation syndrome Obligate (100%) Lethal recessive chondrodysplasia\n# … with 115 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\nCount() was used to find out the number of appearance of each disorder name in descending order.\n\ndf3 <- df_freq_ma %>% \n  count(`Disorder name`)\ndf3 %>% arrange(desc(n))\n\n# A tibble: 40 × 2\n   `Disorder name`                                                             n\n   <chr>                                                                   <int>\n 1 Hydrocephalus-obesity-hypogonadism syndrome                                12\n 2 Pelviscapular dysplasia                                                    11\n 3 46,XX disorder of sex development-skeletal anomalies syndrome               9\n 4 X-linked microcephaly-growth retardation-prognathism-cryptorchidism sy…     9\n 5 Severe intellectual disability-hypotonia-strabismus-coarse face-planov…     7\n 6 Lethal recessive chondrodysplasia                                           6\n 7 Weaver-Williams syndrome                                                    6\n 8 SERKAL syndrome                                                             5\n 9 Patent ductus arteriosus-bicuspid aortic valve-hand anomalies syndrome      4\n10 46,XX gonadal dysgenesis                                                    3\n# … with 30 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\nTo show one of the examples of the most common malformation syndrome with the most associated phenotypic features (with a total of 12 different phenotypic descriptions):\n\ndf_mal_syn <- df %>%\n  filter(`Disorder type` == \"Malformation syndrome\", `HPO frequency` == \"Obligate (100%)\", `Disorder name` == \"Hydrocephalus-obesity-hypogonadism syndrome\") %>% \n  select(`Disorder type`, `HPO frequency`, `Disorder name`, `Preferred HPO term`)\nkable(df_mal_syn)\n\n\n\n\n\n\n\n\n\n\nDisorder type\nHPO frequency\nDisorder name\nPreferred HPO term\n\n\n\n\nMalformation syndrome\nObligate (100%)\nHydrocephalus-obesity-hypogonadism syndrome\nHydrocephalus\n\n\nMalformation syndrome\nObligate (100%)\nHydrocephalus-obesity-hypogonadism syndrome\nShort neck\n\n\nMalformation syndrome\nObligate (100%)\nHydrocephalus-obesity-hypogonadism syndrome\nGynecomastia\n\n\nMalformation syndrome\nObligate (100%)\nHydrocephalus-obesity-hypogonadism syndrome\nHypergonadotropic hypogonadism\n\n\nMalformation syndrome\nObligate (100%)\nHydrocephalus-obesity-hypogonadism syndrome\nIntellectual disability, mild\n\n\nMalformation syndrome\nObligate (100%)\nHydrocephalus-obesity-hypogonadism syndrome\nObesity\n\n\nMalformation syndrome\nObligate (100%)\nHydrocephalus-obesity-hypogonadism syndrome\nMitral valve prolapse\n\n\nMalformation syndrome\nObligate (100%)\nHydrocephalus-obesity-hypogonadism syndrome\nLow posterior hairline\n\n\nMalformation syndrome\nObligate (100%)\nHydrocephalus-obesity-hypogonadism syndrome\nHigh, narrow palate\n\n\nMalformation syndrome\nObligate (100%)\nHydrocephalus-obesity-hypogonadism syndrome\nCubitus valgus\n\n\nMalformation syndrome\nObligate (100%)\nHydrocephalus-obesity-hypogonadism syndrome\nShort stature\n\n\nMalformation syndrome\nObligate (100%)\nHydrocephalus-obesity-hypogonadism syndrome\nShort 4th metacarpal\n\n\n\n\n\n\n\nExplore rare disease validation date\nNow, to add one more piece of work towards this exploratory data analysis, I thought to check out the Validation date column. “Validation date” in this context meant the dates when the annotations of HPO terms were made for each rare disorder, which were based on the source articles listed (as shown in the Source column).\nFirstly, I started with the “Disease” disorder type and singled out the year component from the Validation date column.\n\ndf_val_date <- df %>% \n  mutate(year = year(`Validation date`), label = TRUE, abbr = FALSE)\ndf_val_date\n\n# A tibble: 112,243 × 16\n   Disorder gr…¹ Disor…² HPO d…³ Diagn…⁴ HPO f…⁵ HPO I…⁶ Prefe…⁷ Disor…⁸ Disor…⁹\n   <chr>         <chr>     <dbl> <chr>   <chr>   <chr>   <chr>   <chr>     <dbl>\n 1 Disorder      Disease      59 Diagno… Very f… HP:000… Pectus… Marfan…     558\n 2 Disorder      Disease      59 Diagno… Very f… HP:000… Striae… Marfan…     558\n 3 Disorder      Disease      59 Diagno… Very f… HP:000… Arachn… Marfan…     558\n 4 Disorder      Disease      59 Diagno… Very f… HP:000… Dispro… Marfan…     558\n 5 Disorder      Disease      59 Diagno… Very f… HP:000… Pes pl… Marfan…     558\n 6 Disorder      Disease      59 Diagno… Very f… HP:000… Sponta… Marfan…     558\n 7 Disorder      Disease      59 Diagno… Very f… HP:000… Dilata… Marfan…     558\n 8 Disorder      Disease      59 Diagno… Freque… HP:000… Myopia  Marfan…     558\n 9 Disorder      Disease      59 Diagno… Freque… HP:000… Dental… Marfan…     558\n10 Disorder      Disease      59 Diagno… Freque… HP:000… Pectus… Marfan…     558\n# … with 112,233 more rows, 7 more variables: Online <chr>, Source <chr>,\n#   `Validation date` <dttm>, `Validation status` <chr>, year <dbl>,\n#   label <lgl>, abbr <lgl>, and abbreviated variable names ¹​`Disorder group`,\n#   ²​`Disorder type`, ³​`HPO disorder & clinical entity association count`,\n#   ⁴​`Diagnostic criteria`, ⁵​`HPO frequency`, ⁶​`HPO ID`, ⁷​`Preferred HPO term`,\n#   ⁸​`Disorder name`, ⁹​`Disorder Orphacode`\n# ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\n\n\nTo show this in a dataframe, observations for “Disease” disorder type were shown by using a filter:\n\ndf_val_date_d <- df_val_date %>% \n  select(`Disorder type`, year) %>% \n  filter(`Disorder type` == \"Disease\")\ndf_val_date_d\n\n# A tibble: 57,920 × 2\n   `Disorder type`  year\n   <chr>           <dbl>\n 1 Disease          2016\n 2 Disease          2016\n 3 Disease          2016\n 4 Disease          2016\n 5 Disease          2016\n 6 Disease          2016\n 7 Disease          2016\n 8 Disease          2016\n 9 Disease          2016\n10 Disease          2016\n# … with 57,910 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\nThen to make it easier to visualise, the year counts were plotted in a bar graph. Interestingly, 2016 seemed to be the year for rare disorders to be annotated with the most phenotypic features (if referring back to the original dataset, each observation or row was present for a unique “Preferred HPO term” or phenotypic abnormality).\n\ndf_val_date_d %>% \n  ggplot(aes(x = year)) +\n  geom_bar()\n\nWarning: Removed 49 rows containing non-finite values (stat_count).\n\n\n\n\n\nIt was also worth noting that there were 49 rows of non-finite values excluded from the bar graph above. To look into this, a count on the year column of the dataframe df_val_date_d was done, which confirmed that these were the “NA” or missing values in the validation date column.\n\ndf_val_date_d %>% \n  count(year)\n\n# A tibble: 8 × 2\n   year     n\n  <dbl> <int>\n1  2015   567\n2  2016 14193\n3  2017  5419\n4  2018  6297\n5  2019 10525\n6  2020  9402\n7  2021 11468\n8    NA    49\n\n\n\n\n\nSummary\nTo quickly summarise key findings from this work4 regarding phenotypes associated with rare diseases:\n\nAutosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction was one of the most common rare diseases under the Disease disorder type with the most phenotypic abnormalities recorded, which were:\n\n\nprogressive spastic paraplegia\nmicrocephaly\nmoderately short stature\nnasal, dysarthic speech\ndelayed gross motor development\nprogressive spasticity\nlower limb hyperreflexia\nankle clonus\nretinal pigment epithelial mottling\nprogressive spastic paraparesis\n\n\nFor malformation syndrome of the rare disorder type, Hydrocephalus-obesity-hypogonadism syndrome was found to be one of the most common rare diseases with the most phenotypic abnormalities recorded, which were:\n\n\nhydrocephalus\nshort neck\ngynecomastia\nhypergonadotropic hypogonadism\nintellectual disability, mild\nobesity\nmitral valve prolapse\nlow posterior hairline\nhigh, narrow palate\ncubitus valgus\nshort stature\nshort 4th metacarpal\n\n\nThe year of 2016 had the highest number of HPO terms or phenotypic abnormalities annotated to rare disorders from specific named source articles, and on the contrary, 2015 had the lowest counts from the dataset\n\n\n\n\n\n\nFootnotes\n\n\nUsed only for initial data cleaning stage - please see this GitHub link for details. R was used for the rest of the analysis↩︎\nThis work is under CC BY-SA 4.0 International License if anyone is interested in exploring the dataset further↩︎\n“Orphadata: Free access products description” - April 2020. http://www.orphadata.org/cgi-bin/img/PDF/OrphadataFreeAccessProductsDescription.pdf. Version 2↩︎\nIt’s possible to dig further into the dataset e.g. diagnostic criterion and perhaps even bring back some of the columns removed initially, however due to time constraints (due to being a one-person team and also I’d like to start on the COVID-19 antiviral work soon), I’ll leave some room here for the interested to work on the data↩︎"
  },
  {
    "objectID": "posts/SERCA_project/SERCA_project.html",
    "href": "posts/SERCA_project/SERCA_project.html",
    "title": "SERCA project",
    "section": "",
    "text": "Essentially, having completed this MPhil project1 was more like a warm-up before participating in a real research project at a grand scale. This was a new project at the time (between 2012 – 2014) as no one in my previous lab group was working on it so it was literally a one-person project but we were collaborating with a distant research group. Unfortunately this project came to an early stop during my PhD stage (when I was working part-time still as a pharmacist to support my own cost of living while receiving a puny amount of scholarship plus working on this project at the time and then one extra project added on during PhD). The main reason that this project did no progress was that our collaborators decided to pull out from testing further compounds for us. Although it came as a bit of shock but later it felt less so. Later, I’ve decided that it would still be part of my portfolio to showcase a project that did not proceed further (or in plain words, in the “failed” section).\nReflecting back to the whole experience for this project, I’ve learned my lessons about working with collaborators whose research focus was on entirely different but related field (their one was on molecular biology, while our side was on chemistry, I’ve been spending time working in both computer and chemistry labs, trying to identify likely compound candidate from molecular modelling and then synthesise the compounds in the lab for them to test). There should have been more communications if possible and perhaps we could’ve terminated the project earlier if needed so that we could allocate more time to work on other research project that better suited to the situation of our lab group. To have a closure for this project, I’ve written up a chapter about it in my PhD thesis to show what have been done and what other future work can be added if we have all the time and money in the world.\n Image: Rawpixel.com\nLink to MPhil thesis (beware: quite long)\nAbstract of this project:\nThe goal of this research project was to discover potential chemical compounds that could be further developed to become lead compounds to target secretory pathway calcium ATPase 1 (SPCA1) and also sarcoplasmic-endoplasmic reticulum calcium ATPase (SERCA) pumps. The drug design process would need to be robust enough to ask the question; could a SERCA inhibitor be developed based on the drug design process involving molecular modelling, chemical synthesis and biological testing? If this first step was achieved then the next critical step was to design a SPCA1 inhibitor as SPCA1 was found to be highly involved in basal-like breast cancer. The potential lead compounds would then have the opportunity to become novel anti-cancer agents targeting basal-like breast cancer in this context. The ultimate aim was to widen the current therapeutic agents available for patients with basal-like subtype of breast cancer in the hope to further improve their quality of life and life expectancy.\n\n\n\n\nFootnotes\n\n\nthis was not a perfect example of drug discovery, I was a complete research newbie prior to this MPhil project and thinking back, I think I was far too ambitious…↩︎"
  },
  {
    "objectID": "posts/Publications/Side_projects.html",
    "href": "posts/Publications/Side_projects.html",
    "title": "Publications",
    "section": "",
    "text": "Throughout my PhD, I’ve also collaborated with the lab group members and also other research groups in other academic research projects. The following publications1 were the ones I was involved in:\n\n\n\nPhoto by Clark Young on Unsplash\n\n\n\nHsuan-Yu J. Lin, Rachana Rao Battaje, Jinlong Tan, Munikumar Doddareddy, Hemendra Pal Singh Dhaked, Shalini Srivastava, Bryson A. Hawkins, Laith Mohammad Hilal Al-Shdifat, David E. Hibbs, Dulal Panda, Paul W. Groundwater. Discovery of 20,6-Bis(4-hydroxybenzyl)-2-acetylcyclohexanone, a Novel FtsZ Inhibitor. Molecules. 2022; 27(20), 6993. (IF = 4.927)\nPalanimuthu D, Poon R, Sahni S, Anjum R, Hibbs D, Lin JHY, Bernhardt PV, Kalinowski DS, Richardson DR. A novel class of thiosemicarbazones show multi-functional activity for the treatment of Alzheimer’s disease. Eur J Med Chem. 2017; 139: 612-632. (IF = 4.816)\nPanda D, Bhattacharya D, Gao QH, Oza PM, Lin JHY, Hawkins B, Hibbs DE, Groundwater PW. Identification of agents targeting FtsZ assembly. Future Med Chem. 2016; 8(10):1111-32. (IF = 3.969)\nGao Q, Hanh J, Váradi L, Cairns R, Sjöström H, Liao VW, Wood P, Balaban S, Ong JA, Lin JHY, Lai F, Hoy AJ, Grewal T, Groundwater PW, Hibbs DE. Identification of dual PPARα/γ agonists and their effects on lipid metabolism. Bioorg Med Chem. 2015; 23(24):7676-84. (IF = 2.881)\n\n\n\n\n\nFootnotes\n\n\nNot a large number of publications there, perhaps due to the research topics I’ve chosen, they tend to require months or years to see tangible results… so here is my very humble list as some others may be more productive than me…↩︎"
  },
  {
    "objectID": "posts/01_Drugs_in_rare_diseases/Rare_diseases_drugs.html",
    "href": "posts/01_Drugs_in_rare_diseases/Rare_diseases_drugs.html",
    "title": "Drugs in rare diseases",
    "section": "",
    "text": "Introduction\nSince it is common knowledge that it takes a very long time to discover and develop novel therpapeutic drugs. I’ve also often wondered about drugs for rare diseases and how they’re often for the minorities in the diseased populations. So here is the initial Python and R projects1 about rare disease drugs by using data extracted from FDA’s Orphan Drug Product designation database. I also have to acknowledge “Data Is Plural” website, which has inspired me to look into this dataset.\nUnfortunately this particular dataset I’ve obtained does not contain information on incentives for pharmaceutical companies (from US’s Orphan Drug Act of 1983), which could mean that I might be able to draw some preliminary, basic or raw correlations between incentives and rare disease drug marketing approvals (this might lead to other controversial discussions about this area, which was not my initial aim for this project as I just wanted to explore a dataset on rare disease drugs at the moment).\nThe datatset was for the period from 1983 till present, for approved rare disease drugs only.\n\n\nPython project\nFor Python project2, there was one question in mind to answer:\nHow long did it take on average for a rare disease drug to reach marketing approval?\nPython version of the data analysis: link\nShort summary of findings from this dataset using Python:\n\nThe orphan designation for rare disease drug that had the highest counts between 1983 till present was for the treatment of multiple myeloma\nThe highest counts of final approved indication for rare disease drugs spanned across several different clinical indications – it often ended up with more indication details than the initial orphan designation phase\nThe average time required for a rare disease drug to progress from the initial designation phase to the final approval for marketing was about 1932 days (~5 years)\nThe horizontal bar graph (access from link above) showed the top ten rare disease drugs with the longest time taken to reach the market Tiopronin was the one that took the longest time of 12,215 days (~33 years)\nThe data for Tiopronin appeared to be duplicates, but note that the two were formulated differently as one of them was the enteric-coated (EC) version (marketed as delayed-release tablets under the actual trade name of “Thiola EC”, but recorded in the dataset as “Thiola” only), while the other one was the immediate-release form (Thiola)\n\n Image: Rawpixel.com\n\n\nR project\nFor R project3, there were two questions in mind to answer:\n\nWhat countries were involved in rare disease drug developments?\nHow would the time from designation to approval be displayed in timeline style for selected rare disease drugs?\n\nR versions of the data analysis:\n\nbase R methods via Jupyter notebook with link\nTidyverse version via RStudio with link - done using RMarkdown\n\nShort summary of findings from this dataset using R:\n\nUS was the country that had the most involvement in rare disease drug developments, which was followed by Ireland and the UK, and also a number of other countries\nMore work could possibly go into looking at the duplicates of brand names of the same generic drug e.g. cannabidiol with trade name as Epidiolex that had 5 repeated timelines (shown in link above), which appeared to be different clinical indications for each of these entries after further checks\nThe timelines have also implied that drug discovery and development is a very timely process, which could span many years, such as 10 – 20 years or more, before a drug actually reaches the market for public use\n\n\n\n\n\n\nFootnotes\n\n\nThis work is under CC BY-SA 4.0 International License for anyone interested in exploring the topic further.↩︎\nThe published date of this project would be based on the last day I’ve worked on associated file, prior to the blog move↩︎\nThe R versions, base R and Tidyverse projects, were done after the Python one was completed↩︎"
  },
  {
    "objectID": "posts/Blog-DS_journey/Beginning_of_DS_journey.html",
    "href": "posts/Blog-DS_journey/Beginning_of_DS_journey.html",
    "title": "The beginning of the data science journey",
    "section": "",
    "text": "After my PhD study came to an end at around the end of 2018 to early 2019, I’ve decided to return to New Zealand. This was followed by my tumultuous postdoc searching story and also a solitude time for myself to dig deeper into what I would really like to do research-wise. This, of course, then led to the beginning of the COVID-19 pandemic in early 2020, which in a sense has been world-changing (I don’t know what other words or terms can better describe it) and its after-effect is still hanging around until this very moment…\nRegarding to the postdoc job searching, this has made me ponder really hard about what sort of research I would really like to work on. As I’ve spent time preparing my CV, writing different cover letters, applying for different postdoc-related roles and also after being invited to five job interviews, I’ve decided that it was not quite enough about what I’ve done so far in Masters and PhD work… I’m still lacking some skills. I’ve also realised that I do not necessarily like the traditional academic postdoc work (discovered while and after I’ve applied for numerous postdoc posts in 2019) and also I’m more inclined to work on computational chemistry and cheminformatics side of research.\nAnother “elephant-in-the-room” issue was that it has been very difficult to publish a first-author paper from my PhD research work, due to the impact from the development of COVID-19 pandemic for the last two years (my overseas-based collaborators have been hit hard particularly and they were still working on part of the experiments until the first quarter of the year 2021) and hence probably this was the most likely the reason that I did not get final offers in some academic postdoc positions, due to the lack of first-author papers.\n\n\n\nPhoto by Sergi Kabrera on Unsplash\n\n\nBecause of all the issues and problems, I’ve still kept my old pharmacist job as my side job while I start on a new journey in learning data science. I’ve tested the water since 2019 and temporarily ceased the learning in 2020 due to the pandemic (I worked full-time in hospital which was also another unforgettable experience of course). From the last quarter of 2021, I’ve made up my mind to go full board with data science (as I can’t see my PhD research work being published any time soon so it’s time to consider a possible change in direction). I thought I’d like to learn about it systematically with some sort of logical structures in the course so that I can understand a basic full picture about it in a reasonably short time (I realise data science itself is a profound field) and if there are some sort of accreditations, this would be even better. This was also the sole reason why I started on Coursera’s IBM data science professional certificate in the last quarter of 2021. After learning more about it, I’ve realised how much it has overlapped with cheminformatics and my interests in both areas grew more and more as time goes.\nI have now completed the data science professional certificate, which consisted of a total of 10 courses with assessments, assignments and portfolios (certificates and/or IBM badges viewable from my LinkedIn profile). I have managed to finish the course within about 5 months (from mid-September 2021 till end of January 2022) while working part-time as a locum pharmacist. Although it’s not a perfect course, I think it reflects very nicely what the reality will be like when working as a data scientist or cheminformatician – imperfections in data sources, data analyses and presentations that need to be corrected or problems that need to be solved by looking for answers and working on possible solutions. I think it’s a useful course for newcomers who want to learn more about data science and also for the professionals who would like to refresh or reaffirm knowledge and skills (this is by no means a promotion about Coursera’s data science course but just a personal learning experience only, other course providers may equally provide similar experiences and I would encourage anyone who’s interested to look around and see what other courses are available)."
  },
  {
    "objectID": "posts/Blog-Blog_move/Blog_move.html",
    "href": "posts/Blog-Blog_move/Blog_move.html",
    "title": "Blog move",
    "section": "",
    "text": "I’ve been working on my data analytics portfolio for the last few months, on and off, as I’ve also got another work commitment going on at the same time. While working on my very first portfolio blog at WordPress, I’ve also stumbled across R programming language (due to a data analytics work interview where they actually tested me R!). This then opened up a whole new R world with its friendly online community. Since my interests in R grew further and further, I’ve been looking for places where I can use RStudio IDE and/or R to build blogs and gladly I found Quarto which led me to its Quarto blogs.\n\n\n\nPhoto by Lia Trevarthen on Unsplash\n\n\nSo here is my very first Quarto blog, deployed using Netlify initially and then I also figured out how to deploy it on GitHub Pages, so now I’ve actually got two extra sites running. The process to deploy on Netlify was quite simple as many people have already mentioned (GitHub Pages were also not too complicated as well once I’ve grasped the deployment workflow). I’m still pondering if I should write something on how I started Quarto blogs, but considering so many talented people have already talked about it, I may not go down this route (consider visiting Bea Milz’s lovely post on “Creating a blog with Quarto in 10 steps” - this was what I followed to get my Quarto blog up and running).\nI will be slowly moving my current posts and portfolio projects from WordPress to Quarto blogs. Who knows, maybe I may end up working on building websites, or doing other things that I’ve never imagined I would do before!"
  },
  {
    "objectID": "posts/09_Pills/Rust_evcxr_polars_plotly_final.html",
    "href": "posts/09_Pills/Rust_evcxr_polars_plotly_final.html",
    "title": "Pills dataset - Part 3",
    "section": "",
    "text": "Background\nThe aim of this final part (part 3) for the pills dataset was really for me to start using Rust in a beginner-friendly way. Overall, this trilogy (parts 1 - 3) for the pills dataset formulated an overview of how to use Polars in Python (mainly), Pandas in Python (smaller section) and Polars in Rust (even little less as this was new to me) with Plotly. Over time, I’ve been finding myself learning more optimally by doing and applying, rather than just reading and thinking, so I’ve got myself started in this very new programming language, Rust, to get some familiarities. I anticipated that I would still work with Python and R mainly in the near future, so that I’m not diverting too much and would be at least proficient in at least one programming language.\nMy very initial idea was to integrate Rust-Polars, Plotly in Rust (Plotly.rs) and Jupyter-Evcxr together, and see if I could get a simple data visualisation out of a small dataset. Although the idea sounded simple enough, I was actually quite stuck at the step of importing one of the columns as x-axis variables in Rust-Polars to Plotly.rs. I figured it might possibly be due to my very lack-of-knowledge and lack-of-familiarities with Rust (I do need to continue reading the Rust programming language book), Polars (I’m better with Python-Polars actually), Plotly.rs and also Evcxr. Another possibility could be that Plotly.rs mainly had ndarray support, and Polars was not mentioned explicitly in Plotly.rs so my guess was that these two might not flow very well together. Also, Polars itself was constantly evolving and growing as well.\nSo I’ve decided to leave things as how it would be for now, before I delayed this post any further. If I happened to figure out how to do this in the future, then I’ll come back to update this last part of the project. While I was tackling this little issue mentioned above, somehow I’ve managed to deconstruct Polars dataframe in Rust in Evcxr. So I’ll show a little bit about it below. One slightly good news that came out from all of this, was that I’ve managed to import the other column as y-axis variables, which contained numbers, without problems. I’ve also figured out the Rust codes to convert Series/ChunkedArray to vectors in Rust IDEs (e.g. VS Code, and quite a few others). So I did learn a few things while completing this post, and hoped I could expand further on this later.\nNote: I’ve published all Rust codes as print-only in Quarto markdown file, since it’s not possible to run them in RStudio IDE (Rust was not supported). So all Rust codes were originally run on Jupyter Lab in MacOS, with code outputs being captured as screenshots, which were shown as photos in this post. Here’s the link to the .ipynb file in the GitHub repository for this portfolio website (or alternatively, you could access it from the GitHub icon link at the top of the web page), in case anyone wanted to see the full .ipynb version.\n\n\n\nImport dependencies\nThese dependencies were known as crates in the world of Rust. I’d also like to think of them as libraries or packages we would install or import in Python and R. So this step was necessary before I even started anything decent in Rust. Similar things would also apply to Rust IDEs as well since I’ve played a little bit in VS Code previously.\n```{rust}\n// Set up required dependencies\n:dep ndarray = \"0.15.6\"\n```\n```{rust}\n:dep plotly = { version = \">=0.8.0\", features = [\"plotly_ndarray\"]}\n```\n```{rust}\n// May take a few minutes to load polars crate (might depend on your machine specs)\n:dep polars = { version = \">=0.26.0\", features = [\"lazy\", \"csv-file\", \"strings\", \"dtype-duration\", \"dtype-categorical\", \"concat_str\", \"rank\", \"lazy_regex\", \"ndarray\"]}\n```\n```{rust}\n:dep itertools = {version = \"0.9.0\"}\n```\n\n\n\nImport external crates\n```{rust}\n// Import external crates needed\nextern crate ndarray;\nextern crate plotly;\nextern crate polars;\n```\n\n\n\nSpecify imports or modules required\n```{rust}\nuse ndarray::prelude::*;\nuse polars::prelude::*;\nuse plotly::common::{\n    ColorScale, ColorScalePalette, DashType, Fill, Font, Line, LineShape, Marker, Mode, Title,\n};\nuse plotly::layout::{Axis, BarMode, Layout, Legend, TicksDirection};\nuse plotly::{Plot, Scatter, Bar};\nuse itertools::Itertools;\n```\n\n\n\nReading csv file\nHere, I’ve imported the .csv file saved from part 2 of the project.\n```{rust}\n// Reading .csv file\nlet df = CsvReader::from_path(\"ace_para_count.csv\").unwrap().finish().unwrap();\n```\n```{rust}\ndf\n```\n\n\n\nPhoto by author\n\n\n\n\n\nConverting columns into ndarrays\nI’ve tested plotting in Plotly.rs after a few trials and errors at the beginning, but luckily I’ve spotted the ndarray support from the Plotly.rs book soon enough to figure out that I could convert the “count” column into a ndarray first, which was shown in the code below.\n```{rust}\n// Switch Polars dataframe into 2D array\n// Ensure \"ndarray\" was added as one of the features for polars under dependencies\n\n/*Example from Polars documentation:\nlet df = DataFrame::new(vec![a, b]).unwrap();\nlet ndarray = df.to_ndarray::<Float64Type>().unwrap();\nprintln!(\"{:?}\", ndarray);\n*/\n\n//Note: ndarray for numbers only, not strings, so only \"count\" column was converted\nlet ndarray = df.to_ndarray::<Float64Type>().unwrap();\nprintln!(\"{:?}\", ndarray);\n```\n\n\n\nPhoto by author\n\n\n\n\n\nDeconstructing Polars dataframe in Rust\nBecause “to_ndarray” was only for numerics and not strings, I ran into a problem trying to figure out how to best import this other “Colour” column into Plotly.rs. This led to my little convoluted journey to work with Polars dataframe in Rust, trying to see if I could convert the “Colour” column into a vector (which might not be the best way to do it, but as part of my Rust learning, I went for it anyway). I’ve subsequently tried plotting the “count” column in ndarray as a vector with success, based on the reference from Plotly.rs book that variables for x or y-axis could be placed into a vector by using a vector macro. Eventually, I didn’t quite achieve my goal but I’ve managed to break down or convert the Polars dataframe into different formats.\n```{rust}\n// Select specific column or series by position\nlet Colours = df[0].clone();\n\n//Alternative way to select specific column or series by name\n//let u = df.select_series(&[\"Colour\"]);\n```\n```{rust}\nColours\n```\n\n\n\nPhoto by author\n\n\nThere was a mention of storing series (column) in a vec (as series vector, not vector for strings) in Polars’ documentation, which I’ve tried to plot in Plotly.rs, but it unfortunately failed to work. One of my guesses could be due to the data type used for vector, as Rust was a very type-specific programming language, which also brought its well-known memory safety and other benefits in the long run. My immediate thought was that it probably needed to be a vector for strings, not series, which might make it work. Then I was searching on StackOverflow for similar questions and answers, then I found something related to what I wanted to do from Polars documentations as shown below.\n```{rust}\n// Adapted from: https://docs.rs/polars/latest/polars/docs/eager/index.html#series \n// Extracting data: \n// To be able to extract data out of Series, \n// either by iterating over them or converting them to other datatypes like a Vec<T>, \n// we first need to downcast them to a ChunkedArray<T>. \n// This is needed because we don't know the data type that is held by the Series.\n\n/*use polars::prelude::*; \n  use polars::df;\n\n  fn extract_data() -> PolarsResult<()> { \n  let df = df! [ \"a\" => [None, Some(1.0f32), Some(2.0)], \"str\" => [\"foo\", \"bar\", \"ham\"]]?;\n\n// first extract ChunkedArray to get the inner type.\n\n  let ca = df.column(\"a\")?.f32()?;\n\n// Then convert to vec\n\n  let _to_vec: Vec<Option<f32>> = Vec::from(ca);\n\n// We can also do this with iterators\n\n  let ca = df.column(\"str\")?.utf8()?; \n  let _to_vec: Vec<Option<&str>> = ca.into_iter().collect(); \n  let _to_vec_no_options: Vec<&str> = ca.into_no_null_iter().collect();\n\n  Ok(())\n\n}*/\n```\nInitially, I trialled the iterator function first.\n```{rust}\n// Print out items in column by applying an iterator to it\nprintln!(\"{}\", &Colours.iter().format(\"\\n\"));\n```\n\n\n\nPhoto by author\n\n\nThen, it took me quite a long time to just downcast Series into ChunkedArray, but somehow I’ve managed to figure out the code myself below. One of the likely reasons was due to my choice of using Evcxr, which required Rust codes in slightly different formats than the ones in Rust IDEs (although almost the same).\n```{rust}\n// Somehow worked out how to convert series to chunkedarray by accident!\nprintln!(\"{:?}\", Colours.utf8().unwrap());\n```\n\n\n\nPhoto by author\n\n\nThen I moved onto trying to figure out how to convert or place a ChunkedArray into a vector, with the closest answer shown below. However, bear in mind that these Rust codes were for Rust IDEs, and not for Evcxr, so this added slightly more complexities to what I was trying to do (perhaps I should just stick with Rust IDEs in the future…).\n```{rust}\n//Adpated from StackOverflow - How to get a Vec from polars Series or ChunkedArray?\n//You can collect the values into a Vec.\n\n/*use polars::prelude::*;\n\nfn main() -> Result<()> { let s = Series::new(\"a\", 0..10i32);\n\n    let as_vec: Vec<Option<i32>> = s.i32()?.into_iter().collect();\n\n    //if we are certain we don't have missing values\n    let as_vec: Vec<i32> = s.i32()?.into_no_null_iter().collect();\n    Ok(())\n\n}*/\n```\nI also found another way to iterate the ChunkedArray.\n```{rust}\n//fn iter_forward(ca: &Float32Chunked) { ca.into_iter().for_each(|opt_v| println!(\"{:?}\", opt_v)) } \n```\nI then tested another iterator method, and came up with another line of code as shown below, which listed the colours in the “Colour” column.\n```{rust}\nColours.utf8().unwrap().into_iter().for_each(|array|println!(\"{:?}\", array));\n```\n\n\n\nPhoto by author\n\n\nI also found out, randomly, how to slice strings for Series in Polars. By changing the number of letters to slice through in Some(), the strings or words would vary length accordingly. Here, I’ve used “15” so it covered all the colours (note: the longest would be 12 characters for combination colours).\n```{rust}\n// Another method to use if needing to slice strings\nlet x = Colours.utf8().unwrap().str_slice(0, Some(15));\nx\n```\n\n\n\nPhoto by author\n\n\nLastly, before I got too carried away, I just wanted to show the method from Polars documentations that this was the Polars’ way to select a specific column from Polars dataframe.\n```{rust}\nlet ca = df.clone().lazy().select([cols([\"Colour\"])]).collect()?;\nca\n```\n\n\n\nPhoto by author\n\n\n\n\n\nPlotting Polars dataframe in Plotly.rs\nFor the x-axis, eventually, I reverted for manual input due to the issue mentioned in the background section. So the colours from the “Colour” column were stored in a vector set up manually, rather than coming directly from the dataframe. While searching for answers, I’ve also learnt several other tricks, although not really solving the problem, they might still be useful in the future. For the y-axis, the ndarray for the “count” column was converted into a vector first before being fed into the trace (graph module), and thankfully the plot worked nicely.\n```{rust}\n// MANUAL method:\n// Use vec! macro to create new vectors to hold x variables (words as strings)\n// Manually input the colour names (as ndarray is only for numbers)\nlet x = vec![\"RED\", \"ORANGE;BROWN\", \"YELLOW;WHITE\", \"ORANGE\", \"WHITE\", \"BLUE\"];\n\n// Plot using ndarray, which is supported by Plotly.rs \n// Polars likely not supported yet\n// Convert ndarray (holding counts as y variables) into vector \nlet y = ndarray.column(1).to_vec();\n\n// Use trace as a graph module,\n// choose type of plots needed for x & y variables called\n// Graph options e.g. Scatter, Line or Bar\nlet trace = Scatter::new(x, y);\n\n// Set plot variable as mutable and initiate a plot\nlet mut plot = Plot::new();\n// Add trace (graph) into the plot variable\nplot.add_trace(trace);\n\n// Specify the specs for plot\nlet layout = Layout::new()\n    // Choose height of graph\n    .height(500)\n    // Name x-axis\n    .x_axis(Axis::new().title(Title::new(\"Colours\")))\n    // Name y-axis\n    .y_axis(Axis::new().title(Title::new(\"Count\")))\n    // Add title of graph\n    .title(Title::new(\"Frequency of colours in acetaminophen (paracetamol) oral dosage forms\"));\n\n// Set the layout of the plot\nplot.set_layout(layout);\n\n// Display the plot in Jupyter Lab format \n// For Jupyter Notebook, use: plot.notebook_display();\nplot.lab_display();\nformat!(\"EVCXR_BEGIN_CONTENT application/vnd.plotly.v1+json\\n{}\\nEVCXR_END_CONTENT\", plot.to_json())\n```\n\n\n\nPhoto by author\n\n\n\n\n\nConclusion\nThis last part was the hardest for me to execute out of all 3 parts (it likely took me a good whole week to figure out deconstructing Polars dataframe and trying to work with vectors), as Rust was completely new to me. At one point I thought about jumping back to Python, but I persisted and although I didn’t quite solve the string importation issue, I was somehow happy that I was at least able to see how this programming language could be applied in Polars dataframe library. I also got a taste of using Rust in data visualisations. All I wanted to show was that there were a variety of data tools to use, and knowing your tools of trade would be the most critical when working on different data projects as certain tools would only work the best for certain tasks and scenarios. This warm-up lesson in Rust was quite interesting and I might continue either in VS Code or Evcxr depending on my next topic of interest.\n\n\n\nReferences\nRust programming language book: https://doc.rust-lang.org/book/title-page.html\nPolars crate documentations: https://docs.rs/polars/latest/polars/\nPlotly.rs GitHub repository: https://github.com/igiagkiozis/plotly (link to the Plotly.rs book can be found in “Converting columns into ndarrays” section)\nEvcxr GitHub repository: https://github.com/google/evcxr"
  },
  {
    "objectID": "posts/09_Pills/Rust_polars_pills_df.html",
    "href": "posts/09_Pills/Rust_polars_pills_df.html",
    "title": "Pills dataset - Part 2",
    "section": "",
    "text": "Quick overview\nPart 2 of this project aimed to look at the pills data up close, particularly into the types of dosage forms, colours, shapes and inactive excipients used in oral medications. Plotly was used as the main data visualisation library, which was followed by some text cleaning for a particularly busy column in the dataset. This was then completed with a section in the end to generate a small dataframe, preparing for a simple data visualisation in Rust-Evcxr for the final part of this project (part 3).\n\n\n\n\nPhoto by Myriam Zilles on Unsplash\n\n\n\n\n\nImport libraries and pills dataset\n\nimport polars as pl\nimport plotly.express as px\n\nThe pills.csv file saved from part 1 was imported as shown below.\n\ndf = pl.read_csv(\"pills.csv\")\ndf\n\n\n\n\nshape: (83925, 5)\n\n\n\n\nsplshape_text\n\n\nsplcolor_text\n\n\nspl_strength\n\n\nspl_inactive_ing\n\n\nDosageForm\n\n\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n\"CAPSULE\"\n\n\n\"PINK\"\n\n\n\"TEMAZEPAM 15 m...\n\n\n\"SILICON DIOXID...\n\n\n\"CAPSULE\"\n\n\n\n\n\"ROUND\"\n\n\n\"ORANGE\"\n\n\n\"IBUPROFEN 200 ...\n\n\n\"SILICON DIOXID...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"PENTAGON (5 SI...\n\n\n\"GREEN\"\n\n\n\"DEXAMETHASONE ...\n\n\n\"ANHYDROUS LACT...\n\n\n\"TABLET\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"Nickel Sulfate...\n\n\nnull\n\n\n\"TABLET\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"CLONAZEPAM 0.2...\n\n\n\"SORBITOL;ASPAR...\n\n\n\"TABLET, ORALLY...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"SILDENAFIL CIT...\n\n\n\"ANHYDROUS DIBA...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"OVAL\"\n\n\n\"YELLOW\"\n\n\n\"RISPERIDONE 3 ...\n\n\n\"LACTOSE MONOHY...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"CAPSULE\"\n\n\n\"BLUE\"\n\n\n\"IBUPROFEN 200 ...\n\n\n\"FD&C BLUE NO. ...\n\n\n\"CAPSULE, LIQUI...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"Iloperidone 12...\n\n\n\"silicon dioxid...\n\n\n\"TABLET\"\n\n\n\n\n\"CAPSULE\"\n\n\n\"YELLOW;WHITE\"\n\n\n\"FENOPROFEN CAL...\n\n\n\"CROSPOVIDONE;M...\n\n\n\"CAPSULE\"\n\n\n\n\n\"ROUND\"\n\n\n\"YELLOW\"\n\n\n\"BUTALBITAL 50 ...\n\n\n\"STARCH, CORN;C...\n\n\n\"TABLET\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"ESTRADIOL 0.5 ...\n\n\n\"COPOVIDONE K25...\n\n\n\"TABLET\"\n\n\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"MEMANTINE HYDR...\n\n\n\"SILICON DIOXID...\n\n\n\"TABLET\"\n\n\n\n\n\"CAPSULE\"\n\n\n\"ORANGE\"\n\n\n\"ACETAMINOPHEN ...\n\n\n\"BUTYLATED HYDR...\n\n\n\"CAPSULE, LIQUI...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"LAMOTRIGINE 25...\n\n\n\"MAGNESIUM CARB...\n\n\n\"TABLET, CHEWAB...\n\n\n\n\n\"OVAL\"\n\n\n\"BLUE\"\n\n\n\"ACETAMINOPHEN ...\n\n\n\"ACESULFAME POT...\n\n\n\"TABLET, COATED...\n\n\n\n\n\"OVAL\"\n\n\n\"WHITE\"\n\n\n\"AZITHROMYCIN D...\n\n\n\"CROSCARMELLOSE...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"OVAL\"\n\n\n\"BLUE\"\n\n\n\"IBUPROFEN 200 ...\n\n\n\"FD&C BLUE NO. ...\n\n\n\"CAPSULE, LIQUI...\n\n\n\n\n\"OVAL\"\n\n\n\"WHITE\"\n\n\n\"CETIRIZINE HYD...\n\n\n\"STARCH, CORN;H...\n\n\n\"TABLET\"\n\n\n\n\n\"OVAL\"\n\n\n\"BROWN\"\n\n\n\"OMEPRAZOLE 20 ...\n\n\n\"CARNAUBA WAX;F...\n\n\n\"TABLET, DELAYE...\n\n\n\n\n\"ROUND\"\n\n\n\"PINK;ORANGE;YE...\n\n\n\"CALCIUM CARBON...\n\n\n\"CITRIC ACID MO...\n\n\n\"TABLET, CHEWAB...\n\n\n\n\n\"OVAL\"\n\n\n\"GREEN\"\n\n\n\"ACETAMINOPHEN ...\n\n\n\"STARCH, CORN;D...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"CAPSULE\"\n\n\n\"BLUE\"\n\n\n\"Amlodipine bes...\n\n\n\"Cellulose, mic...\n\n\n\"CAPSULE\"\n\n\n\n\n\"ROUND\"\n\n\n\"ORANGE\"\n\n\n\"DARIFENACIN 15...\n\n\n\"ANHYDROUS DIBA...\n\n\n\"TABLET, EXTEND...\n\n\n\n\n\n\n\n\n\n\nChange column names\nAgain, column names were changed to something easier to read.\n\n# Rename all column names\ndf_new = df.rename({\"splcolor_text\": \"Colour\", \n                    \"splshape_text\": \"Shape\", \n                    \"spl_strength\": \"Drug_strength\", \n                    \"spl_inactive_ing\": \"Inactive_excipients\", \n                    \"DosageForm\": \"Dosage_form\"}\n                  )\ndf_new\n\n\n\n\nshape: (83925, 5)\n\n\n\n\nShape\n\n\nColour\n\n\nDrug_strength\n\n\nInactive_excipients\n\n\nDosage_form\n\n\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n\"CAPSULE\"\n\n\n\"PINK\"\n\n\n\"TEMAZEPAM 15 m...\n\n\n\"SILICON DIOXID...\n\n\n\"CAPSULE\"\n\n\n\n\n\"ROUND\"\n\n\n\"ORANGE\"\n\n\n\"IBUPROFEN 200 ...\n\n\n\"SILICON DIOXID...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"PENTAGON (5 SI...\n\n\n\"GREEN\"\n\n\n\"DEXAMETHASONE ...\n\n\n\"ANHYDROUS LACT...\n\n\n\"TABLET\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"Nickel Sulfate...\n\n\nnull\n\n\n\"TABLET\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"CLONAZEPAM 0.2...\n\n\n\"SORBITOL;ASPAR...\n\n\n\"TABLET, ORALLY...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"SILDENAFIL CIT...\n\n\n\"ANHYDROUS DIBA...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"OVAL\"\n\n\n\"YELLOW\"\n\n\n\"RISPERIDONE 3 ...\n\n\n\"LACTOSE MONOHY...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"CAPSULE\"\n\n\n\"BLUE\"\n\n\n\"IBUPROFEN 200 ...\n\n\n\"FD&C BLUE NO. ...\n\n\n\"CAPSULE, LIQUI...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"Iloperidone 12...\n\n\n\"silicon dioxid...\n\n\n\"TABLET\"\n\n\n\n\n\"CAPSULE\"\n\n\n\"YELLOW;WHITE\"\n\n\n\"FENOPROFEN CAL...\n\n\n\"CROSPOVIDONE;M...\n\n\n\"CAPSULE\"\n\n\n\n\n\"ROUND\"\n\n\n\"YELLOW\"\n\n\n\"BUTALBITAL 50 ...\n\n\n\"STARCH, CORN;C...\n\n\n\"TABLET\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"ESTRADIOL 0.5 ...\n\n\n\"COPOVIDONE K25...\n\n\n\"TABLET\"\n\n\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"MEMANTINE HYDR...\n\n\n\"SILICON DIOXID...\n\n\n\"TABLET\"\n\n\n\n\n\"CAPSULE\"\n\n\n\"ORANGE\"\n\n\n\"ACETAMINOPHEN ...\n\n\n\"BUTYLATED HYDR...\n\n\n\"CAPSULE, LIQUI...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"LAMOTRIGINE 25...\n\n\n\"MAGNESIUM CARB...\n\n\n\"TABLET, CHEWAB...\n\n\n\n\n\"OVAL\"\n\n\n\"BLUE\"\n\n\n\"ACETAMINOPHEN ...\n\n\n\"ACESULFAME POT...\n\n\n\"TABLET, COATED...\n\n\n\n\n\"OVAL\"\n\n\n\"WHITE\"\n\n\n\"AZITHROMYCIN D...\n\n\n\"CROSCARMELLOSE...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"OVAL\"\n\n\n\"BLUE\"\n\n\n\"IBUPROFEN 200 ...\n\n\n\"FD&C BLUE NO. ...\n\n\n\"CAPSULE, LIQUI...\n\n\n\n\n\"OVAL\"\n\n\n\"WHITE\"\n\n\n\"CETIRIZINE HYD...\n\n\n\"STARCH, CORN;H...\n\n\n\"TABLET\"\n\n\n\n\n\"OVAL\"\n\n\n\"BROWN\"\n\n\n\"OMEPRAZOLE 20 ...\n\n\n\"CARNAUBA WAX;F...\n\n\n\"TABLET, DELAYE...\n\n\n\n\n\"ROUND\"\n\n\n\"PINK;ORANGE;YE...\n\n\n\"CALCIUM CARBON...\n\n\n\"CITRIC ACID MO...\n\n\n\"TABLET, CHEWAB...\n\n\n\n\n\"OVAL\"\n\n\n\"GREEN\"\n\n\n\"ACETAMINOPHEN ...\n\n\n\"STARCH, CORN;D...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"CAPSULE\"\n\n\n\"BLUE\"\n\n\n\"Amlodipine bes...\n\n\n\"Cellulose, mic...\n\n\n\"CAPSULE\"\n\n\n\n\n\"ROUND\"\n\n\n\"ORANGE\"\n\n\n\"DARIFENACIN 15...\n\n\n\"ANHYDROUS DIBA...\n\n\n\"TABLET, EXTEND...\n\n\n\n\n\n\n\n\n\n\nVisualising oral dosage forms & colours in pills\nGrabbing only unique drugs in the dataset to minimise duplications.\n\ndf_viz = df_new.unique(subset = \"Drug_strength\")\ndf_viz\n\n\n\n\nshape: (9287, 5)\n\n\n\n\nShape\n\n\nColour\n\n\nDrug_strength\n\n\nInactive_excipients\n\n\nDosage_form\n\n\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n\"CAPSULE\"\n\n\n\"PINK\"\n\n\n\"TEMAZEPAM 15 m...\n\n\n\"SILICON DIOXID...\n\n\n\"CAPSULE\"\n\n\n\n\n\"ROUND\"\n\n\n\"ORANGE\"\n\n\n\"IBUPROFEN 200 ...\n\n\n\"SILICON DIOXID...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"PENTAGON (5 SI...\n\n\n\"GREEN\"\n\n\n\"DEXAMETHASONE ...\n\n\n\"ANHYDROUS LACT...\n\n\n\"TABLET\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"Nickel Sulfate...\n\n\nnull\n\n\n\"TABLET\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"CLONAZEPAM 0.2...\n\n\n\"SORBITOL;ASPAR...\n\n\n\"TABLET, ORALLY...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"SILDENAFIL CIT...\n\n\n\"ANHYDROUS DIBA...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"OVAL\"\n\n\n\"YELLOW\"\n\n\n\"RISPERIDONE 3 ...\n\n\n\"LACTOSE MONOHY...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"Iloperidone 12...\n\n\n\"silicon dioxid...\n\n\n\"TABLET\"\n\n\n\n\n\"CAPSULE\"\n\n\n\"YELLOW;WHITE\"\n\n\n\"FENOPROFEN CAL...\n\n\n\"CROSPOVIDONE;M...\n\n\n\"CAPSULE\"\n\n\n\n\n\"ROUND\"\n\n\n\"YELLOW\"\n\n\n\"BUTALBITAL 50 ...\n\n\n\"STARCH, CORN;C...\n\n\n\"TABLET\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"ESTRADIOL 0.5 ...\n\n\n\"COPOVIDONE K25...\n\n\n\"TABLET\"\n\n\n\n\n\"CAPSULE\"\n\n\n\"YELLOW\"\n\n\n\"BENZONATATE 20...\n\n\n\"D&C YELLOW NO....\n\n\n\"CAPSULE\"\n\n\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"BUSULFAN 2 mg\"\n\n\n\"HYPROMELLOSES ...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"OVAL\"\n\n\n\"ORANGE\"\n\n\n\"AMPHETAMINE SU...\n\n\n\"CELLULOSE, MIC...\n\n\n\"TABLET\"\n\n\n\n\n\"ROUND\"\n\n\n\"GREEN\"\n\n\n\"FOLIC ACID 800...\n\n\n\"MICROCRYSTALLI...\n\n\n\"TABLET\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"ACONITUM NAPEL...\n\n\n\"LACTOSE / MAGN...\n\n\n\"TABLET\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"MATRICARIA CHA...\n\n\n\"ACACIA;LACTOSE...\n\n\n\"TABLET\"\n\n\n\n\n\"OVAL\"\n\n\n\"RED\"\n\n\n\"FOLIC ACID 1 m...\n\n\n\"CELLULOSE, MIC...\n\n\n\"TABLET\"\n\n\n\n\n\"ROUND\"\n\n\n\"BLUE\"\n\n\n\"Labetalol 300 ...\n\n\n\"ANHYDROUS LACT...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"CAPSULE\"\n\n\n\"YELLOW;BLUE\"\n\n\n\"POMALIDOMIDE 1...\n\n\n\"MANNITOL;STARC...\n\n\n\"CAPSULE\"\n\n\n\n\n\"CAPSULE\"\n\n\n\"PURPLE\"\n\n\n\"CALCIUM CITRAT...\n\n\n\"GELATIN;\"\n\n\n\"CAPSULE, GELAT...\n\n\n\n\n\"CAPSULE\"\n\n\n\"GREEN;YELLOW\"\n\n\n\"LENALIDOMIDE 1...\n\n\n\"ANHYDROUS LACT...\n\n\n\"CAPSULE\"\n\n\n\n\n\"OVAL\"\n\n\n\"WHITE\"\n\n\n\"folic acid 1 m...\n\n\n\"cellulose, mic...\n\n\n\"TABLET\"\n\n\n\n\n\"CAPSULE\"\n\n\n\"BLUE\"\n\n\n\"Amlodipine bes...\n\n\n\"Cellulose, mic...\n\n\n\"CAPSULE\"\n\n\n\n\n\n\n\nOne way to avoid switching Polars dataframe to a Pandas one, which could be one of the options to plot data from Polars dataframes in Plotly, was to call the x-axis and y-axis data directly from the dataframe as shown in the codes below.\n\n# scatter plot for colours, dosage forms & drug strengths \nfig = px.scatter(x = df_viz[\"Colour\"], \n                 y = df_viz[\"Dosage_form\"], \n                 color = df_viz[\"Colour\"],\n                 hover_name = df_viz[\"Drug_strength\"],\n                 width = 900, \n                 height = 400,\n                 title = \"Oral dosage forms and colours of pills\")\n\n# Update layout of the plot\nfig.update_layout(\n    # Change title font size\n    title = dict(\n        font = dict(\n            size = 15)),\n    # Centre the title\n    title_x = 0.5,\n    # Edit margins\n    margin = dict(\n        l = 20, r = 20, t = 40, b = 3),\n    # Change x-axis\n    xaxis = dict(\n        tickfont = dict(size = 9), \n        title = \"Colours\"\n    ),\n    # Change y-axis\n    yaxis = dict(\n        tickfont = dict(size = 9), \n        title = \"Dosage forms\"\n    ),\n    # Edit lengend font size\n    legend = dict(\n        font = dict(\n            size = 9)))\n\nfig.show()\n\n\n                                                \n\n\n\nWhite was the most common colour, especially after zooming in the plot. Capsule was very commonly used as the oral dosage form of choice in this dataset.\n\n\n\nVisualising shapes & colours in pills\n\nfig = px.scatter(x = df_viz[\"Colour\"], \n                 y = df_viz[\"Shape\"], \n                 color = df_viz[\"Colour\"],\n                 hover_name = df_viz[\"Drug_strength\"],\n                 width = 900, \n                 height = 400,\n                 title = \"Shapes and colours of pills\")\n\n# Update layout of the plot\nfig.update_layout(\n    # Change title font size\n    title = dict(\n        font = dict(\n            size = 15)),\n    # Centre the title\n    title_x = 0.5,\n    # Edit margins\n    margin = dict(\n        l = 20, r = 20, t = 40, b = 3),\n    # Change x-axis\n    xaxis = dict(\n        tickfont = dict(size = 9), \n        title = \"Colours\"\n    ),\n    # Change y-axis\n    yaxis = dict(\n        tickfont = dict(size = 9), \n        title = \"Shapes\"\n    ),\n    # Edit lengend font size\n    legend = dict(\n        font = dict(\n            size = 9)))\n\nfig.show()\n\n\n                                                \n\n\n\nCapsule was again the most common oral dosage shape used for pills in the dataset. Common colours included red, brown, blue, purple, pink, orange, green, white and yellow. Combination colours followed these common ones, which had a mixture of a variety of colours used simultaneously, likely to avoid confusions and errors in dispensings or administrations.\n\n\n\nVisualising inactive excipients in pills\nThe messiest part of the data actually lied in the column of “Inactive_excipients”, with numerous different punctuations used inconsistently, such as forward slashes, commas and semi-colons. There were vast quantities of different inactive components used for oral dosage forms. Because of this, I had to spend a bit more time cleaning up the texts in order to find out what were the commonly used inactive ingredients in the end.\n\n# Formulated a separate dataframe with just \"Inactive_excipients\"\ndf_ie = df_new.select([pl.col(\"Inactive_excipients\")])\ndf_ie\n\n\n\n\nshape: (83925, 1)\n\n\n\n\nInactive_excipients\n\n\n\n\nstr\n\n\n\n\n\n\n\"SILICON DIOXID...\n\n\n\n\n\"SILICON DIOXID...\n\n\n\n\n\"ANHYDROUS LACT...\n\n\n\n\nnull\n\n\n\n\n\"SORBITOL;ASPAR...\n\n\n\n\n\"ANHYDROUS DIBA...\n\n\n\n\n\"LACTOSE MONOHY...\n\n\n\n\n\"FD&C BLUE NO. ...\n\n\n\n\n\"silicon dioxid...\n\n\n\n\n\"CROSPOVIDONE;M...\n\n\n\n\n\"STARCH, CORN;C...\n\n\n\n\n\"COPOVIDONE K25...\n\n\n\n\n...\n\n\n\n\n\"SILICON DIOXID...\n\n\n\n\n\"BUTYLATED HYDR...\n\n\n\n\n\"MAGNESIUM CARB...\n\n\n\n\n\"ACESULFAME POT...\n\n\n\n\n\"CROSCARMELLOSE...\n\n\n\n\n\"FD&C BLUE NO. ...\n\n\n\n\n\"STARCH, CORN;H...\n\n\n\n\n\"CARNAUBA WAX;F...\n\n\n\n\n\"CITRIC ACID MO...\n\n\n\n\n\"STARCH, CORN;D...\n\n\n\n\n\"Cellulose, mic...\n\n\n\n\n\"ANHYDROUS DIBA...\n\n\n\n\n\n\n\n\nText cleaning for inactive excipients column\nTo prepare this column for data visualisations, I used Polars’ string expressions (or more commonly known as regex - regular expressions) to try and tidy up the raw texts. When I did the text cleaning in Jupyter Lab initially, the line of code for .str.strip(” ,“) worked, but when I converted the .ipynb file into a .qmd (Quarto markdown) one, and used the same line, it failed to work due to the extra space in front of the comma. However, I got around the error by splitting it into two separate units as space and comma, and it worked without problem. One possible reason would be due to the reticulate package needed to run Python in RStudio IDE, and how Polars dataframe library was relatively newer than Pandas dataframe library, which meant certain features in Polars might not have been taken on board in the reticulate package (only my guess).\n\n# Clean string texts \n# Convert uppercase letters into lowercase ones in the excipients column\ndf_de = (df_ie.with_column(pl.col(\"Inactive_excipients\").str.to_lowercase(\n    # replace old punctuations (1st position) with new one (2nd position)\n    ).str.replace_all(\n        \";\", \", \"\n    ).str.replace_all(\n        \" /\", \", \"\n    ).str.replace_all(\n        \"/\", \", \"\n    # Remove extra space & comma by stripping\n    # In Jupyter notebook/lab - can combine space & comma: .str.strip(\" ,\")\n    # For RStudio IDE - separate into two for this to work\n    ).str.strip(\n        \" \"\n    ).str.strip(\n        \",\"\n    # Split the texts by the specified punctuation e.g. comma with space\n    ).str.split(\n        by = \", \"\n    # Create a new column with a new name\n    ).alias(\n        \"Inactive\"\n    )\n# Explode the splitted texts into separate rows within the new column\n).explode(\n    \"Inactive\"\n)\n)\n\ndf_de\n\n\n\n\nshape: (840029, 2)\n\n\n\n\nInactive_excipients\n\n\nInactive\n\n\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n\"SILICON DIOXID...\n\n\n\"silicon dioxid...\n\n\n\n\n\"SILICON DIOXID...\n\n\n\"edetate disodi...\n\n\n\n\n\"SILICON DIOXID...\n\n\n\"lactose monohy...\n\n\n\n\n\"SILICON DIOXID...\n\n\n\"magnesium stea...\n\n\n\n\n\"SILICON DIOXID...\n\n\n\"cellulose\"\n\n\n\n\n\"SILICON DIOXID...\n\n\n\"microcrystalli...\n\n\n\n\n\"SILICON DIOXID...\n\n\n\"starch\"\n\n\n\n\n\"SILICON DIOXID...\n\n\n\"corn\"\n\n\n\n\n\"SILICON DIOXID...\n\n\n\"sodium lauryl ...\n\n\n\n\n\"SILICON DIOXID...\n\n\n\"fd&c blue no. ...\n\n\n\n\n\"SILICON DIOXID...\n\n\n\"fd&c red no. 4...\n\n\n\n\n\"SILICON DIOXID...\n\n\n\"gelatin\"\n\n\n\n\n...\n\n\n...\n\n\n\n\n\"Cellulose, mic...\n\n\n\"shellac\"\n\n\n\n\n\"Cellulose, mic...\n\n\n\"propylene glyc...\n\n\n\n\n\"Cellulose, mic...\n\n\n\"ammonia\"\n\n\n\n\n\"Cellulose, mic...\n\n\n\"fd&c blue no. ...\n\n\n\n\n\"ANHYDROUS DIBA...\n\n\n\"anhydrous diba...\n\n\n\n\n\"ANHYDROUS DIBA...\n\n\n\"ferric oxide r...\n\n\n\n\n\"ANHYDROUS DIBA...\n\n\n\"hypromelloses\"\n\n\n\n\n\"ANHYDROUS DIBA...\n\n\n\"polyethylene g...\n\n\n\n\n\"ANHYDROUS DIBA...\n\n\n\"magnesium stea...\n\n\n\n\n\"ANHYDROUS DIBA...\n\n\n\"titanium dioxi...\n\n\n\n\n\"ANHYDROUS DIBA...\n\n\n\"talc\"\n\n\n\n\n\"ANHYDROUS DIBA...\n\n\n\"ferric oxide y...\n\n\n\n\n\n\n\n\n# Quick look at the dataframe to see before and after text cleaning\nprint(df_de.glimpse())\n\nRows: 840029\nColumns: 2\n$ Inactive_excipients <Utf8> SILICON DIOXIDE;EDETATE DISODIUM;LACTOSE MONOHYDRATE;MAGNESIUM STEARATE;CELLULOSE, MICROCRYSTALLINE;STARCH, CORN;SODIUM LAURYL SULFATE;FD&C BLUE NO. 1;FD&C RED NO. 40;GELATIN;TITANIUM DIOXIDE;BUTYL ALCOHOL;, SILICON DIOXIDE;EDETATE DISODIUM;LACTOSE MONOHYDRATE;MAGNESIUM STEARATE;CELLULOSE, MICROCRYSTALLINE;STARCH, CORN;SODIUM LAURYL SULFATE;FD&C BLUE NO. 1;FD&C RED NO. 40;GELATIN;TITANIUM DIOXIDE;BUTYL ALCOHOL;, SILICON DIOXIDE;EDETATE DISODIUM;LACTOSE MONOHYDRATE;MAGNESIUM STEARATE;CELLULOSE, MICROCRYSTALLINE;STARCH, CORN;SODIUM LAURYL SULFATE;FD&C BLUE NO. 1;FD&C RED NO. 40;GELATIN;TITANIUM DIOXIDE;BUTYL ALCOHOL;, SILICON DIOXIDE;EDETATE DISODIUM;LACTOSE MONOHYDRATE;MAGNESIUM STEARATE;CELLULOSE, MICROCRYSTALLINE;STARCH, CORN;SODIUM LAURYL SULFATE;FD&C BLUE NO. 1;FD&C RED NO. 40;GELATIN;TITANIUM DIOXIDE;BUTYL ALCOHOL;, SILICON DIOXIDE;EDETATE DISODIUM;LACTOSE MONOHYDRATE;MAGNESIUM STEARATE;CELLULOSE, MICROCRYSTALLINE;STARCH, CORN;SODIUM LAURYL SULFATE;FD&C BLUE NO. 1;FD&C RED NO. 40;GELATIN;TITANIUM DIOXIDE;BUTYL ALCOHOL;, SILICON DIOXIDE;EDETATE DISODIUM;LACTOSE MONOHYDRATE;MAGNESIUM STEARATE;CELLULOSE, MICROCRYSTALLINE;STARCH, CORN;SODIUM LAURYL SULFATE;FD&C BLUE NO. 1;FD&C RED NO. 40;GELATIN;TITANIUM DIOXIDE;BUTYL ALCOHOL;, SILICON DIOXIDE;EDETATE DISODIUM;LACTOSE MONOHYDRATE;MAGNESIUM STEARATE;CELLULOSE, MICROCRYSTALLINE;STARCH, CORN;SODIUM LAURYL SULFATE;FD&C BLUE NO. 1;FD&C RED NO. 40;GELATIN;TITANIUM DIOXIDE;BUTYL ALCOHOL;, SILICON DIOXIDE;EDETATE DISODIUM;LACTOSE MONOHYDRATE;MAGNESIUM STEARATE;CELLULOSE, MICROCRYSTALLINE;STARCH, CORN;SODIUM LAURYL SULFATE;FD&C BLUE NO. 1;FD&C RED NO. 40;GELATIN;TITANIUM DIOXIDE;BUTYL ALCOHOL;, SILICON DIOXIDE;EDETATE DISODIUM;LACTOSE MONOHYDRATE;MAGNESIUM STEARATE;CELLULOSE, MICROCRYSTALLINE;STARCH, CORN;SODIUM LAURYL SULFATE;FD&C BLUE NO. 1;FD&C RED NO. 40;GELATIN;TITANIUM DIOXIDE;BUTYL ALCOHOL;, SILICON DIOXIDE;EDETATE DISODIUM;LACTOSE MONOHYDRATE;MAGNESIUM STEARATE;CELLULOSE, MICROCRYSTALLINE;STARCH, CORN;SODIUM LAURYL SULFATE;FD&C BLUE NO. 1;FD&C RED NO. 40;GELATIN;TITANIUM DIOXIDE;BUTYL ALCOHOL;\n$ Inactive            <Utf8> silicon dioxide, edetate disodium, lactose monohydrate, magnesium stearate, cellulose, microcrystalline, starch, corn, sodium lauryl sulfate, fd&c blue no. 1\n\n\n\nAs shown above, the “Inactive_excipients” column was the original column for excipients, where the second column named, “Inactive” was the new column shown after the punctuation tidy-ups, string strip and row text explosion. The excipients were broken down into individual terms, rather than in massively long strings which might not make sense to some readers.\n\n# Re-organise the dataframe to choose the cleaned \"Inactive\" column\ndf_final = df_de.select([\"Inactive\"])\ndf_final\n\n\n\n\nshape: (840029, 1)\n\n\n\n\nInactive\n\n\n\n\nstr\n\n\n\n\n\n\n\"silicon dioxid...\n\n\n\n\n\"edetate disodi...\n\n\n\n\n\"lactose monohy...\n\n\n\n\n\"magnesium stea...\n\n\n\n\n\"cellulose\"\n\n\n\n\n\"microcrystalli...\n\n\n\n\n\"starch\"\n\n\n\n\n\"corn\"\n\n\n\n\n\"sodium lauryl ...\n\n\n\n\n\"fd&c blue no. ...\n\n\n\n\n\"fd&c red no. 4...\n\n\n\n\n\"gelatin\"\n\n\n\n\n...\n\n\n\n\n\"shellac\"\n\n\n\n\n\"propylene glyc...\n\n\n\n\n\"ammonia\"\n\n\n\n\n\"fd&c blue no. ...\n\n\n\n\n\"anhydrous diba...\n\n\n\n\n\"ferric oxide r...\n\n\n\n\n\"hypromelloses\"\n\n\n\n\n\"polyethylene g...\n\n\n\n\n\"magnesium stea...\n\n\n\n\n\"titanium dioxi...\n\n\n\n\n\"talc\"\n\n\n\n\n\"ferric oxide y...\n\n\n\n\n\n\n\n\n# Remove all cells with null values\ndf_final = df_final.drop_nulls()\n\n\n# Group the data by different inactive excipients with counts shown\ndf_final = df_final.groupby(\"Inactive\").agg(pl.count())\ndf_final.head()\n\n\n\n\nshape: (5, 2)\n\n\n\n\nInactive\n\n\ncount\n\n\n\n\nstr\n\n\nu32\n\n\n\n\n\n\n\"propylene glyc...\n\n\n11310\n\n\n\n\n\"ammoniated\"\n\n\n5\n\n\n\n\n\"tricaprilin\"\n\n\n1\n\n\n\n\n\"potassium bica...\n\n\n20\n\n\n\n\n\"glyceryl mono ...\n\n\n6\n\n\n\n\n\n\n\n\n\nInactive excipient counts\n\n# Count each excipient and cast the whole column into integers\ndf_final = df_final.with_column((pl.col(\"count\")).cast(pl.Int64, strict = False))\ndf_final\n\n\n\n\nshape: (1674, 2)\n\n\n\n\nInactive\n\n\ncount\n\n\n\n\nstr\n\n\ni64\n\n\n\n\n\n\n\"propylene glyc...\n\n\n11310\n\n\n\n\n\"ammoniated\"\n\n\n5\n\n\n\n\n\"tricaprilin\"\n\n\n1\n\n\n\n\n\"potassium bica...\n\n\n20\n\n\n\n\n\"glyceryl mono ...\n\n\n6\n\n\n\n\n\"kollidon sr\"\n\n\n4\n\n\n\n\n\" dextrose mono...\n\n\n1\n\n\n\n\n\"d&c red no. 21...\n\n\n3\n\n\n\n\n\" 2000 mw)\"\n\n\n7\n\n\n\n\n\"citrus sinensi...\n\n\n2\n\n\n\n\n\"2-ethylaminoet...\n\n\n1\n\n\n\n\n\"methyl alcohol...\n\n\n1\n\n\n\n\n...\n\n\n...\n\n\n\n\n\"polyethylene o...\n\n\n6\n\n\n\n\n\"gardenia jasmi...\n\n\n1\n\n\n\n\n\"ethyl 2-methyl...\n\n\n3\n\n\n\n\n\"yellow\"\n\n\n2\n\n\n\n\n\" water \"\n\n\n1\n\n\n\n\n\"wax\"\n\n\n2\n\n\n\n\n\"ethylcellulose...\n\n\n2\n\n\n\n\n\"lime oil\"\n\n\n2\n\n\n\n\n\"trimethylsilyl...\n\n\n4\n\n\n\n\n\"adrabetadex\"\n\n\n1\n\n\n\n\n\"agathosma betu...\n\n\n1\n\n\n\n\n\"ubidecarenone\"\n\n\n7\n\n\n\n\n\n\n\n\n\nOverview of inactive excipients used in oral dosage forms\n\nfig = px.scatter(x = df_final[\"Inactive\"], \n                 y = df_final[\"count\"], \n                 hover_name = df_final[\"Inactive\"],\n                 title = \"Inactive excipients and their respective counts in pills\")\n\nfig.update_layout(\n    title = dict(\n        font = dict(\n            size = 15)),\n    title_x = 0.5,\n    margin = dict(\n        l = 20, r = 20, t = 40, b = 10),\n    xaxis = dict(\n        tickfont = dict(size = 9), \n        title = \"Inactive excipients\"\n    ),\n    yaxis = dict(\n        tickfont = dict(size = 9), \n        title = \"Counts\"\n    ),\n    legend = dict(\n        font = dict(\n            size = 9)))\n\n\nfig.show()\n\n\n                                                \n\n\n\n\nFrequently used inactive excipients\n\n# Re-order the excipients with counts in descending order\n# Filter out only the ones with counts over 10,000\ndf_ex = df_final.sort(\"count\", reverse = True).filter((pl.col(\"count\")) >= 10000)\ndf_ex.head()\n\n\n\n\nshape: (5, 2)\n\n\n\n\nInactive\n\n\ncount\n\n\n\n\nstr\n\n\ni64\n\n\n\n\n\n\n\"magnesium stea...\n\n\n58908\n\n\n\n\n\"titanium dioxi...\n\n\n43241\n\n\n\n\n\"unspecified\"\n\n\n35744\n\n\n\n\n\"silicon dioxid...\n\n\n34037\n\n\n\n\n\"starch\"\n\n\n32501\n\n\n\n\n\n\n\n\nfig = px.bar(x = df_ex[\"Inactive\"], \n             y = df_ex[\"count\"], \n             color = df_ex[\"Inactive\"],\n             title = \"Commonly used inactive excipients in pills\")\n\nfig.update_layout(\n    title = dict(\n        font = dict(\n            size = 15)),\n    title_x = 0.5,\n    margin = dict(\n        l = 10, r = 10, t = 40, b = 5),\n    xaxis = dict(\n        tickfont = dict(size = 9), \n        title = \"Inactive excipients\"\n    ),\n    yaxis = dict(\n        tickfont = dict(size = 9), \n        title = \"Counts\"\n    ),\n    legend = dict(\n        font = dict(\n            size = 9)))\n\nfig.show()\n\n\n                                                \n\n\n\nThe text cleaning might not be perfect at this stage, but I think I’ve managed to get most of the core texts cleaned into a more sensible and readable formats. From what I’ve worked out here, the most frequently used inactive ingredient was magnesium stearate, which was followed by titanium dioxide, and then interestingly “unspecified”, which was exactly how it was documented in the original pillbox dataset at the beginning. I didn’t go further digging into what this “unspecified” inactive excipients might be, as in whether it meant it in a singular or plural forms. So this still remained a mystery at this stage, but if all these oral medications were FDA-approved, we would’ve hoped each and everyone of these pills would be verified in safety, quality and effectiveness before they entered into the market for wide prescriptions. In the worst case, each therapeutic drug should also have post-marketing surveillance, for long-term safety monitoring.\n\n\n\n\nCreate a small dataframe for data visualisation in Rust-Evcxr\nAll acetaminophens were filtered out in the “Drug_strength” column and all duplicates were removed in the dataset.\n\ndf_ac = df_new.filter(\n    pl.col(\"Drug_strength\")\n    .str.starts_with(\"acetam\")).unique(subset = [\"Drug_strength\"])\n\ndf_ac\n\n\n\n\nshape: (13, 5)\n\n\n\n\nShape\n\n\nColour\n\n\nDrug_strength\n\n\nInactive_excipients\n\n\nDosage_form\n\n\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n\"CAPSULE\"\n\n\n\"RED\"\n\n\n\"acetaminophen ...\n\n\n\"starch, corn /...\n\n\n\"CAPSULE\"\n\n\n\n\n\"OVAL\"\n\n\n\"WHITE\"\n\n\n\"acetaminophen ...\n\n\n\"anhydrous citr...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"acetaminophen ...\n\n\n\"powdered cellu...\n\n\n\"TABLET\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"acetaminophen ...\n\n\n\"hydroxypropyl ...\n\n\n\"TABLET\"\n\n\n\n\n\"OVAL\"\n\n\n\"ORANGE\"\n\n\n\"acetaminophen ...\n\n\nnull\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"ROUND\"\n\n\n\"BLUE\"\n\n\n\"acetaminophen ...\n\n\n\"FD&C BLUE NO. ...\n\n\n\"TABLET\"\n\n\n\n\n\"ROUND\"\n\n\n\"YELLOW;WHITE\"\n\n\n\"acetaminophen ...\n\n\n\"calcium steara...\n\n\n\"TABLET\"\n\n\n\n\n\"OVAL\"\n\n\n\"WHITE\"\n\n\n\"acetaminophen ...\n\n\n\"carnauba wax;s...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"acetaminophen ...\n\n\n\"powdered cellu...\n\n\n\"TABLET\"\n\n\n\n\n\"CAPSULE\"\n\n\n\"ORANGE;BROWN\"\n\n\n\"acetaminophen ...\n\n\n\"CALCIUM PHOSPH...\n\n\n\"CAPSULE\"\n\n\n\n\n\"OVAL\"\n\n\n\"WHITE\"\n\n\n\"acetaminophen ...\n\n\n\"carnauba wax;H...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"acetaminophen ...\n\n\n\"calcium steara...\n\n\n\"TABLET\"\n\n\n\n\n\"OVAL\"\n\n\n\"BLUE\"\n\n\n\"acetaminophen ...\n\n\n\"carnauba wax;C...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\n\n\nI’ve opted for finding out the different types of colours with their respective counts in oral acetaminophen, or also known as paracetamol in some other countries.\n\ndf_ac = df_ac.groupby(\"Colour\").agg(pl.count())\ndf_ac\n\n\n\n\nshape: (6, 2)\n\n\n\n\nColour\n\n\ncount\n\n\n\n\nstr\n\n\nu32\n\n\n\n\n\n\n\"RED\"\n\n\n1\n\n\n\n\n\"BLUE\"\n\n\n2\n\n\n\n\n\"ORANGE\"\n\n\n1\n\n\n\n\n\"WHITE\"\n\n\n7\n\n\n\n\n\"YELLOW;WHITE\"\n\n\n1\n\n\n\n\n\"ORANGE;BROWN\"\n\n\n1\n\n\n\n\n\n\n\n\nfig = px.scatter(x = df_ac[\"Colour\"], \n                 y = df_ac[\"count\"], \n                 size = df_ac[\"count\"], \n                 color = df_ac[\"Colour\"],\n                 title = \"Frequency of colours in acetaminophen (paracetamol) oral dosage forms\"\n                )\n\nfig.update_layout(\n    xaxis = dict(\n        title = \"Colours\"\n    ), \n    yaxis = dict(\n        title = \"Counts\"\n    )\n)\n\nfig.show()\n\n\n                                                \n\n\n\nI’ve decided to keep the dataframe very simple for part 3 as my original intention was to trial plotting a graph in Evcxr only (nothing fancy at this stage), and also to gain some familiarities with Rust as another new programming language for me. Readers might notice that I’ve opted for a scatter plot in Plotly (in Python3 kernel) here for this last dataframe, and when we finally got to part 3 (hopefully coming soon as I needed to figure how to publish Rust codes in Quarto…), I might very likely revert this to a bar graph (in Rust kernel), due to some technical issues (slow dependency loading, and somehow with Plotly.rs in Evcxr, the scatter graph looked more like scatter line graph instead… more stories to follow) and being a new Rust-Evcxr user. At the very least, I’ve kind of tried something I’ve planned for, although not looking very elegant yet, with rooms for improvements in the future."
  },
  {
    "objectID": "posts/09_Pills/Rust_polars_pills_ws.html",
    "href": "posts/09_Pills/Rust_polars_pills_ws.html",
    "title": "Pills dataset - Part 1",
    "section": "",
    "text": "Introduction\nAs mentioned in my last project, I’ve tried using Evcxr, which provided a way to use Rust interactively in a Jupyter environment. The name, “Evcxr”, was quite hard to remember at first. It was pronounced as “e-vic-ser” according to the author, which I’ve randomly come across in an online tech interview when I was looking into it. I’ve also sort of worked out a way to memorise its spelling by taking specific letters out of “evaluation context for rust” (which was what it was called in its GitHub repository).\nFor users of Jupyter Notebook/Lab and Python, they might be quite used to the working speed of the cell outputs. However, one thing I’ve noticed when I was using Evcxr or Rust kernel in Jupyter Lab was that the speed of cell outputs was noticeably slower (especially at the beginning while loading all the dependencies required). The speed improved when loading external crates and modules, and generally it was faster afterward.\nDue to this reason (note: I did not look into any other optimising strategies for this and this could be restricted to my computer hardware specs, so this might differ for other users), I think Evcxr was not ideal for a very large and complex data science project yet (however if its ecosystem kept developing, it might be improved in the future). One thing of note was that when I was combing through issues in Evcxr’s GitHub repository, someone mentioned the slow compile time of the Rust compiler, which would have likely caused the snail speed, but knowing that the actual program running speed was blazingly fast, some sacrifice at the beginning made sense to me. Overall, Rust was really a systems programming language with memory efficiency (with no garbage collector), type safety and concurrency as some of its notable advantages.\nBecause of the dependency loading issue in the Jupyter environment, and also knowing there was already a dataframe library built from Rust, I’ve opted to use Polars-Python again for the data wrangling part of this project. This was also accompanied by the good old Pandas library as well (under the section of “Transform web-scraped data into dataframe” if anyone wants to jump to that part to see the codes). I then went on to trial using Rust via Evcxr for data visualisation based on a small dataframe by using Plotly.rs. This project would be separated into 3 parts:\n\nPart 1: Initial pillbox dataset loading and web-scraping\nPart 2: Data wrangling and mining for data visualisations\nPart 3: Using Rust for data visualisation\n\nThe main reason I wanted to try Evcxr was that I could see the potential of using Rust interactively to showcase the results in a relatively fast and efficient manner. This meant specific data exploratory results could reach wider audience, leading to more impacts in different fields, in a very broad term. Oppositely, for more specific users such as scientists or engineers, this meant experiments could be carried out in a safe and efficient manner, with test results readily available for future work planning.\n\n\n\nDownload dataset\nThis time the dataset was spotted from Data Is Plural, specifically the 2022.11.30 edition. The section I was interested in was the first paragraph at the top, about “Pills”. By going into one of the links provided in the paragraph, this brought me to the Pillbox dataset from the US National Library of Medicine (NLM). The .csv file was downloaded via the “Export” button at the top right of the webpage.\nThis pillbox dataset was actually retired since 28th January 2021, but was still available for educational or research purposes only. Therefore, it was not recommended for pill identifications as the dataset was not up-to-date. Alternative resources such as DailyMed would be more appropriate for readers in the US (as one of the examples). For readers in other countries, local health professionals and resources would be recommended for up-to-date information.\n\n\n\nImporting library & dataset\n\n# Install/upgrade polars if needed (uncomment the line below)\n#pip install --upgrade polars\n\n\nimport polars as pl\n\n\n# Check version of polars (uncomment line below)\n#pl.show_versions()\n\n\ndf = pl.read_csv(\"pillbox.csv\", ignore_errors = True)\ndf\n\n\n\n\nshape: (83925, 55)\n\n\n\n\nID\n\n\nEnabled?\n\n\ncreated at\n\n\nupdated at\n\n\nspp\n\n\nsetid\n\n\nsplsize\n\n\npillbox_size\n\n\nsplshape\n\n\nsplshape_text\n\n\npillbox_shape_text\n\n\nsplscore\n\n\npillbox_score\n\n\nsplimprint\n\n\npillbox_imprint\n\n\nsplcolor\n\n\nsplcolor_text\n\n\npillbox_color_text\n\n\nspl_strength\n\n\nspl_ingredients\n\n\nspl_inactive_ing\n\n\nsource\n\n\nrxtty\n\n\nrxstring\n\n\nrxcui\n\n\nRxNorm Update time\n\n\nproduct_code\n\n\npart_num\n\n\npart_medicine_name\n\n\nndc9\n\n\nndc_labeler_code\n\n\nndc_product_code\n\n\nmedicine_name\n\n\nmarketing_act_code\n\n\neffective_time\n\n\nfile_name\n\n\nequal_product_code\n\n\ndosage_form\n\n\ndocument_type\n\n\ndea_schedule_code\n\n\ndea_schedule_name\n\n\nauthor_type\n\n\nauthor\n\n\napproval_code\n\n\nimage_source\n\n\nsplimage\n\n\nhas_image\n\n\nepc_match\n\n\nversion_number\n\n\nlaberer_code\n\n\napplication_number\n\n\nupdated\n\n\nstale\n\n\nnew\n\n\nPillbox Value\n\n\n\n\ni64\n\n\nbool\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\ni64\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\ni64\n\n\ni64\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\ni64\n\n\nstr\n\n\nstr\n\n\ni64\n\n\nstr\n\n\ni64\n\n\ni64\n\n\ni64\n\n\nstr\n\n\nstr\n\n\ni64\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nbool\n\n\ni64\n\n\ni64\n\n\nstr\n\n\nstr\n\n\nbool\n\n\nbool\n\n\nbool\n\n\nbool\n\n\n\n\n\n\n41846\n\n\ntrue\n\n\n\"10/17/2017 05:...\n\n\n\"10/02/2020 05:...\n\n\n\"471fa2f1-73a0-...\n\n\n\"471fa2f1-73a0-...\n\n\n16\n\n\nnull\n\n\n\"C48336\"\n\n\n\"CAPSULE\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"5892;V\"\n\n\nnull\n\n\n\"C48328\"\n\n\n\"PINK\"\n\n\nnull\n\n\n\"TEMAZEPAM 15 m...\n\n\n\"TEMAZEPAM[TEMA...\n\n\n\"SILICON DIOXID...\n\n\n\"HRX\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"10/02/2020 04:...\n\n\n\"0603-5892\"\n\n\n0\n\n\nnull\n\n\n6035892\n\n\n603\n\n\n5892\n\n\n\"Temazepam\"\n\n\n\"completed\"\n\n\n20160406\n\n\n\"d912ca54-6569-...\n\n\nnull\n\n\n\"C25158\"\n\n\nnull\n\n\n\"C48677\"\n\n\n\"CIV\"\n\n\n\"LABELER\"\n\n\n\"Qualitest Phar...\n\n\n\"C73584\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n5\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n8100\n\n\ntrue\n\n\n\"10/17/2017 05:...\n\n\n\"10/02/2020 04:...\n\n\n\"116e13c1-ac50-...\n\n\n\"116e13c1-ac50-...\n\n\n10\n\n\nnull\n\n\n\"C48348\"\n\n\n\"ROUND\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"I2\"\n\n\nnull\n\n\n\"C48331\"\n\n\n\"ORANGE\"\n\n\nnull\n\n\n\"IBUPROFEN 200 ...\n\n\n\"IBUPROFEN[IBUP...\n\n\n\"SILICON DIOXID...\n\n\n\"HOTC\"\n\n\n\"SCD\"\n\n\n\"ibuprofen 200 ...\n\n\n310965\n\n\n\"10/02/2020 03:...\n\n\n\"59779-074\"\n\n\n0\n\n\nnull\n\n\n597790074\n\n\n59779\n\n\n74\n\n\n\"ibuprofen\"\n\n\n\"active\"\n\n\n20191120\n\n\n\"55de9f94-89b2-...\n\n\nnull\n\n\n\"C42931\"\n\n\n\"34390-5\"\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"CVS Pharmacy\"\n\n\n\"C73584\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n4\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n5258\n\n\ntrue\n\n\n\"10/17/2017 05:...\n\n\n\"10/17/2017 05:...\n\n\n\"827ce261-307b-...\n\n\n\"827ce261-307b-...\n\n\n7\n\n\nnull\n\n\n\"C48346\"\n\n\n\"PENTAGON (5 SI...\n\n\nnull\n\n\n1\n\n\n2\n\n\n\"par;129\"\n\n\nnull\n\n\n\"C48329\"\n\n\n\"GREEN\"\n\n\nnull\n\n\n\"DEXAMETHASONE ...\n\n\n\"DEXAMETHASONE[...\n\n\n\"ANHYDROUS LACT...\n\n\n\"HRX\"\n\n\nnull\n\n\n\"Dexamethasone ...\n\n\n197583\n\n\nnull\n\n\n\"49884-129\"\n\n\n0\n\n\nnull\n\n\n498840129\n\n\n49884\n\n\n129\n\n\n\"Dexamethasone\"\n\n\n\"active\"\n\n\n20120516\n\n\n\"85a9eebb-be74-...\n\n\nnull\n\n\n\"C42998\"\n\n\n\"34391-3\"\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"Par Pharmaceut...\n\n\n\"C73584\"\n\n\n\"NLM\"\n\n\n\"498840129\"\n\n\ntrue\n\n\nnull\n\n\n4\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\ntrue\n\n\nfalse\n\n\ntrue\n\n\n\n\n21271\n\n\ntrue\n\n\n\"10/17/2017 05:...\n\n\n\"10/02/2020 05:...\n\n\n\"f7f1c99e-1a67-...\n\n\n\"f7f1c99e-1a67-...\n\n\n11\n\n\nnull\n\n\n\"C48348\"\n\n\n\"ROUND\"\n\n\nnull\n\n\n2\n\n\nnull\n\n\n\"LL\"\n\n\nnull\n\n\n\"C48325\"\n\n\n\"WHITE\"\n\n\nnull\n\n\n\"Nickel Sulfate...\n\n\n\"Nickel Sulfate...\n\n\nnull\n\n\n\"HOMEO\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"10/02/2020 04:...\n\n\n\"61480-137\"\n\n\n0\n\n\nnull\n\n\n614800137\n\n\n61480\n\n\n137\n\n\n\"Acunol\"\n\n\n\"active\"\n\n\n20190909\n\n\n\"029eaf64-e66f-...\n\n\nnull\n\n\n\"C42998\"\n\n\n\"34391-3\"\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"PLYMOUTH HEALT...\n\n\n\"C73614\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n8\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n77050\n\n\ntrue\n\n\n\"09/20/2019 09:...\n\n\n\"10/02/2020 05:...\n\n\n\"ecb28fcb-f0d1-...\n\n\n\"ecb28fcb-f0d1-...\n\n\n6\n\n\nnull\n\n\n\"C48348\"\n\n\n\"ROUND\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"L;524\"\n\n\nnull\n\n\n\"C48325\"\n\n\n\"WHITE\"\n\n\nnull\n\n\n\"CLONAZEPAM 0.2...\n\n\n\"CLONAZEPAM[CLO...\n\n\n\"SORBITOL;ASPAR...\n\n\n\"HRX\"\n\n\n\"SCD\"\n\n\n\"clonazepam 0.2...\n\n\n349195\n\n\n\"10/02/2020 04:...\n\n\n\"62332-365\"\n\n\n0\n\n\nnull\n\n\n623320365\n\n\n62332\n\n\n365\n\n\n\"CLONAZEPAM\"\n\n\n\"active\"\n\n\n20190701\n\n\n\"ba5120ce-ed74-...\n\n\nnull\n\n\n\"C42999\"\n\n\nnull\n\n\n\"C48677\"\n\n\n\"CIV\"\n\n\n\"LABELER\"\n\n\n\"Alembic Pharma...\n\n\n\"C73584\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n3\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n76916\n\n\ntrue\n\n\n\"09/20/2019 09:...\n\n\n\"10/02/2020 05:...\n\n\n\"442e41da-24c2-...\n\n\n\"442e41da-24c2-...\n\n\n9\n\n\nnull\n\n\n\"C48348\"\n\n\n\"ROUND\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"LU;V06\"\n\n\nnull\n\n\n\"C48325\"\n\n\n\"WHITE\"\n\n\nnull\n\n\n\"SILDENAFIL CIT...\n\n\n\"SILDENAFIL CIT...\n\n\n\"ANHYDROUS DIBA...\n\n\n\"HRX\"\n\n\n\"SCD\"\n\n\n\"sildenafil 50 ...\n\n\n312950\n\n\n\"10/02/2020 04:...\n\n\n\"70748-132\"\n\n\n0\n\n\nnull\n\n\n707480132\n\n\n70748\n\n\n132\n\n\n\"SILDENAFIL\"\n\n\n\"active\"\n\n\n20191001\n\n\n\"17c537d9-b2e6-...\n\n\nnull\n\n\n\"C42931\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"Lupin Pharmace...\n\n\n\"C73584\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n4\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n20016\n\n\ntrue\n\n\n\"10/17/2017 05:...\n\n\n\"10/02/2020 05:...\n\n\n\"5f0bdf9d-fa78-...\n\n\n\"5f0bdf9d-fa78-...\n\n\n14\n\n\nnull\n\n\n\"C48345\"\n\n\n\"OVAL\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"A;73\"\n\n\nnull\n\n\n\"C48330\"\n\n\n\"YELLOW\"\n\n\nnull\n\n\n\"RISPERIDONE 3 ...\n\n\n\"RISPERIDONE[RI...\n\n\n\"LACTOSE MONOHY...\n\n\n\"HRX\"\n\n\n\"SCD\"\n\n\n\"risperidone 3 ...\n\n\n312832\n\n\n\"10/02/2020 04:...\n\n\n\"65862-123\"\n\n\n0\n\n\nnull\n\n\n658620123\n\n\n65862\n\n\n123\n\n\n\"Risperidone\"\n\n\n\"active\"\n\n\n20180924\n\n\n\"5d2750a4-025a-...\n\n\nnull\n\n\n\"C42931\"\n\n\n\"34391-3\"\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"Aurobindo Phar...\n\n\n\"C73584\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n21\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n67902\n\n\ntrue\n\n\n\"06/27/2019 10:...\n\n\n\"10/02/2020 05:...\n\n\n\"572e672e-b759-...\n\n\n\"572e672e-b759-...\n\n\n19\n\n\nnull\n\n\n\"C48336\"\n\n\n\"CAPSULE\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"AT146\"\n\n\nnull\n\n\n\"C48333\"\n\n\n\"BLUE\"\n\n\nnull\n\n\n\"IBUPROFEN 200 ...\n\n\n\"IBUPROFEN[IBUP...\n\n\n\"FD&C BLUE NO. ...\n\n\n\"HOTC\"\n\n\n\"SCD\"\n\n\n\"ibuprofen 200 ...\n\n\n310964\n\n\n\"10/02/2020 03:...\n\n\n\"50804-750\"\n\n\n0\n\n\nnull\n\n\n508040750\n\n\n50804\n\n\n750\n\n\n\"Ibuprofen\"\n\n\n\"active\"\n\n\n20191101\n\n\n\"148c7665-22d5-...\n\n\nnull\n\n\n\"C42954\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"Good Sense (Ge...\n\n\n\"C73584\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n2\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n75997\n\n\ntrue\n\n\n\"09/20/2019 09:...\n\n\n\"10/02/2020 05:...\n\n\n\"6f17cc91-86b3-...\n\n\n\"6f17cc91-86b3-...\n\n\n12\n\n\nnull\n\n\n\"C48348\"\n\n\n\"ROUND\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"T;12\"\n\n\nnull\n\n\n\"C48325\"\n\n\n\"WHITE\"\n\n\nnull\n\n\n\"Iloperidone 12...\n\n\n\"Iloperidone[Il...\n\n\n\"silicon dioxid...\n\n\n\"HRX\"\n\n\n\"SCD\"\n\n\n\"iloperidone 12...\n\n\n848732\n\n\n\"10/02/2020 04:...\n\n\n\"51672-4184\"\n\n\n0\n\n\nnull\n\n\n516724184\n\n\n51672\n\n\n4184\n\n\n\"Iloperidone\"\n\n\n\"active\"\n\n\n20190802\n\n\n\"6787555e-8a11-...\n\n\nnull\n\n\n\"C42998\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"Taro Pharmaceu...\n\n\n\"C73584\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n1\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n1288\n\n\ntrue\n\n\n\"10/17/2017 05:...\n\n\n\"10/17/2017 05:...\n\n\n\"02a23e48-f371-...\n\n\n\"02a23e48-f371-...\n\n\n23\n\n\nnull\n\n\n\"C48336\"\n\n\n\"CAPSULE\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"RX681\"\n\n\nnull\n\n\n\"C48330;C48325\"\n\n\n\"YELLOW;WHITE\"\n\n\nnull\n\n\n\"FENOPROFEN CAL...\n\n\n\"FENOPROFEN CAL...\n\n\n\"CROSPOVIDONE;M...\n\n\n\"HRX\"\n\n\nnull\n\n\n\"Fenoprofen 200...\n\n\n1799325\n\n\nnull\n\n\n\"54288-129\"\n\n\n0\n\n\nnull\n\n\n542880129\n\n\n54288\n\n\n129\n\n\n\"FENORTHO\"\n\n\n\"active\"\n\n\n20160614\n\n\n\"91b0ac5b-994c-...\n\n\nnull\n\n\n\"C25158\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"BPI Labs LLC\"\n\n\n\"C73594\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n2\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\n\n\n53601\n\n\ntrue\n\n\n\"10/17/2017 09:...\n\n\n\"10/02/2020 05:...\n\n\n\"d2213ffd-18f6-...\n\n\n\"d2213ffd-18f6-...\n\n\n12\n\n\nnull\n\n\n\"C48348\"\n\n\n\"ROUND\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"BA;300\"\n\n\nnull\n\n\n\"C48330\"\n\n\n\"YELLOW\"\n\n\nnull\n\n\n\"BUTALBITAL 50 ...\n\n\n\"BUTALBITAL[BUT...\n\n\n\"STARCH, CORN;C...\n\n\n\"HRX\"\n\n\n\"SCD\"\n\n\n\"acetaminophen ...\n\n\n1249617\n\n\n\"10/02/2020 03:...\n\n\n\"68682-306\"\n\n\n0\n\n\nnull\n\n\n686820306\n\n\n68682\n\n\n306\n\n\n\"Butalbital and...\n\n\n\"active\"\n\n\n20200402\n\n\n\"18ee9ab7-9e5d-...\n\n\nnull\n\n\n\"C42998\"\n\n\nnull\n\n\n\"C48676\"\n\n\n\"CIII\"\n\n\n\"LABELER\"\n\n\n\"Oceanside Phar...\n\n\n\"C73584\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n3\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n1528\n\n\ntrue\n\n\n\"10/17/2017 05:...\n\n\n\"10/02/2020 05:...\n\n\n\"3b8a7426-6f1c-...\n\n\n\"3b8a7426-6f1c-...\n\n\n6\n\n\nnull\n\n\n\"C48348\"\n\n\n\"ROUND\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"M53;LU\"\n\n\nnull\n\n\n\"C48325\"\n\n\n\"WHITE\"\n\n\nnull\n\n\n\"ESTRADIOL 0.5 ...\n\n\n\"ESTRADIOL[ESTR...\n\n\n\"COPOVIDONE K25...\n\n\n\"HRX\"\n\n\n\"BPCK\"\n\n\n\"{28 (estradiol...\n\n\n1806683\n\n\n\"10/02/2020 03:...\n\n\n\"68180-829\"\n\n\n0\n\n\nnull\n\n\n681800829\n\n\n68180\n\n\n829\n\n\n\"AMABELZ\"\n\n\n\"completed\"\n\n\n20200928\n\n\n\"34d4f5d6-6526-...\n\n\nnull\n\n\n\"C42998\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"Lupin Pharmace...\n\n\n\"C73584\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n7\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n\n\n19475\n\n\ntrue\n\n\n\"10/17/2017 05:...\n\n\n\"10/02/2020 05:...\n\n\n\"be032f1e-c123-...\n\n\n\"be032f1e-c123-...\n\n\n8\n\n\nnull\n\n\n\"C48348\"\n\n\n\"ROUND\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"M;104\"\n\n\nnull\n\n\n\"C48325\"\n\n\n\"WHITE\"\n\n\nnull\n\n\n\"MEMANTINE HYDR...\n\n\n\"MEMANTINE HYDR...\n\n\n\"SILICON DIOXID...\n\n\n\"HRX\"\n\n\n\"SCD\"\n\n\n\"memantine hydr...\n\n\n996561\n\n\n\"10/02/2020 04:...\n\n\n\"0378-1104\"\n\n\n0\n\n\nnull\n\n\n3781104\n\n\n378\n\n\n1104\n\n\n\"Memantine Hydr...\n\n\n\"completed\"\n\n\n20140924\n\n\n\"4b207674-ac13-...\n\n\nnull\n\n\n\"C42998\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"Mylan Pharmace...\n\n\n\"C73584\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n5\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n78691\n\n\ntrue\n\n\n\"12/06/2019 06:...\n\n\n\"10/02/2020 05:...\n\n\n\"3c7ef3cf-f7f9-...\n\n\n\"3c7ef3cf-f7f9-...\n\n\n20\n\n\nnull\n\n\n\"C48336\"\n\n\n\"CAPSULE\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"P19\"\n\n\nnull\n\n\n\"C48331\"\n\n\n\"ORANGE\"\n\n\nnull\n\n\n\"ACETAMINOPHEN ...\n\n\n\"ACETAMINOPHEN[...\n\n\n\"BUTYLATED HYDR...\n\n\n\"HOTC\"\n\n\n\"SCD\"\n\n\n\"acetaminophen ...\n\n\n1086997\n\n\n\"10/02/2020 04:...\n\n\n\"72476-848\"\n\n\n0\n\n\nnull\n\n\n724760848\n\n\n72476\n\n\n848\n\n\n\"Multi-Symptom ...\n\n\n\"active\"\n\n\n20191029\n\n\n\"c4f51f20-dd42-...\n\n\nnull\n\n\n\"C42954\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"Care One (Reta...\n\n\n\"C73603\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n1\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\ntrue\n\n\n\n\n38030\n\n\ntrue\n\n\n\"10/17/2017 05:...\n\n\n\"10/02/2020 05:...\n\n\n\"e08920c2-04a3-...\n\n\n\"e08920c2-04a3-...\n\n\n9\n\n\nnull\n\n\n\"C48348\"\n\n\n\"ROUND\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"D99\"\n\n\nnull\n\n\n\"C48325\"\n\n\n\"WHITE\"\n\n\nnull\n\n\n\"LAMOTRIGINE 25...\n\n\n\"LAMOTRIGINE[LA...\n\n\n\"MAGNESIUM CARB...\n\n\n\"HRX\"\n\n\n\"SCD\"\n\n\n\"lamotrigine 25...\n\n\n311264\n\n\n\"10/02/2020 04:...\n\n\n\"65862-362\"\n\n\n0\n\n\nnull\n\n\n658620362\n\n\n65862\n\n\n362\n\n\n\"Lamotrigine\"\n\n\n\"active\"\n\n\n20191029\n\n\n\"59344318-d7b4-...\n\n\nnull\n\n\n\"C42893\"\n\n\n\"34391-3\"\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"Aurobindo Phar...\n\n\n\"C73584\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n20\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n78672\n\n\ntrue\n\n\n\"12/06/2019 06:...\n\n\n\"10/02/2020 05:...\n\n\n\"ee1477ed-00c4-...\n\n\n\"ee1477ed-00c4-...\n\n\n17\n\n\nnull\n\n\n\"C48345\"\n\n\n\"OVAL\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"AAA;1139\"\n\n\nnull\n\n\n\"C48333\"\n\n\n\"BLUE\"\n\n\nnull\n\n\n\"ACETAMINOPHEN ...\n\n\n\"ACETAMINOPHEN[...\n\n\n\"ACESULFAME POT...\n\n\n\"HOTC\"\n\n\n\"GPCK\"\n\n\n\"{8 (acetaminop...\n\n\n1801964\n\n\n\"10/02/2020 04:...\n\n\n\"37808-286\"\n\n\n2\n\n\n\"Acetaminophen,...\n\n\n378080286\n\n\n37808\n\n\n286\n\n\n\"Cold Flu Sever...\n\n\nnull\n\n\n20191004\n\n\n\"941e4166-0964-...\n\n\nnull\n\n\n\"C42897\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"HEB\"\n\n\n\"C73603\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n2\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\ntrue\n\n\n\n\n71471\n\n\ntrue\n\n\n\"06/29/2019 04:...\n\n\n\"10/02/2020 05:...\n\n\n\"a2754618-3df1-...\n\n\n\"a2754618-3df1-...\n\n\n19\n\n\nnull\n\n\n\"C48345\"\n\n\n\"OVAL\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"600\"\n\n\nnull\n\n\n\"C48325\"\n\n\n\"WHITE\"\n\n\nnull\n\n\n\"AZITHROMYCIN D...\n\n\n\"AZITHROMYCIN D...\n\n\n\"CROSCARMELLOSE...\n\n\n\"HRX\"\n\n\n\"SCD\"\n\n\n\"azithromycin 6...\n\n\n204844\n\n\n\"10/02/2020 03:...\n\n\n\"69452-173\"\n\n\n0\n\n\nnull\n\n\n694520173\n\n\n69452\n\n\n173\n\n\n\"Azithromycin\"\n\n\n\"active\"\n\n\n20200624\n\n\n\"a8d7dd04-c391-...\n\n\nnull\n\n\n\"C42931\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"Bionpharma Inc...\n\n\n\"C73584\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n6\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n68841\n\n\ntrue\n\n\n\"06/27/2019 10:...\n\n\n\"10/02/2020 05:...\n\n\n\"7af82ca5-ea36-...\n\n\n\"7af82ca5-ea36-...\n\n\n16\n\n\nnull\n\n\n\"C48345\"\n\n\n\"OVAL\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"1007\"\n\n\nnull\n\n\n\"C48333\"\n\n\n\"BLUE\"\n\n\nnull\n\n\n\"IBUPROFEN 200 ...\n\n\n\"IBUPROFEN[IBUP...\n\n\n\"FD&C BLUE NO. ...\n\n\n\"HOTC\"\n\n\n\"SCD\"\n\n\n\"diphenhydramin...\n\n\n901814\n\n\n\"10/02/2020 03:...\n\n\n\"36800-756\"\n\n\n0\n\n\nnull\n\n\n368000756\n\n\n36800\n\n\n756\n\n\n\"Ibuprofen PM\"\n\n\n\"active\"\n\n\n20191014\n\n\n\"b181db0f-8b6a-...\n\n\nnull\n\n\n\"C42954\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"TOP CARE (Topc...\n\n\n\"C73584\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n2\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n7862\n\n\ntrue\n\n\n\"10/17/2017 05:...\n\n\n\"10/02/2020 05:...\n\n\n\"edc05451-822e-...\n\n\n\"edc05451-822e-...\n\n\n10\n\n\nnull\n\n\n\"C48345\"\n\n\n\"OVAL\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"4H2\"\n\n\nnull\n\n\n\"C48325\"\n\n\n\"WHITE\"\n\n\nnull\n\n\n\"CETIRIZINE HYD...\n\n\n\"CETIRIZINE HYD...\n\n\n\"STARCH, CORN;H...\n\n\n\"HOTC\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"10/02/2020 03:...\n\n\n\"49738-600\"\n\n\n0\n\n\nnull\n\n\n497380600\n\n\n49738\n\n\n600\n\n\n\"smart sense al...\n\n\n\"active\"\n\n\n20160721\n\n\n\"9ceb8c88-c221-...\n\n\nnull\n\n\n\"C42998\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"Kmart Corporat...\n\n\n\"C73584\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n3\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n69440\n\n\ntrue\n\n\n\"06/27/2019 10:...\n\n\n\"10/02/2020 05:...\n\n\n\"facd5359-fc48-...\n\n\n\"facd5359-fc48-...\n\n\n12\n\n\nnull\n\n\n\"C48345\"\n\n\n\"OVAL\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"20\"\n\n\nnull\n\n\n\"C48332\"\n\n\n\"BROWN\"\n\n\nnull\n\n\n\"OMEPRAZOLE 20 ...\n\n\n\"OMEPRAZOLE[OME...\n\n\n\"CARNAUBA WAX;F...\n\n\n\"HOTC\"\n\n\n\"SCD\"\n\n\n\"omeprazole 20 ...\n\n\n402014\n\n\n\"10/02/2020 03:...\n\n\n\"70000-0356\"\n\n\n0\n\n\nnull\n\n\n700000356\n\n\n70000\n\n\n356\n\n\n\"leader omepraz...\n\n\n\"active\"\n\n\n20180316\n\n\n\"facd5359-fc48-...\n\n\nnull\n\n\n\"C42905\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"Cardinal Healt...\n\n\n\"C73594\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n1\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n53092\n\n\ntrue\n\n\n\"10/17/2017 09:...\n\n\n\"10/02/2020 05:...\n\n\n\"b46f11ca-bd09-...\n\n\n\"b46f11ca-bd09-...\n\n\n19\n\n\nnull\n\n\n\"C48348\"\n\n\n\"ROUND\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"L9Y7\"\n\n\nnull\n\n\n\"C48328;C48331;...\n\n\n\"PINK;ORANGE;YE...\n\n\nnull\n\n\n\"CALCIUM CARBON...\n\n\n\"CALCIUM CARBON...\n\n\n\"CITRIC ACID MO...\n\n\n\"HOTC\"\n\n\n\"SCD\"\n\n\n\"calcium carbon...\n\n\n308915\n\n\n\"10/02/2020 04:...\n\n\n\"41163-508\"\n\n\n0\n\n\nnull\n\n\n411630508\n\n\n41163\n\n\n508\n\n\n\"equaline antac...\n\n\n\"active\"\n\n\n20181210\n\n\n\"10041dc3-e9bf-...\n\n\nnull\n\n\n\"C42893\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"Supervalu Inc\"\n\n\n\"C73603\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n2\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n4956\n\n\ntrue\n\n\n\"10/17/2017 05:...\n\n\n\"10/02/2020 05:...\n\n\n\"f8f84be1-e3b1-...\n\n\n\"f8f84be1-e3b1-...\n\n\n19\n\n\nnull\n\n\n\"C48345\"\n\n\n\"OVAL\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"44;677\"\n\n\nnull\n\n\n\"C48329\"\n\n\n\"GREEN\"\n\n\nnull\n\n\n\"ACETAMINOPHEN ...\n\n\n\"ACETAMINOPHEN[...\n\n\n\"STARCH, CORN;D...\n\n\n\"HOTC\"\n\n\n\"SCD\"\n\n\n\"acetaminophen ...\n\n\n1546881\n\n\n\"10/02/2020 04:...\n\n\n\"41250-877\"\n\n\n0\n\n\nnull\n\n\n412500877\n\n\n41250\n\n\n877\n\n\n\"Nite time Seve...\n\n\n\"active\"\n\n\n20200513\n\n\n\"a4d9c4a9-8e8f-...\n\n\nnull\n\n\n\"C42931\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"Meijer Distrib...\n\n\n\"C73603\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n8\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n19029\n\n\ntrue\n\n\n\"10/17/2017 05:...\n\n\n\"10/02/2020 05:...\n\n\n\"254b2202-b14d-...\n\n\n\"254b2202-b14d-...\n\n\n19\n\n\nnull\n\n\n\"C48336\"\n\n\n\"CAPSULE\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"APO;10;40\"\n\n\nnull\n\n\n\"C48333\"\n\n\n\"BLUE\"\n\n\nnull\n\n\n\"Amlodipine bes...\n\n\n\"Amlodipine bes...\n\n\n\"Cellulose, mic...\n\n\n\"HRX\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"10/02/2020 03:...\n\n\n\"60505-3226\"\n\n\n0\n\n\nnull\n\n\n605053226\n\n\n60505\n\n\n3226\n\n\n\"Amlodipine and...\n\n\n\"active\"\n\n\n20170818\n\n\n\"b332e90b-8d4a-...\n\n\nnull\n\n\n\"C25158\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"Apotex Corp.\"\n\n\n\"C73584\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n6\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n13396\n\n\ntrue\n\n\n\"10/17/2017 05:...\n\n\n\"10/17/2017 05:...\n\n\n\"cec47488-ebad-...\n\n\n\"cec47488-ebad-...\n\n\n8\n\n\nnull\n\n\n\"C48348\"\n\n\n\"ROUND\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"DF;15\"\n\n\nnull\n\n\n\"C48331\"\n\n\n\"ORANGE\"\n\n\nnull\n\n\n\"DARIFENACIN 15...\n\n\n\"DARIFENACIN[DA...\n\n\n\"ANHYDROUS DIBA...\n\n\n\"HRX\"\n\n\nnull\n\n\n\"24 HR darifena...\n\n\n543021\n\n\nnull\n\n\n\"35356-272\"\n\n\n0\n\n\nnull\n\n\n353560272\n\n\n35356\n\n\n272\n\n\n\"Enablex\"\n\n\n\"active\"\n\n\n20120305\n\n\n\"85782ed3-ab22-...\n\n\n\"0078-0420\"\n\n\n\"C42927\"\n\n\n\"34391-3\"\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"Lake Erie Medi...\n\n\n\"C73594\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\n1\n\n\n3613\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\n\n\n\n\n\nWhen importing pillbox.csv file initially, an error message actually came up that showed, “…Could not parse ‘10.16’ as dtype Int64 at column 7…”. One way to get around this was to add “ignore_errors” to bypass this error first in order to load the dataset first. This error could be fixed when checking and converting data types for columns.\n\n\n\nInitial data wrangling\nThe Pillbox dataset link from NLM provided a list of column information for users. To quickly see what were the columns in the dataset, we could use “df.glimpse()” to read column names, data types and the first 10 items in each column.\n\nprint(df.glimpse())\n\nRows: 83925\nColumns: 55\n$ ID                   <Int64> 41846, 8100, 5258, 21271, 77050, 76916, 20016, 67902, 75997, 1288        \n$ Enabled?           <Boolean> True, True, True, True, True, True, True, True, True, True               \n$ created at            <Utf8> 10/17/2017 05:32:23 PM, 10/17/2017 05:29:56 PM, 10/17/2017 05:29:44 PM, 10/17/2017 05:30:52 PM, 09/20/2019 09:10:47 PM, 09/20/2019 09:10:41 PM, 10/17/2017 05:30:47 PM, 06/27/2019 10:45:17 PM, 09/20/2019 09:09:57 PM, 10/17/2017 05:29:25 PM\n$ updated at            <Utf8> 10/02/2020 05:14:07 PM, 10/02/2020 04:59:28 PM, 10/17/2017 05:29:44 PM, 10/02/2020 05:10:28 PM, 10/02/2020 05:14:51 PM, 10/02/2020 05:15:50 PM, 10/02/2020 05:12:38 PM, 10/02/2020 05:04:25 PM, 10/02/2020 05:12:06 PM, 10/17/2017 05:29:25 PM\n$ spp                   <Utf8> 471fa2f1-73a0-49be-89f3-d3e2cfdaeca0-0603-5892-0, 116e13c1-ac50-400f-880f-5779f0155b96-59779-074-0, 827ce261-307b-4398-8993-333c08e601fe-49884-129-0, f7f1c99e-1a67-4b34-b1f4-0ac38b9d8006-61480-137-0, ecb28fcb-f0d1-4558-b460-ecabd0f6009e-62332-365-0, 442e41da-24c2-412f-be6b-d549692943fd-70748-132-0, 5f0bdf9d-fa78-45e8-913a-81beff57cf34-65862-123-0, 572e672e-b759-4db1-9e8f-279b1f6f3c51-50804-750-0, 6f17cc91-86b3-42e3-9bf2-935dd360c3eb-51672-4184-0, 02a23e48-f371-448b-92b2-e2d010be1886-54288-129-0\n$ setid                 <Utf8> 471fa2f1-73a0-49be-89f3-d3e2cfdaeca0, 116e13c1-ac50-400f-880f-5779f0155b96, 827ce261-307b-4398-8993-333c08e601fe, f7f1c99e-1a67-4b34-b1f4-0ac38b9d8006, ecb28fcb-f0d1-4558-b460-ecabd0f6009e, 442e41da-24c2-412f-be6b-d549692943fd, 5f0bdf9d-fa78-45e8-913a-81beff57cf34, 572e672e-b759-4db1-9e8f-279b1f6f3c51, 6f17cc91-86b3-42e3-9bf2-935dd360c3eb, 02a23e48-f371-448b-92b2-e2d010be1886\n$ splsize              <Int64> 16, 10, 7, 11, 6, 9, 14, 19, 12, 23                                      \n$ pillbox_size          <Utf8> None, None, None, None, None, None, None, None, None, None               \n$ splshape              <Utf8> C48336, C48348, C48346, C48348, C48348, C48348, C48345, C48336, C48348, C48336\n$ splshape_text         <Utf8> CAPSULE, ROUND, PENTAGON (5 SIDED), ROUND, ROUND, ROUND, OVAL, CAPSULE, ROUND, CAPSULE\n$ pillbox_shape_text    <Utf8> None, None, None, None, None, None, None, None, None, None               \n$ splscore             <Int64> 1, 1, 1, 2, 1, 1, 1, 1, 1, 1                                             \n$ pillbox_score        <Int64> None, None, 2, None, None, None, None, None, None, None                  \n$ splimprint            <Utf8> 5892;V, I2, par;129, LL, L;524, LU;V06, A;73, AT146, T;12, RX681         \n$ pillbox_imprint       <Utf8> None, None, None, None, None, None, None, None, None, None               \n$ splcolor              <Utf8> C48328, C48331, C48329, C48325, C48325, C48325, C48330, C48333, C48325, C48330;C48325\n$ splcolor_text         <Utf8> PINK, ORANGE, GREEN, WHITE, WHITE, WHITE, YELLOW, BLUE, WHITE, YELLOW;WHITE\n$ pillbox_color_text    <Utf8> None, None, None, None, None, None, None, None, None, None               \n$ spl_strength          <Utf8> TEMAZEPAM 15 mg;, IBUPROFEN 200 mg;, DEXAMETHASONE 6 mg;, Nickel Sulfate 1 [hp_X];Potassium Bromide 1 [hp_X];Sodium Bromide 1 [hp_X];Zinc Sulfate Anhydrous 1 [hp_X];Sulfur 1 [hp_X];, CLONAZEPAM 0.25 mg;, SILDENAFIL CITRATE 50 mg;, RISPERIDONE 3 mg;, IBUPROFEN 200 mg;, Iloperidone 12 mg;, FENOPROFEN CALCIUM 200 mg;\n$ spl_ingredients       <Utf8> TEMAZEPAM[TEMAZEPAM];, IBUPROFEN[IBUPROFEN];, DEXAMETHASONE[DEXAMETHASONE];, Nickel Sulfate[NICKEL CATION];Potassium Bromide[BROMIDE ION];Sodium Bromide[BROMIDE ION];Zinc Sulfate Anhydrous[ZINC CATION];Sulfur[Sulfur];, CLONAZEPAM[CLONAZEPAM];, SILDENAFIL CITRATE[SILDENAFIL];, RISPERIDONE[RISPERIDONE];, IBUPROFEN[IBUPROFEN];, Iloperidone[Iloperidone];, FENOPROFEN CALCIUM[FENOPROFEN];\n$ spl_inactive_ing      <Utf8> SILICON DIOXIDE;EDETATE DISODIUM;LACTOSE MONOHYDRATE;MAGNESIUM STEARATE;CELLULOSE, MICROCRYSTALLINE;STARCH, CORN;SODIUM LAURYL SULFATE;FD&C BLUE NO. 1;FD&C RED NO. 40;GELATIN;TITANIUM DIOXIDE;BUTYL ALCOHOL;, SILICON DIOXIDE;STARCH, CORN;CROSCARMELLOSE SODIUM;FD&C RED NO. 40;FD&C YELLOW NO. 6;FERRIC OXIDE RED;MICROCRYSTALLINE CELLULOSE;POLYETHYLENE GLYCOL, UNSPECIFIED;POLYVINYL ALCOHOL, UNSPECIFIED;STEARIC ACID;TALC;TITANIUM DIOXIDE;, ANHYDROUS LACTOSE;CELLULOSE, MICROCRYSTALLINE;CROSCARMELLOSE SODIUM;STEARIC ACID;MAGNESIUM STEARATE;FD&C BLUE NO. 1;D&C YELLOW NO. 10;FD&C YELLOW NO. 6;, None, SORBITOL;ASPARTAME;SODIUM LAURYL SULFATE;CROSPOVIDONE;MANNITOL;SILICON DIOXIDE;TALC;MAGNESIUM STEARATE;, ANHYDROUS DIBASIC CALCIUM PHOSPHATE;CELLULOSE, MICROCRYSTALLINE;CROSCARMELLOSE SODIUM;HYPROMELLOSE 2910 (6 MPA.S);MAGNESIUM STEARATE;POLYETHYLENE GLYCOL 400;SILICON DIOXIDE;TITANIUM DIOXIDE;, LACTOSE MONOHYDRATE;MICROCRYSTALLINE CELLULOSE;SILICON DIOXIDE;MAGNESIUM STEARATE;HYPROMELLOSE 2910 (6 MPA.S);TITANIUM DIOXIDE;POLYETHYLENE GLYCOL 400;D&C YELLOW NO. 10;, FD&C BLUE NO. 1;GELATIN;POLYETHYLENE GLYCOL, UNSPECIFIED;POTASSIUM HYDROXIDE;WATER;SORBITOL;SORBITAN;MEDIUM-CHAIN TRIGLYCERIDES;FD&C YELLOW NO. 6;LECITHIN, SOYBEAN;, silicon dioxide;crospovidone (15 MPA.S AT 5%);hypromellose, unspecified;lactose monohydrate;magnesium stearate;microcrystalline cellulose;water;, CROSPOVIDONE;MAGNESIUM STEARATE;SODIUM LAURYL SULFATE;TALC;GELATIN;TITANIUM DIOXIDE;BROWN IRON OXIDE;\n$ source                <Utf8> HRX, HOTC, HRX, HOMEO, HRX, HRX, HRX, HOTC, HRX, HRX                     \n$ rxtty                 <Utf8> None, SCD, None, None, SCD, SCD, SCD, SCD, SCD, None                     \n$ rxstring              <Utf8> None, ibuprofen 200 MG Oral Tablet, Dexamethasone 6 MG Oral Tablet, None, clonazepam 0.25 MG Disintegrating Oral Tablet, sildenafil 50 MG Oral Tablet, risperidone 3 MG Oral Tablet, ibuprofen 200 MG Oral Capsule, iloperidone 12 MG Oral Tablet, Fenoprofen 200 MG Oral Capsule [Fenortho]\n$ rxcui                <Int64> None, 310965, 197583, None, 349195, 312950, 312832, 310964, 848732, 1799325\n$ RxNorm Update time    <Utf8> 10/02/2020 04:21:55 PM, 10/02/2020 03:07:40 PM, None, 10/02/2020 04:01:35 PM, 10/02/2020 04:25:40 PM, 10/02/2020 04:30:41 PM, 10/02/2020 04:13:39 PM, 10/02/2020 03:30:07 PM, 10/02/2020 04:10:33 PM, None\n$ product_code          <Utf8> 0603-5892, 59779-074, 49884-129, 61480-137, 62332-365, 70748-132, 65862-123, 50804-750, 51672-4184, 54288-129\n$ part_num             <Int64> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0                                             \n$ part_medicine_name    <Utf8> None, None, None, None, None, None, None, None, None, None               \n$ ndc9                 <Int64> 6035892, 597790074, 498840129, 614800137, 623320365, 707480132, 658620123, 508040750, 516724184, 542880129\n$ ndc_labeler_code     <Int64> 603, 59779, 49884, 61480, 62332, 70748, 65862, 50804, 51672, 54288       \n$ ndc_product_code     <Int64> 5892, 74, 129, 137, 365, 132, 123, 750, 4184, 129                        \n$ medicine_name         <Utf8> Temazepam, ibuprofen, Dexamethasone, Acunol, CLONAZEPAM, SILDENAFIL, Risperidone, Ibuprofen, Iloperidone, FENORTHO\n$ marketing_act_code    <Utf8> completed, active, active, active, active, active, active, active, active, active\n$ effective_time       <Int64> 20160406, 20191120, 20120516, 20190909, 20190701, 20191001, 20180924, 20191101, 20190802, 20160614\n$ file_name             <Utf8> d912ca54-6569-4e58-a8ef-620eddd03163.xml, 55de9f94-89b2-4bfb-a41d-6660ba6e7a6d.xml, 85a9eebb-be74-43a1-a36f-26ae4c4131aa.xml, 029eaf64-e66f-447e-9ac3-037620370f85.xml, ba5120ce-ed74-40be-936d-c172805d88d1.xml, 17c537d9-b2e6-4d71-a481-c7c7cafdb3a2.xml, 5d2750a4-025a-40a1-97d2-d9447a37afbb.xml, 148c7665-22d5-494c-9add-98428435f392.xml, 6787555e-8a11-481c-b05c-179b0aedcf5c.xml, 91b0ac5b-994c-468f-9331-542b8f92f9a8.xml\n$ equal_product_code    <Utf8> None, None, None, None, None, None, None, None, None, None               \n$ dosage_form           <Utf8> C25158, C42931, C42998, C42998, C42999, C42931, C42931, C42954, C42998, C25158\n$ document_type         <Utf8> None, 34390-5, 34391-3, 34391-3, None, None, 34391-3, None, None, None   \n$ dea_schedule_code     <Utf8> C48677, None, None, None, C48677, None, None, None, None, None           \n$ dea_schedule_name     <Utf8> CIV, None, None, None, CIV, None, None, None, None, None                 \n$ author_type           <Utf8> LABELER, LABELER, LABELER, LABELER, LABELER, LABELER, LABELER, LABELER, LABELER, LABELER\n$ author                <Utf8> Qualitest Pharmaceuticals, CVS Pharmacy, Par Pharmaceutical Inc., PLYMOUTH HEALTHCARE PRODUCTS LLC, Alembic Pharmaceuticals Inc., Lupin Pharmaceuticals, Inc., Aurobindo Pharma Limited, Good Sense (Geiss, Destin & Dunn, Inc.), Taro Pharmaceuticals U.S.A., Inc., BPI Labs LLC\n$ approval_code         <Utf8> C73584, C73584, C73584, C73614, C73584, C73584, C73584, C73584, C73584, C73594\n$ image_source          <Utf8> None, None, NLM, None, None, None, None, None, None, None                \n$ splimage              <Utf8> None, None, 498840129, None, None, None, None, None, None, None          \n$ has_image          <Boolean> False, False, True, False, False, False, False, False, False, False      \n$ epc_match            <Int64> None, None, None, None, None, None, None, None, None, None               \n$ version_number       <Int64> 5, 4, 4, 8, 3, 4, 21, 2, 1, 2                                            \n$ laberer_code          <Utf8> None, None, None, None, None, None, None, None, None, None               \n$ application_number    <Utf8> None, None, None, None, None, None, None, None, None, None               \n$ updated            <Boolean> True, True, False, True, True, True, True, True, True, False             \n$ stale              <Boolean> False, False, True, False, False, False, False, False, False, True       \n$ new                <Boolean> False, False, False, False, False, False, False, False, False, False     \n$ Pillbox Value      <Boolean> False, False, True, False, False, False, False, False, False, False      \n\n\n\nA relatively simple dataset would be extracted first for these pills data since I was an inexperienced user of Rust. Therefore, I’ve selected only certain columns for this purpose.\n\ndf_med = df.select([# shapes of medicines\n                    \"splshape_text\", \n                    # colours of medicines\n                    \"splcolor_text\",\n                    # strengths of medicines\n                    \"spl_strength\", \n                    # inactive ingredients/excipients in medicines  \n                    \"spl_inactive_ing\",\n                    # dosage forms of medicines e.g. capsules or tablets etc.\n                    \"dosage_form\"]\n                  )\ndf_med\n\n\n\n\nshape: (83925, 5)\n\n\n\n\nsplshape_text\n\n\nsplcolor_text\n\n\nspl_strength\n\n\nspl_inactive_ing\n\n\ndosage_form\n\n\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n\"CAPSULE\"\n\n\n\"PINK\"\n\n\n\"TEMAZEPAM 15 m...\n\n\n\"SILICON DIOXID...\n\n\n\"C25158\"\n\n\n\n\n\"ROUND\"\n\n\n\"ORANGE\"\n\n\n\"IBUPROFEN 200 ...\n\n\n\"SILICON DIOXID...\n\n\n\"C42931\"\n\n\n\n\n\"PENTAGON (5 SI...\n\n\n\"GREEN\"\n\n\n\"DEXAMETHASONE ...\n\n\n\"ANHYDROUS LACT...\n\n\n\"C42998\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"Nickel Sulfate...\n\n\nnull\n\n\n\"C42998\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"CLONAZEPAM 0.2...\n\n\n\"SORBITOL;ASPAR...\n\n\n\"C42999\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"SILDENAFIL CIT...\n\n\n\"ANHYDROUS DIBA...\n\n\n\"C42931\"\n\n\n\n\n\"OVAL\"\n\n\n\"YELLOW\"\n\n\n\"RISPERIDONE 3 ...\n\n\n\"LACTOSE MONOHY...\n\n\n\"C42931\"\n\n\n\n\n\"CAPSULE\"\n\n\n\"BLUE\"\n\n\n\"IBUPROFEN 200 ...\n\n\n\"FD&C BLUE NO. ...\n\n\n\"C42954\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"Iloperidone 12...\n\n\n\"silicon dioxid...\n\n\n\"C42998\"\n\n\n\n\n\"CAPSULE\"\n\n\n\"YELLOW;WHITE\"\n\n\n\"FENOPROFEN CAL...\n\n\n\"CROSPOVIDONE;M...\n\n\n\"C25158\"\n\n\n\n\n\"ROUND\"\n\n\n\"YELLOW\"\n\n\n\"BUTALBITAL 50 ...\n\n\n\"STARCH, CORN;C...\n\n\n\"C42998\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"ESTRADIOL 0.5 ...\n\n\n\"COPOVIDONE K25...\n\n\n\"C42998\"\n\n\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"MEMANTINE HYDR...\n\n\n\"SILICON DIOXID...\n\n\n\"C42998\"\n\n\n\n\n\"CAPSULE\"\n\n\n\"ORANGE\"\n\n\n\"ACETAMINOPHEN ...\n\n\n\"BUTYLATED HYDR...\n\n\n\"C42954\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"LAMOTRIGINE 25...\n\n\n\"MAGNESIUM CARB...\n\n\n\"C42893\"\n\n\n\n\n\"OVAL\"\n\n\n\"BLUE\"\n\n\n\"ACETAMINOPHEN ...\n\n\n\"ACESULFAME POT...\n\n\n\"C42897\"\n\n\n\n\n\"OVAL\"\n\n\n\"WHITE\"\n\n\n\"AZITHROMYCIN D...\n\n\n\"CROSCARMELLOSE...\n\n\n\"C42931\"\n\n\n\n\n\"OVAL\"\n\n\n\"BLUE\"\n\n\n\"IBUPROFEN 200 ...\n\n\n\"FD&C BLUE NO. ...\n\n\n\"C42954\"\n\n\n\n\n\"OVAL\"\n\n\n\"WHITE\"\n\n\n\"CETIRIZINE HYD...\n\n\n\"STARCH, CORN;H...\n\n\n\"C42998\"\n\n\n\n\n\"OVAL\"\n\n\n\"BROWN\"\n\n\n\"OMEPRAZOLE 20 ...\n\n\n\"CARNAUBA WAX;F...\n\n\n\"C42905\"\n\n\n\n\n\"ROUND\"\n\n\n\"PINK;ORANGE;YE...\n\n\n\"CALCIUM CARBON...\n\n\n\"CITRIC ACID MO...\n\n\n\"C42893\"\n\n\n\n\n\"OVAL\"\n\n\n\"GREEN\"\n\n\n\"ACETAMINOPHEN ...\n\n\n\"STARCH, CORN;D...\n\n\n\"C42931\"\n\n\n\n\n\"CAPSULE\"\n\n\n\"BLUE\"\n\n\n\"Amlodipine bes...\n\n\n\"Cellulose, mic...\n\n\n\"C25158\"\n\n\n\n\n\"ROUND\"\n\n\n\"ORANGE\"\n\n\n\"DARIFENACIN 15...\n\n\n\"ANHYDROUS DIBA...\n\n\n\"C42927\"\n\n\n\n\n\n\n\n\n\n\n\nPhoto by Hans-Peter Gauster on Unsplash\n\n\n\n\nWeb scraping\nThis was not planned initially but this might make my life a lot easier if I could scrape the dosage form table found through the Pillbox link, since the dosage form column was full of C-letter codes. These dosage form codes were hard to understand, so once I’ve got the codes along with corresponding dosage forms in texts, the web-scraped information would be converted into a dataframe for further data manipulations.\n\n# Uncomment lines below to install libraries needed for web-scraping\n#!pip install requests\n#!pip install beautifulsoup4\n\n\nImport libraries\n\nimport requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\n\nI’ve opted for using Beautiful Soup as the web-scraping library in Python, along with the requests library to be able to make a URL request call to retrieve web information. There were of course many other tools available as well. A caveat to be taken into consideration was that when web-scraping, it was always recommended to check whether the information being scraped were under a specific copyright license and so on. In this case, I’ve checked that the dosage form table link - https://www.fda.gov/industry/structured-product-labeling-resources/dosage-forms was from US FDA and it was stated that the information (both texts and graphs) were not copyrighted (unless otherwise stated, for this particular web page, there was nothing stated along those lines), but a link to this webpage should be provided so that readers could access most current information in the future.\n\n\nSend web requests\n\n# Specify URL address with information intended for web-scraping\nurl = \"https://www.fda.gov/industry/structured-product-labeling-resources/dosage-forms\"\n# Request the web information via requests library & save under a data object\ndata = requests.get(url)\n\n\n\nParse web content\n\n# Parse the web content from the URL link by using Beautiful Soup\nsoup = BeautifulSoup(data.content, \"html.parser\")\n\n\n\nPrint web content\n\n# Print out the scraped web information\nprint(soup.prettify())\n\n<!DOCTYPE html>\n<html dir=\"ltr\" lang=\"en\" prefix=\"content: http://purl.org/rss/1.0/modules/content/  dc: http://purl.org/dc/terms/  foaf: http://xmlns.com/foaf/0.1/  og: http://ogp.me/ns#  rdfs: http://www.w3.org/2000/01/rdf-schema#  schema: http://schema.org/  sioc: http://rdfs.org/sioc/ns#  sioct: http://rdfs.org/sioc/types#  skos: http://www.w3.org/2004/02/skos/core#  xsd: http://www.w3.org/2001/XMLSchema# \">\n <head>\n  <meta charset=\"utf-8\"/>\n  <script async=\"\" src=\"https://www.googletagmanager.com/gtag/js?id=UA-22737364-1\">\n  </script>\n  <meta content=\"This web page has a list of dosage form terms and National Cancer Institute Thesaurus concept codes associated with those term for use in Structured Product Labeling (SPL) documents submitted to FDA.\" name=\"description\"/>\n  <meta content=\"Dosage Forms\" name=\"dcterms.title\"/>\n  <meta content=\"Office of the Commissioner\" name=\"dcterms.creator\"/>\n  <meta content=\"This web page has a list of dosage form terms and National Cancer Institute Thesaurus concept codes associated with those term for use in Structured Product Labeling (SPL) documents submitted to FDA.\" name=\"dcterms.description\"/>\n  <meta content=\"FDA\" name=\"dcterms.publisher\"/>\n  <meta content=\"DO NOT USE - Office of Health Informatics\" name=\"dcterms.contributor\"/>\n  <meta content=\"Article\" name=\"dcterms.type\"/>\n  <meta content=\"FDA\" name=\"dcterms.source\"/>\n  <meta content=\"Manufacturers\" name=\"dcterms.audience\"/>\n  <meta content=\"U.S. Food and Drug Administration\" property=\"og:site_name\"/>\n  <meta content=\"Article\" property=\"og:type\"/>\n  <meta content=\"https://www.fda.gov/industry/structured-product-labeling-resources/dosage-forms\" property=\"og:url\"/>\n  <meta content=\"Dosage Forms\" property=\"og:title\"/>\n  <meta content=\"Thu, 02/03/2022 - 10:05\" property=\"og:updated_time\"/>\n  <meta content=\"FDA\" property=\"article:publisher\"/>\n  <meta content=\"Thu, 02/03/2022 - 09:02\" property=\"article:published_time\"/>\n  <meta content=\"Thu, 02/03/2022 - 10:05\" property=\"article:modified_time\"/>\n  <meta content=\"tWxlDhm4ANdksJZPj7TBmHgNoMqZCnecPp0Aa2vC9XA\" name=\"google-site-verification\"/>\n  <meta content=\"summary_large_image\" name=\"twitter:card\"/>\n  <meta content=\"@US_FDA\" name=\"twitter:site\"/>\n  <meta content=\"Dosage Forms\" name=\"twitter:title\"/>\n  <meta content=\"@US_FDA\" name=\"twitter:creator\"/>\n  <meta content=\"width\" name=\"MobileOptimized\"/>\n  <meta content=\"true\" name=\"HandheldFriendly\"/>\n  <meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n  <script type=\"application/ld+json\">\n   {\n    \"@context\": \"https://schema.org\",\n    \"@graph\": [\n        {\n            \"@type\": \"Article\",\n            \"headline\": \"Dosage Forms\",\n            \"name\": \"Dosage Forms\",\n            \"description\": \"This web page has a list of dosage form terms and National Cancer Institute Thesaurus concept codes associated with those term for use in Structured Product Labeling (SPL) documents submitted to FDA.\",\n            \"image\": {\n                \"@type\": \"ImageObject\",\n                \"representativeOfPage\": \"True\"\n            },\n            \"datePublished\": \"\\u003Ctime datetime=\\u00222022-02-03T09:02:47Z\\u0022\\u003EThu, 02/03/2022 - 09:02\\u003C/time\\u003E\",\n            \"dateModified\": \"\\u003Ctime datetime=\\u00222022-02-03T10:05:00Z\\u0022\\u003EThu, 02/03/2022 - 10:05\\u003C/time\\u003E\",\n            \"author\": {\n                \"@type\": \"Organization\",\n                \"name\": \"\\u003Ca href=\\u0022/taxonomy/term/819\\u0022 hreflang=\\u0022en\\u0022\\u003EOffice of the Commissioner\\u003C/a\\u003E\"\n            },\n            \"publisher\": {\n                \"@type\": \"Organization\",\n                \"name\": \"FDA\"\n            }\n        },\n        {\n            \"@type\": \"WebSite\"\n        }\n    ]\n}\n  </script>\n  <meta content=\"https://www.fda.gov/themes/custom/preview/img/FDA-Social-Graphic.png\" property=\"og:image\"/>\n  <meta content=\"https://www.fda.gov/themes/custom/preview/img/FDA-Social-Graphic.png\" name=\"twitter:image\"/>\n  <meta content=\"This web page has a list of dosage form terms and National Cancer Institute Thesaurus concept codes associated with those term for use in Structured Product Labeling (SPL) documents submitted to FDA.\" property=\"og:description\"/>\n  <meta content=\"This web page has a list of dosage form terms and National Cancer Institute Thesaurus concept codes associated with those term for use in Structured Product Labeling (SPL) documents submitted to FDA.\" property=\"twitter:description\"/>\n  <link href=\"/themes/custom/preview/favicon.ico\" rel=\"icon\" type=\"image/vnd.microsoft.icon\"/>\n  <link href=\"https://www.fda.gov/industry/structured-product-labeling-resources/dosage-forms\" hreflang=\"en\" rel=\"alternate\"/>\n  <link href=\"https://www.fda.gov/industry/structured-product-labeling-resources/dosage-forms\" rel=\"canonical\"/>\n  <link href=\"https://www.fda.gov/node/358928\" rel=\"shortlink\"/>\n  <script defer=\"\" src=\"/files/google_tag/production/google_tag.script.js?rphai9\">\n  </script>\n  <title>\n   Dosage Forms | FDA\n  </title>\n  <link href=\"/files/css/css_VQK8mppKquBsweKvwlYQE65XHMoWqDIaAS_w8yNPtaw.css\" media=\"all\" rel=\"stylesheet\"/>\n  <link href=\"/files/css/css_n8jaIwaGAEBwhyOVADYKEvBfI14hjYfW5coDh69qBY0.css\" media=\"all\" rel=\"stylesheet\"/>\n  <script async=\"\" src=\"https://script.crazyegg.com/pages/scripts/0024/3700.js\">\n  </script>\n  <script id=\"_fed_an_ua_tag\" language=\"javascript\" src=\"https://dap.digitalgov.gov/Universal-Federated-Analytics-Min.js?agency=HHS&amp;subagency=FDA&amp;sdor=fda.gov&amp;dclink=true\">\n  </script>\n  <script>\n   window.dataLayer = window.dataLayer || [];function gtag(){dataLayer.push(arguments)};gtag(\"js\", new Date());gtag(\"config\", \"UA-22737364-1\", {\"groups\":\"default\",\"anonymize_ip\":true,\"allow_ad_personalization_signals\":false});\n  </script>\n </head>\n <body class=\"role-anonymous path-node page-node-type-article has-glyphicons\">\n  <div class=\"sr-only\" id=\"quicklinks\">\n   <ul>\n    <li>\n     <a class=\"sr-only sr-only-focusable\" href=\"#main-content\" tabindex=\"1\">\n      Skip to main content\n     </a>\n    </li>\n    <li>\n     <a class=\"sr-only sr-only-focusable\" href=\"#search-form\" tabindex=\"1\">\n      Skip to FDA Search\n     </a>\n    </li>\n    <li>\n     <a class=\"sr-only sr-only-focusable\" href=\"#section-nav\" tabindex=\"1\">\n      Skip to in this section menu\n     </a>\n    </li>\n    <li>\n     <a class=\"sr-only sr-only-focusable\" href=\"#footer-heading\" tabindex=\"1\">\n      Skip to footer links\n     </a>\n    </li>\n   </ul>\n  </div>\n  <noscript aria-hidden=\"true\">\n   <iframe height=\"0\" src=\"https://www.googletagmanager.com/ns.html?id=GTM-M95XGZW\" style=\"display:none;visibility:hidden\" width=\"0\">\n   </iframe>\n  </noscript>\n  <div class=\"dialog-off-canvas-main-canvas\" data-off-canvas-main-canvas=\"\">\n   <div class=\"main-container container-fluid\">\n    <div class=\"row\">\n     <header class=\"lcds-header container-fluid\" role=\"header\">\n      <div class=\"row us-masthead\">\n       <div class=\"usa-banner col-xs-12\">\n        <img alt=\"U.S. flag\" class=\"usa-banner__us-flag\" src=\"/themes/custom/preview/assets/images/US_Flag.png\"/>\n        <span>\n         An official website of the United States government\n        </span>\n        <a aria-controls=\"USABannerMenu\" aria-expanded=\"false\" class=\"collapsed\" data-target=\"#USABannerMenu\" data-toggle=\"collapse\" id=\"USMenuButton\">\n         Here’s how you know\n         <span class=\"toggle-indicator\">\n         </span>\n        </a>\n        <div aria-labelledby=\"USMenuButton\" class=\"col-xs-12 collapse usa-banner__menu\" id=\"USABannerMenu\">\n         <div aria-hidden=\"true\" class=\"row usa-banner-content usa-grid usa-accordion-content\" id=\"gov-banner\">\n          <div class=\"col-xs-12 col-sm-6 col-md-3\">\n           <img alt=\"Dot gov\" class=\"usa-banner-icon usa-media_block-img\" src=\"/themes/custom/preview/assets/images/icon-dot-gov.svg\" style=\"width:3em;\"/>\n           <div class=\"usa-media_block-body\">\n            <p>\n             <strong>\n              The .gov means it’s official.\n             </strong>\n             <br/>\n             Federal government websites often end in .gov or .mil. Before sharing sensitive information, make sure you're on a federal government site.\n            </p>\n           </div>\n          </div>\n          <div class=\"col-xs-12 col-sm-6 col-md-3\">\n           <img alt=\"SSL\" class=\"usa-banner-icon usa-media_block-img\" src=\"/themes/custom/preview/assets/images/icon-https.svg\" style=\"width:3em;\"/>\n           <div class=\"usa-media_block-body\">\n            <p>\n             <strong>\n              The site is secure.\n             </strong>\n             <br/>\n             The\n             <strong>\n              https://\n             </strong>\n             ensures that you are connecting to the official website and that any information you provide is encrypted and transmitted securely.\n            </p>\n           </div>\n          </div>\n         </div>\n        </div>\n       </div>\n      </div>\n      <div class=\"row fda-masthead\">\n       <div class=\"col-xs-4 col-md-8\">\n        <a href=\"/\" title=\"FDA Homepage\">\n         <h1 class=\"fda-masthead__fda-logo\">\n          U.S. Food and Drug Administration\n         </h1>\n        </a>\n       </div>\n       <div class=\"col-xs-8 col-md-4\">\n        <ul class=\"fda-masthead__item-list\">\n         <li>\n          <a class=\"btn btn-default btn-sm fda-masthead__btn-search\" id=\"btn-search\" title=\"\">\n           <span aria-hidden=\"true\" class=\"fa fa-search\">\n           </span>\n           <span class=\"fda-masthead__btn-label\">\n            Search\n           </span>\n          </a>\n         </li>\n         <li>\n          <a aria-expanded=\"true\" class=\"btn btn-default btn-sm fda-masthead__btn-menu collapsed\" data-toggle=\"collapse\" href=\"#primary-nav\" id=\"menu-btn\">\n           <span aria-hidden=\"true\" class=\"fa fa-bars\">\n           </span>\n           <span class=\"fda-masthead__btn-label\">\n            Menu\n           </span>\n          </a>\n         </li>\n        </ul>\n       </div>\n       <form accept-charset=\"UTF-8\" action=\"/search\" class=\"fda-masthead__search sr-only\" id=\"search-form\" method=\"GET\" name=\"searchForm\" role=\"search\">\n        <div class=\"search-popover\" id=\"search-popover\">\n         <div class=\"input-group pull-right\" id=\"search-group\">\n          <label class=\"sr-only\" for=\"search-query\">\n           Search FDA\n          </label>\n          <input aria-autocomplete=\"list\" aria-haspopup=\"true\" class=\"form-control search-input\" id=\"search-query\" name=\"s\" placeholder=\"Search FDA\" title=\"Enter the terms you wish to search for.\" type=\"text\"/>\n          <span class=\"input-group-btn\" id=\"input-group-btn\">\n           <button class=\"btn btn-danger search-btn\" id=\"search-btn\" title=\"Search\" type=\"submit\">\n            <span aria-hidden=\"true\" class=\"fa fa-search\">\n             <span class=\"sr-only\">\n              Submit search\n             </span>\n            </span>\n           </button>\n          </span>\n         </div>\n        </div>\n       </form>\n      </div>\n      <nav class=\"lcds-primary-nav row collapse\" id=\"primary-nav\">\n       <div class=\"col-md-5 col-lg-4\">\n        <section class=\"lcds-primary-nav__group lcds-primary-nav__group--bordered\">\n         <h2 class=\"lcds-primary-nav__group-heading\">\n          Featured\n         </h2>\n         <ul class=\"lcds-primary-nav__list lcds-primary-nav__list--featured\">\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/about-fda/contact-fda\">\n            Contact FDA\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/regulatory-information/search-fda-guidance-documents\">\n            FDA Guidance Documents\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/safety/recalls-market-withdrawals-safety-alerts\">\n            Recalls, Market Withdrawals and Safety Alerts\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/news-events/newsroom/press-announcements\">\n            Press Announcements\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/inspections-compliance-enforcement-and-criminal-investigations/compliance-actions-and-activities/warning-letters\">\n            Warning Letters\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/advisory-committees\">\n            Advisory Committees\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/about-fda/en-espanol\">\n            En Español\n           </a>\n          </li>\n         </ul>\n        </section>\n       </div>\n       <div class=\"col-md-7 col-lg-8\">\n        <section class=\"lcds-primary-nav__group lcds-primary-nav__group--bordered\">\n         <h2 class=\"lcds-primary-nav__group-heading\">\n          Products\n         </h2>\n         <ul class=\"lcds-primary-nav__list\">\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/food\">\n            Food\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/drugs\">\n            Drugs\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/medical-devices\">\n            Medical Devices\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/radiation-emitting-products\">\n            Radiation-Emitting Products\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/vaccines-blood-biologics\">\n            Vaccines, Blood, and Biologics\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/animal-veterinary\">\n            Animal and Veterinary\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/cosmetics\">\n            Cosmetics\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/tobacco-products\">\n            Tobacco Products\n           </a>\n          </li>\n         </ul>\n        </section>\n        <section class=\"lcds-primary-nav__group lcds-primary-nav__group--bordered\">\n         <h2 class=\"lcds-primary-nav__group-heading\">\n          Topics\n         </h2>\n         <ul class=\"lcds-primary-nav__list\">\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/about-fda\">\n            About FDA\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/combination-products\">\n            Combination Products\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/regulatory-information\">\n            Regulatory Information\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/safety\">\n            Safety\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/emergency-preparedness-and-response\">\n            Emergency Preparedness\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/international-programs\">\n            International Programs\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/news-events\">\n            News and Events\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/training-and-continuing-education\">\n            Training and Continuing Education\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/inspections-compliance-enforcement-and-criminal-investigations\">\n            Inspections and Compliance\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/science-research\">\n            Science and Research\n           </a>\n          </li>\n         </ul>\n        </section>\n        <section class=\"lcds-primary-nav__group lcds-primary-nav__group--bordered\">\n         <h2 class=\"lcds-primary-nav__group-heading\">\n          Information For\n         </h2>\n         <ul class=\"lcds-primary-nav__list\">\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/consumers\">\n            Consumers\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/patients\">\n            Patients\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/industry\">\n            Industry\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/health-professionals\">\n            Health Professionals\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/federal-state-local-tribal-and-territorial-officials\">\n            Federal, State and Local Officials\n           </a>\n          </li>\n         </ul>\n        </section>\n       </div>\n      </nav>\n     </header>\n     <div class=\"col-xs-12\">\n      <div class=\"hidden\" data-drupal-messages-fallback=\"\">\n      </div>\n     </div>\n     <section class=\"block block-ctools block-entity-viewnode clearfix\" data-block-plugin-id=\"entity_view:node\" id=\"block-entityviewcontent\">\n      <a class=\"lcds-button--expandable collapsed hidden-md hidden-lg\" data-toggle=\"collapse\" href=\"#section-nav\">\n       In this section\n       <span class=\"visible-sm-inline-block\">\n        :\n\n                Structured Product Labeling Resources\n       </span>\n      </a>\n      <nav class=\"lcds-card lcds-section-nav lcds-section-nav hidden-md hidden-lg collapse\" id=\"section-nav\">\n       <ul class=\"lcds-section-nav__list\">\n        <li>\n         <a class=\"lcds-section-nav__section-link lcds-section-nav__link lcds-section-nav__parent-link visible-xs-block visible-sm-block\" href=\"/industry/fda-data-standards-advisory-board/structured-product-labeling-resources\" title=\"Structured Product Labeling Resources\">\n          Structured Product Labeling Resources\n         </a>\n         <div class=\"views-element-container form-group\">\n          <div class=\"view view-in-this-section view-id-in_this_section view-display-id-block_5 js-view-dom-id-b13c61e6f0cd52a31b0ccbd998f47cc31050537f43a7d78f4599b9e8091c77e0\">\n           <div>\n            <ul class=\"lcds-section-nav__section-link__active lcds-section-nav__list\">\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/risk-evaluation-and-mitigation-strategies-rems-spl-resources\">\n               Risk Evaluation and Mitigation Strategies (REMS) SPL Resources\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/business-entity-identifiers\">\n               Business Entity Identifiers\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/business-operation\">\n               Business Operation\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/business-operation-qualifier\">\n               Business Operation Qualifier\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/code-system-object-identifiers\">\n               Code System Object Identifiers\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/combination-product-types\">\n               Combination Product Types\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/contributing-factor-general\">\n               Contributing Factor - General\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/document-type-including-content-labeling-type\">\n               Document Type including Content of Labeling Type\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/dosage-forms\">\n               Dosage Forms\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/electronic-animal-drug-product-listing-directory\">\n               Electronic Animal Drug Product Listing Directory\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/equivalence-codes\">\n               Equivalence Codes\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/flavor\">\n               Flavor\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/geopolitical-entities-names-and-codes-genc\">\n               Geopolitical Entities, Names, and Codes (GENC)\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/indication-category\">\n               Indication Category\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/intent-use\">\n               Intent of Use\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/lab-test\">\n               Lab Test\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/license-disciplinary-action\">\n               License Disciplinary Action\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/licensed\">\n               Licensed\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/limitation-useissues\">\n               Limitation of Use/Issues\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/marketing-category\">\n               Marketing Category\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/marketing-status\">\n               Marketing Status\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/medical-condition\">\n               Medical Condition\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/ndcnhric-labeler-codes\">\n               NDC/NHRIC Labeler Codes\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/nsde\">\n               NSDE\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/package-type\">\n               Package Type\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/pharmacokinetic-effect\">\n               Pharmacokinetic Effect\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/pharmacologic-class\">\n               Pharmacologic Class\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/positron-emission-tomography-pet-drug-spl\">\n               Positron Emission Tomography (PET) Drug SPL\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/precondition-categories\">\n               Precondition Categories\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/race\">\n               Race\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/rems-approval\">\n               REMS Approval\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/rems-protocol\">\n               REMS Protocol\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/rems-requirements\">\n               REMS Requirements\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/rems-stakeholder\">\n               REMS Stakeholder\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/resources-spl-commercial-software-and-conversion-vendors-and-fda-regulated-company-self-generated\">\n               Resources for SPL Commercial Software and Conversion Vendors and FDA-Regulated Company Self-Generated SPL Software Developers\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/route-administration\">\n               Route of Administration\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/section-headings-loinc\">\n               Section Headings (LOINC)\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/sex\">\n               Sex\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/spl-color\">\n               SPL Color\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/spl-dea-schedule\">\n               SPL DEA Schedule\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/spl-lot-distribution-data-distribution-codes\">\n               SPL Lot Distribution Data - Distribution Codes\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/spl-shape\">\n               SPL Shape\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/spl-standard-training\">\n               SPL Standard Training\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/spl-xforms\">\n               SPL Xforms\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/time-units\">\n               Time Units\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/type-consequence\">\n               Type of Consequence\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/uniis-preferred-substance-names-and-their-identified-synonyms\">\n               UNIIs, Preferred Substance Names, and their Identified Synonyms\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/units-measure\">\n               Units of Measure\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/units-presentation\">\n               Units of Presentation\n              </a>\n             </li>\n            </ul>\n           </div>\n          </div>\n         </div>\n         <div class=\"views-element-container form-group\">\n          <div class=\"view view-in-this-section-sub view-id-in_this_section_sub view-display-id-block_2 js-view-dom-id-150a9e8325156f6482279b2a2d5893625da8fd0de62f3f456cbdaac3b07db443\">\n          </div>\n         </div>\n        </li>\n       </ul>\n      </nav>\n     </section>\n     <section class=\"block block-ctools block-entity-viewnode clearfix\" data-block-plugin-id=\"entity_view:node\" id=\"block-entityviewcontent-15\">\n      <ol class=\"lcds-breadcrumb visible-md visible-lg\">\n       <li>\n        <a href=\"/\">\n         Home\n        </a>\n       </li>\n       <li>\n        <a href=\"/industry\">\n         For Industry\n        </a>\n       </li>\n       <li>\n        <a href=\"/industry/fda-data-standards-advisory-board\">\n         FDA Data Standards Advisory Board\n        </a>\n       </li>\n       <li>\n        <a href=\"/industry/fda-data-standards-advisory-board/structured-product-labeling-resources\">\n         Structured Product Labeling Resources\n        </a>\n       </li>\n       <li>\n        <a class=\"current-link\">\n         Dosage Forms\n        </a>\n       </li>\n      </ol>\n      <ol class=\"lcds-breadcrumb visible-sm visible-xs\">\n       <li>\n        <a href=\"/industry/fda-data-standards-advisory-board/structured-product-labeling-resources\" title=\"Structured Product Labeling Resources\">\n         Structured Product Labeling Resources\n        </a>\n       </li>\n      </ol>\n     </section>\n     <main>\n      <article class=\"article main-content container-fluid\" id=\"main-content\" role=\"article\">\n       <header class=\"row content-header\" role=\"heading\">\n        <section class=\"block block-ctools block-entity-viewnode clearfix\" data-block-plugin-id=\"entity_view:node\" id=\"block-entityviewcontent-2\">\n         <div class=\"col-sm-12 col-md-8 col-md-offset-2\">\n          <h1 class=\"content-title text-center\">\n           Dosage Forms\n          </h1>\n          <div class=\"lcds-toolbar lcds-toolbar--social\">\n           <ul class=\"lcds-share lcds-share--default\">\n            <li class=\"lcds-share__item\">\n             <a class=\"lcds-share__btn lcds-share--default__btn-facebook js-share\" href=\"https://www.facebook.com/sharer/sharer.php?u=https://www.fda.gov%2Findustry%2Fstructured-product-labeling-resources%2Fdosage-forms\" id=\"fb-share\" target=\"_blank\">\n              <span aria-hidden=\"true\" class=\"fa icon-facebook\">\n              </span>\n              Share\n             </a>\n            </li>\n            <li class=\"lcds-share__item\">\n             <a class=\"lcds-share__btn lcds-share--default__btn-twitter js-share\" href=\"https://twitter.com/intent/tweet/?text=Dosage%20Forms&amp;url=https://www.fda.gov%2Findustry%2Fstructured-product-labeling-resources%2Fdosage-forms\" id=\"twitter-share\" target=\"_blank\">\n              <span aria-hidden=\"true\" class=\"fa icon-twitter\">\n              </span>\n              Tweet\n             </a>\n            </li>\n            <li class=\"lcds-share__item hidden-xs\">\n             <a class=\"lcds-share__btn lcds-share--default__btn-linkedin js-share\" href=\"https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.fda.gov%2Findustry%2Fstructured-product-labeling-resources%2Fdosage-forms&amp;title=Dosage%20Forms&amp;source=FDA\" id=\"linkedin-share\" target=\"_blank\">\n              <span aria-hidden=\"true\" class=\"fa icon-linkedin\">\n              </span>\n              Linkedin\n             </a>\n            </li>\n            <li class=\"lcds-share__item\">\n             <a class=\"lcds-share__btn lcds-share--default__btn-mail\" href=\"mailto:?subject=Dosage%20Forms&amp;body=https://www.fda.gov%2Findustry%2Fstructured-product-labeling-resources%2Fdosage-forms\">\n              <span aria-hidden=\"true\" class=\"fa icon-envelope\">\n              </span>\n              Email\n             </a>\n            </li>\n            <li class=\"lcds-share__item hidden-xs\">\n             <a class=\"lcds-share__btn lcds-share--default__btn-print\" href=\"javascript:window.print();\" title=\"Print this page\">\n              <span aria-hidden=\"true\" class=\"fa icon-print\">\n              </span>\n              Print\n             </a>\n            </li>\n           </ul>\n           <div class=\"form-group\">\n           </div>\n          </div>\n         </div>\n        </section>\n       </header>\n       <div class=\"col-md-8 col-md-push-2\" role=\"main\">\n        <p>\n         NCI Thesaurus OID: 2.16.840.1.113883.3.26.1.1\n        </p>\n        <p>\n         NCI concept code for pharmaceutical dosage form: C42636\n        </p>\n        <p>\n        </p>\n        <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" style=\"height: 2683px;\" width=\"95%\">\n         <tbody>\n          <tr>\n           <th scope=\"col\" style=\"height: 13px; text-align: left;\" valign=\"top\" width=\"400\">\n            <strong>\n             SPL Acceptable Term\n            </strong>\n           </th>\n           <th scope=\"col\" style=\"height: 13px; text-align: left;\" valign=\"top\" width=\"316\">\n            <strong>\n             Code\n            </strong>\n           </th>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"height: 21px; text-align: left;\" valign=\"top\">\n            AEROSOL\n           </td>\n           <td style=\"height: 21px;\" valign=\"top\" width=\"316\">\n            C42887\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            AEROSOL, FOAM\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42888\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            AEROSOL, METERED\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42960\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            AEROSOL, POWDER\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42971\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            AEROSOL, SPRAY\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42889\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            BAR, CHEWABLE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42892\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            BEAD\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42890\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            CAPSULE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C25158\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            CAPSULE, COATED\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42895\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            CAPSULE, COATED PELLETS\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42896\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            CAPSULE, COATED, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42917\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            CAPSULE, DELAYED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42902\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            CAPSULE, DELAYED RELEASE PELLETS\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42904\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            CAPSULE, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42916\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            CAPSULE, FILM COATED, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42928\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            CAPSULE, GELATIN COATED\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42936\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            CAPSULE, LIQUID FILLED\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42954\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            CELLULAR SHEET\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C100103\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            CHEWABLE GEL\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C134876\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            CLOTH\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60884\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            CONCENTRATE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60891\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            CREAM\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C28944\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            CREAM, AUGMENTED\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60897\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            CRYSTAL\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42901\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            DISC\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C43525\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            DOUCHE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42679\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            DRESSING\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42763\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            DRUG-ELUTING CONTACT LENS\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C185352\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            ELIXIR\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42912\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            EMULSION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42913\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            ENEMA\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42915\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            EXTRACT\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42929\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            FIBER, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60926\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            FILM\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42932\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            FILM, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42920\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            FILM, SOLUBLE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42984\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            FOR SOLUTION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60927\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            FOR SUSPENSION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60928\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            FOR SUSPENSION, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60929\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            GAS\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42933\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            GEL\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42934\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            GEL, DENTIFRICE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42906\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            GEL, METERED\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60930\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            GLOBULE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42937\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            GRANULE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42938\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            GRANULE, DELAYED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42903\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            GRANULE, EFFERVESCENT\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42909\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            GRANULE, FOR SOLUTION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42939\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            GRANULE, FOR SUSPENSION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42940\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            GRANULE, FOR SUSPENSION, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42921\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            GUM, CHEWING\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42894\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            IMPLANT\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42942\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INHALANT\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42944\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INJECTABLE FOAM\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C113106\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INJECTABLE, LIPOSOMAL\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60931\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INJECTION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42946\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INJECTION, EMULSION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42914\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INJECTION, LIPID COMPLEX\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42950\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INJECTION, POWDER, FOR SOLUTION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42974\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INJECTION, POWDER, FOR SUSPENSION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42976\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INJECTION, POWDER, FOR SUSPENSION, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42977\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INJECTION, POWDER, LYOPHILIZED, FOR LIPOSOMAL SUSPENSION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42959\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INJECTION, POWDER, LYOPHILIZED, FOR SOLUTION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42957\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INJECTION, POWDER, LYOPHILIZED, FOR SUSPENSION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42958\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INJECTION, POWDER, LYOPHILIZED, FOR SUSPENSION, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42956\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INJECTION, SOLUTION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42945\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INJECTION, SOLUTION, CONCENTRATE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42899\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INJECTION, SUSPENSION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42995\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INJECTION, SUSPENSION, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42926\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INJECTION, SUSPENSION, LIPOSOMAL\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42951\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INJECTION, SUSPENSION, SONICATED\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42988\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INSERT\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60933\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INSERT, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42922\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INTRAUTERINE DEVICE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C47915\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            IRRIGANT\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42947\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            JELLY\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42948\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            KIT\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C47916\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            LINIMENT\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42949\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            LIPSTICK\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42952\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            LIQUID\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42953\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            LIQUID, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60934\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            LOTION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C29167\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            LOTION, AUGMENTED\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60957\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            LOTION/SHAMPOO\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60958\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            LOZENGE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42955\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            MOUTHWASH\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C29269\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            NOT APPLICABLE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C48624\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            OIL\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42965\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            OINTMENT\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42966\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            OINTMENT, AUGMENTED\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60984\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            PASTE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42967\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            PASTE, DENTIFRICE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42907\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            PASTILLE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60985\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            PATCH\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42968\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            PATCH, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42923\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            PATCH, EXTENDED RELEASE, ELECTRICALLY CONTROLLED\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42911\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            PELLET\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42969\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            PELLET, IMPLANTABLE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42943\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            PELLETS, COATED, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42918\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            PILL\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C25394\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            PLASTER\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42970\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            POULTICE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C47913\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            POWDER\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42972\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            POWDER, DENTIFRICE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42908\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            POWDER, FOR SOLUTION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42973\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            POWDER, FOR SUSPENSION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42975\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            POWDER, METERED\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42961\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            RING\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60988\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            RINSE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42979\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SALVE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42980\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SHAMPOO\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42981\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SHAMPOO, SUSPENSION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42982\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SOAP\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42983\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SOLUTION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42986\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SOLUTION, CONCENTRATE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42898\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SOLUTION, FOR SLUSH\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42987\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SOLUTION, GEL FORMING / DROPS\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60994\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SOLUTION, GEL FORMING, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42935\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SOLUTION/ DROPS\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60992\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SPONGE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C47912\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SPRAY\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42989\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SPRAY, METERED\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42962\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SPRAY, SUSPENSION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42990\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            STICK\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42991\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            STRIP\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C47914\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SUPPOSITORY\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42993\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SUPPOSITORY, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42924\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SUSPENSION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42994\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SUSPENSION, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42925\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SUSPENSION/ DROPS\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60995\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SWAB\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C47898\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SYRUP\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42996\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SYSTEM\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C17423\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42998\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET, CHEWABLE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42893\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET, CHEWABLE, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C124794\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET, COATED\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42897\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET, COATED PARTICLES\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60997\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET, DELAYED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42905\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET, DELAYED RELEASE PARTICLES\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42997\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET, EFFERVESCENT\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42910\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42927\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET, FILM COATED\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42931\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET, FILM COATED, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42930\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET, FOR SOLUTION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C61004\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET, FOR SUSPENSION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C61005\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET, MULTILAYER\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42964\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET, MULTILAYER, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42963\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET, ORALLY DISINTEGRATING\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42999\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET, ORALLY DISINTEGRATING, DELAYED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C61006\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET, SOLUBLE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42985\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET, SUGAR COATED\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42992\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET WITH SENSOR\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C147579\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TAMPON\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C47892\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TAPE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C47897\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TINCTURE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C43000\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TROCHE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C43001\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"height: 13px; text-align: left;\" valign=\"top\">\n            WAFER\n           </td>\n           <td style=\"height: 13px;\" valign=\"top\" width=\"316\">\n            C43003\n           </td>\n          </tr>\n         </tbody>\n        </table>\n        <p>\n        </p>\n       </div>\n       <aside class=\"col-md-2 col-md-push-2\" role=\"complementary\">\n        <section class=\"block block-ctools block-entity-viewnode clearfix\" data-block-plugin-id=\"entity_view:node\" id=\"block-entityviewcontent-4\">\n         <div about=\"/industry/structured-product-labeling-resources/dosage-forms\" class=\"region region-\" role=\"article\">\n          <aside class=\"lcds-card lcds-card--border-top\" role=\"menu\">\n           <ul class=\"lcds-description-list\">\n            <div class=\"node-current-date\">\n             <li class=\"lcds-description-list__item\">\n              <div>\n               <h2 class=\"lcds-description-list__item-heading\">\n                Content current as of:\n               </h2>\n               <p class=\"lcds-description-list__item-text\">\n                <time datetime=\"2022-02-03T10:05:00Z\">\n                 02/03/2022\n                </time>\n               </p>\n              </div>\n             </li>\n            </div>\n            <li class=\"lcds-description-list__item\">\n             <div>\n             </div>\n            </li>\n           </ul>\n          </aside>\n         </div>\n        </section>\n       </aside>\n       <aside class=\"col-md-2 col-md-pull-10\" role=\"complementary\">\n        <section class=\"block block-ctools block-entity-viewnode clearfix\" data-block-plugin-id=\"entity_view:node\" id=\"block-entityviewcontent-3\">\n         <div about=\"/industry/structured-product-labeling-resources/dosage-forms\" class=\"region region-\" role=\"article\">\n          <nav class=\"lcds-card lcds-section-nav lcds-section-nav--side hidden-xs hidden-sm\" id=\"section-nav\">\n           <ul class=\"lcds-section-nav__list lcds-section-nav--side__list\">\n            <li>\n             <a class=\"lcds-section-nav__link lcds-section-nav--side__link lcds-section-nav__parent-link lcds-section-nav--side__parent-link\" href=\"/industry/fda-data-standards-advisory-board/structured-product-labeling-resources\">\n              Structured Product Labeling Resources\n             </a>\n             <div class=\"views-element-container form-group\">\n              <div class=\"view view-in-this-section view-id-in_this_section view-display-id-block_4 js-view-dom-id-7052ac552cdf9acaaacaa914f38eb45810207bb0b850a71d83827891898b73a4\">\n               <div class=\"item-list\">\n                <ul class=\"lcds-section-nav__active lcds-section-nav__list lcds-section-nav--side__list\">\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/risk-evaluation-and-mitigation-strategies-rems-spl-resources\">\n                   REMS SPL Resources\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/business-entity-identifiers\">\n                   Business Entity Identifiers\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/business-operation\">\n                   Business Operation\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/business-operation-qualifier\">\n                   Business Operation Qualifier\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/code-system-object-identifiers\">\n                   Code System Object Identifiers\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/combination-product-types\">\n                   Combination Product Types\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/contributing-factor-general\">\n                   Contributing Factor - General\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/document-type-including-content-labeling-type\">\n                   Document Type including Content of Labeling Type\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/dosage-forms\">\n                   Dosage Forms\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/electronic-animal-drug-product-listing-directory\">\n                   Electronic Animal Drug Product Listing Directory\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/equivalence-codes\">\n                   Equivalence Codes\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/flavor\">\n                   Flavor\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/geopolitical-entities-names-and-codes-genc\">\n                   Geopolitical Entities, Names, and Codes (GENC)\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/indication-category\">\n                   Indication Category\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/intent-use\">\n                   Intent of Use\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/lab-test\">\n                   Lab Test\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/license-disciplinary-action\">\n                   License Disciplinary Action\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/licensed\">\n                   Licensed\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/limitation-useissues\">\n                   Limitation of Use/Issues\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/marketing-category\">\n                   Marketing Category\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/marketing-status\">\n                   Marketing Status\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/medical-condition\">\n                   Medical Condition\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/ndcnhric-labeler-codes\">\n                   NDC/NHRIC Labeler Codes\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/nsde\">\n                   NSDE\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/package-type\">\n                   Package Type\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/pharmacokinetic-effect\">\n                   Pharmacokinetic Effect\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/pharmacologic-class\">\n                   Pharmacologic Class\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/positron-emission-tomography-pet-drug-spl\">\n                   Positron Emission Tomography (PET) Drug SPL\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/precondition-categories\">\n                   Precondition Categories\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/race\">\n                   Race\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/rems-approval\">\n                   REMS Approval\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/rems-protocol\">\n                   REMS Protocol\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/rems-requirements\">\n                   REMS Requirements\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/rems-stakeholder\">\n                   REMS Stakeholder\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/resources-spl-commercial-software-and-conversion-vendors-and-fda-regulated-company-self-generated\">\n                   Resources for SPL Commercial Software and Conversion Vendors and FDA-Regulated Company Self-Generated SPL Software Developers\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/route-administration\">\n                   Route of Administration\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/section-headings-loinc\">\n                   Section Headings (LOINC)\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/sex\">\n                   Sex\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/spl-color\">\n                   SPL Color\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/spl-dea-schedule\">\n                   SPL DEA Schedule\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/spl-lot-distribution-data-distribution-codes\">\n                   SPL Lot Distribution Data - Distribution Codes\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/spl-shape\">\n                   SPL Shape\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/spl-standard-training\">\n                   SPL Standard Training\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/spl-xforms\">\n                   SPL Xforms\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/time-units\">\n                   Time Units\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/type-consequence\">\n                   Type of Consequence\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/uniis-preferred-substance-names-and-their-identified-synonyms\">\n                   UNIIs, Preferred Substance Names, and their Identified Synonyms\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/units-measure\">\n                   Units of Measure\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/units-presentation\">\n                   Units of Presentation\n                  </a>\n                 </li>\n                </ul>\n               </div>\n              </div>\n             </div>\n             <div class=\"views-element-container form-group\">\n              <div class=\"view view-in-this-section-sub view-id-in_this_section_sub view-display-id-block_1 js-view-dom-id-d6b7e60010e3c8b128f9529aafa6118c16146d9d2f9752ab7ab27c9702c81b73\">\n              </div>\n             </div>\n            </li>\n           </ul>\n          </nav>\n         </div>\n        </section>\n       </aside>\n      </article>\n     </main>\n    </div>\n   </div>\n   <div class=\"region region-subscribe\">\n    <section class=\"block block-ctools block-entity-viewnode clearfix\" data-block-plugin-id=\"entity_view:node\" id=\"block-entityviewcontent-5\">\n    </section>\n   </div>\n   <footer class=\"lcds-footer container-fluid\">\n    <div class=\"row lcds-footer__primary\">\n     <h2 class=\"sr-only\" id=\"footer-heading\">\n      Footer Links\n     </h2>\n     <nav class=\"text-center\">\n      <div class=\"col-sm-4\">\n       <ul class=\"nav\">\n        <li>\n         <a href=\"/about-fda/about-website/fdagov-archive\">\n          FDA Archive\n         </a>\n        </li>\n        <li>\n         <a href=\"/about-fda\">\n          About FDA\n         </a>\n        </li>\n        <li>\n         <a href=\"/about-fda/about-website/internet-accessibility\">\n          Accessibility\n         </a>\n        </li>\n       </ul>\n      </div>\n      <div class=\"col-sm-4\">\n       <ul class=\"nav\">\n        <li>\n         <a href=\"/about-fda/visitor-information\">\n          Visitor Information\n         </a>\n        </li>\n        <li>\n         <a href=\"/about-fda/about-website/website-policies\">\n          Website Policies / Privacy\n         </a>\n        </li>\n        <li>\n         <a href=\"/about-fda/jobs-and-training-fda/no-fear-act\">\n          No FEAR Act\n         </a>\n        </li>\n        <li>\n         <a href=\"https://www.hhs.gov/vulnerability-disclosure-policy/index.html\">\n          Vulnerability Disclosure Policy\n         </a>\n        </li>\n       </ul>\n      </div>\n      <div class=\"col-sm-4\">\n       <ul class=\"nav\">\n        <li>\n         <a href=\"/regulatory-information/freedom-information\" title=\"Freedom of Information Act\">\n          FOIA\n         </a>\n        </li>\n        <li>\n         <a href=\"https://www.hhs.gov/\" target=\"_blank\" title=\"Health and Human Services\">\n          HHS.gov\n         </a>\n        </li>\n        <li>\n         <a href=\"https://www.usa.gov/\" target=\"_blank\">\n          USA.gov\n         </a>\n        </li>\n       </ul>\n      </div>\n     </nav>\n    </div>\n    <div class=\"row lcds-footer__secondary\">\n     <div class=\"col-sm-12 col-md-6 col-lg-4 lcds-footer__social-links\">\n      <a class=\"btn btn-default btn-md\" href=\"/about-fda/contact-fda\">\n       Contact FDA\n      </a>\n      <a class=\"no-disclaimer\" href=\"https://www.facebook.com/FDA\" title=\"Follow FDA on Facebook\">\n       <span aria-hidden=\"true\" class=\"fa fa-facebook fa-2x\">\n        <span class=\"sr-only\">\n         Follow FDA on Facebook\n        </span>\n       </span>\n      </a>\n      <a class=\"no-disclaimer\" href=\"https://www.twitter.com/US_FDA\" title=\"Follow FDA on Twitter\">\n       <span aria-hidden=\"true\" class=\"fa fa-twitter fa-2x\">\n        <span class=\"sr-only\">\n         Follow FDA on Twitter\n        </span>\n       </span>\n      </a>\n      <a class=\"no-disclaimer\" href=\"https://instagram.com/FDA\" title=\"Follow FDA on Instagram\">\n       <span aria-hidden=\"true\" class=\"fa fa-instagram fa-2x\">\n        <span class=\"sr-only\">\n         Follow FDA on Instagram\n        </span>\n       </span>\n      </a>\n      <br class=\"visible-xs-inline\">\n       <a class=\"no-disclaimer\" href=\"https://www.linkedin.com/company/fda/\" title=\"Follow FDA on LinkedIn\">\n        <span aria-hidden=\"true\" class=\"fa fa-linkedin fa-2x\">\n         <span class=\"sr-only\">\n          Follow FDA on LinkedIn\n         </span>\n        </span>\n       </a>\n       <a class=\"no-disclaimer\" href=\"https://youtube.com/@US_FDA\" title=\"View FDA videos on YouTube\">\n        <span aria-hidden=\"true\" class=\"fa fa-youtube fa-2x\">\n         <span class=\"sr-only\">\n          View FDA videos on YouTube\n         </span>\n        </span>\n       </a>\n       <a href=\"/about-fda/contact-fda/subscribe-podcasts-and-news-feeds\" title=\"Subscribe to FDA RSS feeds\">\n        <span aria-hidden=\"true\" class=\"fa fa-rss fa-2x\">\n         <span class=\"sr-only\">\n          Subscribe to FDA RSS feeds\n         </span>\n        </span>\n       </a>\n      </br>\n     </div>\n     <a href=\"/\" title=\"FDA Homepage\">\n      <div class=\"visible-lg-block col-lg-4 text-center lcds-footer__logo\">\n       <span class=\"sr-only\">\n        FDA Homepage\n       </span>\n      </div>\n     </a>\n     <div class=\"col-sm-12 col-md-6 col-lg-4 text-center lcds-footer__contact-number\">\n      <span aria-hidden=\"true\" class=\"fa fa-phone\">\n      </span>\n      <span class=\"sr-only\">\n       Contact Number\n      </span>\n      1-888-INFO-FDA (1-888-463-6332)\n     </div>\n    </div>\n    <script type=\"text/javascript\">\n     (function(){var g=function(e,h,f,g){\n  this.get=function(a){for(var a=a+\"=\",c=document.cookie.split(\";\"),b=0,e=c.length;b<e;b++){for(var d=c[b];\" \"==d.charAt(0);)d=d.substring(1,d.length);if(0==d.indexOf(a))return d.substring(a.length,d.length)}return null};\n  this.set=function(a,c){var b=\"\",b=new Date;b.setTime(b.getTime()+6048E5);b=\"; expires=\"+b.toGMTString();document.cookie=a+\"=\"+c+b+\"; path=/; \"};\n  this.check=function(){var a=this.get(f);if(a)a=a.split(\":\");else if(100!=e)\"v\"==h&&(e=Math.random()>=e/100?0:100),a=[h,e,0],this.set(f,a.join(\":\"));else return!0;var c=a[1];if(100==c)return!0;switch(a[0]){case \"v\":return!1;case \"r\":return c=a[2]%Math.floor(100/c),a[2]++,this.set(f,a.join(\":\")),!c}return!0};\n  this.go=function(){if(this.check()){var a=document.createElement(\"script\");a.type=\"text/javascript\";a.src=g+ \"&t=\" + (new Date()).getTime();document.body&&document.body.appendChild(a)}};\n  this.start=function(){var a=this;window.addEventListener?window.addEventListener(\"load\",function(){a.go()},!1):window.attachEvent&&window.attachEvent(\"onload\",function(){a.go()})}};\n  try{(new g(100,\"r\",\"QSI_S_ZN_6FpQ8uiCQiPh6SN\",\"https://zn6fpq8uicqiph6sn-fdawebcx.gov1.siteintercept.qualtrics.com/SIE/?Q_ZID=ZN_6FpQ8uiCQiPh6SN\")).start()}catch(i){}})();\n    </script>\n    <div id=\"ZN_6FpQ8uiCQiPh6SN\">\n     <!--DO NOT REMOVE-CONTENTS PLACED HERE-->\n    </div>\n    <!--END WEBSITE FEEDBACK SNIPPET-->\n   </footer>\n   <a class=\"btn btn-primary btn-top\" href=\"\" id=\"btn-top\">\n    <span class=\"sr-only\">\n     Back to\n    </span>\n    Top\n   </a>\n  </div>\n  <script data-drupal-selector=\"drupal-settings-json\" type=\"application/json\">\n   {\"path\":{\"baseUrl\":\"\\/\",\"scriptPath\":null,\"pathPrefix\":\"\",\"currentPath\":\"node\\/358928\",\"currentPathIsAdmin\":false,\"isFront\":false,\"currentLanguage\":\"en\"},\"pluralDelimiter\":\"\\u0003\",\"suppressDeprecationErrors\":true,\"jquery\":{\"ui\":{\"datepicker\":{\"isRTL\":false,\"firstDay\":0}}},\"fda_ckeditor_enhancements\":{\"basePath\":\"modules\\/custom\\/fda_ckeditor_enhancements\"},\"google_analytics\":{\"account\":\"UA-22737364-1\",\"trackOutbound\":true,\"trackMailto\":true,\"trackDownload\":true,\"trackDownloadExtensions\":\"7z|aac|arc|arj|asf|asx|avi|bin|csv|doc(x|m)?|dot(x|m)?|exe|flv|gif|gz|gzip|hqx|jar|jpe?g|js|mp(2|3|4|e?g)|mov(ie)?|msi|msp|pdf|phps|png|ppt(x|m)?|pot(x|m)?|pps(x|m)?|ppam|sld(x|m)?|thmx|qtm?|ra(m|r)?|sea|sit|tar|tgz|torrent|txt|wav|wma|wmv|wpd|xls(x|m|b)?|xlt(x|m)|xlam|xml|z|zip\"},\"bootstrap\":{\"forms_has_error_value_toggle\":1,\"modal_animation\":1,\"modal_backdrop\":\"true\",\"modal_focus_input\":1,\"modal_keyboard\":1,\"modal_select_text\":1,\"modal_show\":1,\"modal_size\":\"\",\"popover_enabled\":1,\"popover_animation\":1,\"popover_auto_close\":1,\"popover_container\":\"body\",\"popover_content\":\"\",\"popover_delay\":\"0\",\"popover_html\":0,\"popover_placement\":\"right\",\"popover_selector\":\"\",\"popover_title\":\"\",\"popover_trigger\":\"click\"},\"ajax\":[],\"user\":{\"uid\":0,\"permissionsHash\":\"3aef67b4ac7d861d8624bf1f7ab2bc9cfc56d3c25b7d709dc15466dfa996dfb0\"}}\n  </script>\n  <script src=\"/files/js/js_Dci7uLWeq40FWcpIjiQjBlWDUvAHJXOZvUm0MMnj0C8.js\">\n  </script>\n </body>\n</html>\n\n\n\nThe following step was optional, but might be useful later, the web content could be saved as a file as shown below.\n\n# Create a file by passing the request content into write () method\n# and save the dosage form table as a file in binary format\nwith open(\"FDA_dosage_form\", \"wb\") as file:\n    file.write(data.content)\n\n\n\n\n\nTransform web-scraped data into dataframe\n\n\nUsing Pandas dataframe library\n\nPandas.append()\nThe original pandas.append() method was going to be deprecated in future versions of Pandas. This old method was shown as below:\n```{python}\n# Create an empty dataframe with columns named \"Dosage_form\" & \"Code\"\ndosage_form = pd.DataFrame(columns = [\"Dosage_form\", \"Code\"])\n\n# Create a loop to find all <tr> tags in the soup object (scraped html content)\nfor row in soup.find_all(\"tr\"): \n  # Set the columns to contain contents under <td> tags by searching all rows\n  col = row.find_all(\"td\") \n    # if columns are not an empty list, \n    # add the texts under columns in specified orders\n    if (col != []): \n    dosage = col[0].text \n    code = col[1].text \n\n# Append each text item into the dosage_form dataframe\ndosage_form = dosage_form.append({\"Dosage_form\":dosage, \"Code\":code}, ignore_index = True)\n\n# Show dataframe\ndosage_form\n```\nThis method might still work currently, however, the newer and recommended methods would be to use the pandas.concat() method as shown below.\n\n\nPandas.concat()\nFirst example:\n\n# Create an empty dictionary\ndict = []\n\n# Create a loop to iterate through html tags from the soup (scraped html content)\n# find all html tags that began with <tr>\nfor row in soup.find_all(\"tr\"):\n    # each column would hold the items under <td> tags\n    col = row.find_all(\"td\")\n    if (col != []): \n        # dosage form in column 1\n        dosage = col[0].text\n        # code in column 2\n        code = col[1].text\n        # Append each dosage form & code into the dictionary\n        dict.append({\"DosageForm\": dosage, \"dosage_form\": code})\n\n# Check if the loop was iterating through the html tags\n# and that it was appending each dosage form & code into the dictionary \n# Uncomment line below\n#print(dict)\n\n# Create an empty dataframe with the column names wanted\ndosage_form = pd.DataFrame(columns = [\"DosageForm\", \"dosage_form\"])\n\n# Concatenate the dosage_form dataframe with the dataframe converted from dict\ndf_new = pd.concat([dosage_form, pd.DataFrame.from_dict(dict)])\n\n# Print the combined dataframe df_new\ndf_new\n\n\n\n\n\n  \n    \n      \n      DosageForm\n      dosage_form\n    \n  \n  \n    \n      0\n      AEROSOL\n      C42887\n    \n    \n      1\n      AEROSOL, FOAM\n      C42888\n    \n    \n      2\n      AEROSOL, METERED\n      C42960\n    \n    \n      3\n      AEROSOL, POWDER\n      C42971\n    \n    \n      4\n      AEROSOL, SPRAY\n      C42889\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      153\n      TAMPON\n      C47892\n    \n    \n      154\n      TAPE\n      C47897\n    \n    \n      155\n      TINCTURE\n      C43000\n    \n    \n      156\n      TROCHE\n      C43001\n    \n    \n      157\n      WAFER\n      C43003\n    \n  \n\n158 rows × 2 columns\n\n\n\n\n\nPandas.from_dict()\nSecond example by using pd.from_dict() method, which might have less lines of codes:\n\n# Create an empty dictionary\ndict = []\n\n# Create a loop to iterate through html tags from the soup (scraped html content)\n# find all html tags that began with <tr>\nfor row in soup.find_all(\"tr\"):\n    # each column would hold the items under <td> tags\n    col = row.find_all(\"td\")\n    if (col != []): \n        # dosage form in column 1\n        dosage = col[0].text\n        # code in column 2\n        code = col[1].text\n        # Append each dosage form & code into the dict\n        dict.append({\"DosageForm\": dosage, \"dosage_form\": code})\n\n# Check if the loop was working to iterate through the html tags\n# and that it was appending each dosage form & code into the dictionary \n# Uncomment line below\n#print(dict)\n\n# Convert the dictionary into a dataframe\ndf_new = pd.DataFrame.from_dict(dict)\n\n# Print the dataframe df_new\ndf_new\n\n\n\n\n\n  \n    \n      \n      DosageForm\n      dosage_form\n    \n  \n  \n    \n      0\n      AEROSOL\n      C42887\n    \n    \n      1\n      AEROSOL, FOAM\n      C42888\n    \n    \n      2\n      AEROSOL, METERED\n      C42960\n    \n    \n      3\n      AEROSOL, POWDER\n      C42971\n    \n    \n      4\n      AEROSOL, SPRAY\n      C42889\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      153\n      TAMPON\n      C47892\n    \n    \n      154\n      TAPE\n      C47897\n    \n    \n      155\n      TINCTURE\n      C43000\n    \n    \n      156\n      TROCHE\n      C43001\n    \n    \n      157\n      WAFER\n      C43003\n    \n  \n\n158 rows × 2 columns\n\n\n\n\n\n\nUsing Polars dataframe library\nPolars dataframe library also had a from_dict() method that could convert dictionary into a dataframe as shown below:\n\n# Create an empty dictionary\ndict = []\n\n# Create a loop to iterate through html tags from the soup (scraped html content)\n# find all html tags that began with <tr>\nfor row in soup.find_all(\"tr\"):\n    # each column would hold the items under <td> tags\n    col = row.find_all(\"td\")\n    if (col != []): \n        # dosage form in column 1\n        dosage = col[0].text\n        # code in column 2\n        code = col[1].text\n        # Append each dosage form & code into the dict\n        dict.append({\"DosageForm\": dosage, \"dosage_form\": code})\n\n# Check if the loop was iterating through the html tags\n# and that it was also appending each dosage form & code into the dictionary \n# Uncomment line below\n#print(dict)\n\n# Convert dictionary to dataframe\nnew_df = pl.from_dicts(dict)\nnew_df\n\n\n\n\nshape: (158, 2)\n\n\n\n\nDosageForm\n\n\ndosage_form\n\n\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n\"AEROSOL\"\n\n\n\"C42887\"\n\n\n\n\n\"AEROSOL, FOAM\"\n\n\n\"C42888\"\n\n\n\n\n\"AEROSOL, METER...\n\n\n\"C42960\"\n\n\n\n\n\"AEROSOL, POWDE...\n\n\n\"C42971\"\n\n\n\n\n\"AEROSOL, SPRAY...\n\n\n\"C42889\"\n\n\n\n\n\"BAR, CHEWABLE\"\n\n\n\"C42892\"\n\n\n\n\n\"BEAD\"\n\n\n\"C42890\"\n\n\n\n\n\"CAPSULE\"\n\n\n\"C25158\"\n\n\n\n\n\"CAPSULE, COATE...\n\n\n\"C42895\"\n\n\n\n\n\"CAPSULE, COATE...\n\n\n\"C42896\"\n\n\n\n\n\"CAPSULE, COATE...\n\n\n\"C42917\"\n\n\n\n\n\"CAPSULE, DELAY...\n\n\n\"C42902\"\n\n\n\n\n...\n\n\n...\n\n\n\n\n\"TABLET, MULTIL...\n\n\n\"C42964\"\n\n\n\n\n\"TABLET, MULTIL...\n\n\n\"C42963\"\n\n\n\n\n\"TABLET, ORALLY...\n\n\n\"C42999\"\n\n\n\n\n\"TABLET, ORALLY...\n\n\n\"C61006\"\n\n\n\n\n\"TABLET, SOLUBL...\n\n\n\"C42985\"\n\n\n\n\n\"TABLET, SUGAR ...\n\n\n\"C42992\"\n\n\n\n\n\"TABLET WITH SE...\n\n\n\"C147579\"\n\n\n\n\n\"TAMPON\"\n\n\n\"C47892\"\n\n\n\n\n\"TAPE\"\n\n\n\"C47897\"\n\n\n\n\n\"TINCTURE\"\n\n\n\"C43000\"\n\n\n\n\n\"TROCHE\"\n\n\n\"C43001\"\n\n\n\n\n\"WAFER\"\n\n\n\"C43003\"\n\n\n\n\n\n\n\n\n\n\nPreparation of dataframe for data visualisation\nOnce we have the scraped dataframe ready, we could combine it with our original dataframe from the .csv file (the idea was basically doing dataframe join). Then the dosage form code column could be removed to make it easier to read.\n\n# Join the two dataframes together\ndf_final = df_med.join(new_df, on = \"dosage_form\")\n# Drop the column dosage_form which had codes of each dosage form \ndf_final = df_final.drop(\"dosage_form\")\ndf_final\n\n\n\n\nshape: (83925, 5)\n\n\n\n\nsplshape_text\n\n\nsplcolor_text\n\n\nspl_strength\n\n\nspl_inactive_ing\n\n\nDosageForm\n\n\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n\"CAPSULE\"\n\n\n\"PINK\"\n\n\n\"TEMAZEPAM 15 m...\n\n\n\"SILICON DIOXID...\n\n\n\"CAPSULE\"\n\n\n\n\n\"ROUND\"\n\n\n\"ORANGE\"\n\n\n\"IBUPROFEN 200 ...\n\n\n\"SILICON DIOXID...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"PENTAGON (5 SI...\n\n\n\"GREEN\"\n\n\n\"DEXAMETHASONE ...\n\n\n\"ANHYDROUS LACT...\n\n\n\"TABLET\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"Nickel Sulfate...\n\n\nnull\n\n\n\"TABLET\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"CLONAZEPAM 0.2...\n\n\n\"SORBITOL;ASPAR...\n\n\n\"TABLET, ORALLY...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"SILDENAFIL CIT...\n\n\n\"ANHYDROUS DIBA...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"OVAL\"\n\n\n\"YELLOW\"\n\n\n\"RISPERIDONE 3 ...\n\n\n\"LACTOSE MONOHY...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"CAPSULE\"\n\n\n\"BLUE\"\n\n\n\"IBUPROFEN 200 ...\n\n\n\"FD&C BLUE NO. ...\n\n\n\"CAPSULE, LIQUI...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"Iloperidone 12...\n\n\n\"silicon dioxid...\n\n\n\"TABLET\"\n\n\n\n\n\"CAPSULE\"\n\n\n\"YELLOW;WHITE\"\n\n\n\"FENOPROFEN CAL...\n\n\n\"CROSPOVIDONE;M...\n\n\n\"CAPSULE\"\n\n\n\n\n\"ROUND\"\n\n\n\"YELLOW\"\n\n\n\"BUTALBITAL 50 ...\n\n\n\"STARCH, CORN;C...\n\n\n\"TABLET\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"ESTRADIOL 0.5 ...\n\n\n\"COPOVIDONE K25...\n\n\n\"TABLET\"\n\n\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"MEMANTINE HYDR...\n\n\n\"SILICON DIOXID...\n\n\n\"TABLET\"\n\n\n\n\n\"CAPSULE\"\n\n\n\"ORANGE\"\n\n\n\"ACETAMINOPHEN ...\n\n\n\"BUTYLATED HYDR...\n\n\n\"CAPSULE, LIQUI...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"LAMOTRIGINE 25...\n\n\n\"MAGNESIUM CARB...\n\n\n\"TABLET, CHEWAB...\n\n\n\n\n\"OVAL\"\n\n\n\"BLUE\"\n\n\n\"ACETAMINOPHEN ...\n\n\n\"ACESULFAME POT...\n\n\n\"TABLET, COATED...\n\n\n\n\n\"OVAL\"\n\n\n\"WHITE\"\n\n\n\"AZITHROMYCIN D...\n\n\n\"CROSCARMELLOSE...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"OVAL\"\n\n\n\"BLUE\"\n\n\n\"IBUPROFEN 200 ...\n\n\n\"FD&C BLUE NO. ...\n\n\n\"CAPSULE, LIQUI...\n\n\n\n\n\"OVAL\"\n\n\n\"WHITE\"\n\n\n\"CETIRIZINE HYD...\n\n\n\"STARCH, CORN;H...\n\n\n\"TABLET\"\n\n\n\n\n\"OVAL\"\n\n\n\"BROWN\"\n\n\n\"OMEPRAZOLE 20 ...\n\n\n\"CARNAUBA WAX;F...\n\n\n\"TABLET, DELAYE...\n\n\n\n\n\"ROUND\"\n\n\n\"PINK;ORANGE;YE...\n\n\n\"CALCIUM CARBON...\n\n\n\"CITRIC ACID MO...\n\n\n\"TABLET, CHEWAB...\n\n\n\n\n\"OVAL\"\n\n\n\"GREEN\"\n\n\n\"ACETAMINOPHEN ...\n\n\n\"STARCH, CORN;D...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"CAPSULE\"\n\n\n\"BLUE\"\n\n\n\"Amlodipine bes...\n\n\n\"Cellulose, mic...\n\n\n\"CAPSULE\"\n\n\n\n\n\"ROUND\"\n\n\n\"ORANGE\"\n\n\n\"DARIFENACIN 15...\n\n\n\"ANHYDROUS DIBA...\n\n\n\"TABLET, EXTEND...\n\n\n\n\n\n\n\n\nHere, we could save the intended dataframe for data visualisation as a .csv file, so that further data wrangling and mining could be done later for part 2. This also avoided making request calls to the website again and again by extracting the scraped web information as a stand-alone file which could be imported when needed later on.\n\n# Save the inital cleaned dataframe as .csv file\n# for use in a new .ipynb file with Rust kernel\ndf_final.write_csv(\"pills.csv\", sep = \",\")"
  },
  {
    "objectID": "posts/Blog-Update/Update_on_portfolio.html",
    "href": "posts/Blog-Update/Update_on_portfolio.html",
    "title": "Update on portfolio",
    "section": "",
    "text": "So things have gone a little busier than usual behind the scene from last week till this week. As we know it, it’s always hard to plan when things are on the flow, especially in the current climate. So, a little about what I’m working on lately:\n\n\n\nPhoto by RetroSupply on Unsplash\n\n\n\nI’ve started working on an extension project to the rare disease work (recent Python project) by delving further into the natural history of rare diseases by using Orphanet’s data source (having fun working with xml files)\nWith the turn of events lately, I’m now also learning R programming language (which is something I was planning to do much later, but… to do this now is also fine as this’ll keep me on the ball) and surprisingly it is quite similar to Python in some ways but not at all as well\nTableau project most likely needs further work apart from what the dashboard is looking like at the moment (might be still a bit bare) but at the moment, my focus is on above two projects in the meantime. I’ll try to squeeze more time to work on this soon\n\nOther than that, I’m grateful that I can still work on things of great interests and the world is somehow still functioning in its best possible ways – onwards and upwards hopefully."
  },
  {
    "objectID": "posts/07_Molecular_similarities_in_COVID-19_antivirals/Mol_sim_covid.html",
    "href": "posts/07_Molecular_similarities_in_COVID-19_antivirals/Mol_sim_covid.html",
    "title": "Molecular similarities in selected COVID-19 antivirals",
    "section": "",
    "text": "Why this post?\nWell, I’ve always had a thought sitting at the back of my mind about working on a chemistry-related data project. It was partly due to the research saga detailed in another blog post. About two months ago, I thought I will never be able to get anything decent (e.g. first-author paper) published out of my PhD, so I was thinking of going down the route of working on health data science, which was where I could tie in my pharmacist background. Miraculously, the paper actually got published last month, which meant I might have more career options now…\nThe funny thing was that before I knew this paper was coming, I’ve already made up my mind about working on at least one piece of chemistry-related work before leaving it behind completely. Therefore, this was how I got myself started on this post, a small piece of cheminformatics work on molecular similarity for selected COVID-19 antivirals, as taking my first baby step in this field.\n\n\nHeads up\nThis work was coded entirely in Python3 and saved as .ipynb file initially in Jupyter Notebook. It was later converted into .qmd file via CLI1, which was run without problems in RStudio IDE. One thing to note was that all 2D chemical structures or similarity maps did not physically show up in RStudio IDE after code executions, but after file rendering, all of them appeared accordingly in the published version.\n\n\n\n\nPhoto by D koi on Unsplash\n\n\n\n\n\n\nThe COVID-19 antivirals\nWithout going into too much pharmacodynamic profiles for these antivirals, as that could easily be another blog post, I’ll provide only brief overviews on how these medicines were used mainly in the New Zealand context (may vary for different countries).\n\nnirmatrelvir & ritonavir\nOne of the oral COVID-19 antivirals, marketed as Paxlovid, was indicated for mild to moderate symptoms, or at risk of severe disease. For effectiveness, it needed to be taken within 5 days of symptom onset, otherwise it might not work as expected. As a side note, ritonavir was added like an enhancer agent for nirmatrelvir, due to its known ability to inhibit CYP3A2-mediated metabolism of nirmatrelvir, therefore, by having it also inside the oral tablet, it would ensure that the plasma concentration of nirmatrelvir would be kept at an optimal therapeutic level in vivo, vital for the antiviral effect. One of the well-known downsides for this medicine was that it could cause drug interactions with several other commonly used medications such as dabigatran, or potent CYP3A inducers such as carbamazepine as one of the examples (for full drug interaction profiles, please consult local guidelines). Renal functions was also another important factor to consider when dosing.\n\n\nmolnupiravir\nThis was the other oral COVID-19 antiviral, also indicated for mild to moderate symptoms or at risk of severe disease, and also if the option of nirmatrelvir with ritonavir was unsuitable. It was often selected as an oral alternative to nirmatrelvir with ritonavir to avoid drug interactions. It also needed to be taken within 5 days of symptom onset to reach optimal effect.\n\n\nremdesivir\nThis was administered via intravenous infusion for selected adult or paediatric patients (depends on local guidelines) when they were hospitalised and at risk of developing severe disease. Current consideration for its use would be within 7 days of symptom onset. It was classed as a section 29 medicine, which meant it was unapproved, but could be prescribed on a case-by-case basis by qualified medical practitioners.\n\n\nbaricitinib\nThis was also another unapproved, section 29 medicine, indicated for use in hospitalised patients on a case-by-case basis. It was indicated for moderate to severe disease with renally-adjusted dose via oral or nasogastric route.\n\n\n\n\nSource of dataset\nThe URLs to obtain canonical simplified molecular input line entry systems (SMILES) of all 5 molecules are listed below (there are several different ways to obtain SMILES for molecules, I’ve decided to use PubChem in this case):\n\nPubChem [Internet]. Bethesda (MD): National Library of Medicine (US), National Center for Biotechnology Information; 2004-. PubChem Compound Summary for CID 155903259, Nirmatrelvir; [cited 2022 Nov. 13]. Available from: https://pubchem.ncbi.nlm.nih.gov/compound/Nirmatrelvir\nPubChem [Internet]. Bethesda (MD): National Library of Medicine (US), National Center for Biotechnology Information; 2004-. PubChem Compound Summary for CID 392622, Ritonavir; [cited 2022 Nov. 13]. Available from: https://pubchem.ncbi.nlm.nih.gov/compound/Ritonavir\nPubChem [Internet]. Bethesda (MD): National Library of Medicine (US), National Center for Biotechnology Information; 2004-. PubChem Compound Summary for CID 145996610, EIDD-2801; [cited 2022 Nov. 13]. Available from: https://pubchem.ncbi.nlm.nih.gov/compound/eidd-2801\nPubChem [Internet]. Bethesda (MD): National Library of Medicine (US), National Center for Biotechnology Information; 2004-. PubChem Compound Summary for CID 121304016, Remdesivir; [cited 2022 Nov. 13]. Available from: https://pubchem.ncbi.nlm.nih.gov/compound/Remdesivir\nPubChem [Internet]. Bethesda (MD): National Library of Medicine (US), National Center for Biotechnology Information; 2004-. PubChem Compound Summary for CID 44205240, Baricitinib; [cited 2022 Nov. 13]. Available from: https://pubchem.ncbi.nlm.nih.gov/compound/Baricitinib\n\n\n\n\nInstall modules/libraries\nInstall relevant libraries if needed.\n\n# Uncomment and install the following libraries if required \n#!pip install rdkit-pypi pandas mols2grid matplotlib\n\nImport libraries needed as shown below.\n\n# RDKit chemistry\nfrom rdkit import Chem\n# RDKit drawing\nfrom rdkit.Chem.Draw import IPythonConsole\nfrom rdkit.Chem import Draw\n# RDKit fingerprint generator\nfrom rdkit.Chem import rdFingerprintGenerator\n# RDKit functionality for basic data structures\nfrom rdkit.Chem import DataStructs\n# Settings to improve quality of structures\nfrom rdkit.Chem import rdDepictor\n# SVG = scalable vector graphics, set to false if wanting PNGs instead\nIPythonConsole.ipython_useSVG = True\nrdDepictor.SetPreferCoordGen(True)\n# Add ability to add a molecule to a dataframe\nfrom rdkit.Chem import PandasTools\n# mols2grid library provides convenient way to display molecules in a grid\nimport mols2grid\n# for dataframe manipulations\nimport pandas as pd\n# for plotting graphs\nimport matplotlib.pyplot as plt\n\n\n\n\nGenerate RDKit molecules based on SMILES\nBefore any actual molecular manipulation work could begin, the SMILES of all 5 molecules were downloaded from the source URLs. I’ve downloaded all 5 molecules’ SMILES and saved them as separate .sdf files (selected 2D structure option).\nSo I started off with nirmatrelvir with its canonical SMILES retrieved from PubChem. To display a molecule as a 2D chemical structure graphically, an open-source cheminformatics toolkit library, RDKit, was used.\n\n# Generate a RDKit molecule representing nirmatrelvir\nnmt = Chem.MolFromSmiles(\"CC1(C2C1C(N(C2)C(=O)C(C(C)(C)C)NC(=O)C(F)(F)F)C(=O)NC(CC3CCNC3=O)C#N)C\")\nnmt\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Create a RDKit molecule for ritonavir using canonical SMILES\nrit = Chem.MolFromSmiles(\"CC(C)C1=NC(=CS1)CN(C)C(=O)NC(C(C)C)C(=O)NC(CC2=CC=CC=C2)CC(C(CC3=CC=CC=C3)NC(=O)OCC4=CN=CS4)O\")\nrit\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Create a RDKit molecule for molnupiravir using canonical SMILES\nmol = Chem.MolFromSmiles(\"CC(C)C(=O)OCC1C(C(C(O1)N2C=CC(=NC2=O)NO)O)O\")\nmol\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Create a RDKit molecule for remdesivir by using canonical SMILES\nrem = Chem.MolFromSmiles(\"CCC(CC)COC(=O)C(C)NP(=O)(OCC1C(C(C(O1)(C#N)C2=CC=C3N2N=CN=C3N)O)O)OC4=CC=CC=C4\")\nrem\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Create a RDKit molecule for baricitinib by using canonical SMILES\nbar = Chem.MolFromSmiles(\"CCS(=O)(=O)N1CC(C1)(CC#N)N2C=C(C=N2)C3=C4C=CNC4=NC=N3\")\nbar\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDisplay 2D molecules in grid view\nTo display all 5 molecules in a grid view, I’ve saved all separate .sdf files into one .sdf file (e.g. covid_antivirals.sdf). A quick way to do this was via CLI by using one line of code: cat *.sdf > file_name.sdf (replace “file_name” as the actual file name wanted). One thing to be aware of was to make sure which working directory this was saved to, as it needed to be in the same directory as the .qmd file for it to work.\n\n# Save all 5 COVID-19 antivirals as a list in a cpds object\ncpds = [x for x in Chem.SDMolSupplier(\"covid_antivirals.sdf\")]\ncpds\n\n[<rdkit.Chem.rdchem.Mol at 0x11af999a0>,\n <rdkit.Chem.rdchem.Mol at 0x11af99b60>,\n <rdkit.Chem.rdchem.Mol at 0x11af99bd0>,\n <rdkit.Chem.rdchem.Mol at 0x11af99c40>,\n <rdkit.Chem.rdchem.Mol at 0x11af99cb0>]\n\n\nWell, this flexible grid view with function to select molecules would be much more useful if there were several thousands of molecules downloaded. I was just basically trialling this as a practice, which turned out quite nicely.\n\n# Display all compounds in a flexible grid view with selection function\nmols2grid.display(cpds)\n\n\n\n\n\n\n\n\n\nThen I thought about adding drug names to each molecule, rather than listing their IUPAC3 names, for the sake of easier reading and viewing. One of the ways to do this was to add legend with the drug names in the same order.\n\n# Display compounds in grid view with drug names shown\nDraw.MolsToGridImage(cpds, \n                     molsPerRow = 3, \n                     legends = (\"baricitinib\", \"molnupiravir\", \"nirmatrelvir\", \"remdesivir\", \"ritonavir\"), \n                     subImgSize=(300, 300), \n                     useSVG = True\n                    )\n\n\n\n\n\n\n\nSimilarity maps\nNow this part was interesting to me and I’ve spent at least a day or two to just try and understand the fundamentals behind this functionality in RDKit. One of the biggest help for me to fully understand this was this paper: Riniker, S.; Landrum, G. A. “Similarity Maps - A Visualization Strategy for Molecular Fingerprints and Machine-Learning Methods” J. Cheminf. 5:43 (2013). It explained the full methodology behind generating similarity map between compounds using molecular fingerprints.\n\n# Build similarity maps between molecules\n# Import additional libraries needed\nfrom rdkit.Chem.Draw import SimilarityMaps\nimport io\nfrom PIL import Image\n\nThe following step was important to ensure a good image of the map was produced for the molecules, by creating a function for “show_png” first, which was used later.\n\n# Binary i/o keeps data as bytes in an in-memory buffer\n# A function that creates a bytes object as an image\ndef show_png(data):\n    bio = io.BytesIO(data)\n    img = Image.open(bio)\n    return img\n\nI’ve randomly set nirmatrelvir as the reference compound. The other 4 molecules were set as test or probe molecules to be compared with the reference compound. So here I’ve compared nirmatrelvir with ritonavir first.\n\n# Create a Draw2D object \"a\" and specify size of 2D image\na = Draw.MolDraw2DCairo(500, 500)\n# Produces a similarity map for nirmatrelvir and ritonavir\n# Specify which compounds to compare (reference and probe) for the similarity map\nfig, maxweight = SimilarityMaps.GetSimilarityMapForFingerprint(nmt, rit, \n                                                               # creates a lambda function (anonymous function) for use within SimilarityMaps, \n                                                               # then select fingerprint type e.g. Morgan fingerprint\n                                                               # types of Morgan fingerprint: bit vector (bv, default) & count vector (count)\n                                                               lambda b, c: SimilarityMaps.GetMorganFingerprint(b, c, radius = 2, fpType = 'bv'),\n                                                               draw2d = a)\n\n# Finish drawing Draw2D object \"a\"                                                                                       \na.FinishDrawing()\n# Display similarity map                                                             \nshow_png(a.GetDrawingText())\n\n\n\n\nTo quickly explain how to look at the contour or topographical map in different colours for the molecule:\n\nGreen shades represented a positive difference or where the similarity decreased when the bits4 were removed\nPink shades showed negative difference or where the similarity increased when the bits were removed\nGrey shades meant there was no change\n\nAnother parameter that might allow us to interpret more easily was to obtain the maximum weight (also known as “maxweight” in the code) for the structure comparison between two molecules. Maximum weight could be understood as maximum difference between the reference and probe molecules. By default, maximum weight was capped at 1.0. This function was already built in above code, so to find out the maximum weight or difference for nirmatrelvir and ritonavir, simply just use the print() function.\n\n# Max weight between nirmatrelvir and ritonavir \nprint(maxweight)\n\n0.03389096421417358\n\n\nI’ve then saved this particular maxweight result with a different label name (to clearly show which molecules were being compared), for later use.\n\nmol2_rit_maxw_mol1 = maxweight\nmol2_rit_maxw_mol1\n\n0.03389096421417358\n\n\nTo further explain and understand the parameter of maximum weight, this paper by Riniker and Landrum have included a full calculation styled as pseudocodes in Python. I have attempted to summarise them in words, along with the codes (adapted from the paper), as below:\n```{python}\n# 1. Calculate the fingerprint for reference molecule\nref_fp = calculate_fingerprint (ref_mol)\n\n# 2. Calculate the fingerprint for test molecule\nthis_fp = calculate_fingerprint (this_mol)\n\n# 3. Create an empty weights list\nweights = []\n\n# 4. Calculate original similarity for ref mol & test mol based on Dice similarity\norig_simil = dice_similarity(ref_fp, this_fp)\n\n# 5. Loop over the different atoms present in the test mol\nfor atom in this_mol.get_atoms:\n\n# 5. (cont.) Generate a new fingerprint by calculating new fingerprints without each of the atom for the test mol\n    new_fp = calculate_fingerprint_without_atom(this_mol, atom)\n    \n# 5. (cont.) Calculate new similarity for the ref fingerprint & new fingerprint based on Dice similarity\n    new_simil = dice_similarity(ref_fp, new_fp)\n    \n# 6. The atomic weight will be calculated as the difference between the original similarity and the new similarity\nweight = original_simil - new_simil\n\n# 7. The atomic weight obtained for each loop iteration (for each atom present) will be added up to contribute to the final atomic weight\nweights.append(weight)\n\n# Note: maximum absolute weight is normalised and capped at 1.0\n```\nNext one was between nirmatrelvir and molnupiravir. I’ve renamed “maxweight” to “mol3_mol_maxw_mol1” to reflect this parameter was measured between 3rd molecule (molnupiravir) and 1st molecule (nirmatrelvir).\n\n# 2. Comparing nirmatrelvir and molnupiravir\na = Draw.MolDraw2DCairo(400, 400)\n# Produces a similarity map for molecules selected\n# Specify which compounds to compare (reference and probe) for the similarity map\nfig, mol3_mol_maxw_mol1 = SimilarityMaps.GetSimilarityMapForFingerprint(nmt, mol, \n                                                               # creates a lambda function (anonymous function) for use within SimilarityMaps, \n                                                               # then select fingerprint type e.g. Morgan fingerprint\n                                                               # types of Morgan fingerprint: bit vector (bv, default) & count vector (count)\n                                                               lambda b, c: SimilarityMaps.GetMorganFingerprint(b, c, radius = 2, fpType = 'bv'),\n                                                               draw2d = a)\n\n# Finish drawing Draw2D object \"a\"                                                                                       \na.FinishDrawing()\n# Display similarity map                                                             \nshow_png(a.GetDrawingText())\n\n\n\n\nThe maximum weight between nirmatrelvir and molnupiravir was shown as below.\n\nprint(mol3_mol_maxw_mol1)\n\n0.026617250673854453\n\n\nSimilarity map was then generated for nirmatrelvir and remdesivir.\n\n# 3. Comparing nirmatrelvir and remdesivir\na = Draw.MolDraw2DCairo(400, 400)\n# Produces a similarity map for molecules selected\n# Specify which compounds to compare (reference and probe) for the similarity map\nfig, mol4_rem_maxw_mol1 = SimilarityMaps.GetSimilarityMapForFingerprint(nmt, rem, \n                                                               # creates a lambda function (anonymous function) for use within SimilarityMaps, \n                                                               # then select fingerprint type e.g. Morgan fingerprint\n                                                               # types of Morgan fingerprint: bit vector (bv, default) & count vector (count)\n                                                               lambda b, c: SimilarityMaps.GetMorganFingerprint(b, c, radius = 2, fpType = 'bv'),\n                                                               draw2d = a)\n\n# Finish drawing Draw2D object \"a\"                                                                                       \na.FinishDrawing()\n# Display similarity map                                                             \nshow_png(a.GetDrawingText())\n\n\n\n\nTheir maximum weight was found as below.\n\nprint(mol4_rem_maxw_mol1)\n\n0.021674876847290636\n\n\nLastly, the comparison was made between nirmatrelvir and baricitinib.\n\n# 4. Comparing nirmatrelvir and baricitinib\na = Draw.MolDraw2DCairo(400, 400)\n# Produces a similarity map for molecules selected\n# Specify which compounds to compare (reference and probe) for the similarity map\nfig, mol5_bar_maxw_mol1 = SimilarityMaps.GetSimilarityMapForFingerprint(nmt, bar, \n                                                               # creates a lambda function (anonymous function) for use within SimilarityMaps, \n                                                               # then select fingerprint type e.g. Morgan fingerprint\n                                                               # types of Morgan fingerprint: bit vector (bv, default) & count vector (count)\n                                                               lambda b, c: SimilarityMaps.GetMorganFingerprint(b, c, radius = 2, fpType = 'bv'),\n                                                               draw2d = a)\n\n# Finish drawing Draw2D object \"a\"                                                                                       \na.FinishDrawing()\n# Display similarity map                                                             \nshow_png(a.GetDrawingText())\n\n\n\n\nThe maximum weight was found as below.\n\nprint(mol5_bar_maxw_mol1)\n\n0.026242075777679508\n\n\nShort summary:\n\nNirmatrelvir vs. remdesivir had the smallest maximum weight or difference out of all 5 compounds\nNirmatrelvir vs. ritonavir had the biggest maximum weight or difference out of all compounds, the second biggest one would be between nirmatrelvir and molnupiravir\n\n\n\n\nFingerprint generator\nAfter using the similarity maps, I found more things to trial in RDKit, and this one was a fingerprint generator. I’ve decided to use the same 5 molecules as before, and see if I could get similar results.\n\n# Re-label molecules for later use\nmol1 = nmt\nmol2 = rit\nmol3 = mol\nmol4 = rem\nmol5 = bar\n\n# Combine all 5 molecules into a list\nmols = [mol1, mol2, mol3, mol4, mol5]\n\nBelow was the set of codes used to generate a fingerprint between compounds. I’ve changed the radius to 2 to align with the similarity map test above.\n\n# Create an object fp to generate fingerprint\n# Default radius of molecule = 3 \nfp = rdFingerprintGenerator.GetMorganGenerator(radius = 2)\n# Get fingerprints of all molecules in the list\nfp1 = [fp.GetFingerprint(x) for x in mols]\nfp1\n\n[<rdkit.DataStructs.cDataStructs.ExplicitBitVect at 0x11b156ff0>,\n <rdkit.DataStructs.cDataStructs.ExplicitBitVect at 0x11b157060>,\n <rdkit.DataStructs.cDataStructs.ExplicitBitVect at 0x11b1570d0>,\n <rdkit.DataStructs.cDataStructs.ExplicitBitVect at 0x11b157140>,\n <rdkit.DataStructs.cDataStructs.ExplicitBitVect at 0x11b1571b0>]\n\n\nA loop was created to iterate through all 5 antivirals to compare their molecular similarities by using Tanimoto coefficient (TC)5. Particularly, each molecule was compared to the other 4 molecules, with results printed as shown below.\n\nfor i in range(len(fp1)):\n    for a in range(i):\n        tc = DataStructs.TanimotoSimilarity(fp1[i], fp1[a])\n        print(f'mol{i+1}-mol{a+1}: Tanimoto coefficient {tc}')\n\nmol2-mol1: Tanimoto coefficient 0.08461538461538462\nmol3-mol1: Tanimoto coefficient 0.10891089108910891\nmol3-mol2: Tanimoto coefficient 0.14953271028037382\nmol4-mol1: Tanimoto coefficient 0.10687022900763359\nmol4-mol2: Tanimoto coefficient 0.1386861313868613\nmol4-mol3: Tanimoto coefficient 0.19811320754716982\nmol5-mol1: Tanimoto coefficient 0.11214953271028037\nmol5-mol2: Tanimoto coefficient 0.09243697478991597\nmol5-mol3: Tanimoto coefficient 0.10989010989010989\nmol5-mol4: Tanimoto coefficient 0.15517241379310345\n\n\nI then saved each TC separately between nirmatrelvir and other 4 molecules. This was to create another list of these TCs for data visualisation later.\n\n# Tanimoto coefficient between nirmatrelvir (mol1) & ritonavir (mol2)\ntc_mol1_mol2 = DataStructs.TanimotoSimilarity(fp1[0], fp1[1])\n\n# Tanimoto coefficient between nirmatrelvir (mol1) & molnupiravir (mol3)\ntc_mol1_mol3 = DataStructs.TanimotoSimilarity(fp1[0], fp1[2])\n\n# Tanimoto coefficient between nirmatrelvir (mol1) & remdesivir (mol4)\ntc_mol1_mol4 = DataStructs.TanimotoSimilarity(fp1[0], fp1[3])\n\n# Tanimoto coefficient between nirmatrelvir (mol1) & baricitinib (mol5)\ntc_mol1_mol5 = DataStructs.TanimotoSimilarity(fp1[0], fp1[4])\n\nA new list was created to save all TCs for nirmatrelvir versus other 4 molecules.\n\ntc_mols = [tc_mol1_mol2, tc_mol1_mol3, tc_mol1_mol4, tc_mol1_mol5]\ntc_mols\n\n[0.08461538461538462,\n 0.10891089108910891,\n 0.10687022900763359,\n 0.11214953271028037]\n\n\nI thought to include following codes to ensure I wasn’t losing track on which molecule was which by having them displayed as 2D structures with labels.\n\n# Display compounds to help with recognising which antivirals are being compared\nDraw.MolsToGridImage(mols, \n                     molsPerRow = 3, \n                     legends = (\"mol1 = nirmatrelvir\", \"mol2 = ritonavir\", \"mol3 = molnupiravir\", \"mol4 = remdesivir\", \"mol5 = baricitinib\"), \n                     subImgSize=(300, 300), \n                     useSVG = True\n                    )\n\n\n\n\nAnother list was generated to save all maximum weights between nirmatrelvir and the rest of the molecules.\n\nmaxw_diff = [mol2_rit_maxw_mol1, mol3_mol_maxw_mol1, mol4_rem_maxw_mol1, mol5_bar_maxw_mol1]\nmaxw_diff\n\n[0.03389096421417358,\n 0.026617250673854453,\n 0.021674876847290636,\n 0.026242075777679508]\n\n\nA new dataframe was also created to include maximum weights and TCs of all 5 molecules.\n\ndf_ms = pd.DataFrame(list(zip(maxw_diff, tc_mols)),\n                     index = ['nmt_v_rit', 'nmt_v_mol', 'nmt_v_rem', 'nmt_v_bar'],\n                     columns = ['Maxweight', 'T_coeff']\n                    )\ndf_ms\n\n\n\n\n\n  \n    \n      \n      Maxweight\n      T_coeff\n    \n  \n  \n    \n      nmt_v_rit\n      0.033891\n      0.084615\n    \n    \n      nmt_v_mol\n      0.026617\n      0.108911\n    \n    \n      nmt_v_rem\n      0.021675\n      0.106870\n    \n    \n      nmt_v_bar\n      0.026242\n      0.112150\n    \n  \n\n\n\n\nTo produce a bar graph representing these parameters, I realised I would probably need to change the index into a column instead.\n\ndf_ms.reset_index(inplace = True)\ndf_ms_new = df_ms.rename(columns = {'index': 'Molecules'})\ndf_ms_new\n\n\n\n\n\n  \n    \n      \n      Molecules\n      Maxweight\n      T_coeff\n    \n  \n  \n    \n      0\n      nmt_v_rit\n      0.033891\n      0.084615\n    \n    \n      1\n      nmt_v_mol\n      0.026617\n      0.108911\n    \n    \n      2\n      nmt_v_rem\n      0.021675\n      0.106870\n    \n    \n      3\n      nmt_v_bar\n      0.026242\n      0.112150\n    \n  \n\n\n\n\n\n\n\nData visualisation and some findings\nA side-by-side bar graph showing two different molecular similarity parameters - maximum weights from similarity map and TCs calculated from Morgan fingerprints - was plotted based on the dataframe created above. It showed similar trend between these two molecular similarity tests for these known COVID-19 antivirals. In that, nirmatrelvir versus ritonavir showed the largest molecular difference out of all 5 compounds with the highest maximum weight. This was reflected in the lowest TC as the shortest orange bar, which implied a low similarity between the two molecules. Interestingly, between nirmatrelvir and remdesivir, it appeared the maximum weight was lowest of all 5 molecules, but the TC did not quite reflect that (being lower than that for nirmatrelvir versus molnupiravir and baricitinib).\n\n# Set the overall font size to make all labels on graph easier to read\nplt.rcParams.update({'font.size': 10})\n\n# Used nirmatrelvir as reference compound (mol1) and compared it with 4 other antivirals\n# If wanting stacked bar graph:\n#df_ms_new.plot(x = 'Molecules', \n               #kind = 'bar', \n               #width = 0.3, \n               #stacked = True, \n               #title = 'Molecular similarities between 5 known COVID-19 antivirals'\n               #)\n#plt.show()\n\n# Side-by-side bar graph\ndf_ms_new.plot(x = 'Molecules', \n               y = ['Maxweight', 'T_coeff'], \n               kind = 'bar', \n               figsize = (7, 7)\n               )\n# Add title\nplt.title(label = 'Molecular similarities between 5 known COVID-19 antivirals')\n\n# Add caption for graph re. abbreviations of all the molecules compared \n# Import textwrap module\nimport textwrap\nt = \"nmt = nirmatrelvir, \"\\\n    \"rit = ritonavir, \"\\\n    \"mol = molnupiravir, \"\\\n    \"rem = remdesivir, \"\\\n    \"bar = baricitinib\"\nb = textwrap.fill(t, width = 58)\nx = 'Molecules'\ny = ['Maxweight', 'T_coeff']\nplt.text(len(x) / 2, 0, b, ha = 'left', va = 'bottom')\n\nText(4.5, 0, 'nmt = nirmatrelvir, rit = ritonavir, mol = molnupiravir,\\nrem = remdesivir, bar = baricitinib')\n\n\n\n\n\n\nOne possibility for this difference could be that the maximum weight parameter in the similarity map test was based on Dice similarity (if referring back to the pseudocodes for how to calculate atomic weight), but for the other fingerprint generator test, Tanimoto similarity (also known as Jaccard coefficient) was used instead. These two similarity coefficients were actually calculated differently, with their equivalent equations shown below.\n\nTanimoto similarity/coefficient\nTC was the ratio of the number of chemical features common to two molecules (e.g. molecule a and molecule b) to the total number of chemical features in the two molecules. The following equation summarised this.\n\\[\n\\text{Tanimoto coefficient} = \\frac{(a \\cap b)}{(a + b - (a \\cap b))}\n\\]\n\n\nDice similarity/coefficient\nOn the other hand, Dice coefficient described the number of features in common for molecules a and b, relative to the average size of the total number of chemical features present in the two molecules. The weighting factor of 0.5 was shown in the denominator (or can be 2 in the numerator). The coefficient also ranges from zero to 1. The following showed the equation of Dice similarity.\n\\[\n\\text{Dice coefficient} = \\frac{(a \\cap b)}{0.5\\times(a + b)}\n\\]\n\n\n\n\nAcknowledgement\nThe codes used in this post were heavily inspired by and adapted from the following blogs and website shown below. I’ve learnt a lot from them, and would like to thank the existence of these blogs and website, which are helping readers like me to learn in an open-source manner. I particularly like the clear and concise writing style from P. Walter’s Practical Cheminformatics blog which is easy to follow. Iwatobipen’s is life worth living? blog has shown a very diverse range of cheminformatics tools available for use, and I’m constantly surprised by how many there are from this blog and also the generous sharing of all the codes.\n\nP. Walter’s blog\nIwatobipen’s blog\nRDKit documentation by G. Landrum\n\n\n\n\nFinal words\nI have read quite a few blog posts from P. Walter and Iwatobipen, and have enjoyed them but never quite got around to write one myself, so finally I did it! Although this post itself was not written in a grand scale, and I would warmly welcome comments for improvements or corrections, I hope to project what I did here in the future, e.g. to apply them to a much larger set of compounds. My very draft thought now is to perhaps trial using ChEMBL database, which is a well-known open-source cheminformatics library.\nAs a little prelude to what other work I’m planning to do, I’ve managed to start learning Rust as well. There is a back story about why I’ve started learning Rust, which I’ll leave as a probable new post in the future if I feel it fits the context of the post. From what I’ve tried so far, only at seedling stage, it’s going to be an even steeper learning curve than Python and R, but I feel it’s going to benefit whatever I’m planning to do consciously or unconsciously in the future.\n\n\n\n\n\nFootnotes\n\n\nCommand line interface↩︎\nCytochrome P450 enzymes of 3A subfamily↩︎\nInternational Union of Pure and Applied Chemistry↩︎\nBits in a bit vector or counts in a count vector are converted from structural features in chemical structures to formulate molecular fingerprints, which subsequently allows a more efficient way to compare chemical structures computationally↩︎\nRanged from zero (lowest similarity) to 1.0 (highest similarity), more on this in the next section↩︎"
  },
  {
    "objectID": "posts/10_ML2_Small_molecules_in_ChEMBL_database/ML2_chembl_cpds.html",
    "href": "posts/10_ML2_Small_molecules_in_ChEMBL_database/ML2_chembl_cpds.html",
    "title": "Small molecules in ChEMBL database",
    "section": "",
    "text": "Machine learning in drug discovery - series 2\n\n\n\nIntroduction\nThis work was really a continuation of the first machine learning (ML) in drug discovery series, “Small molecules in ChEMBL database - Polars dataframe library and machine learning in scikit-learn” (referred to as ML series 1 from here onwards). In particular, I wanted to work on the logistics regression (LR) model, and look into other strategies that I could use to improve it. Last time, I used LogisticRegression() method on the df_ml dataframe (df_ml_pd was the actual dataframe name used in ML series 1, to denote a conversion from a Polars to Pandas dataframe). I’ve not changed any parameters for the LR estimator, which meant everything was kept at default settings. Overall, this was an example of a default prototype of a LR classifer, which most likely would be too simplistic and not really reflecting real-world equivalents, but it sort of helped me to think in terms of a LR and ML context.\nThis time, with a goal of trying to improve the model, I’ve planned to use cross-validation and hyper-parameter tuning at least to evaluate the estimator performance. It was also worth evaluating whether LR was the best ML approach for the df_ml dataset, which would likely need to be kept as a separate post to avoid another lengthy read. I also, on the other hand, have had an idea in mind of doing a ML series 3 looking at re-training the model and a final evaluation, which would keep me busy in the coming weeks.\n\n\n\n\n\n\nNote\n\n\n\nIn scikit-learn, an estimator is alluding to the variety of ML approaches (as one of my interpretations), which are usually grouped into classification (e.g. naive Bayes, logistic regression), regression (e.g. support vector regression), clustering (e.g. K-means clustering) and dimensionality reduction (e.g. principal component analysis). A useful guide to help with choosing the right estimator can be found here. For a full definition of what an estimator is, refer to this link.\n\n\n\n\nMachine learning series - overall plan\nThe overall plan for the ML series for small molecules in ChEMBL database could be visualised through the following flow chart, which was adapted and modified from the section on cross-validation in scikit-learn. This current post was targeting the ML series 2 subgraph area.\n\n\n\n\n%%{ init: { 'flowchart': { 'curve': 'monotoneY' } } }%%\nflowchart TB\n  subgraph ML series 1\n  A[Cleaned dataset] --> B(Train data)\n  A --> C(Test data)\n  end\n  subgraph ML series 3\n  B --> D(Re-train model)\n  C --> E[Final evaluation]\n  D --> E\n  end\n  subgraph ML series 2\n  B --> G([Cross validation & hyper-parameter tuning])\n  G --> H([Best parameters])\n  F([Parameters]) --> G\n  H --> D\n  end\n\n\n\n\n\n\n\n\n\n\n\n\nImport dataframe from ML series 1\nSince scikit-learn mainly supports Pandas dataframes for ML, I’ve opted to use Pandas instead of Polars dataframe library this time, to avoid the extra step of converting a Polars dataframe into a Pandas one.\n\nimport pandas as pd\n\nI’ve exported the final dataframe from ML series 1 as a .csv file, so that we could continue on this ML series and work on the LR model further. For this ML series 2, the .csv file was imported as shown below.\n\ndf_ml = pd.read_csv(\"df_ml.csv\")\ndf_ml.head()\n\n\n\n\n\n  \n    \n      \n      Max_Phase\n      #RO5 Violations\n      QED Weighted\n      CX LogP\n      CX LogD\n      Heavy Atoms\n    \n  \n  \n    \n      0\n      0\n      0\n      0.91\n      2.05\n      0.62\n      21\n    \n    \n      1\n      0\n      2\n      0.16\n      1.51\n      -0.41\n      48\n    \n    \n      2\n      0\n      2\n      0.20\n      5.05\n      3.27\n      46\n    \n    \n      3\n      0\n      0\n      0.53\n      3.21\n      3.21\n      24\n    \n    \n      4\n      0\n      1\n      0.14\n      2.80\n      2.80\n      37\n    \n  \n\n\n\n\n\n# Check rows and columns of the df_ml dataframe if needed\n#df_ml.shape\n\n\n\n\nImport libraries for machine learning\n\n# Install scikit-learn - an open-source ML library\n# Uncomment the line below if needing to install this library\n#!pip install -U scikit-learn\n\n\n# Import scikit-learn\nimport sklearn\n\n# Check version of scikit-learn \nprint(sklearn.__version__)\n\n1.2.0\n\n\nOther libraries needed to generate ML model were imported as below.\n\n# To use NumPy arrays to prepare X & y variables\nimport numpy as np\n\n# To normalise dataset prior to running ML\nfrom sklearn import preprocessing\n# To split dataset into training & testing sets\nfrom sklearn.model_selection import train_test_split\n\n\n\n\nLogistic regression\nTo get the LR model ready, the X and y variables were defined with the same sets of physicochemical features from the small molecules in the df_ml dataset.\n\n\nDefining X and y variables\n\n# Define X variables from df_ml dataset\nX = np.asarray(df_ml[[\"#RO5 Violations\", \n                      \"QED Weighted\", \n                      \"CX LogP\", \n                      \"CX LogD\", \n                      \"Heavy Atoms\"]]\n              )\nX[0:5]\n\narray([[ 0.  ,  0.91,  2.05,  0.62, 21.  ],\n       [ 2.  ,  0.16,  1.51, -0.41, 48.  ],\n       [ 2.  ,  0.2 ,  5.05,  3.27, 46.  ],\n       [ 0.  ,  0.53,  3.21,  3.21, 24.  ],\n       [ 1.  ,  0.14,  2.8 ,  2.8 , 37.  ]])\n\n\n\n# Define y variable\ny = np.asarray(df_ml[\"Max_Phase\"])\ny[0:5]\n\narray([0, 0, 0, 0, 0])\n\n\n\n\n\nTraining and testing sets\n\n# Split dataset into training & testing sets\n\n# Random number generator - note: this may produce different result each time\n#rng = np.random.RandomState(0) \n\n# Edited post to use random_state = 250 \n# to be the same as ML series 1 for reproducible result\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 250)\nprint('Training set:', X_train.shape, y_train.shape)\nprint('Testing set:', X_test.shape, y_test.shape)\n\nTraining set: (1515, 5) (1515,)\nTesting set: (379, 5) (379,)\n\n\n\n\n\nPreprocessing data\n\n# Normalise & clean the dataset\n# Fit on the training set - not on testing set as this might lead to data leakage\n# Transform on the testing set\nX = preprocessing.StandardScaler().fit(X_train).transform(X_test)\nX[0:5]\n\narray([[-0.61846489, -0.79518088,  0.57523481,  0.76170581,  0.47638078],\n       [-0.61846489, -1.24006401,  1.27389185,  1.25867492,  0.37925834],\n       [-0.61846489,  0.4949802 , -0.18352175,  0.12634023, -1.27182321],\n       [-0.61846489, -0.79518088,  0.03433905,  0.28360894, -0.68908855],\n       [-0.61846489, -0.48376269,  0.61655324,  0.79630492, -0.20347633]])\n\n\n\n\n\nFitting LR classifier on training set\nOne major difference to the LR classifier this time was that cross-validation was included by using the LogisticRegressionCV model while fitting the training data.\n\n# Import logistic regression CV estimator\nfrom sklearn.linear_model import LogisticRegressionCV\n\n# Change to LogisticRegressionCV() - LR with built-in cross validation\n# Create an instance of logistic regression CV classifier and fit the data\nLogR = LogisticRegressionCV().fit(X_train, y_train)\nLogR\n\nLogisticRegressionCV()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LogisticRegressionCVLogisticRegressionCV()\n\n\n\n\n\nApplying LogisticRegressionCV classifier on testing set for prediction\n\ny_mp = LogR.predict(X_test)\ny_mp\n\narray([0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n       1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n       1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n       1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n       1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n       0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n       0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n       0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n       0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n       0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n       1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n       0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n       1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n       1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n       0, 0, 1, 0, 0])\n\n\n\n\n\nConverting predicted values into a dataframe\n\n# Predicted values were based on log odds\n# Use describe() method to get characteristics of the distribution\npred = pd.DataFrame(LogR.predict_log_proba(X))\npred.describe()\n\n\n\n\n\n  \n    \n      \n      0\n      1\n    \n  \n  \n    \n      count\n      379.000000\n      379.000000\n    \n    \n      mean\n      -1.062787\n      -0.442845\n    \n    \n      std\n      0.235029\n      0.109879\n    \n    \n      min\n      -2.435645\n      -0.793868\n    \n    \n      25%\n      -1.165361\n      -0.504319\n    \n    \n      50%\n      -1.049435\n      -0.430992\n    \n    \n      75%\n      -0.926131\n      -0.373691\n    \n    \n      max\n      -0.601649\n      -0.091612\n    \n  \n\n\n\n\nAlternatively, a quicker way to get predicted probabilities was via predict_proba() method in scikit-learn.\n\ny_mp_proba = LogR.predict_proba(X_test)\n# Uncomment below to see the predicted probabilities printed\n#print(y_mp_proba)\n\n\n\n\nConverting predicted probabilities into a dataframe\n\n# Use describe() to show distributions\ny_mp_prob = pd.DataFrame(y_mp_proba)\ny_mp_prob.describe()\n\n\n\n\n\n  \n    \n      \n      0\n      1\n    \n  \n  \n    \n      count\n      379.000000\n      379.000000\n    \n    \n      mean\n      0.482928\n      0.517072\n    \n    \n      std\n      0.172099\n      0.172099\n    \n    \n      min\n      0.009285\n      0.144482\n    \n    \n      25%\n      0.372812\n      0.391971\n    \n    \n      50%\n      0.511104\n      0.488896\n    \n    \n      75%\n      0.608029\n      0.627188\n    \n    \n      max\n      0.855518\n      0.990715\n    \n  \n\n\n\n\n\n\n\n\nCross-validation & hyper-parameter tuning\n\n\nCross-validation\nCross-validation was designed to minimise sample loss if all of our datasets were partitioned into three lots for training, testing and validation purposes. Readers might notice an additional set of data for validation here. One of the biggest reasons to add this validation set was that often overfitting could happen on the testing set with testing data being leaked into the model, due to parameter tweaking until the model performed optimally as desired. By having a validation set of the data, this overfitting problem could be avoided.\nIn general, model training could take place initially on the training set, with the validation set used for first evaluation, which would be followed by a final evaluation on the testing set if the model testing worked as expected. The “cross” part of the cross-validation was the part that described the process of splitting the training data into many smaller number (“k”) of sets, which was also why cross-validation was also known as “k-fold cross-validation”. With the use of k-fold cross-validation, the training set was essentially equivalent to k-1 of the folds of the training data. The trained model would then be validated by using the remaining parts of the training data, which was almost like being used as a testing data to measure the performance of the trained model.\n\n\n\n\n\n\nNote\n\n\n\nIn short, cross-validation was commonly used as an out-of-sample evaluation metric, where each observation was used for both training and testing, leading to more effective use of data.\n\n\n\n\n\nDecoding LogisticRegressionCV classifier\nSince we’ve used LogisticRegressionCV classifier for the LR models, this meant it would be unnecessary to use GridSearchCV again according to the definition of the estimatorCV as shown below.\nAs quoted from scikit-learn on cross-validation estimator:\nAn estimator that has built-in cross-validation capabilities to automatically select the best hyper-parameters (see the User Guide). Some example of cross-validation estimators are ElasticNetCV and LogisticRegressionCV. Cross-validation estimators are named EstimatorCV and tend to be roughly equivalent to GridSearchCV(Estimator(), …). The advantage of using a cross-validation estimator over the canonical estimator class along with grid search is that they can take advantage of warm-starting by reusing precomputed results in the previous steps of the cross-validation process. This generally leads to speed improvements. An exception is the RidgeCV class, which can instead perform efficient Leave-One-Out (LOO) CV. By default, all these estimators, apart from RidgeCV with an LOO-CV, will be refitted on the full training dataset after finding the best combination of hyper-parameters.\nTherefore, the cross validation part for the LR model was taken care of by the LogisticRegressionCV classifier. However, I wanted to find out more about this particular estimator, so to further dissect LogisticRegressionCV classifer, Stratified K-Folds cross-validator was actually found to be used in its default setting. One of the parameters in the classifier that was closely related to the Stratified K-Folds was the cv parameter. It was a cross-validation generator that could be tuned by providing integers as its equivalent number of folds used. Its default value for LogisticRegressionCV was set as “None”, which was equivalent to and changed from 3-fold to 5-fold in scikit-learn version 0.22.\n\n\n\nHyper-parameter tuning - how parameters affect LR model\nTo explicitly see the details of all the parameters used after the cross-validation, the names and values of these parameters could be checked for the estimator by using the code below.\n```{python}\n# To find the parameters of any ML estimator as suggested by *scikit-learn*\nestimator.get_params()\n```\nIn this example, the LR model built was named LogR. All the parameters used for LogR by the LogisticRegressionCV classifer were:\n\nLogR.get_params()\n\n{'Cs': 10,\n 'class_weight': None,\n 'cv': None,\n 'dual': False,\n 'fit_intercept': True,\n 'intercept_scaling': 1.0,\n 'l1_ratios': None,\n 'max_iter': 100,\n 'multi_class': 'auto',\n 'n_jobs': None,\n 'penalty': 'l2',\n 'random_state': None,\n 'refit': True,\n 'scoring': None,\n 'solver': 'lbfgs',\n 'tol': 0.0001,\n 'verbose': 0}\n\n\nHowever, by showing this set of parameters used by LogisticRegressionCV classifier wouldn’t really tell much about whether any of these parameters were indeed the best ones to fit the model with. So to find out how these parameters influenced the LR model, it was probably best to run a test by using several different parameters on the model to observe the effects. I’ve had two parameters in mind that I thought would affect the confusion matrix at least - cv and random_state parameters after doing some manual trial and errors by changing the cv and random_state values in the code. However, upon reading and digging further in the online information and resource pools, I quickly realised that cv parameter would probably matter more than random_state parameter. This was based on this line from scikit-learn about the LogisticRegressionCV classifer,\n For the grid of Cs values and l1_ratios values, the best hyperparameter is selected by the cross-validator StratifiedKFold, but it can be changed using the cv parameter.\nSo it appeared that changing cv parameter could affect Cs and l1_ratios values as well. Also from scikit-learn documentation on LR, other parameters that could be tuned were:\n\nsolvers - algorithms used in classifiers\npenalties (or regularisation)  - aims to reduce model generalisation errors and regulate or prevent overfitting\nC - controls regularisation or penalty strengths (which would be already taken care of in this case if using LogisticRegressionCV classifier).\n\n\n\n\nSummary table for different penalties supported by different solvers in logistic regression, adapted from scikit-learn - https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression. Note: only certain penalties and solvers work together, OVR = One-vs-Rest.\n\n\nA few other online projects or tutorials using logistic regression in scikit-learn had also mentioned that logistic regression in general did not have a lot of key hyper-parameters for tuning. Another post I happened to bump into even concluded that better time should be used to link the model results with the actual business metrics instead, rather than trying to use hyper-parameter tuning on the LR model. Nevertheless, I still wanted to see how these parameters would affect the LR model in this case, even if it was of minor significance, so that I would fully understand how all of them would work together, and how tuning hyper-parameters would be like.\nIn order to search and test the LR parameters on the different models that would be generated in the test, I’ve opted to use RepeatedStratifiedKFold as the cross-validation method (which was the default cross-validator method used in LogisticRegressionCV classifier). The “Repeated” version of it would repeat Stratified K-Fold at the stated (n) times. Because of this, GridSearchCV would then be used to exhaustively search for all the best parameters in this case, with the aim to see how the changes in parameters would affect the accuracy scores for each model.\n\n# Re-sampled y variable randomly so that there were same numbers of samples as X variables\ny = np.asarray(df_ml[\"Max_Phase\"].sample(n = 379, random_state = 250))\ny.shape\n\n(379,)\n\n\n\n# Code adapted from: https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\n\n# Set up LR model to test (the estimatorCV version)\nmodel = LogisticRegressionCV()\n\n# Set up parameters to test\n# Note: default value for cv = 5-fold\ncv = [5, 10, 20, 30]\n# Note: default value for Cs = 10 (integers or floats only)\nCs = [1, 10, 50, 100]\n# Note: default solver = \"lbfgs\"\nsolvers = [\"lbfgs\", \"liblinear\", \"newton-cg\", \"newton-cholesky\"]\n# \"sag\", \"saga\" not used as the dataset used here was small\n# they were mainly used for large datasets for speed\npenalty = [\"l2\"]\n\n# Specify grid for parameters to test in grid search\ngrid = dict(cv = cv, Cs = Cs, solver = solvers, penalty = penalty)\n\n# Specify type of cross-validation method to be used\nCV = RepeatedStratifiedKFold(n_splits = 5, n_repeats = 2, random_state = 2)\n\n# Set up grid search\n# Specify grid search parameters\ngrid_search = GridSearchCV(\n  # Specify model\n  estimator = model,\n  # Specify parameters to test\n  param_grid = grid,\n  # Number of jobs to run in parallel \n  # 1 = no parallel jobs; \n  # None = unset, but could be interpreted as \"1\" unless otherwise specified; \n  # -1 = all processors used\n  n_jobs = -1,\n  # Type of cross-validation method to be used \n  # (if none set, default 5-fold cv will be used)\n  cv = CV, \n  # Type of scoring to be used to evaluate the model\n  scoring = \"accuracy\",\n  # Value to assign to the \"scoring\" of the model \n  # if an error occurs during model fitting\n  error_score = 0\n  )\n  \n# fit the grid search on X and y variables\ngrid_result = grid_search.fit(X, y)\n\n# Results with means & standard deviations of accuracy scores \n# with parameters used\nprint(\"Best mean test score: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_[\"mean_test_score\"]\nstd = grid_result.cv_results_[\"std_test_score\"]\nparams = grid_result.cv_results_[\"params\"]\nfor mean, stdv, param in zip(means, std, params):\n    print(\"%f (%f) with: %r\" % (mean, stdv, param))\n\nBest mean test score: 0.699263 using {'Cs': 50, 'cv': 5, 'penalty': 'l2', 'solver': 'lbfgs'}\n0.532982 (0.005887) with: {'Cs': 1, 'cv': 5, 'penalty': 'l2', 'solver': 'lbfgs'}\n0.670281 (0.055017) with: {'Cs': 1, 'cv': 5, 'penalty': 'l2', 'solver': 'liblinear'}\n0.532982 (0.005887) with: {'Cs': 1, 'cv': 5, 'penalty': 'l2', 'solver': 'newton-cg'}\n0.532982 (0.005887) with: {'Cs': 1, 'cv': 5, 'penalty': 'l2', 'solver': 'newton-cholesky'}\n0.532982 (0.005887) with: {'Cs': 1, 'cv': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n0.670281 (0.055017) with: {'Cs': 1, 'cv': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n0.532982 (0.005887) with: {'Cs': 1, 'cv': 10, 'penalty': 'l2', 'solver': 'newton-cg'}\n0.532982 (0.005887) with: {'Cs': 1, 'cv': 10, 'penalty': 'l2', 'solver': 'newton-cholesky'}\n0.532982 (0.005887) with: {'Cs': 1, 'cv': 20, 'penalty': 'l2', 'solver': 'lbfgs'}\n0.670281 (0.055017) with: {'Cs': 1, 'cv': 20, 'penalty': 'l2', 'solver': 'liblinear'}\n0.532982 (0.005887) with: {'Cs': 1, 'cv': 20, 'penalty': 'l2', 'solver': 'newton-cg'}\n0.532982 (0.005887) with: {'Cs': 1, 'cv': 20, 'penalty': 'l2', 'solver': 'newton-cholesky'}\n0.532982 (0.005887) with: {'Cs': 1, 'cv': 30, 'penalty': 'l2', 'solver': 'lbfgs'}\n0.670281 (0.055017) with: {'Cs': 1, 'cv': 30, 'penalty': 'l2', 'solver': 'liblinear'}\n0.532982 (0.005887) with: {'Cs': 1, 'cv': 30, 'penalty': 'l2', 'solver': 'newton-cg'}\n0.532982 (0.005887) with: {'Cs': 1, 'cv': 30, 'penalty': 'l2', 'solver': 'newton-cholesky'}\n0.697930 (0.041930) with: {'Cs': 10, 'cv': 5, 'penalty': 'l2', 'solver': 'lbfgs'}\n0.696614 (0.041302) with: {'Cs': 10, 'cv': 5, 'penalty': 'l2', 'solver': 'liblinear'}\n0.697930 (0.041930) with: {'Cs': 10, 'cv': 5, 'penalty': 'l2', 'solver': 'newton-cg'}\n0.697930 (0.041930) with: {'Cs': 10, 'cv': 5, 'penalty': 'l2', 'solver': 'newton-cholesky'}\n0.696614 (0.041720) with: {'Cs': 10, 'cv': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n0.696614 (0.041720) with: {'Cs': 10, 'cv': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n0.696614 (0.041720) with: {'Cs': 10, 'cv': 10, 'penalty': 'l2', 'solver': 'newton-cg'}\n0.696614 (0.041720) with: {'Cs': 10, 'cv': 10, 'penalty': 'l2', 'solver': 'newton-cholesky'}\n0.693982 (0.051953) with: {'Cs': 10, 'cv': 20, 'penalty': 'l2', 'solver': 'lbfgs'}\n0.699246 (0.039988) with: {'Cs': 10, 'cv': 20, 'penalty': 'l2', 'solver': 'liblinear'}\n0.693982 (0.051953) with: {'Cs': 10, 'cv': 20, 'penalty': 'l2', 'solver': 'newton-cg'}\n0.693982 (0.051953) with: {'Cs': 10, 'cv': 20, 'penalty': 'l2', 'solver': 'newton-cholesky'}\n0.695298 (0.041882) with: {'Cs': 10, 'cv': 30, 'penalty': 'l2', 'solver': 'lbfgs'}\n0.695298 (0.041882) with: {'Cs': 10, 'cv': 30, 'penalty': 'l2', 'solver': 'liblinear'}\n0.695298 (0.041882) with: {'Cs': 10, 'cv': 30, 'penalty': 'l2', 'solver': 'newton-cg'}\n0.695298 (0.041882) with: {'Cs': 10, 'cv': 30, 'penalty': 'l2', 'solver': 'newton-cholesky'}\n0.699263 (0.043226) with: {'Cs': 50, 'cv': 5, 'penalty': 'l2', 'solver': 'lbfgs'}\n0.699263 (0.043226) with: {'Cs': 50, 'cv': 5, 'penalty': 'l2', 'solver': 'liblinear'}\n0.699263 (0.043226) with: {'Cs': 50, 'cv': 5, 'penalty': 'l2', 'solver': 'newton-cg'}\n0.699263 (0.043226) with: {'Cs': 50, 'cv': 5, 'penalty': 'l2', 'solver': 'newton-cholesky'}\n0.697930 (0.041095) with: {'Cs': 50, 'cv': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n0.697930 (0.041095) with: {'Cs': 50, 'cv': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n0.697930 (0.041095) with: {'Cs': 50, 'cv': 10, 'penalty': 'l2', 'solver': 'newton-cg'}\n0.697930 (0.041095) with: {'Cs': 50, 'cv': 10, 'penalty': 'l2', 'solver': 'newton-cholesky'}\n0.692667 (0.049633) with: {'Cs': 50, 'cv': 20, 'penalty': 'l2', 'solver': 'lbfgs'}\n0.693982 (0.049566) with: {'Cs': 50, 'cv': 20, 'penalty': 'l2', 'solver': 'liblinear'}\n0.692667 (0.049633) with: {'Cs': 50, 'cv': 20, 'penalty': 'l2', 'solver': 'newton-cg'}\n0.692667 (0.049633) with: {'Cs': 50, 'cv': 20, 'penalty': 'l2', 'solver': 'newton-cholesky'}\n0.693982 (0.043222) with: {'Cs': 50, 'cv': 30, 'penalty': 'l2', 'solver': 'lbfgs'}\n0.692667 (0.042897) with: {'Cs': 50, 'cv': 30, 'penalty': 'l2', 'solver': 'liblinear'}\n0.693982 (0.043222) with: {'Cs': 50, 'cv': 30, 'penalty': 'l2', 'solver': 'newton-cg'}\n0.693982 (0.043222) with: {'Cs': 50, 'cv': 30, 'penalty': 'l2', 'solver': 'newton-cholesky'}\n0.696632 (0.042453) with: {'Cs': 100, 'cv': 5, 'penalty': 'l2', 'solver': 'lbfgs'}\n0.695298 (0.041047) with: {'Cs': 100, 'cv': 5, 'penalty': 'l2', 'solver': 'liblinear'}\n0.696632 (0.042453) with: {'Cs': 100, 'cv': 5, 'penalty': 'l2', 'solver': 'newton-cg'}\n0.696632 (0.042453) with: {'Cs': 100, 'cv': 5, 'penalty': 'l2', 'solver': 'newton-cholesky'}\n0.697930 (0.040672) with: {'Cs': 100, 'cv': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n0.696614 (0.040455) with: {'Cs': 100, 'cv': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n0.697930 (0.040672) with: {'Cs': 100, 'cv': 10, 'penalty': 'l2', 'solver': 'newton-cg'}\n0.697930 (0.040672) with: {'Cs': 100, 'cv': 10, 'penalty': 'l2', 'solver': 'newton-cholesky'}\n0.693982 (0.050944) with: {'Cs': 100, 'cv': 20, 'penalty': 'l2', 'solver': 'lbfgs'}\n0.693982 (0.049566) with: {'Cs': 100, 'cv': 20, 'penalty': 'l2', 'solver': 'liblinear'}\n0.693982 (0.050944) with: {'Cs': 100, 'cv': 20, 'penalty': 'l2', 'solver': 'newton-cg'}\n0.693982 (0.050944) with: {'Cs': 100, 'cv': 20, 'penalty': 'l2', 'solver': 'newton-cholesky'}\n0.695298 (0.040623) with: {'Cs': 100, 'cv': 30, 'penalty': 'l2', 'solver': 'lbfgs'}\n0.692667 (0.042897) with: {'Cs': 100, 'cv': 30, 'penalty': 'l2', 'solver': 'liblinear'}\n0.695298 (0.040623) with: {'Cs': 100, 'cv': 30, 'penalty': 'l2', 'solver': 'newton-cg'}\n0.695298 (0.040623) with: {'Cs': 100, 'cv': 30, 'penalty': 'l2', 'solver': 'newton-cholesky'}\n\n\n\n\n\n\nResults & discussions\nTrends observed from the grid search above (when penalty = l2):\n\nFor Cs = 1, the best accuracy score was 0.670281 across all 4 different cv parameters (5, 10, 20, 30), and the best solver was liblinear\nFor Cs = 10, the best accuracy score was 0.699246 for cv = 20 and when solver was set as liblinear\nfor Cs = 50, the best accuracy score was 0.699263 for cv = 5 across all 4 solvers\nfor Cs = 100, the best accuracy score was 0.697930 for cv = 10 across 3 out of 4 solvers only, which were lbfgs, newton-cg and newton-cholesky\n\nIt appeared that for smaller values of Cs, liblinear might be more suitable than the default lbfgs solver. However, for higher values of Cs, e.g. 50 and above, liblinear might not always be the best solver. The values of Cs and cv parameters that generated the best mean accuracy score were 50 and 5 respectively. The best mean accuracy score produced was 0.699263 with a standard deviation of 0.043226. Solver-wise, there were actually 3 other solvers, liblinear, newton-cg and newton-cholesky, along with the default lbfgs that generated the same mean accuracy score and standard deviations while using Cs = 50 and cv = 5. In my initial LogisticRegressionCV model, I used a different value of Cs parameter (at 10), but with the same cv and penalty parameters.\nTherefore, for the next ML series 3, the plan was to re-train the LogisticRegression model with the newly-discovered best parameters and re-evaluate the model to see if there would be any particular differences. Although currently I suspected the differences might be small (which probably also echoed other ML work on different datasets that also used LR), since the accuracy scores generated from this grid search and ML series 1 were very similar. However, the goal of this post was to understand how cross-validation could be used for hyper-parameter tuning to find the optimal parameters to avoid overfitting a ML model, and this was likely more applicable in other ML approaches.\n\n\n\nFinal words\n\n\n\n\n\n\nNote\n\n\n\nFeel free to skip this final part as this was really me speaking my thoughts out loud about my portfolio lately.\n\n\nI once read a blog post on learning ML, which has suggested to go broadly in topics, then go deep in one of them, which I’ve agreed wholeheartedly as the approach to go about in the tech world, since there are no ways on earth to learn absolutely everything completely (even OpenAI’s ChatGPT has limits - being restricted by the amount and types of input data being fed into the GPT). So, since I’ve branched into 3 programming languages so far, I’ve decided not to expand further into new programming languages for now, to avoid being “half-bucket-full” for everything, I should really narrow down my focus now. To name the 3 programming languages in the order I’ve learnt them, they are Python, R and Rust. In that, I’m most comfortable with Python as that is my first language, then it’s R, followed by Rust, which is almost brand new. I think right now is a good time for me to go deep into an area that has always caught my attentions. So I’ll be concentrating more on ML in my portfolio in the near future.\n\n\n\nReferences\n\nscikit-learn documentation - particularly on LogisticRegressionCV classifier and GridSearchCV\nScikit-learn: Machine Learning in Python, Pedregosa et al., JMLR 12, pp. 2825-2830, 2011.\nBruce, P., Bruce, A. & Gedeck P. (2020). Practical statistics for data scientists. O’Reilly.\nStack Overflow"
  },
  {
    "objectID": "posts/04_Natural_history_of_rare_diseases_–_malformation_syndrome/Natural_history_rare_diseases_mal_syn.html",
    "href": "posts/04_Natural_history_of_rare_diseases_–_malformation_syndrome/Natural_history_rare_diseases_mal_syn.html",
    "title": "Natural history of rare diseases - malformation syndrome",
    "section": "",
    "text": "Introduction\nSo my current interests are still in rare diseases from Orphanet website so the next focus is on natural history of rare diseases, specifically I’d like to focus on malformation syndrome1 for now. There are so much more data available on Orphanet, which I’d really like to look further into such as phenotypes associated with different rare diseases, so this is likely the next one I’ll be working on.\n\n\n\nPhoto by Sangharsh Lohakare on Unsplash\n\n\n\n\nProject link\nThe .ipynb file can be found in my GitHub repository of Portfolio-projects at this URL: https://github.com/jhylin/Portfolio-projects or go to this link, which will take you to the Jupyter notebook for this work to show the differences in life spans for different rare diseases under this particular disorder type.\n\n\nSummary\n\nTurner syndrome and Prune belly syndrome are the only two disorders of the malformation syndrome type that have an average age of onset at antenatal period, with an average age of death in the elderly years\nThis means these two rare disorders have had relatively long life spans out of all the rare diseases present in the dataset\nOppositely, there are far more rare disorders, such as Noonan syndrome, Trisomy 13, Hydraencephaly and more, with early childhood deaths while having the same antenatal onsets as Turner syndrome and Prune belly syndrome\n\n\n\n\n\n\nFootnotes\n\n\nThis project was last committed on 27th June 2022 on GitHub so I’ve set it as the published date, prior to the blog move. This work is under CC BY-SA 4.0 International License for anyone interested in exploring the topic further.↩︎"
  },
  {
    "objectID": "posts/06_Long_COVID_update/ExtractTableFromPDF.html",
    "href": "posts/06_Long_COVID_update/ExtractTableFromPDF.html",
    "title": "Table scraping from PDF",
    "section": "",
    "text": "Quick introduction\nRecently I had the idea of continuing the long COVID exploration and thought that I’ve never tried scraping a PDF before, so by combining these two ideas together, I ended up with this little piece of work as another post.\nA quick heads up: Java should be installed in order for tabula-py to work seamlessly, since tabula-py is actually a Python wrapper for tabula-java. In this case, I’ve relied on Homebrew to install Java, but there are several other different options available online and I’ll leave this open for people who’re interested to explore themselves. Once it’s installed, we can then check for the Java version to ensure it’s installed properly.\n\n# Check the version of Java\n!java -version\n\nopenjdk version \"17.0.4.1\" 2022-08-12\nOpenJDK Runtime Environment Temurin-17.0.4.1+1 (build 17.0.4.1+1)\nOpenJDK 64-Bit Server VM Temurin-17.0.4.1+1 (build 17.0.4.1+1, mixed mode, sharing)\n\n\n\n\nInstalling and importing libraries\nThen we would install any libraries needed for scraping table data from PDF, which in this case, I ended up using only one library.\n\n!pip install -q tabula-py\n\n\n[notice] A new release of pip available: 22.3.1 -> 23.0.1\n[notice] To update, run: pip install --upgrade pip\n\n\n\n# import read_pdf from the tabula library\nfrom tabula import read_pdf\n\n\n\nData source\nSource of the table was from this journal paper by Healey Q, Sheikh A, Daines L, Vasileiou E. Symptoms and signs of long COVID: A rapid review and meta-analysis. J Glob Health 2022;12:05014. Creative Commons Attribution 4.0 International Public License\n\n\n\nPhoto by Steve Richey on Unsplash\n\n\n\n\nTable scraping\nFirstly, I trialled scraping the table from page 4 of the journal paper, which only really scraped about half of the table. I then went on to add in another line of code to specify the scraping area1 on the PDF page in inches (this part could be deduced by using the in-built PDF tool).\nOne thing I wasn’t too sure about was that the tabula-py documentation did state that the default = full page, but in fact, it appeared to be not the case (only half of the table showed up). Also, the journal paper I was using had the tables printed in landscape layout (rather than the more common portrait style), so it wasn’t completely clear if landscape version was making this harder or the other way.\n\n#specify the scraping area (top, left, bottom, right)\ntest_area = \"10.05,6.60,10.05,6.60\" \ndf = read_pdf(\"Journal.pdf\", pages = \"4\", area = test_area, guess = False, stream = True, pandas_options={'header':None})\ndf\n\n[                                                    0\n 0   VREIESWEAPROCINHT TSHEME 1:  Healey et al. COV...\n 1    Table 1. Characteristics of the included studies\n 2                             Author Hospital (%) Age\n 3   (country) {ICU (%)} (years) Comorbiditiestime ...\n 4   41% hypertension, 15% diabetes, Generalised/MS...\n 5   11% obesity, 11% endocrine disease, Respirator...\n 6   10% malignancy, 9% IHD, 8% Neuropsychiatric 43...\n 7    Bellan (Italy) dyslipidaemia, 7% AF, 6% COPD, 6%\n 8   100 {12} 61 107 ENT 5% gustatory dysfunction, ...\n 9             [19] CKD, 6% haematological disease, 5%\n 10             anxiety/depression, 4% cerebrovascular\n 11  disease, 3% liver disease, 3% VTE, 2% Gastroin...\n 12                         IBD, 2% autoimmune disease\n 13  Generalised/MSK Fatigue, myalgia, arthralgia, ...\n 14  Respiratory Dyspnoea, cough, chest pain, sputu...\n 15       Bliddal 28% allergy, 17% osteoarthritis, 15%\n 16  Neuropsychiatric Memory issues, concentration ...\n 17  (Denmark) 0 50 hypertension, 9% thyroid diseas...\n 18  ENT Olfactory dysfunction, gustatory dysfuncti...\n 19                                        [20] asthma\n 20  Gastrointestinal Diarrhoea, anorexia, abdomina...\n 21                              Others Red runny eyes\n 22        Chiesa- 6% hypertension, 6% hypothyroidism,\n 23  Estomba Not stated 41 6% asthma, 4% autoimmune...\n 24          (Italy) [21] 3% diabetes, 2% IHD, 1% COPD\n 25                                             Cousyn\n 26  0 35 Not stated 60 ENT 16.8% olfactory dysfunc...\n 27                                      (France) [22]\n 28  Generalised/MSK 45% fatigue, 15% myalgia, 3% f...\n 29  33% dyspnoea, 33% cough. Normal spirometry, no...\n 30                                        Respiratory\n 31                                   distance on 6MWT\n 32  Neuropsychiatric 18% cognitive issues, 15% hea...\n 33          Daher 59% hypertension, 25% diabetes, 22%\n 34  ENT 12% olfactory dysfunction, 12% rhinorrhoea...\n 35   (Germany) 100 64 CKD, 19% IHD, 13% asthma, 9% 56\n 36  9% diarrhoea, 6% nausea, 3% abdominal pain, no...\n 37  18% angina, normal left ventricular function, ...\n 38                                     Cardiovascular\n 39                                         biomarkers\n 40  Normal FBC, normal coagulation screen, raised ...\n 41                                   Other biomarkers\n 42  U&Es, normal CRP, normal procalcitonin, normal...\n 43  26% hypertension, 12% diabetes, Generalised/MS...\n 44                                         Fernandez-\n 45                 12% IHD, 7% asthma, 5% obesity, 4%\n 46                        de-Las-Penas 100 {7} 61 340\n 47  COPD, 2% cerebrovascular disease, 2% Respirato...\n 48                                       (Spain) [23]\n 49                            rheumatological disease\n 50  47% hypertension, 42% dyslipidaemia, Generalis...\n 51                                           Froidure\n 52  28% obesity, 22% diabetes, 9% Abnormal chest C...\n 53                           (Belgium) 100 {22} 60 98\n 54  asthma, 4% COPD, 2% lung cancer, Respiratory t...\n 55                                               [24]\n 56  1% ILD cough, 4% chest tightness, normal spiro...\n 57  2022  •  Vol. 12  •  05014 4 www.jogh.org •  d...]\n\n\nOnce above worked, I moved onto scraping the whole table across pages 4 to 6 of the PDF, and then saved the scraped table into a .csv file, which appeared automatically in the working directory.\n\nimport tabula\ntest_area = \"10.05,6.60,10.05,6.60\"\n# Convert and save scraped data into specified file format\ntabula.convert_into(\"Journal.pdf\", \"Full_table_scraped.csv\", output_format = \"csv\", pages = \"4-6\", area = test_area, guess = False, stream = True)\n!cat Full_table_scraped.csv\n\nVREIESWEAPROCINHT TSHEME 1:  Healey et al. COVID-19 PANDEMIC\nTable 1. Characteristics of the included studies\nAuthor Hospital (%) Age\n(country) {ICU (%)} (years) Comorbiditiestime (days) Follow-up Body system Results\n\"41% hypertension, 15% diabetes, Generalised/MSK 5.9% myalgia, 5.9% arthralgia\"\n\"11% obesity, 11% endocrine disease, Respiratory 5.5% dyspnoea, 2.5% cough, 0.4% chest pain, 51.6% reduced DLCO, normal spirometry\"\n\"10% malignancy, 9% IHD, 8% Neuropsychiatric 43% PTSD symptoms\"\n\"Bellan (Italy) dyslipidaemia, 7% AF, 6% COPD, 6%\"\n\"100 {12} 61 107 ENT 5% gustatory dysfunction, 4.6% olfactory dysfunction\"\n\"[19] CKD, 6% haematological disease, 5%\"\n\"anxiety/depression, 4% cerebrovascular\"\n\"disease, 3% liver disease, 3% VTE, 2% Gastrointestinal 1.3% diarrhoea\"\n\"IBD, 2% autoimmune disease\"\n\"Generalised/MSK Fatigue, myalgia, arthralgia, chills, fever\"\n\"Respiratory Dyspnoea, cough, chest pain, sputum production\"\n\"Bliddal 28% allergy, 17% osteoarthritis, 15%\"\n\"Neuropsychiatric Memory issues, concentration issues, headache\"\n\"(Denmark) 0 50 hypertension, 9% thyroid disease, 8% 84\"\n\"ENT Olfactory dysfunction, gustatory dysfunction, sore throat, rhinorrhoea, sneezing\"\n[20] asthma\n\"Gastrointestinal Diarrhoea, anorexia, abdominal pain, nausea\"\nOthers Red runny eyes\n\"Chiesa- 6% hypertension, 6% hypothyroidism,\"\n\"Estomba Not stated 41 6% asthma, 4% autoimmune disease, 47 ENT 51% olfactory dysfunction\"\n\"(Italy) [21] 3% diabetes, 2% IHD, 1% COPD\"\nCousyn\n\"0 35 Not stated 60 ENT 16.8% olfactory dysfunction, 9.6% gustatory dysfunction\"\n(France) [22]\n\"Generalised/MSK 45% fatigue, 15% myalgia, 3% fever, slight pain/discomfort\"\n\"33% dyspnoea, 33% cough. Normal spirometry, normal ABG, reduced DLCO, reduced\"\nRespiratory\ndistance on 6MWT\n\"Neuropsychiatric 18% cognitive issues, 15% headache, mild depression, subthreshold anxiety\"\n\"Daher 59% hypertension, 25% diabetes, 22%\"\n\"ENT 12% olfactory dysfunction, 12% rhinorrhoea, 9% gustatory dysfunction, 9% sore throat\"\n\"(Germany) 100 64 CKD, 19% IHD, 13% asthma, 9% 56\"\n\"9% diarrhoea, 6% nausea, 3% abdominal pain, normal LFTs[17] COPD, 9% AF, 9% heart failureGastrointestinal\"\n\"18% angina, normal left ventricular function, normal right ventricular function, normal cardiac\"\nCardiovascular\nbiomarkers\n\"Normal FBC, normal coagulation screen, raised ferritin, potentially raised D-dimer, normal\"\nOther biomarkers\n\"U&Es, normal CRP, normal procalcitonin, normal TFTs, normal IL-6\"\n\"26% hypertension, 12% diabetes, Generalised/MSK 61.2% fatigue\"\nFernandez-\n\"12% IHD, 7% asthma, 5% obesity, 4%\"\nde-Las-Penas 100 {7} 61 340\n\"COPD, 2% cerebrovascular disease, 2% Respiratory 23.3% dyspnoea, 6.5% chest pain, 2.5% cough\"\n(Spain) [23]\nrheumatological disease\n\"47% hypertension, 42% dyslipidaemia, Generalised/MSK 25% fatigue\"\nFroidure\n\"28% obesity, 22% diabetes, 9% Abnormal chest CT: 67% ground glass opacities, 44% reticulations, 20% fibrotic lesions/\"\n(Belgium) 100 {22} 60 98\n\"asthma, 4% COPD, 2% lung cancer, Respiratory traction bronchiectasis, 7% consolidations. 46% reduced DLCO, 35% dyspnoea, 10% dry\"\n[24]\n\"1% ILD cough, 4% chest tightness, normal spirometry\"\n2022  •  Vol. 12  •  05014 4 www.jogh.org •  doi: 10.7189/jogh.12.05014\n\"\",,,,,,,Symptoms and signs of long COVID: A rapid review\nTable 1. continued,,,,,,,\nAuthor (country) Hospital (%) {ICU (%)},Age (years),,,Comorbidities,Follow-up time (days),,Body system Results\n\"\",,,,,,,Generalised/MSK 17% fatigue\nGerhards,,,,,,,\n\"\",,,,,,,\"Neuropsychiatric Depression, concentration issues\"\n(Germany) 10,46,,,Not stated,183,,\n\"\",,,,,,,ENT 27% olfactory/gustatory dysfunction\n[25],,,,,,,\n\"\",,,,,,,Others Alopecia\n\"\",,,,,,,\"Generalised/MSK Fatigue, arthralgia, myalgia\"\n\"\",,,,\"38% hypertension, 22% obesity, 19%\",,,\nGhosn,,,,,,,\"Respiratory Dyspnoea, cough\"\n100 {29},61,,,\"diabetes, 18% IHD, 10% COPD, 7%\",194,,\n(France) [26],,,,,,,Neuropsychiatric Headache\n\"\",,,,\"CKD, 7% malignancy, 1% liver disease\",,,\n\"\",,,,,,,\"ENT Rhinorrhoea, olfactory dysfunction, gustatory dysfunction, sore throat\"\n\"\",,,,,,,\"62% abnormal chest CT: 35% fibrotic-like changes, 27% ground glass opacities/interstitial\"\nHan (China),,,,\"28% hypertension, 14% respiratory\",,,\"thickening, nodules/masses, interlobar pleural traction, pulmonary atelectasis and\"\n100,54,,,,175,,Respiratory\n[27],,,,\"disease, 11% diabetes\",,,\"bronchiectasis. 26% reduced DLCO, 14% mild dyspnoea, 10% sputum production, 6.1% dry\"\n\"\",,,,,,,cough\n\"\",,,,,,,\"Generalised/MSK 50% fatigue, 35.7% arthralgia, 21.4% myalgia\"\nHolmes,,,,,,,\"Respiratory 28.6% cough, 25% dyspnoea, 3.6% chest pain\"\n(Australia) 0,57,,,Not stated,183,,Neuropsychiatric 10.7% headache\n[28],,,,,,,\"ENT 28.6% olfactory dysfunction, 14.3% rhinorrhoea\"\n\"\",,,,,,,Gastrointestinal No abdominal pain\n\"\",,,,\"49% obesity, 48% hypertension,\",,,\"Generalised/MSK 44.8% fatigue, 21.3% myalgia, 15.8% arthralgia, 1.1% fever, 1.1% ulcer\"\n\"\",,,,\"28% diabetes, 12% IHD, 11%\",,,\"Respiratory 31.7% dyspnoea, 25.1% cough, 14.8% sputum production\"\n\"\",,,,\"dyslipidaemia, 10% asthma, 10%\",,,\"Neuropsychiatric 12.6% headache, 8.7% cognitive issues\"\nJacobs (USA),,,,\"malignancy, 5% arrhythmia, 4%\",,,\n100,57,,,,35,,\"ENT 9.8% gustatory dysfunction, 9.3% olfactory dysfunction\"\n[29],,,,\"COPD, 4% hypothyroidism, 4%\",,,\n\"\",,,,,,,Gastrointestinal 3.8% diarrhoea\n\"\",,,,\"depression, anxiety or schizophrenia,\",,,\n\"\",,,,\"3% heart failure, 3% sleep apnoea, 2%\",,,\"Others 8.2% eye irritation, 1.1% ulcer\"\n\"\",,,,VTE,,,\n\"\",,,,\"36% obesity, 29% hypertension,\",,,\"Generalised/MSK 63% fatigue, 35% myalgia\"\nLeth,,,,\"12% malignancy, 10% IHD, 8%\",,,\"Respiratory 53% dyspnoea, 24% cough, 20% chest pain, 12% sputum production\"\n(Denmark) 100 {12},58,,,\"asthma, 8% COPD, 4% diabetes, 4%\",128,,\"Neuropsychiatric 45% concentration issues, 27% headache, 27% paraesthesia\"\n[30],,,,\"hyperthyroidism, 2% cerebrovascular\",,,\"ENT 31% gustatory dysfunction, 27% olfactory dysfunction, 10% sore throat\"\n\"\",,,,disease,,,\"Gastrointestinal 10% abdominal pain, 8% diarrhoea, 8% nausea, 4% anorexia\"\n\"\",,,,,,,\"Generalised/MSK 33% fatigue, 1.4% arthralgia, 0.6% myalgia\"\n\"\",,,,,,,\"Respiratory 8.5% cough, 7% dyspnoea, 0.8% chest pain\"\nMahmud,,,,,,,\n\"\",,,,,,,\"3.9% circadian rhythm disorders, 3.4% headache, 2.3% sleep disturbance, 1.4% adjustment\"\n(Bangladesh) Not stated,40,,,\"15% hypertension, 14% diabetes\",30,,Neuropsychiatric\n\"\",,,,,,,disorder\n[18],,,,,,,\n\"\",,,,,,,\"ENT 2.3% vertigo, 2% olfactory dysfunction\"\n\"\",,,,,,,Cardiovascular 1.4% palpitation\n\"\",,,,,,,RESEARCH THEME 1:\n\"\",,,,,,,VCOIEVWIDP-O1I9N PTASNDEMIC\nwww.jogh.org • doi: 10.7189/jogh.12.05014,,,,5,,,2022  •  Vol. 12  •  05014\nRVEIESWEAPROCINHT TSHEME 1:  Healey et al. COVID-19 PANDEMIC\nTable 1. continued\nAuthor Hospital (%) Age Follow-up\n(country) {ICU (%)} (years) Comorbidities time (days) Body system Results\nOtte\n\"42.3% subjective olfactory dysfunction, 26.9% objective olfactory dysfunction (discrimination\"\n(Germany) 0 45 Not stated 201 ENT\nand identification issues)\n[31]\n\"Generalised/MSK 13.1% fatigue, 8.2% rheumatological issues\"\n\"23% hypertension, 16% obesity, 6% Respiratory 6% dyspnoea, 2% cough, 0.8% chest pain\"\n\"Peghin (Italy) diabetes, 4% respiratory disease, 1% Neuropsychiatric 9.6% neurological disorders, 4.9% psychiatric disorders, 2.7% headache\"\n26 53 191\n\"[32] IHD, 2% liver disease, 1% depression/ ENT 10.4% olfactory/gustatory dysfunction,\"\n\"anxiety, 0% CKD Gastrointestinal 1.5% gastrointestinal disorders\"\n\"Others 3.7% alopecia, 3.4% cutaneous manifestations, 0.3% ocular symptoms\"\n\"Generalised/MSK 24% night sweats, 0% fever\"\n\"63% abnormal chest CT: ground-glass opacities, reticular lesions, consolidations, bronchial\"\n\"Respiratory dilation. 36% dyspnoea, abnormal spirometry: 22% reduced FVC, 22% reduced FEV1, normal\"\n\"40% cardiovascular disease, 30% FEV1/FVC. 21% reduced DLCO, 17% cough\"\n\"hypertension, 19% dyslipidaemia,\"\nSonnweber Neuropsychiatric 22% sleep disorders\n\"75 57 17% diabetes, 7% asthma, 7% CKD, 103\"\n(Austria) [16] ENT 19% olfactory dysfunction\n\"6% COPD, 6% liver disease, 6%\"\n\"malignancy, 1% ILD Gastrointestinal 9% diarrhoea/vomiting\"\n\"97% normal LVEF, 55% diastolic dysfunction on echo, 23% raised NT-proBNP, 10%\"\nCardiovascular\n\"pulmonary hypertension, 1% pericardial effusion\"\n\"Other biomarkers Raised D-dimer, potentially raised ferritin, normal CRP, normal procalcitonin, normal IL-6\"\n\"Generalised/MSK Fatigue, myalgia, fever\"\n\"Respiratory Dyspnoea, cough, chest pain\"\n\"Sudre (UK, 26% obesity, 14% respiratory disease, Neuropsychiatric Headache, paraesthesia, numbness, concentration/ memory issues\"\n\"USA, Sweden) 14 42 10% asthma, 3% diabetes, 2% IHD, 84\"\n\"[33] 1% CKD ENT Olfactory dysfunction, sore throat, hoarse voice, tinnitus, earache\"\n\"Gastrointestinal Diarrhoea, abdominal pain\"\nCardiovascular Palpitations/tachycardia\n\"Vaira (Italy) 29% obesity, 27% IHD, 15%\"\n\"23 51 60 ENT 21% olfactory dysfunction, 7.9% gustatory dysfunction\"\n\"[34] respiratory disease, 11% diabetes\"\n\"ICU – intensive care unit, IHD – ischaemic heart disease, AF – atrial fibrillation, COPD – chronic obstructive pulmonary disease, CKD – chronic kidney disease, VTE – venous thromboembolism, IBD – inflammatory bowel\"\n\"disease, NS – not stated, ILD – interstitial lung disease, MSK – musculoskeletal, ENT – ear, nose, and throat, OGD – olfactory-gustatory dysfunction, DLCO – diffusing capacity for carbon monoxide, PTSD – posttraumatic\"\n\"stress disorder, ABG – arterial blood gas, 6MWT – 6-min walk test, LFT – liver function test, FBC – full blood count, U&E – urea and electrolyte, CRP – c-reactive protein, TFT – thyroid function test, IL-6 – interleukin-6,\"\n\"FVC – forced vital capacity, FEV1 – forced expiratory volume in one second, NT-proBNP – N-terminal pro B-type natriuretic peptide\"\n2022  •  Vol. 12  •  05014 6 www.jogh.org •  doi: 10.7189/jogh.12.05014\n\n\n\n\nShort summary\nThe PDF scraping exercise only worked to a certain degree2, as the data did not arrive in a proper tabular format. I’ve also gone on to read several online resources and looked into tabula-py and tabula-java, it was clearly shown in their GitHub repo that there were existing issues for tables that have merged cells, empty cells or no column lines (which was what I had in this case). All of them tend to result in jumbled or merged rows or columns. It tends to work better if the tables in the PDFs are already in a proper table format i.e. columns and rows marked by lines. Nevertheless, the purpose of scraping the table data was achieved as full data were there after checking, but just not in a clean and tidy state so the next post named, “Long COVID - an update” would take us into the next stage to see what this tabular data would tell us about long COVID (all done in R).\n\n\n\n\n\nFootnotes\n\n\nThanks to Stack Overflow as I’ve managed to find this solution from several different scenarios and comments.↩︎\nor it could be my ignorance to other better methods - please leave a comment as I’d like to learn!↩︎"
  },
  {
    "objectID": "posts/06_Long_COVID_update/Long_COVID_update.html",
    "href": "posts/06_Long_COVID_update/Long_COVID_update.html",
    "title": "Long COVID - an update",
    "section": "",
    "text": "Background\nThis was another update on the current long COVID saga around the world that I thought to follow up from my earlier work (details in the SQL and Tableau projects). This time the dataset was obtained from another journal paper, which had data collected until July 2021 (the previous paper was only until March 2021). I’ve used Python to extract a table from the PDF of the paper and also Excel to assist with data cleaning. This was followed by using R to analyse and visualise all the data.\n\n\nSource of dataset\nJournal paper by Healey Q, Sheikh A, Daines L, Vasileiou E. Symptoms and signs of long COVID: A rapid review and meta-analysis. J Glob Health 2022;12:05014. Creative Commons Attribution 4.0 International Public License\n\n\nData scraping from PDF\nThe dataset was scraped from a PDF obtained via PubMed (journal paper source as shown above) by using tabula-py (for details please see this post, “Table scraping from PDF”). Unfortunately I had trouble installing a similar R package remotely after it was archived (tabulizer package with known issues in its GitHub repository) so I trialled tabula-py instead. It worked for scraping all the data from the target table, but the downside was that the scraped data did not inherit the original tabular format on PDF, with columns and rows all jumbled. I’ve discussed a little bit more on the likely reason for this in the blog post link above. So in short, the final scraped table was cleaned in Excel and saved as .csv file, which was then imported as shown below.\n\n\nData inspection and wrangling\n\n# Uncomment below if requiring installations of packages\n# install.packages(\"wordcloud\")\n# install.packages(\"RColorBrewer\")\n# install.packages(\"tidytext\")\n# install.packages(\"leaflet\")\n\nLoading all the required libraries below. Install libraries needed as shown in codes above.\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(knitr)\nlibrary(leaflet)\nlibrary(tidytext)\nlibrary(wordcloud)\nlibrary(RColorBrewer)\n\n\ndf <- read_csv(\"Full_table.csv\")\n\nNew names:\nRows: 75 Columns: 9\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(5): Author (country), Hospital (%) {ICU (%)}, Comorbidities, Body syste... dbl\n(2): Age (years), Follow-up time (days) lgl (2): ...8, ...9\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -> `...8`\n• `` -> `...9`\n\n\n\n\n\nHere’s a quick overview on the hospitalisation rates across all the studies from this paper.\n\ndf_hosp <- df %>% \n  select(`Author (country)`, `Hospital (%) {ICU (%)}`)\ndf_hosp\n\n# A tibble: 75 × 2\n   `Author (country)` `Hospital (%) {ICU (%)}`\n   <chr>              <chr>                   \n 1 Bellan (Italy)     100 {12}                \n 2 Bellan (Italy)     <NA>                    \n 3 Bellan (Italy)     <NA>                    \n 4 Bellan (Italy)     <NA>                    \n 5 Bellan (Italy)     <NA>                    \n 6 Bliddal (Denmark)  0                       \n 7 Bliddal (Denmark)  <NA>                    \n 8 Bliddal (Denmark)  <NA>                    \n 9 Bliddal (Denmark)  <NA>                    \n10 Bliddal (Denmark)  <NA>                    \n# … with 65 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\n\nSeparating columns and change column type\nThe table column of Hospital (%) {ICU (%)} was separated into two separate columns to allow clearer differentiation between hospital and ICU rates within each study. The data type for Hospital (%) column was also changed from character to numeric so we can plot a bar graph later on (otherwise the x-axis may not be accurate or properly shown).\n\ndf_hosp_icu <- df_hosp %>% \n  # separate column into two columns\n  separate(`Hospital (%) {ICU (%)}`, c(\"Hospital (%)\", \"ICU (%)\"))%>% \n  # change column type\n  mutate(across(`Hospital (%)`, as.numeric))\n# show the first 10 rows as example\nc <- head(df_hosp_icu, 10)\nkable(c)\n\n\n\n\nAuthor (country)\nHospital (%)\nICU (%)\n\n\n\n\nBellan (Italy)\n100\n12\n\n\nBellan (Italy)\nNA\nNA\n\n\nBellan (Italy)\nNA\nNA\n\n\nBellan (Italy)\nNA\nNA\n\n\nBellan (Italy)\nNA\nNA\n\n\nBliddal (Denmark)\n0\nNA\n\n\nBliddal (Denmark)\nNA\nNA\n\n\nBliddal (Denmark)\nNA\nNA\n\n\nBliddal (Denmark)\nNA\nNA\n\n\nBliddal (Denmark)\nNA\nNA\n\n\n\n\n\n\n\nSeparating rows\nThe listed co-morbidities for each study were separated into separate rows, rather than into columns, to avoid adding too many columns all at once.\n\ndf_new <- df %>% \n  separate_rows(Comorbidities, sep = \", \")\n# Show the first 10 rows as example\ne <- head(df_new, 10)\nkable(e)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAuthor (country)\nHospital (%) {ICU (%)}\nAge (years)\nComorbidities\nFollow-up time (days)\nBody system\nResults\n…8\n…9\n\n\n\n\nBellan (Italy)\n100 {12}\n61\n41% hypertension\n107\nGeneralised/MSK\n5.9% myalgia, 5.9% arthralgia\nNA\nNA\n\n\nBellan (Italy)\n100 {12}\n61\n15% diabetes\n107\nGeneralised/MSK\n5.9% myalgia, 5.9% arthralgia\nNA\nNA\n\n\nBellan (Italy)\n100 {12}\n61\n11% obesity\n107\nGeneralised/MSK\n5.9% myalgia, 5.9% arthralgia\nNA\nNA\n\n\nBellan (Italy)\n100 {12}\n61\n11% endocrine disease\n107\nGeneralised/MSK\n5.9% myalgia, 5.9% arthralgia\nNA\nNA\n\n\nBellan (Italy)\n100 {12}\n61\n10% malignancy\n107\nGeneralised/MSK\n5.9% myalgia, 5.9% arthralgia\nNA\nNA\n\n\nBellan (Italy)\n100 {12}\n61\n9% IHD\n107\nGeneralised/MSK\n5.9% myalgia, 5.9% arthralgia\nNA\nNA\n\n\nBellan (Italy)\n100 {12}\n61\n8% dyslipidaemia\n107\nGeneralised/MSK\n5.9% myalgia, 5.9% arthralgia\nNA\nNA\n\n\nBellan (Italy)\n100 {12}\n61\n7% AF\n107\nGeneralised/MSK\n5.9% myalgia, 5.9% arthralgia\nNA\nNA\n\n\nBellan (Italy)\n100 {12}\n61\n6% COPD\n107\nGeneralised/MSK\n5.9% myalgia, 5.9% arthralgia\nNA\nNA\n\n\nBellan (Italy)\n100 {12}\n61\n6% CKD\n107\nGeneralised/MSK\n5.9% myalgia, 5.9% arthralgia\nNA\nNA\n\n\n\n\n\n\n\nA frequency count showing types of comorbidities in long COVID\nI then noticed how the comorbidities for each study were listed with different percentages and to gather a quick initial overall picture of the data, I started by removing these digits and percentage symbols. Obviously since I was still quite new to R (started using R in July), I soon ran into a problem as I kept on getting stuck with not having the count() function to actually count unique elements under the co-morbidities column.\nBy looking at the magnified circle on the right in the image below, you would notice a subtle difference in spacing, so yes the culprit was the space1 and once it was removed, count() worked nicely as how it should be. One small downside was that it would also remove the space between the co-morbidity terms e.g. “liver disease” became “liverdisease”, but since it achieved the aim intended to do unique counts on all the co-morbidities, I left it as it was.\n\n\n\nScreenshot of the extra space(s) in dataframe\n\n\n\ndf_new %>% \n  # Remove % symbol, numbers and don't forget to remove spaces as well in the column! \n  mutate(Comorbidities = str_remove_all(Comorbidities, \"[:digit:]|[%]|[ ]\")) %>%\n  # Add this line to filter out all the \"NA\"s\n  filter(!is.na(Comorbidities)) %>% \n  # Count the comorbidities in descending order\n  count(Comorbidities, sort = TRUE) \n\n# A tibble: 37 × 2\n   Comorbidities     n\n   <chr>         <int>\n 1 diabetes         14\n 2 hypertension     13\n 3 IHD              10\n 4 asthma            9\n 5 COPD              9\n 6 obesity           9\n 7 CKD               6\n 8 malignancy        5\n 9 dyslipidaemia     4\n10 liverdisease      4\n# … with 27 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\nNow we could observe the top 3 frequency of all co-morbidities listed were: diabetes, hypertension and IHD2. These were followed by, unsurprisingly, common respiratory illnesses such as asthma, COPD3, then obesity, and also CKD4, malignancy, dyslipidaemia and so on. These would be considered as high risk factors of developing long COVID symptoms if someone had these co-morbidities present before being infected by the coronoviruses.\n\n\n\nData visualisations\n\nBar graph for hospitalisation rate\nThen a line of code to filter out the results of “NA” under the column of Hospital (%) was added. Most of the cells with “NA” were there to fill the multiple empty row entries for other variables and not for the Hospital (%) column, therefore these “NA”s were removed in this instance. The horizontal bar graph below showed the COVID-19 hospitalisation rate for studies in different countries, presenting a very diverse results between 0% and 100% hospitalisations across all 19 cohort studies.\n\ndf_hosp_icu %>% \n  # filter out all NAs\n  filter(!is.na(`Hospital (%)`)) %>% \n  # plot the bar graph\n  ggplot(aes(x = `Author (country)`, y = `Hospital (%)`)) + \n  geom_bar(stat = \"identity\") +\n  coord_flip()\n\n\n\n\nCOVID-19 hospitalisation rate across different countries\n\n\n\n\nNote: two of the studies were removed from above, these studies were by Chiesa-Estomba (Italy) and Mahmud (Bangladesh), which had “Not stated” recorded under Hospital (%) {ICU (%)} column. When the Hospital (%) column was converted from character to numeric, these two rows were converted to “NA” automatically.\n\n\nInteractive map for long COVID results\n\nPreparing dataframe for map\n\ndf_new_a <- df %>% \n  # separate Author (country) column into two columns \n  # note: rename country as region - needed for joining data later on\n  separate(`Author (country)`, c(\"Author\", \"region\")) %>% \n  # print only the columns as selected\n  select(`region`, Results)\n\n# The study author name, Fernandez-de-Las-Penas (Spain), got separated as above\n# so replace \"de\" under Country column with the actual country name of Spain\ndf_new_a[df_new_a == \"de\"] <- \"Spain\" \n# Show first 10 rows as example\nd <- head(df_new_a, 10)\nkable(d)\n\n\n\n\n\n\n\n\nregion\nResults\n\n\n\n\nItaly\n5.9% myalgia, 5.9% arthralgia\n\n\nItaly\n5.5% dyspnoea, 2.5% cough, 0.4% chest pain, 51.6% reduced DLCO, normal spirometry\n\n\nItaly\n43% PTSD symptoms\n\n\nItaly\n5% gustatory dysfunction, 4.6% olfactory dysfunction\n\n\nItaly\n1.3% diarrhoea\n\n\nDenmark\nfatigue, myalgia, arthralgia, chills, fever\n\n\nDenmark\ndyspnoea, cough, chest pain, sputum production\n\n\nDenmark\nmemory issues, concentration issues, headache\n\n\nDenmark\nolfactory dysfunction, gustatory dysfunction, sore throat, rhinorrhoea, sneezing\n\n\nDenmark\ndiarrhoea, anorexia, abdominal pain, nausea\n\n\n\n\n\n\ndf1 <- df_new_a %>% \n  # re-group dataframe based on region column\n  group_by(`region`) %>%\n  # merge all rows under Results column into one string\n  summarise(across(everything(), ~toString(.)))\ndf1\n\n# A tibble: 13 × 2\n   region     Results                                                           \n   <chr>      <chr>                                                             \n 1 Australia  50% fatigue, 35.7% arthralgia, 21.4% myalgia, 28.6% cough, 25% dy…\n 2 Austria    24% night sweats, 0% fever, 63% abnormal chest CT: ground-glass o…\n 3 Bangladesh 33% fatigue, 1.4% arthralgia, 0.6% myalgia, 8.5% cough, 7% dyspno…\n 4 Belgium    25% fatigue, abnormal chest CT: 67% ground glass opacities, 44% r…\n 5 China      62% abnormal chest CT: 35% fibrotic-like changes, 27% ground glas…\n 6 Denmark    fatigue, myalgia, arthralgia, chills, fever, dyspnoea, cough, che…\n 7 Estomba    51% olfactory dysfunction                                         \n 8 France     16.8% olfactory dysfunction, 9.6% gustatory dysfunction, fatigue,…\n 9 Germany    45% fatigue, 15% myalgia, 3% fever, slight pain/discomfort, 33% d…\n10 Italy      5.9% myalgia, 5.9% arthralgia, 5.5% dyspnoea, 2.5% cough, 0.4% ch…\n11 Spain      61.2% fatigue, 23.3% dyspnoea, 6.5% chest pain, 2.5% cough        \n12 UK         fatigue, myalgia, fever, dyspnoea, cough, chest pain, headache, p…\n13 USA        44.8% fatigue, 21.3% myalgia, 15.8% arthralgia, 1.1% fever, 1.1% …\n\n\n\n# grab the world map data from ggplot\nmapdata <- map_data(\"world\") \n# view full dataset in separate tab \nview(mapdata)\n\n\n# combine mapdata dataframe (contains longitudes & latitudes of each country) \n# with df_new_a dataframe (contains country info)\nmapdata <- left_join(mapdata, df1, by = \"region\")\nhead(mapdata)\n\n       long      lat group order region subregion Results\n1 -69.89912 12.45200     1     1  Aruba      <NA>    <NA>\n2 -69.89571 12.42300     1     2  Aruba      <NA>    <NA>\n3 -69.94219 12.43853     1     3  Aruba      <NA>    <NA>\n4 -70.00415 12.50049     1     4  Aruba      <NA>    <NA>\n5 -70.06612 12.54697     1     5  Aruba      <NA>    <NA>\n6 -70.05088 12.59707     1     6  Aruba      <NA>    <NA>\n\n\n\n# filter out all the empty or \"NA\" cells\nmapdata_new <- mapdata %>% filter(!is.na(mapdata$Results))\nhead(mapdata_new)\n\n      long       lat group order    region                   subregion\n1 123.5945 -12.42568   133  7115 Australia Ashmore and Cartier Islands\n2 123.5952 -12.43594   133  7116 Australia Ashmore and Cartier Islands\n3 123.5732 -12.43418   133  7117 Australia Ashmore and Cartier Islands\n4 123.5725 -12.42393   133  7118 Australia Ashmore and Cartier Islands\n5 123.5945 -12.42568   133  7119 Australia Ashmore and Cartier Islands\n6 158.8788 -54.70976   139  7267 Australia            Macquarie Island\n                                                                                                                                                                      Results\n1 50% fatigue, 35.7% arthralgia, 21.4% myalgia, 28.6% cough, 25% dyspnoea, 3.6% chest pain, 10.7% headache, 28.6% olfactory dysfunction, 14.3% rhinorrhoea, no abdominal pain\n2 50% fatigue, 35.7% arthralgia, 21.4% myalgia, 28.6% cough, 25% dyspnoea, 3.6% chest pain, 10.7% headache, 28.6% olfactory dysfunction, 14.3% rhinorrhoea, no abdominal pain\n3 50% fatigue, 35.7% arthralgia, 21.4% myalgia, 28.6% cough, 25% dyspnoea, 3.6% chest pain, 10.7% headache, 28.6% olfactory dysfunction, 14.3% rhinorrhoea, no abdominal pain\n4 50% fatigue, 35.7% arthralgia, 21.4% myalgia, 28.6% cough, 25% dyspnoea, 3.6% chest pain, 10.7% headache, 28.6% olfactory dysfunction, 14.3% rhinorrhoea, no abdominal pain\n5 50% fatigue, 35.7% arthralgia, 21.4% myalgia, 28.6% cough, 25% dyspnoea, 3.6% chest pain, 10.7% headache, 28.6% olfactory dysfunction, 14.3% rhinorrhoea, no abdominal pain\n6 50% fatigue, 35.7% arthralgia, 21.4% myalgia, 28.6% cough, 25% dyspnoea, 3.6% chest pain, 10.7% headache, 28.6% olfactory dysfunction, 14.3% rhinorrhoea, no abdominal pain\n\n\nI realised that map_data(“world”) showed all the longitudes and latitudes for subregions of each country, which might not be required for the map I wanted. So after trialling the map visualisation several times, I opted to use centroids of each country instead, to leave the map in a cleaner and easy-to-see state. Otherwise one of the maps I tested before ended up with countless blobs of circles marking the boundaries of each country, looking like a 5-year-old’s map drawing!\n\nmapdata_final <- mapdata_new %>% \n  group_by(region) %>% \n  # Using centroids of countries = means of longitudes and latitudes for each country\n  summarise(long = mean(long), lat = mean(lat))\nkable(mapdata_final)\n\n\n\n\nregion\nlong\nlat\n\n\n\n\nAustralia\n136.998543\n-25.18300\n\n\nAustria\n13.473366\n47.57973\n\n\nBangladesh\n90.506118\n23.50905\n\n\nBelgium\n4.732104\n50.59063\n\n\nChina\n106.847575\n35.08244\n\n\nDenmark\n10.731255\n55.70473\n\n\nFrance\n3.226979\n46.16686\n\n\nGermany\n10.401156\n51.20461\n\n\nItaly\n11.752853\n42.16598\n\n\nSpain\n-2.906821\n40.67995\n\n\nUK\n-4.098750\n55.55813\n\n\nUSA\n-121.625310\n48.74333\n\n\n\n\n\n\n# join above mapdata_final with the df1 which contains countries and long COVID results\ndf1_mapdata <- left_join(mapdata_final, df1, by = \"region\")\nkable(df1_mapdata)\n\n\n\n\n\n\n\n\n\n\nregion\nlong\nlat\nResults\n\n\n\n\nAustralia\n136.998543\n-25.18300\n50% fatigue, 35.7% arthralgia, 21.4% myalgia, 28.6% cough, 25% dyspnoea, 3.6% chest pain, 10.7% headache, 28.6% olfactory dysfunction, 14.3% rhinorrhoea, no abdominal pain\n\n\nAustria\n13.473366\n47.57973\n24% night sweats, 0% fever, 63% abnormal chest CT: ground-glass opacities, reticular lesions, consolidations, bronchial dilation. 36% dyspnoea, abnormal spirometry: 22% reduced FVC, 22% reduced FEV1, normal FEV1/FVC. 21% reduced DLCO, 17% cough, 22% sleep disorders, 19% olfactory dysfunction, 9% diarrhoea/vomiting, 97% normal LVEF, 55% diastolic dysfunction on echo, 23% raised NT-proBNP, 10% pulmonary hypertension, 1% pericardial effusion, raised D-dimer, potentially raised ferritin, normal CRP, normal procalcitonin, normal IL-6\n\n\nBangladesh\n90.506118\n23.50905\n33% fatigue, 1.4% arthralgia, 0.6% myalgia, 8.5% cough, 7% dyspnoea, 0.8% chest pain, 3.9% circadian rhythm disorders, 3.4% headache, 2.3% sleep disturbance, 1.4% adjustment disorder, 2.3% vertigo, 2% olfactory dysfunction, 1.4% palpitation\n\n\nBelgium\n4.732104\n50.59063\n25% fatigue, abnormal chest CT: 67% ground glass opacities, 44% reticulations, 20% fibrotic lesions/traction bronchiectasis, 7% consolidations. 46% reduced DLCO, 35% dyspnoea, 10% dry cough, 4% chest tightness, normal spirometry\n\n\nChina\n106.847575\n35.08244\n62% abnormal chest CT: 35% fibrotic-like changes, 27% ground glass opacities/interstitial thickening, nodules/masses, interlobar pleural traction, pulmonary atelectasis and bronchiectasis. 26% reduced DLCO, 14% mild dyspnoea, 10% sputum production, 6.1% dry cough\n\n\nDenmark\n10.731255\n55.70473\nfatigue, myalgia, arthralgia, chills, fever, dyspnoea, cough, chest pain, sputum production, memory issues, concentration issues, headache, olfactory dysfunction, gustatory dysfunction, sore throat, rhinorrhoea, sneezing, diarrhoea, anorexia, abdominal pain, nausea, red runny eyes, 63% fatigue, 35% myalgia, 53% dyspnoea, 24% cough, 20% chest pain, 12% sputum production, 45% concentration issues, 27% headache, 27% paraesthesia, 31% gustatory dysfunction, 27% olfactory dysfunction, 10% sore throat, 10% abdominal pain, 8% diarrhoea, 8% nausea, 4% anorexia\n\n\nFrance\n3.226979\n46.16686\n16.8% olfactory dysfunction, 9.6% gustatory dysfunction, fatigue, arthralgia, myalgia, dyspnoea, cough, headache, rhinorrhoea, olfactory dysfunction, gustatory dysfunction, sore throat\n\n\nGermany\n10.401156\n51.20461\n45% fatigue, 15% myalgia, 3% fever, slight pain/discomfort, 33% dyspnoea, 33% cough. Normal spirometry, normal ABG, reduced DLCO, reduced distance on 6MWT, 18% cognitive issues, 15% headache, mild depression, subthreshold anxiety, 12% olfactory dysfunction, 12% rhinorrhoea, 9% gustatory dysfunction, 9% sore throat, 9% diarrhoea, 6% nausea, 3% abdominal pain, normal LFTs, 18% angina, normal left ventricular function, normal right ventricular function, normal cardiac biomarkers, normal FBC, normal coagulation screen, raised ferritin, potentially raised D-dimer, normal U&Es, normal CRP, normal procalcitonin, normal TFTs, normal IL-6, 17% fatigue, depression, concentration issues, 27% olfactory/gustatory dysfunction, alopecia, 42.3% subjective olfactory dysfunction, 26.9% objective olfactory dysfunction (discrimination and identification issues)\n\n\nItaly\n11.752853\n42.16598\n5.9% myalgia, 5.9% arthralgia, 5.5% dyspnoea, 2.5% cough, 0.4% chest pain, 51.6% reduced DLCO, normal spirometry, 43% PTSD symptoms, 5% gustatory dysfunction, 4.6% olfactory dysfunction, 1.3% diarrhoea, 13.1% fatigue, 8.2% rheumatological issues, 6% dyspnoea, 2% cough, 0.8% chest pain, 9.6% neurological disorders, 4.9% psychiatric disorders, 2.7% headache, 10.4% olfactory/gustatory dysfunction, 1.5% gastrointestinal disorders, 3.7% alopecia, 3.4% cutaneous manifestations, 0.3% ocular symptoms, 21% olfactory dysfunction, 7.9% gustatory dysfunction\n\n\nSpain\n-2.906821\n40.67995\n61.2% fatigue, 23.3% dyspnoea, 6.5% chest pain, 2.5% cough\n\n\nUK\n-4.098750\n55.55813\nfatigue, myalgia, fever, dyspnoea, cough, chest pain, headache, paraesthesia, numbness, concentration/ memory issues, olfactory dysfunction, sore throat, hoarse voice, tinnitus, earache, diarrhoea, abdominal pain, palpitations/tachycardia\n\n\nUSA\n-121.625310\n48.74333\n44.8% fatigue, 21.3% myalgia, 15.8% arthralgia, 1.1% fever, 1.1% ulcer, 31.7% dyspnoea, 25.1% cough, 14.8% sputum production, 12.6% headache, 8.7% cognitive issues, 9.8% gustatory dysfunction, 9.3% olfactory dysfunction, 3.8% diarrhoea, 8.2% eye irritation, 1.1% ulcer\n\n\n\n\n\n\n# Prepare pop up information\ndf1_mapdata <- df1_mapdata %>% \n  # paste region and Results columns into popup_info and add it as a new column into dataset\n  # bold texts and add break lines by using html tags as shown\n  mutate(popup_info = paste(\"<b>\",region,\"</b>\",\"<br/>\",\"<b>\",\"Long COVID symptoms:\",\"</b>\",\"<br/>\", Results))\ndf1_mapdata\n\n# A tibble: 12 × 5\n   region        long   lat Results                                      popup…¹\n   <chr>        <dbl> <dbl> <chr>                                        <chr>  \n 1 Australia   137.   -25.2 50% fatigue, 35.7% arthralgia, 21.4% myalgi… <b> Au…\n 2 Austria      13.5   47.6 24% night sweats, 0% fever, 63% abnormal ch… <b> Au…\n 3 Bangladesh   90.5   23.5 33% fatigue, 1.4% arthralgia, 0.6% myalgia,… <b> Ba…\n 4 Belgium       4.73  50.6 25% fatigue, abnormal chest CT: 67% ground … <b> Be…\n 5 China       107.    35.1 62% abnormal chest CT: 35% fibrotic-like ch… <b> Ch…\n 6 Denmark      10.7   55.7 fatigue, myalgia, arthralgia, chills, fever… <b> De…\n 7 France        3.23  46.2 16.8% olfactory dysfunction, 9.6% gustatory… <b> Fr…\n 8 Germany      10.4   51.2 45% fatigue, 15% myalgia, 3% fever, slight … <b> Ge…\n 9 Italy        11.8   42.2 5.9% myalgia, 5.9% arthralgia, 5.5% dyspnoe… <b> It…\n10 Spain        -2.91  40.7 61.2% fatigue, 23.3% dyspnoea, 6.5% chest p… <b> Sp…\n11 UK           -4.10  55.6 fatigue, myalgia, fever, dyspnoea, cough, c… <b> UK…\n12 USA        -122.    48.7 44.8% fatigue, 21.3% myalgia, 15.8% arthral… <b> US…\n# … with abbreviated variable name ¹​popup_info\n\n\n\nleaflet() %>% \n  # initialising the graphics environment for map\n  addTiles() %>% \n  # add circle markers to map\n  # use the df1_mapdata dataset containing countries, longitudes, latitudes and long COVID results\n  # add data, latitudes, longitudes, radius of circles, pop up information\n  addCircleMarkers(data = df1_mapdata, lat = ~lat, lng = ~long, radius = ~3, popup = ~popup_info)\n\n\n\nInteractive map for long COVID symptoms\n\n\nABG = arterial blood gas, CT = computed tomography, CRP = c-reactive protein, DLCO = diffusing capacity for carbon monoxide, FBC = full blood count, FEV1 = forced expiratory volume in one second, FVC = forced vital capacity, IL-6 = interleukin-6, LFT = liver function test, LVEF = left ventricular ejection fraction, NT-proBNP = N-terminal pro B-type natriuretic peptide, PTSD = posttraumatic stress disorder, 6MWT = 6-min walk test, U&E = urea and electrolyte, TFT = thyroid function test\n\n\n\nText mining for word cloud\nWhen skimming through the Results column, it appeared some of the terms recorded were repetitive, so a wordcloud might be another interesting way to see if it could highlight any particular long COVID symptoms from this meta-analysis.\n\n# Select the results column\ntext <- df$Results\n# Remove numbers from the texts so that the digits won't appear in the wordcloud\ntext1 <- str_replace_all(text, \"[:digit:]\", \"\")\ntext1\n\n [1] \".% myalgia, .% arthralgia\"                                                                                                                                                                                                                                \n [2] \".% dyspnoea, .% cough, .% chest pain, .% reduced DLCO, normal spirometry\"                                                                                                                                                                                 \n [3] \"% PTSD symptoms\"                                                                                                                                                                                                                                          \n [4] \"% gustatory dysfunction, .% olfactory dysfunction\"                                                                                                                                                                                                        \n [5] \".% diarrhoea\"                                                                                                                                                                                                                                             \n [6] \"fatigue, myalgia, arthralgia, chills, fever\"                                                                                                                                                                                                              \n [7] \"dyspnoea, cough, chest pain, sputum production\"                                                                                                                                                                                                           \n [8] \"memory issues, concentration issues, headache\"                                                                                                                                                                                                            \n [9] \"olfactory dysfunction, gustatory dysfunction, sore throat, rhinorrhoea, sneezing\"                                                                                                                                                                         \n[10] \"diarrhoea, anorexia, abdominal pain, nausea\"                                                                                                                                                                                                              \n[11] \"red runny eyes\"                                                                                                                                                                                                                                           \n[12] \"% olfactory dysfunction\"                                                                                                                                                                                                                                  \n[13] \".% olfactory dysfunction, .% gustatory dysfunction\"                                                                                                                                                                                                       \n[14] \"% fatigue, % myalgia, % fever, slight pain/discomfort\"                                                                                                                                                                                                    \n[15] \"% dyspnoea, % cough. Normal spirometry, normal ABG, reduced DLCO, reduced distance on MWT\"                                                                                                                                                                \n[16] \"% cognitive issues, % headache, mild depression, subthreshold anxiety\"                                                                                                                                                                                    \n[17] \"% olfactory dysfunction, % rhinorrhoea, % gustatory dysfunction, % sore throat\"                                                                                                                                                                           \n[18] \"% diarrhoea, % nausea, % abdominal pain, normal LFTs\"                                                                                                                                                                                                     \n[19] \"% angina, normal left ventricular function, normal right ventricular function, normal cardiac biomarkers\"                                                                                                                                                 \n[20] \"normal FBC, normal coagulation screen, raised ferritin, potentially raised D-dimer, normal U&Es, normal CRP, normal procalcitonin, normal TFTs, normal IL-\"                                                                                               \n[21] \".% fatigue\"                                                                                                                                                                                                                                               \n[22] \".% dyspnoea, .% chest pain, .% cough\"                                                                                                                                                                                                                     \n[23] \"% fatigue\"                                                                                                                                                                                                                                                \n[24] \"abnormal chest CT: % ground glass opacities, % reticulations, % fibrotic lesions/traction bronchiectasis, % consolidations. % reduced DLCO, % dyspnoea, % dry cough, % chest tightness, normal spirometry\"                                                \n[25] \"% fatigue\"                                                                                                                                                                                                                                                \n[26] \"depression, concentration issues\"                                                                                                                                                                                                                         \n[27] \"% olfactory/gustatory dysfunction\"                                                                                                                                                                                                                        \n[28] \"alopecia\"                                                                                                                                                                                                                                                 \n[29] \"fatigue, arthralgia, myalgia\"                                                                                                                                                                                                                             \n[30] \"dyspnoea, cough\"                                                                                                                                                                                                                                          \n[31] \"headache\"                                                                                                                                                                                                                                                 \n[32] \"rhinorrhoea, olfactory dysfunction, gustatory dysfunction, sore throat\"                                                                                                                                                                                   \n[33] \"% abnormal chest CT: % fibrotic-like changes, % ground glass opacities/interstitial thickening, nodules/masses, interlobar pleural traction, pulmonary atelectasis and bronchiectasis. % reduced DLCO, % mild dyspnoea, % sputum production, .% dry cough\"\n[34] \"% fatigue, .% arthralgia, .% myalgia\"                                                                                                                                                                                                                     \n[35] \".% cough, % dyspnoea, .% chest pain\"                                                                                                                                                                                                                      \n[36] \".% headache\"                                                                                                                                                                                                                                              \n[37] \".% olfactory dysfunction, .% rhinorrhoea\"                                                                                                                                                                                                                 \n[38] \"no abdominal pain\"                                                                                                                                                                                                                                        \n[39] \".% fatigue, .% myalgia, .% arthralgia, .% fever, .% ulcer\"                                                                                                                                                                                                \n[40] \".% dyspnoea, .% cough, .% sputum production\"                                                                                                                                                                                                              \n[41] \".% headache, .% cognitive issues\"                                                                                                                                                                                                                         \n[42] \".% gustatory dysfunction, .% olfactory dysfunction\"                                                                                                                                                                                                       \n[43] \".% diarrhoea\"                                                                                                                                                                                                                                             \n[44] \".% eye irritation, .% ulcer\"                                                                                                                                                                                                                              \n[45] \"% fatigue, % myalgia\"                                                                                                                                                                                                                                     \n[46] \"% dyspnoea, % cough, % chest pain, % sputum production\"                                                                                                                                                                                                   \n[47] \"% concentration issues, % headache, % paraesthesia\"                                                                                                                                                                                                       \n[48] \"% gustatory dysfunction, % olfactory dysfunction, % sore throat\"                                                                                                                                                                                          \n[49] \"% abdominal pain, % diarrhoea, % nausea, % anorexia\"                                                                                                                                                                                                      \n[50] \"% fatigue, .% arthralgia, .% myalgia\"                                                                                                                                                                                                                     \n[51] \".% cough, % dyspnoea, .% chest pain\"                                                                                                                                                                                                                      \n[52] \".% circadian rhythm disorders, .% headache, .% sleep disturbance, .% adjustment disorder\"                                                                                                                                                                 \n[53] \".% vertigo, % olfactory dysfunction\"                                                                                                                                                                                                                      \n[54] \".% palpitation\"                                                                                                                                                                                                                                           \n[55] \".% subjective olfactory dysfunction, .% objective olfactory  dysfunction (discrimination and identification issues)\"                                                                                                                                      \n[56] \".% fatigue, .% rheumatological issues\"                                                                                                                                                                                                                    \n[57] \"% dyspnoea, % cough, .% chest pain\"                                                                                                                                                                                                                       \n[58] \".% neurological disorders, .% psychiatric disorders, .% headache\"                                                                                                                                                                                         \n[59] \".% olfactory/gustatory dysfunction\"                                                                                                                                                                                                                       \n[60] \".% gastrointestinal disorders\"                                                                                                                                                                                                                            \n[61] \".% alopecia, .% cutaneous manifestations, .% ocular symptoms\"                                                                                                                                                                                             \n[62] \"% night sweats, % fever\"                                                                                                                                                                                                                                  \n[63] \"% abnormal chest CT: ground-glass opacities, reticular lesions, consolidations, bronchial dilation. % dyspnoea, abnormal spirometry: % reduced FVC, % reduced FEV, normal FEV/FVC. % reduced DLCO, % cough\"                                               \n[64] \"% sleep disorders\"                                                                                                                                                                                                                                        \n[65] \"% olfactory dysfunction\"                                                                                                                                                                                                                                  \n[66] \"% diarrhoea/vomiting\"                                                                                                                                                                                                                                     \n[67] \"% normal LVEF, % diastolic dysfunction on echo, % raised NT-proBNP, % pulmonary hypertension, % pericardial effusion\"                                                                                                                                     \n[68] \"raised D-dimer, potentially raised ferritin, normal CRP, normal procalcitonin, normal IL-\"                                                                                                                                                                \n[69] \"fatigue, myalgia, fever\"                                                                                                                                                                                                                                  \n[70] \"dyspnoea, cough, chest pain\"                                                                                                                                                                                                                              \n[71] \"headache, paraesthesia, numbness, concentration/ memory issues\"                                                                                                                                                                                           \n[72] \"olfactory dysfunction, sore throat, hoarse voice, tinnitus, earache\"                                                                                                                                                                                      \n[73] \"diarrhoea, abdominal pain\"                                                                                                                                                                                                                                \n[74] \"palpitations/tachycardia\"                                                                                                                                                                                                                                 \n[75] \"% olfactory dysfunction, .% gustatory dysfunction\"                                                                                                                                                                                                        \n\n\n\n# Change the text into a tibble\ntext_df <- tibble(line = 1:75, text = text1)\ntext_df\n\n# A tibble: 75 × 2\n    line text                                                                   \n   <int> <chr>                                                                  \n 1     1 .% myalgia, .% arthralgia                                              \n 2     2 .% dyspnoea, .% cough, .% chest pain, .% reduced DLCO, normal spiromet…\n 3     3 % PTSD symptoms                                                        \n 4     4 % gustatory dysfunction, .% olfactory dysfunction                      \n 5     5 .% diarrhoea                                                           \n 6     6 fatigue, myalgia, arthralgia, chills, fever                            \n 7     7 dyspnoea, cough, chest pain, sputum production                         \n 8     8 memory issues, concentration issues, headache                          \n 9     9 olfactory dysfunction, gustatory dysfunction, sore throat, rhinorrhoea…\n10    10 diarrhoea, anorexia, abdominal pain, nausea                            \n# … with 65 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\n\n# Tokenise the texts in the selected column\ntext_df1 <- text_df %>% \n  unnest_tokens(word, text)\ntext_df1\n\n# A tibble: 399 × 2\n    line word      \n   <int> <chr>     \n 1     1 myalgia   \n 2     1 arthralgia\n 3     2 dyspnoea  \n 4     2 cough     \n 5     2 chest     \n 6     2 pain      \n 7     2 reduced   \n 8     2 dlco      \n 9     2 normal    \n10     2 spirometry\n# … with 389 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\n\ntext_df1 %>% \n  # Remove stop_words\n  anti_join(stop_words) %>% \n  # Count the frequency of appearance of each word\n  count(word) %>% \n  # Then create a wordcloud\n  with(wordcloud(word, n, colors = brewer.pal(8,\"Dark2\")))\n\n\n\n# display.brewer.all to display all colour palettes if wanting to use different colours\n\nA known drawback of wordcloud was that the length of a word might influence how big it might appear in the wordcloud, so it was not completely dependent on the word frequencies in a set of texts. Nevertheless, it was one of the ways to get a rough idea about the most common terms cropping up in collected texts. This last part was more like a small exercise for me and also for anyone who might want to try this but did not where to start.\n\n\n\nSummary\nLong COVID had shown a very versatile and diverse range of signs and symptoms, often resembling other known post-viral illnesses such as myalgic encephalomyelitis and chronic fatigue syndrome, the interactive map above would enable readers to see specific long COVID symptoms for selected countries. People with diabetes, hypertension and IHD might have higher risk of suffering from long COVID if they were infected with the coronoviruses. The types of co-morbidities were not limited to these three unfortunately and several other chronic illnesses mentioned above might also contribute to similar risk. The most affected body systems in long COVID were in respiratory tract, ear, nose and throat areas, musculoskeletal parts, gastrointestinal tract and last, but not the least, neuropsychiatric systems which could bring fatigue and memory/concentration issue, or more widely known as the “brain fog”. All of these outcomes also did not vary widely from earlier meta-analyses on long COVID, reiterating the wide health ramifications that COVID-19 could inflict upon global populations.\n\nAcknowledgement\nI have to thank several online resources when I was trying to build the interactive map. Most notably, I’ve adapted my codes based on these two useful online resources:\n\nR tutorial: Creating Maps and mapping data with ggplot2 by Dr Paul Christiansen\nCreating interactive maps in R by A&G Statworks\n\nI also have to thank all the package creators for all the packages used here and all the authors of the journal paper (as mentioned under “Source of dataset”) which provided the long COVID data.\n\nsessionInfo()\n\nR version 4.2.0 (2022-04-22)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Catalina 10.15.7\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] wordcloud_2.6      RColorBrewer_1.1-3 tidytext_0.3.4     leaflet_2.1.1     \n [5] knitr_1.39         forcats_0.5.1      stringr_1.4.0      dplyr_1.0.9       \n [9] purrr_0.3.4        readr_2.1.2        tidyr_1.2.0        tibble_3.1.8      \n[13] ggplot2_3.3.6      tidyverse_1.3.2   \n\nloaded via a namespace (and not attached):\n [1] httr_1.4.3          maps_3.4.0          bit64_4.0.5        \n [4] vroom_1.5.7         jsonlite_1.8.0      modelr_0.1.8       \n [7] assertthat_0.2.1    highr_0.9           googlesheets4_1.0.0\n[10] cellranger_1.1.0    yaml_2.3.5          pillar_1.8.0       \n[13] backports_1.4.1     lattice_0.20-45     glue_1.6.2         \n[16] digest_0.6.29       rvest_1.0.2         colorspace_2.0-3   \n[19] htmltools_0.5.3     Matrix_1.4-1        pkgconfig_2.0.3    \n[22] broom_1.0.0         haven_2.5.0         scales_1.2.0       \n[25] tzdb_0.3.0          googledrive_2.0.0   farver_2.1.1       \n[28] generics_0.1.3      ellipsis_0.3.2      withr_2.5.0        \n[31] cli_3.4.1           magrittr_2.0.3      crayon_1.5.1       \n[34] readxl_1.4.0        evaluate_0.15       tokenizers_0.2.1   \n[37] janeaustenr_1.0.0   fs_1.5.2            fansi_1.0.3        \n[40] SnowballC_0.7.0     xml2_1.3.3          tools_4.2.0        \n[43] hms_1.1.1           gargle_1.2.0        lifecycle_1.0.1    \n[46] munsell_0.5.0       reprex_2.0.1        compiler_4.2.0     \n[49] rlang_1.0.4         grid_4.2.0          rstudioapi_0.13    \n[52] htmlwidgets_1.5.4   crosstalk_1.2.0     labeling_0.4.2     \n[55] rmarkdown_2.14      gtable_0.3.0        DBI_1.1.3          \n[58] R6_2.5.1            lubridate_1.8.0     fastmap_1.1.0      \n[61] bit_4.0.4           utf8_1.2.2          stringi_1.7.8      \n[64] parallel_4.2.0      Rcpp_1.0.9          vctrs_0.4.1        \n[67] dbplyr_2.2.1        tidyselect_1.1.2    xfun_0.31          \n\n\n\n\n\n\n\n\nFootnotes\n\n\nIt took probably at least half an hour to figure this out… eventually I thought to look at the column itself long enough to see if I’d missed anything… then voila!↩︎\nischaemic heart disease↩︎\nchronic obstructive pulmonary disease↩︎\nchronic kidney disease↩︎"
  },
  {
    "objectID": "posts/08_ML1_Small_molecules_in_ChEMBL_database/ML1_chembl_cpds.html",
    "href": "posts/08_ML1_Small_molecules_in_ChEMBL_database/ML1_chembl_cpds.html",
    "title": "Small molecules in ChEMBL database",
    "section": "",
    "text": "Machine learning in drug discovery - series 1\n\n\n\nBackground\nAs my interests gradually grew for Rust, I realised why so many people said it might be a hard programming language to learn. My head was spinning after reading the Rust programming language book and watching a few online teaching videos about it. I then decided to start from something I was more familiar with, and somehow through various online ventures and searching, I’ve managed to start two projects in parallel. The first one was where I used Polars dataframe library, and the second one would be about using Rust through an interactive user interface such as Jupyter notebook. I’ve anticipated that the second project would take much longer time for me to finish, so I would be tackling the first project for now.\nThis project was about using Polars, a blazingly fast dataframe library that was written completely in Rust with a very light Python binding that was available for use via Python or Rust, so I started using Polars via Python on Jupyter Lab initially, which involved data wrangling, some exploratory data analysis (EDA), and a reasonably larger section on using machine learning (ML) through scikit-learn. The editing and publishing of this post was mainly achieved via RStudio IDE.\n\n\n\nInstall Polars\n\n# To install Polars dataframe library\n# Uncomment below to download and install Polars\n#!pip install polars\n\n# Update Polars version\n# Uncomment the line below to update Polars\n#!pip install --upgrade polars\n\nOnce Polars was installed, the next step was to import it for use.\n\nimport polars as pl\n\n\n# Show version of Polars\n# Uncomment line below to check version of Polars installed/updated\n#pl.show_versions()\n\n\n\n\nDownload dataset\nThe dataset, which was purely about small molecules and their physicochemical properties, was downloaded from ChEMBL database and saved as a .csv file. I’ve decided not to upload the “chembl_mols.csv” file due to its sheer size (around 0.6 GB), and also I’d like to stay using free open-source resources (including GitHub) at this stage. I’ve looked into the Git large file system, but for the free version it only provides 2 GB, which at this stage, I think by adding this larger than usual .csv file along with my portfolio blog repository may exceed this limit in no time.\nFor anyone who would like to use the same dataset, the file I used would be equivalent to a straight download from the home page of ChEMBL database, via clicking on the “Distinct compounds” (please see the circled area in the image below). Options were available to download the files as .csv, .tsv or .sdf formats (located at the top right of the page).\n\n\n\n\nImage adapted from ChEMBL database website\n\n\n\nOnce we’ve had the file ready, it would be read via the usual read_csv() method.\n\ndf = pl.read_csv(\"chembl_mols.csv\")\ndf.head() #read first 5 rows\n#df #read full dataset\n\n\n\n\nshape: (5, 1)\n\n\n\n\nChEMBL ID\";\"Name\";\"Synonyms\";\"Type\";\"Max Phase\";\"Molecular Weight\";\"Targets\";\"Bioactivities\";\"AlogP\";\"Polar Surface Area\";\"HBA\";\"HBD\";\"#RO5 Violations\";\"#Rotatable Bonds\";\"Passes Ro3\";\"QED Weighted\";\"CX Acidic pKa\";\"CX Basic pKa\";\"CX LogP\";\"CX LogD\";\"Aromatic Rings\";\"Structure Type\";\"Inorganic Flag\";\"Heavy Atoms\";\"HBA (Lipinski)\";\"HBD (Lipinski)\";\"#RO5 Violations (Lipinski)\";\"Molecular Weight (Monoisotopic)\";\"Molecular Species\";\"Molecular Formula\";\"Smiles\";\"Inchi Key\n\n\n\n\nstr\n\n\n\n\n\n\n\"CHEMBL1206185;...\n\n\n\n\n\"CHEMBL539070;\"...\n\n\n\n\n\"CHEMBL3335528;...\n\n\n\n\n\"CHEMBL2419030;...\n\n\n\n\n\"CHEMBL4301448;...\n\n\n\n\n\n\n\n\n\n\nData wrangling\nNow, since this dataset was downloaded as a .csv file, this meant it was likely to have a certain delimiter between each variable. So the whole dataset was presented as strings where each string represented each compound in each row. Each variable was separated by semicolons. To read it properly, I’ve added a delimiter term in the code to transform the dataframe into a more readable format.\n\n# By referring to Polars documentation, \n# use \"sep\" to set the delimiter of the file\n# which was semicolons in this case\ndf = pl.read_csv(\"chembl_mols.csv\", sep = \";\")\n# Show the first 10 rows of data\n#df.head(10)\n# or full dataset\ndf\n\n\n\n\nshape: (2331700, 32)\n\n\n\n\nChEMBL ID\n\n\nName\n\n\nSynonyms\n\n\nType\n\n\nMax Phase\n\n\nMolecular Weight\n\n\nTargets\n\n\nBioactivities\n\n\nAlogP\n\n\nPolar Surface Area\n\n\nHBA\n\n\nHBD\n\n\n#RO5 Violations\n\n\n#Rotatable Bonds\n\n\nPasses Ro3\n\n\nQED Weighted\n\n\nCX Acidic pKa\n\n\nCX Basic pKa\n\n\nCX LogP\n\n\nCX LogD\n\n\nAromatic Rings\n\n\nStructure Type\n\n\nInorganic Flag\n\n\nHeavy Atoms\n\n\nHBA (Lipinski)\n\n\nHBD (Lipinski)\n\n\n#RO5 Violations (Lipinski)\n\n\nMolecular Weight (Monoisotopic)\n\n\nMolecular Species\n\n\nMolecular Formula\n\n\nSmiles\n\n\nInchi Key\n\n\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\ni64\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\ni64\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n\"CHEMBL1206185\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"607.88\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"9.46\"\n\n\n\"89.62\"\n\n\n\"5\"\n\n\n\"2\"\n\n\n\"2\"\n\n\n\"17\"\n\n\n\"N\"\n\n\n\"0.09\"\n\n\n\"-1.91\"\n\n\n\"8.38\"\n\n\n\"9.40\"\n\n\n\"9.36\"\n\n\n\"3\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"42\"\n\n\n\"5\"\n\n\n\"3\"\n\n\n\"2\"\n\n\n\"607.2790\"\n\n\n\"ACID\"\n\n\n\"C35H45NO4S2\"\n\n\n\"CCCCCCCCCCC#CC...\n\n\n\"UFBLKYIDZFRLPR...\n\n\n\n\n\"CHEMBL539070\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"286.79\"\n\n\n\"1\"\n\n\n\"1\"\n\n\n\"2.28\"\n\n\n\"73.06\"\n\n\n\"6\"\n\n\n\"2\"\n\n\n\"0\"\n\n\n\"5\"\n\n\n\"N\"\n\n\n\"0.63\"\n\n\n\"13.84\"\n\n\n\"3.64\"\n\n\n\"2.57\"\n\n\n\"2.57\"\n\n\n\"2\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"17\"\n\n\n\"5\"\n\n\n\"3\"\n\n\n\"0\"\n\n\n\"250.0888\"\n\n\n\"NEUTRAL\"\n\n\n\"C11H15ClN4OS\"\n\n\n\"CCCOc1ccccc1-c...\n\n\n\"WPEWNRKLKLNLSO...\n\n\n\n\n\"CHEMBL3335528\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"842.80\"\n\n\n\"2\"\n\n\n\"6\"\n\n\n\"0.18\"\n\n\n\"269.57\"\n\n\n\"18\"\n\n\n\"5\"\n\n\n\"2\"\n\n\n\"17\"\n\n\n\"N\"\n\n\n\"0.09\"\n\n\n\"3.20\"\n\n\n\"None\"\n\n\n\"3.31\"\n\n\n\"-0.14\"\n\n\n\"3\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"60\"\n\n\n\"19\"\n\n\n\"5\"\n\n\n\"2\"\n\n\n\"842.2633\"\n\n\n\"ACID\"\n\n\n\"C41H46O19\"\n\n\n\"COC(=O)[C@H](O...\n\n\n\"KGUJQZWYZPYYRZ...\n\n\n\n\n\"CHEMBL2419030\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"359.33\"\n\n\n\"4\"\n\n\n\"4\"\n\n\n\"3.94\"\n\n\n\"85.13\"\n\n\n\"6\"\n\n\n\"1\"\n\n\n\"0\"\n\n\n\"3\"\n\n\n\"N\"\n\n\n\"0.66\"\n\n\n\"None\"\n\n\n\"None\"\n\n\n\"3.66\"\n\n\n\"3.66\"\n\n\n\"2\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"24\"\n\n\n\"6\"\n\n\n\"1\"\n\n\n\"0\"\n\n\n\"359.0551\"\n\n\n\"NEUTRAL\"\n\n\n\"C14H12F3N3O3S\"\n\n\n\"O=c1nc(NC2CCCC...\n\n\n\"QGDMYSDFCXOKML...\n\n\n\n\n\"CHEMBL4301448\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"465.55\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"5.09\"\n\n\n\"105.28\"\n\n\n\"6\"\n\n\n\"4\"\n\n\n\"1\"\n\n\n\"10\"\n\n\n\"N\"\n\n\n\"0.15\"\n\n\n\"None\"\n\n\n\"12.14\"\n\n\n\"4.41\"\n\n\n\"2.00\"\n\n\n\"4\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"33\"\n\n\n\"7\"\n\n\n\"5\"\n\n\n\"1\"\n\n\n\"465.1635\"\n\n\n\"BASE\"\n\n\n\"C24H24FN5O2S\"\n\n\n\"N=C(N)NCCCOc1c...\n\n\n\"RXTJPHLPHOZLFS...\n\n\n\n\n\"CHEMBL3827271\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"712.85\"\n\n\n\"1\"\n\n\n\"1\"\n\n\n\"-2.84\"\n\n\n\"319.06\"\n\n\n\"10\"\n\n\n\"11\"\n\n\n\"2\"\n\n\n\"16\"\n\n\n\"N\"\n\n\n\"0.07\"\n\n\n\"4.08\"\n\n\n\"10.49\"\n\n\n\"-6.88\"\n\n\n\"-8.95\"\n\n\n\"0\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"50\"\n\n\n\"19\"\n\n\n\"14\"\n\n\n\"3\"\n\n\n\"712.4232\"\n\n\n\"ZWITTERION\"\n\n\n\"C31H56N10O9\"\n\n\n\"CC(C)C[C@@H]1N...\n\n\n\"QJQNNLICZLLPMB...\n\n\n\n\n\"CHEMBL1969944\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"\"\n\n\n\"56\"\n\n\n\"56\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"NONE\"\n\n\n-1\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\n\n\"CHEMBL3465961\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"319.42\"\n\n\n\"16\"\n\n\n\"22\"\n\n\n\"2.22\"\n\n\n\"50.50\"\n\n\n\"4\"\n\n\n\"1\"\n\n\n\"0\"\n\n\n\"6\"\n\n\n\"N\"\n\n\n\"0.87\"\n\n\n\"None\"\n\n\n\"9.38\"\n\n\n\"2.13\"\n\n\n\"-0.44\"\n\n\n\"1\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"23\"\n\n\n\"4\"\n\n\n\"1\"\n\n\n\"0\"\n\n\n\"319.2060\"\n\n\n\"BASE\"\n\n\n\"C18H26FN3O\"\n\n\n\"CC(O)CN1CCC(CN...\n\n\n\"FZEVYCHTADTXPM...\n\n\n\n\n\"CHEMBL587495\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"478.54\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"6.85\"\n\n\n\"66.73\"\n\n\n\"4\"\n\n\n\"3\"\n\n\n\"1\"\n\n\n\"6\"\n\n\n\"N\"\n\n\n\"0.23\"\n\n\n\"10.67\"\n\n\n\"8.47\"\n\n\n\"6.04\"\n\n\n\"4.93\"\n\n\n\"5\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"34\"\n\n\n\"4\"\n\n\n\"4\"\n\n\n\"1\"\n\n\n\"478.1439\"\n\n\n\"NEUTRAL\"\n\n\n\"C26H21F3N4S\"\n\n\n\"Nc1cccc(CNCc2c...\n\n\n\"KZOHKPSNJBXTRJ...\n\n\n\n\n\"CHEMBL3824158\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"422.48\"\n\n\n\"2\"\n\n\n\"4\"\n\n\n\"5.09\"\n\n\n\"109.54\"\n\n\n\"6\"\n\n\n\"2\"\n\n\n\"1\"\n\n\n\"10\"\n\n\n\"N\"\n\n\n\"0.31\"\n\n\n\"4.59\"\n\n\n\"7.99\"\n\n\n\"2.49\"\n\n\n\"2.42\"\n\n\n\"2\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"31\"\n\n\n\"7\"\n\n\n\"2\"\n\n\n\"1\"\n\n\n\"422.1842\"\n\n\n\"ACID\"\n\n\n\"C24H26N2O5\"\n\n\n\"CCCCCCCNC(C1=C...\n\n\n\"AXOVDUYYBUYLPC...\n\n\n\n\n\"CHEMBL194112\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"366.38\"\n\n\n\"2\"\n\n\n\"3\"\n\n\n\"4.80\"\n\n\n\"57.53\"\n\n\n\"3\"\n\n\n\"2\"\n\n\n\"0\"\n\n\n\"1\"\n\n\n\"N\"\n\n\n\"0.75\"\n\n\n\"8.98\"\n\n\n\"None\"\n\n\n\"4.84\"\n\n\n\"4.83\"\n\n\n\"1\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"26\"\n\n\n\"3\"\n\n\n\"2\"\n\n\n\"0\"\n\n\n\"366.1443\"\n\n\n\"NEUTRAL\"\n\n\n\"C20H21F3O3\"\n\n\n\"C[C@]12CCC3c4c...\n\n\n\"FIBOSLUEJGPVMK...\n\n\n\n\n\"CHEMBL2047226\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"452.40\"\n\n\n\"4\"\n\n\n\"8\"\n\n\n\"4.93\"\n\n\n\"53.08\"\n\n\n\"5\"\n\n\n\"2\"\n\n\n\"0\"\n\n\n\"7\"\n\n\n\"N\"\n\n\n\"0.53\"\n\n\n\"None\"\n\n\n\"8.47\"\n\n\n\"4.51\"\n\n\n\"3.29\"\n\n\n\"3\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"29\"\n\n\n\"5\"\n\n\n\"2\"\n\n\n\"0\"\n\n\n\"451.1372\"\n\n\n\"NEUTRAL\"\n\n\n\"C23H26BrN5\"\n\n\n\"Brc1ccc(CNc2cc...\n\n\n\"WOAVNWHCIXCOIZ...\n\n\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n\n\n\"CHEMBL387315\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"673.99\"\n\n\n\"2\"\n\n\n\"2\"\n\n\n\"9.83\"\n\n\n\"43.86\"\n\n\n\"3\"\n\n\n\"0\"\n\n\n\"2\"\n\n\n\"21\"\n\n\n\"N\"\n\n\n\"0.08\"\n\n\n\"None\"\n\n\n\"9.57\"\n\n\n\"10.60\"\n\n\n\"8.45\"\n\n\n\"4\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"50\"\n\n\n\"5\"\n\n\n\"0\"\n\n\n\"2\"\n\n\n\"673.4607\"\n\n\n\"BASE\"\n\n\n\"C45H59N3O2\"\n\n\n\"CCCCCc1ccc(C(=...\n\n\n\"HVSKDFHVTFRADD...\n\n\n\n\n\"CHEMBL540121\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"540.05\"\n\n\n\"2\"\n\n\n\"3\"\n\n\n\"2.39\"\n\n\n\"147.14\"\n\n\n\"6\"\n\n\n\"4\"\n\n\n\"1\"\n\n\n\"8\"\n\n\n\"N\"\n\n\n\"0.22\"\n\n\n\"5.02\"\n\n\n\"11.48\"\n\n\n\"-0.75\"\n\n\n\"-0.78\"\n\n\n\"4\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"36\"\n\n\n\"9\"\n\n\n\"5\"\n\n\n\"1\"\n\n\n\"503.1627\"\n\n\n\"ZWITTERION\"\n\n\n\"C26H26ClN5O4S\"\n\n\n\"Cc1ccn(NS(=O)(...\n\n\n\"TZLGWENJAJXWGA...\n\n\n\n\n\"CHEMBL2387650\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"496.01\"\n\n\n\"2\"\n\n\n\"13\"\n\n\n\"6.03\"\n\n\n\"66.84\"\n\n\n\"5\"\n\n\n\"1\"\n\n\n\"1\"\n\n\n\"7\"\n\n\n\"N\"\n\n\n\"0.32\"\n\n\n\"3.57\"\n\n\n\"None\"\n\n\n\"6.77\"\n\n\n\"3.42\"\n\n\n\"3\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"33\"\n\n\n\"5\"\n\n\n\"1\"\n\n\n\"1\"\n\n\n\"495.0366\"\n\n\n\"ACID\"\n\n\n\"C25H18ClNO4S2\"\n\n\n\"O=C(O)[C@@H](C...\n\n\n\"LSYQEQADGPAMNF...\n\n\n\n\n\"CHEMBL374041\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"504.50\"\n\n\n\"2\"\n\n\n\"4\"\n\n\n\"3.04\"\n\n\n\"144.95\"\n\n\n\"8\"\n\n\n\"3\"\n\n\n\"1\"\n\n\n\"10\"\n\n\n\"N\"\n\n\n\"0.28\"\n\n\n\"6.59\"\n\n\n\"4.37\"\n\n\n\"2.17\"\n\n\n\"1.33\"\n\n\n\"3\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"37\"\n\n\n\"11\"\n\n\n\"3\"\n\n\n\"2\"\n\n\n\"504.1645\"\n\n\n\"NEUTRAL\"\n\n\n\"C26H24N4O7\"\n\n\n\"CCOCCC1(Oc2ccc...\n\n\n\"ABCSNHDQYHOLOO...\n\n\n\n\n\"CHEMBL394794\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"707.86\"\n\n\n\"1\"\n\n\n\"2\"\n\n\n\"4.31\"\n\n\n\"183.99\"\n\n\n\"12\"\n\n\n\"3\"\n\n\n\"2\"\n\n\n\"9\"\n\n\n\"N\"\n\n\n\"0.18\"\n\n\n\"12.10\"\n\n\n\"None\"\n\n\n\"3.09\"\n\n\n\"3.09\"\n\n\n\"0\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"50\"\n\n\n\"13\"\n\n\n\"3\"\n\n\n\"2\"\n\n\n\"707.3881\"\n\n\n\"NEUTRAL\"\n\n\n\"C37H57NO12\"\n\n\n\"C=C1[C@@H](O)C...\n\n\n\"CFMSPOHWBQUTHN...\n\n\n\n\n\"CHEMBL2035815\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"534.89\"\n\n\n\"10\"\n\n\n\"10\"\n\n\n\"4.46\"\n\n\n\"146.01\"\n\n\n\"10\"\n\n\n\"3\"\n\n\n\"1\"\n\n\n\"8\"\n\n\n\"N\"\n\n\n\"0.28\"\n\n\n\"None\"\n\n\n\"6.22\"\n\n\n\"3.48\"\n\n\n\"3.48\"\n\n\n\"4\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"37\"\n\n\n\"11\"\n\n\n\"4\"\n\n\n\"2\"\n\n\n\"534.1142\"\n\n\n\"NEUTRAL\"\n\n\n\"C22H18ClF3N8O3...\n\n\n\"C=CC(=O)NCc1co...\n\n\n\"ZRZKVZZVULTROL...\n\n\n\n\n\"CHEMBL1586325\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"425.47\"\n\n\n\"6\"\n\n\n\"7\"\n\n\n\"3.11\"\n\n\n\"109.62\"\n\n\n\"5\"\n\n\n\"1\"\n\n\n\"0\"\n\n\n\"8\"\n\n\n\"N\"\n\n\n\"0.44\"\n\n\n\"13.84\"\n\n\n\"None\"\n\n\n\"3.24\"\n\n\n\"3.24\"\n\n\n\"3\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"30\"\n\n\n\"8\"\n\n\n\"1\"\n\n\n\"0\"\n\n\n\"425.1045\"\n\n\n\"NEUTRAL\"\n\n\n\"C21H19N3O5S\"\n\n\n\"O=C(CN(c1cccc(...\n\n\n\"XVDMUGUIAWGPNU...\n\n\n\n\n\"CHEMBL2017916\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"312.35\"\n\n\n\"3\"\n\n\n\"3\"\n\n\n\"2.86\"\n\n\n\"77.00\"\n\n\n\"6\"\n\n\n\"1\"\n\n\n\"0\"\n\n\n\"4\"\n\n\n\"N\"\n\n\n\"0.80\"\n\n\n\"8.13\"\n\n\n\"3.49\"\n\n\n\"2.17\"\n\n\n\"2.10\"\n\n\n\"3\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"22\"\n\n\n\"6\"\n\n\n\"1\"\n\n\n\"0\"\n\n\n\"312.0681\"\n\n\n\"NEUTRAL\"\n\n\n\"C15H12N4O2S\"\n\n\n\"COc1ccc(-c2nnc...\n\n\n\"XIZUJGDKNPVNQA...\n\n\n\n\n\"CHEMBL374652\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"403.83\"\n\n\n\"1\"\n\n\n\"1\"\n\n\n\"5.98\"\n\n\n\"36.02\"\n\n\n\"2\"\n\n\n\"2\"\n\n\n\"1\"\n\n\n\"4\"\n\n\n\"N\"\n\n\n\"0.42\"\n\n\n\"13.65\"\n\n\n\"None\"\n\n\n\"5.36\"\n\n\n\"5.36\"\n\n\n\"3\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"26\"\n\n\n\"2\"\n\n\n\"2\"\n\n\n\"1\"\n\n\n\"403.0421\"\n\n\n\"NEUTRAL\"\n\n\n\"C18H14ClF4NOS\"\n\n\n\"CC(O)(CSc1ccc(...\n\n\n\"CRPQTBRTHURKII...\n\n\n\n\n\"CHEMBL1416264\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"380.41\"\n\n\n\"6\"\n\n\n\"8\"\n\n\n\"3.06\"\n\n\n\"85.07\"\n\n\n\"7\"\n\n\n\"1\"\n\n\n\"0\"\n\n\n\"5\"\n\n\n\"N\"\n\n\n\"0.54\"\n\n\n\"13.85\"\n\n\n\"3.86\"\n\n\n\"2.47\"\n\n\n\"2.47\"\n\n\n\"4\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"27\"\n\n\n\"7\"\n\n\n\"1\"\n\n\n\"0\"\n\n\n\"380.0856\"\n\n\n\"NEUTRAL\"\n\n\n\"C18H13FN6OS\"\n\n\n\"O=C(CSc1ccc2nn...\n\n\n\"QVYIEKHEJKFNAT...\n\n\n\n\n\"CHEMBL213734\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"288.26\"\n\n\n\"2\"\n\n\n\"3\"\n\n\n\"2.32\"\n\n\n\"101.70\"\n\n\n\"5\"\n\n\n\"2\"\n\n\n\"0\"\n\n\n\"5\"\n\n\n\"N\"\n\n\n\"0.50\"\n\n\n\"7.20\"\n\n\n\"None\"\n\n\n\"2.36\"\n\n\n\"1.95\"\n\n\n\"2\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"21\"\n\n\n\"7\"\n\n\n\"2\"\n\n\n\"0\"\n\n\n\"288.0746\"\n\n\n\"NEUTRAL\"\n\n\n\"C14H12N2O5\"\n\n\n\"O=C(COc1ccccc1...\n\n\n\"PZTWAHGBGTWVEB...\n\n\n\n\n\"CHEMBL1531634\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"320.16\"\n\n\n\"19\"\n\n\n\"21\"\n\n\n\"4.40\"\n\n\n\"29.10\"\n\n\n\"2\"\n\n\n\"1\"\n\n\n\"0\"\n\n\n\"4\"\n\n\n\"N\"\n\n\n\"0.67\"\n\n\n\"None\"\n\n\n\"None\"\n\n\n\"4.04\"\n\n\n\"4.04\"\n\n\n\"2\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"19\"\n\n\n\"2\"\n\n\n\"1\"\n\n\n\"0\"\n\n\n\"319.0008\"\n\n\n\"NEUTRAL\"\n\n\n\"C15H11BrFNO\"\n\n\n\"O=C(/C=C/Nc1cc...\n\n\n\"DKPWCCDDKFLKEC...\n\n\n\n\n\n\n\n\nInitially, I only wanted to download around 24 compounds from the ChEMBL database first. Unknowingly, I ended up downloading the whole curated set of 2,331,700 small molecules (!), and I found this out when I loaded the dataframe after setting up the delimiter for the csv file, which later led to the file size problem mentioned earlier.\nLoading these 2,331,700 rows of data was fast, which occurred within a few seconds without exaggeration. This echoed many users’ experiences with Polars, so this was another nice surprise, and once again confirmed that Rust, and also Apache arrow, which was used as Polars’ foundation, were solid in speed.\nNow I had the full dataframe, and I wanted to find out what types of physicochemical properties were there for the compounds.\n\n# Print all column names and data types \nprint(df.glimpse())\n\nRows: 2331700\nColumns: 32\n$ ChEMBL ID                        <Utf8> CHEMBL1206185, CHEMBL539070, CHEMBL3335528, CHEMBL2419030, CHEMBL4301448, CHEMBL3827271, CHEMBL1969944, CHEMBL3465961, CHEMBL587495, CHEMBL3824158\n$ Name                             <Utf8> , , , , , , , , ,                                             \n$ Synonyms                         <Utf8> , , , , , , , , ,                                             \n$ Type                             <Utf8> Small molecule, Small molecule, Small molecule, Small molecule, Small molecule, Small molecule, Small molecule, Small molecule, Small molecule, Small molecule\n$ Max Phase                       <Int64> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0                                  \n$ Molecular Weight                 <Utf8> 607.88, 286.79, 842.80, 359.33, 465.55, 712.85, , 319.42, 478.54, 422.48\n$ Targets                          <Utf8> , 1, 2, 4, , 1, 56, 16, , 2                                   \n$ Bioactivities                    <Utf8> , 1, 6, 4, , 1, 56, 22, , 4                                   \n$ AlogP                            <Utf8> 9.46, 2.28, 0.18, 3.94, 5.09, -2.84, , 2.22, 6.85, 5.09       \n$ Polar Surface Area               <Utf8> 89.62, 73.06, 269.57, 85.13, 105.28, 319.06, , 50.50, 66.73, 109.54\n$ HBA                              <Utf8> 5, 6, 18, 6, 6, 10, , 4, 4, 6                                 \n$ HBD                              <Utf8> 2, 2, 5, 1, 4, 11, , 1, 3, 2                                  \n$ #RO5 Violations                  <Utf8> 2, 0, 2, 0, 1, 2, , 0, 1, 1                                   \n$ #Rotatable Bonds                 <Utf8> 17, 5, 17, 3, 10, 16, , 6, 6, 10                              \n$ Passes Ro3                       <Utf8> N, N, N, N, N, N, , N, N, N                                   \n$ QED Weighted                     <Utf8> 0.09, 0.63, 0.09, 0.66, 0.15, 0.07, , 0.87, 0.23, 0.31        \n$ CX Acidic pKa                    <Utf8> -1.91, 13.84, 3.20, None, None, 4.08, , None, 10.67, 4.59     \n$ CX Basic pKa                     <Utf8> 8.38, 3.64, None, None, 12.14, 10.49, , 9.38, 8.47, 7.99      \n$ CX LogP                          <Utf8> 9.40, 2.57, 3.31, 3.66, 4.41, -6.88, , 2.13, 6.04, 2.49       \n$ CX LogD                          <Utf8> 9.36, 2.57, -0.14, 3.66, 2.00, -8.95, , -0.44, 4.93, 2.42     \n$ Aromatic Rings                   <Utf8> 3, 2, 3, 2, 4, 0, , 1, 5, 2                                   \n$ Structure Type                   <Utf8> MOL, MOL, MOL, MOL, MOL, MOL, NONE, MOL, MOL, MOL             \n$ Inorganic Flag                  <Int64> -1, -1, -1, -1, -1, -1, -1, -1, -1, -1                        \n$ Heavy Atoms                      <Utf8> 42, 17, 60, 24, 33, 50, , 23, 34, 31                          \n$ HBA (Lipinski)                   <Utf8> 5, 5, 19, 6, 7, 19, , 4, 4, 7                                 \n$ HBD (Lipinski)                   <Utf8> 3, 3, 5, 1, 5, 14, , 1, 4, 2                                  \n$ #RO5 Violations (Lipinski)       <Utf8> 2, 0, 2, 0, 1, 3, , 0, 1, 1                                   \n$ Molecular Weight (Monoisotopic)  <Utf8> 607.2790, 250.0888, 842.2633, 359.0551, 465.1635, 712.4232, , 319.2060, 478.1439, 422.1842\n$ Molecular Species                <Utf8> ACID, NEUTRAL, ACID, NEUTRAL, BASE, ZWITTERION, , BASE, NEUTRAL, ACID\n$ Molecular Formula                <Utf8> C35H45NO4S2, C11H15ClN4OS, C41H46O19, C14H12F3N3O3S, C24H24FN5O2S, C31H56N10O9, , C18H26FN3O, C26H21F3N4S, C24H26N2O5\n$ Smiles                           <Utf8> CCCCCCCCCCC#CC(N)c1ccccc1-c1ccc(Sc2ccc(OCCCC)cc2)c(S(=O)(=O)O)c1, CCCOc1ccccc1-c1nnc(NN)s1.Cl, COC(=O)[C@H](O[C@@H]1O[C@@H](C)[C@@H](O)[C@@H](O)[C@@H]1O)[C@@H](O[C@@H]1O[C@H](CO)[C@H](OC(=O)c2ccccc2)[C@H](O[C@H](Cc2ccccc2)C(=O)O)[C@H]1OC(=O)c1ccccc1)C(=O)OC, O=c1nc(NC2CCCC2)sc2c([N+](=O)[O-])cc(C(F)(F)F)cc12, N=C(N)NCCCOc1ccc(CNc2nc3ccc(Oc4ccc(F)cc4)cc3s2)cc1, CC(C)C[C@@H]1NC(=O)[C@H](CCCNC(N)=O)NC(=O)[C@H](CCCCN)NC(=O)[C@H](CC(=O)O)NC(=O)[C@H](CCCCN)NC(=O)CCNC1=O, , CC(O)CN1CCC(CN(C)Cc2cc(C#N)ccc2F)CC1, Nc1cccc(CNCc2ccc(-c3ccc(-c4nc5cc(C(F)(F)F)ccc5[nH]4)s3)cc2)c1, CCCCCCCNC(C1=C(O)C(=O)c2ccccc2C1=O)c1ccc([N+](=O)[O-])cc1\n$ Inchi Key                        <Utf8> UFBLKYIDZFRLPR-UHFFFAOYSA-N, WPEWNRKLKLNLSO-UHFFFAOYSA-N, KGUJQZWYZPYYRZ-LWEWUKDVSA-N, QGDMYSDFCXOKML-UHFFFAOYSA-N, RXTJPHLPHOZLFS-UHFFFAOYSA-N, QJQNNLICZLLPMB-VUBDRERZSA-N, , FZEVYCHTADTXPM-UHFFFAOYSA-N, KZOHKPSNJBXTRJ-UHFFFAOYSA-N, AXOVDUYYBUYLPC-UHFFFAOYSA-N\n\n\n\nThere were a few terms where I wasn’t sure of their exact meanings, so I went through the ChEMBL_31 schema documentation and ChEMBL database website to find out. This took a while and was an important step to take so that I would know what to do when reaching the ML phase.\nI have selected a few physicochemical properties down below so that readers and I could gather some reasonable understandings for each term. The explanations for each term were adapted from ChEMBL_31 schema documentation (available as “Release notes” on the website), or if definitions for certain terms were not available from the documentation, I resorted to interpret them myself by going into “Dinstict compounds” section on the ChEMBL database, where I would click on, e.g. bioactivities, for a random compound in there to see what results showed up and then described them below.\nThe definitions for some of the listed physicochemical properties were:\nMax Phase - Maximum phase of development reached for the compound (where 4 = approved). Null was where max phase has not yet been assigned.\nBioactivities - Various biological assays used for the compounds e.g. IC50, GI50, potency tests etc.\nAlogP - Calculated partition coefficient\nHBA - Number of hydrogen bond acceptors\nHBD - Number of hydrogen bond donors\n#RO5 Violations - Number of violations of Lipinski’s rule-of-five, using HBA and HBD definitions\nPasses Ro3 - Indicated whether the compound passed the rule-of-three (MW < 300, logP < 3 etc)\nQED Weighted - Weighted quantitative estimate of drug likeness (as defined by Bickerton et al., Nature Chem 2012)\nInorganic flag - Indicated whether the molecule was inorganic (i.e., containing only metal atoms and <2 carbon atoms), where 1 = inorganic compound and -1 = not inorganic compound (assuming 0 meant it was neither case or yet to be assigned)\nHeavy Atoms - Number of heavy (non-hydrogen) atoms\nCX Acidic pKa - The most acidic pKa calculated using ChemAxon v17.29.0\nCX Basic pKa - The most basic pKa calculated using ChemAxon v17.29.0\nCX LogP - The calculated octanol/water partition coefficient using ChemAxon v17.29.0\nCX LogD - The calculated octanol/water distribution coefficient at pH = 7.4 using ChemAxon v17.29.0\nStructure Type - based on compound_structures table, where SEQ indicated an entry in the protein_therapeutics table instead, NONE indicated an entry in neither tables, e.g. structure unknown\nInchi Key - the IUPAC international chemical identifier key\nFrom the df.glimpse() method previously, there were a lot of columns with the data type of “Utf8”, which meant they were strings. There were only two columns that had “Int64”, which meant they were integers. A lot of these columns were actually storing numbers as strings. So to make my life easier, I went on to convert these data types into the more appropriate ones for selected columns.\n\n# Convert data types for multiple selected columns\n# Note: only takes two positional arguments, \n# so needed to use [] in code to allow more than two\n\n# Multiple columns all at once - with_columns()\n# Single column - with_column()\n\n# Use alias if wanting to keep original data type in column, \n# as it adds a new column under an alias name to dataframe\ndf_new = df.with_columns(\n    [\n        (pl.col(\"Molecular Weight\")).cast(pl.Float64, strict = False),\n        (pl.col(\"Targets\")).cast(pl.Int64, strict = False),\n        (pl.col(\"Bioactivities\")).cast(pl.Int64, strict = False),\n        (pl.col(\"AlogP\")).cast(pl.Float64, strict = False),\n        (pl.col(\"Polar Surface Area\")).cast(pl.Float64, strict = False),\n        (pl.col(\"HBA\")).cast(pl.Int64, strict = False),\n        (pl.col(\"HBD\")).cast(pl.Int64, strict = False),\n        (pl.col(\"#RO5 Violations\")).cast(pl.Int64, strict = False),\n        (pl.col(\"#Rotatable Bonds\")).cast(pl.Int64, strict = False),\n        (pl.col(\"QED Weighted\")).cast(pl.Float64, strict = False),\n        (pl.col(\"CX Acidic pKa\")).cast(pl.Float64, strict = False),\n        (pl.col(\"CX Basic pKa\")).cast(pl.Float64, strict = False),\n        (pl.col(\"CX LogP\")).cast(pl.Float64, strict = False),\n        (pl.col(\"CX LogD\")).cast(pl.Float64, strict = False),\n        (pl.col(\"Aromatic Rings\")).cast(pl.Int64, strict = False),\n        (pl.col(\"Heavy Atoms\")).cast(pl.Int64, strict = False),\n        (pl.col(\"HBA (Lipinski)\")).cast(pl.Int64, strict = False),\n        (pl.col(\"HBD (Lipinski)\")).cast(pl.Int64, strict = False),\n        (pl.col(\"#RO5 Violations (Lipinski)\")).cast(pl.Int64, strict = False),\n        (pl.col(\"Molecular Weight (Monoisotopic)\")).cast(pl.Float64, strict = False)\n    ]\n)\ndf_new.head()\n\n\n\n\nshape: (5, 32)\n\n\n\n\nChEMBL ID\n\n\nName\n\n\nSynonyms\n\n\nType\n\n\nMax Phase\n\n\nMolecular Weight\n\n\nTargets\n\n\nBioactivities\n\n\nAlogP\n\n\nPolar Surface Area\n\n\nHBA\n\n\nHBD\n\n\n#RO5 Violations\n\n\n#Rotatable Bonds\n\n\nPasses Ro3\n\n\nQED Weighted\n\n\nCX Acidic pKa\n\n\nCX Basic pKa\n\n\nCX LogP\n\n\nCX LogD\n\n\nAromatic Rings\n\n\nStructure Type\n\n\nInorganic Flag\n\n\nHeavy Atoms\n\n\nHBA (Lipinski)\n\n\nHBD (Lipinski)\n\n\n#RO5 Violations (Lipinski)\n\n\nMolecular Weight (Monoisotopic)\n\n\nMolecular Species\n\n\nMolecular Formula\n\n\nSmiles\n\n\nInchi Key\n\n\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\ni64\n\n\nf64\n\n\ni64\n\n\ni64\n\n\nf64\n\n\nf64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\nstr\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\ni64\n\n\nstr\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\nf64\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n\"CHEMBL1206185\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n607.88\n\n\nnull\n\n\nnull\n\n\n9.46\n\n\n89.62\n\n\n5\n\n\n2\n\n\n2\n\n\n17\n\n\n\"N\"\n\n\n0.09\n\n\n-1.91\n\n\n8.38\n\n\n9.4\n\n\n9.36\n\n\n3\n\n\n\"MOL\"\n\n\n-1\n\n\n42\n\n\n5\n\n\n3\n\n\n2\n\n\n607.279\n\n\n\"ACID\"\n\n\n\"C35H45NO4S2\"\n\n\n\"CCCCCCCCCCC#CC...\n\n\n\"UFBLKYIDZFRLPR...\n\n\n\n\n\"CHEMBL539070\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n286.79\n\n\n1\n\n\n1\n\n\n2.28\n\n\n73.06\n\n\n6\n\n\n2\n\n\n0\n\n\n5\n\n\n\"N\"\n\n\n0.63\n\n\n13.84\n\n\n3.64\n\n\n2.57\n\n\n2.57\n\n\n2\n\n\n\"MOL\"\n\n\n-1\n\n\n17\n\n\n5\n\n\n3\n\n\n0\n\n\n250.0888\n\n\n\"NEUTRAL\"\n\n\n\"C11H15ClN4OS\"\n\n\n\"CCCOc1ccccc1-c...\n\n\n\"WPEWNRKLKLNLSO...\n\n\n\n\n\"CHEMBL3335528\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n842.8\n\n\n2\n\n\n6\n\n\n0.18\n\n\n269.57\n\n\n18\n\n\n5\n\n\n2\n\n\n17\n\n\n\"N\"\n\n\n0.09\n\n\n3.2\n\n\nnull\n\n\n3.31\n\n\n-0.14\n\n\n3\n\n\n\"MOL\"\n\n\n-1\n\n\n60\n\n\n19\n\n\n5\n\n\n2\n\n\n842.2633\n\n\n\"ACID\"\n\n\n\"C41H46O19\"\n\n\n\"COC(=O)[C@H](O...\n\n\n\"KGUJQZWYZPYYRZ...\n\n\n\n\n\"CHEMBL2419030\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n359.33\n\n\n4\n\n\n4\n\n\n3.94\n\n\n85.13\n\n\n6\n\n\n1\n\n\n0\n\n\n3\n\n\n\"N\"\n\n\n0.66\n\n\nnull\n\n\nnull\n\n\n3.66\n\n\n3.66\n\n\n2\n\n\n\"MOL\"\n\n\n-1\n\n\n24\n\n\n6\n\n\n1\n\n\n0\n\n\n359.0551\n\n\n\"NEUTRAL\"\n\n\n\"C14H12F3N3O3S\"\n\n\n\"O=c1nc(NC2CCCC...\n\n\n\"QGDMYSDFCXOKML...\n\n\n\n\n\"CHEMBL4301448\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n465.55\n\n\nnull\n\n\nnull\n\n\n5.09\n\n\n105.28\n\n\n6\n\n\n4\n\n\n1\n\n\n10\n\n\n\"N\"\n\n\n0.15\n\n\nnull\n\n\n12.14\n\n\n4.41\n\n\n2.0\n\n\n4\n\n\n\"MOL\"\n\n\n-1\n\n\n33\n\n\n7\n\n\n5\n\n\n1\n\n\n465.1635\n\n\n\"BASE\"\n\n\n\"C24H24FN5O2S\"\n\n\n\"N=C(N)NCCCOc1c...\n\n\n\"RXTJPHLPHOZLFS...\n\n\n\n\n\n\n\nOnce all the columns’ data types have been checked and converted to appropriate types accordingly, I used null_count() to see the distributions of all null entries in the dataset.\n\n# Check for any null or NA or \"\" entries in the dataset\n# Alternative code that worked similarly was df.select(pl.all().null_count())\ndf_new.null_count()\n\n\n\n\nshape: (1, 32)\n\n\n\n\nChEMBL ID\n\n\nName\n\n\nSynonyms\n\n\nType\n\n\nMax Phase\n\n\nMolecular Weight\n\n\nTargets\n\n\nBioactivities\n\n\nAlogP\n\n\nPolar Surface Area\n\n\nHBA\n\n\nHBD\n\n\n#RO5 Violations\n\n\n#Rotatable Bonds\n\n\nPasses Ro3\n\n\nQED Weighted\n\n\nCX Acidic pKa\n\n\nCX Basic pKa\n\n\nCX LogP\n\n\nCX LogD\n\n\nAromatic Rings\n\n\nStructure Type\n\n\nInorganic Flag\n\n\nHeavy Atoms\n\n\nHBA (Lipinski)\n\n\nHBD (Lipinski)\n\n\n#RO5 Violations (Lipinski)\n\n\nMolecular Weight (Monoisotopic)\n\n\nMolecular Species\n\n\nMolecular Formula\n\n\nSmiles\n\n\nInchi Key\n\n\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\n\n\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n23249\n\n\n96223\n\n\n96223\n\n\n83571\n\n\n83571\n\n\n83571\n\n\n83571\n\n\n83571\n\n\n83571\n\n\n0\n\n\n83571\n\n\n1052439\n\n\n882168\n\n\n83795\n\n\n83795\n\n\n83571\n\n\n0\n\n\n0\n\n\n83571\n\n\n83571\n\n\n83571\n\n\n83571\n\n\n23252\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n\n\n\n\n\n\n# Drop rows with null entries\ndf_dn = df_new.drop_nulls()\ndf_dn \n# Number of rows reduced to 736,570\n\n\n\n\nshape: (736570, 32)\n\n\n\n\nChEMBL ID\n\n\nName\n\n\nSynonyms\n\n\nType\n\n\nMax Phase\n\n\nMolecular Weight\n\n\nTargets\n\n\nBioactivities\n\n\nAlogP\n\n\nPolar Surface Area\n\n\nHBA\n\n\nHBD\n\n\n#RO5 Violations\n\n\n#Rotatable Bonds\n\n\nPasses Ro3\n\n\nQED Weighted\n\n\nCX Acidic pKa\n\n\nCX Basic pKa\n\n\nCX LogP\n\n\nCX LogD\n\n\nAromatic Rings\n\n\nStructure Type\n\n\nInorganic Flag\n\n\nHeavy Atoms\n\n\nHBA (Lipinski)\n\n\nHBD (Lipinski)\n\n\n#RO5 Violations (Lipinski)\n\n\nMolecular Weight (Monoisotopic)\n\n\nMolecular Species\n\n\nMolecular Formula\n\n\nSmiles\n\n\nInchi Key\n\n\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\ni64\n\n\nf64\n\n\ni64\n\n\ni64\n\n\nf64\n\n\nf64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\nstr\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\ni64\n\n\nstr\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\nf64\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n\"CHEMBL539070\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n286.79\n\n\n1\n\n\n1\n\n\n2.28\n\n\n73.06\n\n\n6\n\n\n2\n\n\n0\n\n\n5\n\n\n\"N\"\n\n\n0.63\n\n\n13.84\n\n\n3.64\n\n\n2.57\n\n\n2.57\n\n\n2\n\n\n\"MOL\"\n\n\n-1\n\n\n17\n\n\n5\n\n\n3\n\n\n0\n\n\n250.0888\n\n\n\"NEUTRAL\"\n\n\n\"C11H15ClN4OS\"\n\n\n\"CCCOc1ccccc1-c...\n\n\n\"WPEWNRKLKLNLSO...\n\n\n\n\n\"CHEMBL3827271\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n712.85\n\n\n1\n\n\n1\n\n\n-2.84\n\n\n319.06\n\n\n10\n\n\n11\n\n\n2\n\n\n16\n\n\n\"N\"\n\n\n0.07\n\n\n4.08\n\n\n10.49\n\n\n-6.88\n\n\n-8.95\n\n\n0\n\n\n\"MOL\"\n\n\n-1\n\n\n50\n\n\n19\n\n\n14\n\n\n3\n\n\n712.4232\n\n\n\"ZWITTERION\"\n\n\n\"C31H56N10O9\"\n\n\n\"CC(C)C[C@@H]1N...\n\n\n\"QJQNNLICZLLPMB...\n\n\n\n\n\"CHEMBL3824158\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n422.48\n\n\n2\n\n\n4\n\n\n5.09\n\n\n109.54\n\n\n6\n\n\n2\n\n\n1\n\n\n10\n\n\n\"N\"\n\n\n0.31\n\n\n4.59\n\n\n7.99\n\n\n2.49\n\n\n2.42\n\n\n2\n\n\n\"MOL\"\n\n\n-1\n\n\n31\n\n\n7\n\n\n2\n\n\n1\n\n\n422.1842\n\n\n\"ACID\"\n\n\n\"C24H26N2O5\"\n\n\n\"CCCCCCCNC(C1=C...\n\n\n\"AXOVDUYYBUYLPC...\n\n\n\n\n\"CHEMBL1991010\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n454.05\n\n\n60\n\n\n60\n\n\n5.18\n\n\n40.54\n\n\n3\n\n\n1\n\n\n1\n\n\n8\n\n\n\"N\"\n\n\n0.6\n\n\n13.88\n\n\n8.48\n\n\n6.34\n\n\n5.22\n\n\n2\n\n\n\"MOL\"\n\n\n-1\n\n\n31\n\n\n3\n\n\n1\n\n\n1\n\n\n417.2668\n\n\n\"NEUTRAL\"\n\n\n\"C28H36ClNO2\"\n\n\n\"CCc1ccc(/C=C/C...\n\n\n\"XJDPAUYFONOZBC...\n\n\n\n\n\"CHEMBL195644\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n375.47\n\n\n2\n\n\n3\n\n\n4.95\n\n\n70.42\n\n\n4\n\n\n2\n\n\n0\n\n\n2\n\n\n\"N\"\n\n\n0.73\n\n\n9.52\n\n\n3.73\n\n\n3.92\n\n\n3.91\n\n\n2\n\n\n\"MOL\"\n\n\n-1\n\n\n28\n\n\n4\n\n\n2\n\n\n0\n\n\n375.1834\n\n\n\"NEUTRAL\"\n\n\n\"C24H25NO3\"\n\n\n\"C[C@]12CCC3c4c...\n\n\n\"MOBPUUUBXAHZBM...\n\n\n\n\n\"CHEMBL255263\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n388.42\n\n\n4\n\n\n4\n\n\n2.42\n\n\n95.16\n\n\n4\n\n\n2\n\n\n0\n\n\n4\n\n\n\"N\"\n\n\n0.72\n\n\n11.24\n\n\n1.02\n\n\n1.74\n\n\n1.74\n\n\n3\n\n\n\"MOL\"\n\n\n-1\n\n\n27\n\n\n7\n\n\n2\n\n\n0\n\n\n388.1005\n\n\n\"NEUTRAL\"\n\n\n\"C18H17FN4O3S\"\n\n\n\"O=C(Cc1ccc(F)c...\n\n\n\"JXSGQHRSUUOSAF...\n\n\n\n\n\"CHEMBL504846\"\n\n\n\"\"\n\n\n\"25-Deacetyl-Ri...\n\n\n\"Small molecule...\n\n\n0\n\n\n807.0\n\n\n3\n\n\n21\n\n\n3.9\n\n\n202.64\n\n\n13\n\n\n7\n\n\n3\n\n\n3\n\n\n\"N\"\n\n\n0.23\n\n\n8.61\n\n\n8.27\n\n\n3.4\n\n\n2.87\n\n\n1\n\n\n\"MOL\"\n\n\n-1\n\n\n58\n\n\n14\n\n\n7\n\n\n3\n\n\n806.4466\n\n\n\"NEUTRAL\"\n\n\n\"C44H62N4O10\"\n\n\n\"CO[C@H]1/C=C/O...\n\n\n\"MVUYPJALSSDCQB...\n\n\n\n\n\"CHEMBL85010\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n508.96\n\n\n4\n\n\n5\n\n\n2.65\n\n\n139.21\n\n\n9\n\n\n3\n\n\n1\n\n\n7\n\n\n\"N\"\n\n\n0.22\n\n\n7.03\n\n\n2.71\n\n\n3.27\n\n\n2.75\n\n\n1\n\n\n\"MOL\"\n\n\n-1\n\n\n35\n\n\n10\n\n\n3\n\n\n1\n\n\n508.1612\n\n\n\"NEUTRAL\"\n\n\n\"C24H29ClN2O8\"\n\n\n\"CCOCCNC(=O)CO/...\n\n\n\"PHPBXALSGRFDIK...\n\n\n\n\n\"CHEMBL1364151\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n314.39\n\n\n5\n\n\n6\n\n\n2.5\n\n\n54.56\n\n\n4\n\n\n1\n\n\n0\n\n\n3\n\n\n\"N\"\n\n\n0.88\n\n\n13.45\n\n\n7.28\n\n\n2.38\n\n\n2.14\n\n\n2\n\n\n\"MOL\"\n\n\n-1\n\n\n23\n\n\n5\n\n\n1\n\n\n0\n\n\n314.163\n\n\n\"NEUTRAL\"\n\n\n\"C18H22N2O3\"\n\n\n\"Cc1[nH]c2ccccc...\n\n\n\"OKIWVYPITFJCJI...\n\n\n\n\n\"CHEMBL2047203\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n855.36\n\n\n5\n\n\n6\n\n\n7.45\n\n\n272.16\n\n\n10\n\n\n4\n\n\n2\n\n\n13\n\n\n\"N\"\n\n\n0.06\n\n\n-10.58\n\n\n5.78\n\n\n4.35\n\n\n4.11\n\n\n4\n\n\n\"MOL\"\n\n\n-1\n\n\n61\n\n\n20\n\n\n4\n\n\n3\n\n\n854.3492\n\n\n\"ACID\"\n\n\n\"C40H47ClN14O6\"\n\n\n\"COC(=O)N[C@H](...\n\n\n\"QDXJQBSKIKHCKU...\n\n\n\n\n\"CHEMBL3798157\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n455.45\n\n\n28\n\n\n64\n\n\n4.77\n\n\n105.24\n\n\n6\n\n\n3\n\n\n0\n\n\n5\n\n\n\"N\"\n\n\n0.4\n\n\n7.29\n\n\n3.02\n\n\n3.97\n\n\n3.64\n\n\n4\n\n\n\"MOL\"\n\n\n-1\n\n\n32\n\n\n8\n\n\n3\n\n\n0\n\n\n455.0864\n\n\n\"NEUTRAL\"\n\n\n\"C21H15F2N5O3S\"\n\n\n\"CNC(=O)c1cc(Oc...\n\n\n\"LADWERPDOVRXBZ...\n\n\n\n\n\"CHEMBL1337107\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n296.33\n\n\n2\n\n\n2\n\n\n2.29\n\n\n64.35\n\n\n5\n\n\n1\n\n\n0\n\n\n4\n\n\n\"N\"\n\n\n0.75\n\n\n12.82\n\n\n4.35\n\n\n2.35\n\n\n2.35\n\n\n3\n\n\n\"MOL\"\n\n\n-1\n\n\n22\n\n\n5\n\n\n1\n\n\n0\n\n\n296.1161\n\n\n\"NEUTRAL\"\n\n\n\"C17H16N2O3\"\n\n\n\"COC(=O)Cn1c(C(...\n\n\n\"SBCXFZQMSVPTPA...\n\n\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n\n\n\"CHEMBL255122\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n529.07\n\n\n1\n\n\n2\n\n\n2.81\n\n\n110.43\n\n\n6\n\n\n3\n\n\n1\n\n\n5\n\n\n\"N\"\n\n\n0.47\n\n\n12.29\n\n\n6.33\n\n\n1.68\n\n\n1.65\n\n\n3\n\n\n\"MOL\"\n\n\n-1\n\n\n36\n\n\n9\n\n\n3\n\n\n1\n\n\n528.171\n\n\n\"NEUTRAL\"\n\n\n\"C25H29ClN6O3S\"\n\n\n\"CCC(=O)N1CCC(N...\n\n\n\"RAMXCQDJYLSGRA...\n\n\n\n\n\"CHEMBL2018776\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n516.04\n\n\n5\n\n\n5\n\n\n6.1\n\n\n97.84\n\n\n8\n\n\n2\n\n\n2\n\n\n13\n\n\n\"N\"\n\n\n0.26\n\n\n12.76\n\n\n9.18\n\n\n5.66\n\n\n3.88\n\n\n3\n\n\n\"MOL\"\n\n\n-1\n\n\n36\n\n\n9\n\n\n2\n\n\n2\n\n\n515.2299\n\n\n\"BASE\"\n\n\n\"C26H34ClN5O4\"\n\n\n\"CCCCOc1cc2c(Nc...\n\n\n\"FARPVPMCEBTTDI...\n\n\n\n\n\"CHEMBL97207\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n286.12\n\n\n2\n\n\n2\n\n\n1.31\n\n\n99.82\n\n\n5\n\n\n2\n\n\n0\n\n\n3\n\n\n\"N\"\n\n\n0.89\n\n\n13.08\n\n\n0.38\n\n\n2.1\n\n\n2.1\n\n\n2\n\n\n\"MOL\"\n\n\n-1\n\n\n18\n\n\n6\n\n\n4\n\n\n0\n\n\n285.0184\n\n\n\"NEUTRAL\"\n\n\n\"C10H9Cl2N5O\"\n\n\n\"NC(=O)c1nnn(Cc...\n\n\n\"HULYRQSWFVUVSF...\n\n\n\n\n\"CHEMBL221343\"\n\n\n\"\"\n\n\n\"LUF-5980\"\n\n\n\"Small molecule...\n\n\n0\n\n\n313.4\n\n\n5\n\n\n7\n\n\n5.42\n\n\n41.57\n\n\n2\n\n\n1\n\n\n1\n\n\n3\n\n\n\"N\"\n\n\n0.55\n\n\n11.75\n\n\n3.12\n\n\n5.46\n\n\n5.46\n\n\n4\n\n\n\"MOL\"\n\n\n-1\n\n\n24\n\n\n3\n\n\n1\n\n\n1\n\n\n313.1579\n\n\n\"NEUTRAL\"\n\n\n\"C21H19N3\"\n\n\n\"CC(C)c1nc2c(-c...\n\n\n\"REXYMDQLBZWOMA...\n\n\n\n\n\"CHEMBL1420018\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n255.27\n\n\n15\n\n\n20\n\n\n2.31\n\n\n69.39\n\n\n4\n\n\n1\n\n\n0\n\n\n4\n\n\n\"N\"\n\n\n0.52\n\n\n13.72\n\n\n2.76\n\n\n2.38\n\n\n2.38\n\n\n2\n\n\n\"MOL\"\n\n\n-1\n\n\n19\n\n\n4\n\n\n2\n\n\n0\n\n\n255.0895\n\n\n\"NEUTRAL\"\n\n\n\"C15H13NO3\"\n\n\n\"Nc1cccc(C(=O)O...\n\n\n\"UTIDKUVFKVXYLT...\n\n\n\n\n\"CHEMBL2314244\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n470.61\n\n\n7\n\n\n9\n\n\n1.86\n\n\n122.72\n\n\n6\n\n\n6\n\n\n1\n\n\n17\n\n\n\"N\"\n\n\n0.2\n\n\n8.96\n\n\n10.81\n\n\n-0.72\n\n\n-3.93\n\n\n2\n\n\n\"MOL\"\n\n\n-1\n\n\n34\n\n\n8\n\n\n6\n\n\n1\n\n\n470.2893\n\n\n\"BASE\"\n\n\n\"C26H38N4O4\"\n\n\n\"O=C(Cc1ccccc1O...\n\n\n\"SUKXUTUXGGJIBX...\n\n\n\n\n\"CHEMBL1420130\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n226.3\n\n\n2\n\n\n2\n\n\n1.89\n\n\n63.08\n\n\n5\n\n\n1\n\n\n0\n\n\n3\n\n\n\"N\"\n\n\n0.63\n\n\n12.05\n\n\n1.31\n\n\n2.94\n\n\n2.94\n\n\n1\n\n\n\"MOL\"\n\n\n-1\n\n\n15\n\n\n4\n\n\n1\n\n\n0\n\n\n226.0776\n\n\n\"NEUTRAL\"\n\n\n\"C10H14N2O2S\"\n\n\n\"CC(C)(C)C(=O)C...\n\n\n\"LCGAKQAOOABKRG...\n\n\n\n\n\"CHEMBL2419480\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n456.52\n\n\n3\n\n\n3\n\n\n1.56\n\n\n129.46\n\n\n8\n\n\n1\n\n\n0\n\n\n8\n\n\n\"N\"\n\n\n0.59\n\n\n3.99\n\n\n1.9\n\n\n2.14\n\n\n1.2\n\n\n2\n\n\n\"MOL\"\n\n\n-1\n\n\n32\n\n\n9\n\n\n1\n\n\n0\n\n\n456.1467\n\n\n\"ACID\"\n\n\n\"C22H24N4O5S\"\n\n\n\"CCOC(=O)c1cc(C...\n\n\n\"TXYSLOQUANFYQS...\n\n\n\n\n\"CHEMBL540121\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n540.05\n\n\n2\n\n\n3\n\n\n2.39\n\n\n147.14\n\n\n6\n\n\n4\n\n\n1\n\n\n8\n\n\n\"N\"\n\n\n0.22\n\n\n5.02\n\n\n11.48\n\n\n-0.75\n\n\n-0.78\n\n\n4\n\n\n\"MOL\"\n\n\n-1\n\n\n36\n\n\n9\n\n\n5\n\n\n1\n\n\n503.1627\n\n\n\"ZWITTERION\"\n\n\n\"C26H26ClN5O4S\"\n\n\n\"Cc1ccn(NS(=O)(...\n\n\n\"TZLGWENJAJXWGA...\n\n\n\n\n\"CHEMBL374041\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n504.5\n\n\n2\n\n\n4\n\n\n3.04\n\n\n144.95\n\n\n8\n\n\n3\n\n\n1\n\n\n10\n\n\n\"N\"\n\n\n0.28\n\n\n6.59\n\n\n4.37\n\n\n2.17\n\n\n1.33\n\n\n3\n\n\n\"MOL\"\n\n\n-1\n\n\n37\n\n\n11\n\n\n3\n\n\n2\n\n\n504.1645\n\n\n\"NEUTRAL\"\n\n\n\"C26H24N4O7\"\n\n\n\"CCOCCC1(Oc2ccc...\n\n\n\"ABCSNHDQYHOLOO...\n\n\n\n\n\"CHEMBL2017916\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n312.35\n\n\n3\n\n\n3\n\n\n2.86\n\n\n77.0\n\n\n6\n\n\n1\n\n\n0\n\n\n4\n\n\n\"N\"\n\n\n0.8\n\n\n8.13\n\n\n3.49\n\n\n2.17\n\n\n2.1\n\n\n3\n\n\n\"MOL\"\n\n\n-1\n\n\n22\n\n\n6\n\n\n1\n\n\n0\n\n\n312.0681\n\n\n\"NEUTRAL\"\n\n\n\"C15H12N4O2S\"\n\n\n\"COc1ccc(-c2nnc...\n\n\n\"XIZUJGDKNPVNQA...\n\n\n\n\n\"CHEMBL1416264\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n380.41\n\n\n6\n\n\n8\n\n\n3.06\n\n\n85.07\n\n\n7\n\n\n1\n\n\n0\n\n\n5\n\n\n\"N\"\n\n\n0.54\n\n\n13.85\n\n\n3.86\n\n\n2.47\n\n\n2.47\n\n\n4\n\n\n\"MOL\"\n\n\n-1\n\n\n27\n\n\n7\n\n\n1\n\n\n0\n\n\n380.0856\n\n\n\"NEUTRAL\"\n\n\n\"C18H13FN6OS\"\n\n\n\"O=C(CSc1ccc2nn...\n\n\n\"QVYIEKHEJKFNAT...\n\n\n\n\n\n\n\n\n# Check that all rows with null values were dropped\ndf_dn.null_count()\n\n\n\n\nshape: (1, 32)\n\n\n\n\nChEMBL ID\n\n\nName\n\n\nSynonyms\n\n\nType\n\n\nMax Phase\n\n\nMolecular Weight\n\n\nTargets\n\n\nBioactivities\n\n\nAlogP\n\n\nPolar Surface Area\n\n\nHBA\n\n\nHBD\n\n\n#RO5 Violations\n\n\n#Rotatable Bonds\n\n\nPasses Ro3\n\n\nQED Weighted\n\n\nCX Acidic pKa\n\n\nCX Basic pKa\n\n\nCX LogP\n\n\nCX LogD\n\n\nAromatic Rings\n\n\nStructure Type\n\n\nInorganic Flag\n\n\nHeavy Atoms\n\n\nHBA (Lipinski)\n\n\nHBD (Lipinski)\n\n\n#RO5 Violations (Lipinski)\n\n\nMolecular Weight (Monoisotopic)\n\n\nMolecular Species\n\n\nMolecular Formula\n\n\nSmiles\n\n\nInchi Key\n\n\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\n\n\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n\n\n\n\n\n\n# To see summary statistics for df_dn dataset\ndf_dn.describe()\n\n\n\n\nshape: (7, 33)\n\n\n\n\ndescribe\n\n\nChEMBL ID\n\n\nName\n\n\nSynonyms\n\n\nType\n\n\nMax Phase\n\n\nMolecular Weight\n\n\nTargets\n\n\nBioactivities\n\n\nAlogP\n\n\nPolar Surface Area\n\n\nHBA\n\n\nHBD\n\n\n#RO5 Violations\n\n\n#Rotatable Bonds\n\n\nPasses Ro3\n\n\nQED Weighted\n\n\nCX Acidic pKa\n\n\nCX Basic pKa\n\n\nCX LogP\n\n\nCX LogD\n\n\nAromatic Rings\n\n\nStructure Type\n\n\nInorganic Flag\n\n\nHeavy Atoms\n\n\nHBA (Lipinski)\n\n\nHBD (Lipinski)\n\n\n#RO5 Violations (Lipinski)\n\n\nMolecular Weight (Monoisotopic)\n\n\nMolecular Species\n\n\nMolecular Formula\n\n\nSmiles\n\n\nInchi Key\n\n\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nstr\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nstr\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n\"count\"\n\n\n\"736570\"\n\n\n\"736570\"\n\n\n\"736570\"\n\n\n\"736570\"\n\n\n736570.0\n\n\n736570.0\n\n\n736570.0\n\n\n736570.0\n\n\n736570.0\n\n\n736570.0\n\n\n736570.0\n\n\n736570.0\n\n\n736570.0\n\n\n736570.0\n\n\n\"736570\"\n\n\n736570.0\n\n\n736570.0\n\n\n736570.0\n\n\n736570.0\n\n\n736570.0\n\n\n736570.0\n\n\n\"736570\"\n\n\n736570.0\n\n\n736570.0\n\n\n736570.0\n\n\n736570.0\n\n\n736570.0\n\n\n736570.0\n\n\n\"736570\"\n\n\n\"736570\"\n\n\n\"736570\"\n\n\n\"736570\"\n\n\n\n\n\"null_count\"\n\n\n\"0\"\n\n\n\"0\"\n\n\n\"0\"\n\n\n\"0\"\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n\"0\"\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n\"0\"\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n\"0\"\n\n\n\"0\"\n\n\n\"0\"\n\n\n\"0\"\n\n\n\n\n\"mean\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n0.007937\n\n\n431.880042\n\n\n5.520715\n\n\n8.705471\n\n\n3.325204\n\n\n97.58116\n\n\n5.890221\n\n\n2.274721\n\n\n0.489124\n\n\n6.216262\n\n\nnull\n\n\n0.510936\n\n\n9.59944\n\n\n5.074377\n\n\n2.815115\n\n\n2.17363\n\n\n2.754412\n\n\nnull\n\n\n-0.929521\n\n\n30.266113\n\n\n7.276555\n\n\n2.497847\n\n\n0.576319\n\n\n428.334452\n\n\nnull\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\n\n\"std\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n0.164565\n\n\n135.637543\n\n\n14.784793\n\n\n55.537836\n\n\n1.980414\n\n\n47.40847\n\n\n2.459106\n\n\n1.681943\n\n\n0.794171\n\n\n3.894505\n\n\nnull\n\n\n0.229039\n\n\n3.583639\n\n\n3.234099\n\n\n2.286325\n\n\n2.645694\n\n\n1.2009\n\n\nnull\n\n\n0.255953\n\n\n9.54406\n\n\n3.067158\n\n\n2.081485\n\n\n0.908719\n\n\n133.755653\n\n\nnull\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\n\n\"min\"\n\n\n\"CHEMBL10\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n0.0\n\n\n45.04\n\n\n1.0\n\n\n1.0\n\n\n-12.92\n\n\n3.24\n\n\n1.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n\"N\"\n\n\n0.01\n\n\n-20.03\n\n\n0.0\n\n\n-16.71\n\n\n-26.04\n\n\n0.0\n\n\n\"BOTH\"\n\n\n-1.0\n\n\n3.0\n\n\n1.0\n\n\n0.0\n\n\n0.0\n\n\n45.0215\n\n\n\"ACID\"\n\n\n\"C10H10Br2N2O\"\n\n\n\"Br.Br.C/C(=N/N...\n\n\n\"AAAADVYFXUUVEO...\n\n\n\n\n\"max\"\n\n\n\"CHEMBL99998\"\n\n\n\"t-4-AMINOCROTO...\n\n\n\"trovafloxacin9...\n\n\n\"Unknown\"\n\n\n4.0\n\n\n1901.51\n\n\n1334.0\n\n\n17911.0\n\n\n16.83\n\n\n595.22\n\n\n32.0\n\n\n25.0\n\n\n4.0\n\n\n59.0\n\n\n\"Y\"\n\n\n0.95\n\n\n14.0\n\n\n38.8\n\n\n18.31\n\n\n18.31\n\n\n28.0\n\n\n\"MOL\"\n\n\n0.0\n\n\n76.0\n\n\n34.0\n\n\n32.0\n\n\n4.0\n\n\n999.4063\n\n\n\"ZWITTERION\"\n\n\n\"HNNa2O8S2\"\n\n\n\"n1nc2c([nH]1)c...\n\n\n\"ZZZZEJJXQQRZBH...\n\n\n\n\n\"median\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n0.0\n\n\n413.46\n\n\n2.0\n\n\n3.0\n\n\n3.37\n\n\n88.32\n\n\n5.0\n\n\n2.0\n\n\n0.0\n\n\n5.0\n\n\nnull\n\n\n0.51\n\n\n10.51\n\n\n4.7\n\n\n2.97\n\n\n2.46\n\n\n3.0\n\n\nnull\n\n\n-1.0\n\n\n29.0\n\n\n7.0\n\n\n2.0\n\n\n0.0\n\n\n410.2066\n\n\nnull\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\n\n\n\n\n\n\n\nSome exploratory data analysis\nOne of the columns that jumped out from the summary statistics of the df_dn dataset was the “Targets” column. It ranged from 1 to 1334 targets. Out of curiosity, I went through several places on ChEMBL website to find out the exact definition of “Target”. Eventually I settled on an answer which explained that the “Target” column represented the number of targets associated with the particular ChEMBL compound listed. I then singled out the ChEMBL compound with 1334 targets recorded, it turned out to be imatinib, which was marketed as Gleevec, and was a well-known prescription medicine for leukaemia and other selected oncological disorders with many well-documented drug interactions.\n\n# This was confirmed via a filter function, which brought up CHEMBL1421, or also known as dasatinib\ndf_dn.filter(pl.col(\"Targets\") == 1334)\n\n\n\n\nshape: (1, 32)\n\n\n\n\nChEMBL ID\n\n\nName\n\n\nSynonyms\n\n\nType\n\n\nMax Phase\n\n\nMolecular Weight\n\n\nTargets\n\n\nBioactivities\n\n\nAlogP\n\n\nPolar Surface Area\n\n\nHBA\n\n\nHBD\n\n\n#RO5 Violations\n\n\n#Rotatable Bonds\n\n\nPasses Ro3\n\n\nQED Weighted\n\n\nCX Acidic pKa\n\n\nCX Basic pKa\n\n\nCX LogP\n\n\nCX LogD\n\n\nAromatic Rings\n\n\nStructure Type\n\n\nInorganic Flag\n\n\nHeavy Atoms\n\n\nHBA (Lipinski)\n\n\nHBD (Lipinski)\n\n\n#RO5 Violations (Lipinski)\n\n\nMolecular Weight (Monoisotopic)\n\n\nMolecular Species\n\n\nMolecular Formula\n\n\nSmiles\n\n\nInchi Key\n\n\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\ni64\n\n\nf64\n\n\ni64\n\n\ni64\n\n\nf64\n\n\nf64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\nstr\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\ni64\n\n\nstr\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\nf64\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n\"CHEMBL941\"\n\n\n\"IMATINIB\"\n\n\n\"GLAMOX|Gleevec...\n\n\n\"Small molecule...\n\n\n4\n\n\n493.62\n\n\n1334\n\n\n4359\n\n\n4.59\n\n\n86.28\n\n\n7\n\n\n2\n\n\n0\n\n\n7\n\n\n\"N\"\n\n\n0.39\n\n\n12.69\n\n\n7.84\n\n\n4.38\n\n\n3.8\n\n\n4\n\n\n\"MOL\"\n\n\n0\n\n\n37\n\n\n8\n\n\n2\n\n\n0\n\n\n493.259\n\n\n\"NEUTRAL\"\n\n\n\"C29H31N7O\"\n\n\n\"Cc1ccc(NC(=O)c...\n\n\n\"KTUFNOKKBVMGRW...\n\n\n\n\n\n\n\nTo explore other physicochemical and molecular properties in the dataframe, “Max Phase” was one of the first few that drew my interests. So it tagged each ChEMBL compound with a max phase number from 0 to 4, where 4 meant the compound was approved (usually also meant it was already a prescription medicine). Thinking along this line, I thought what about those compounds that had max phase as 0, because they were the ones still pending associations with max phase numbers. By extending on this idea, this could be a good opportunity to introduce some ML to predict whether these zero max phase compounds would enter the approved max phase.\nFirstly, I had a look at the overall distribution of the max phase compounds in this dataframe df_dn.\n\n# Interested in what types of \"Max Phase\" were recorded \n# for the curated small molecules in ChEMBL database\ndf_dn.groupby(\"Max Phase\", maintain_order = True).agg(pl.count())\n\n\n\n\nshape: (5, 2)\n\n\n\n\nMax Phase\n\n\ncount\n\n\n\n\ni64\n\n\nu32\n\n\n\n\n\n\n0\n\n\n734633\n\n\n\n\n3\n\n\n303\n\n\n\n\n4\n\n\n954\n\n\n\n\n2\n\n\n441\n\n\n\n\n1\n\n\n239\n\n\n\n\n\n\n\nA quick groupby function showed that there were only 954 small molecules approved. Phase 3 recorded a total of 303 small molecules. For phase 2, there were 441 small molecules, followed by 239 compounds in phase 1. There were, however, a total amount of 734,633 small molecules that had zero as phase number (as per ChEMBL_31 schema documentation). Note: these figures were only for ChEMBL compounds with full documentations in the dataset (excluding entries or compounds with N/A or “” (empty) string cells).\nOne of the other parameters I was interested in was “QED Weighted”. So I went further into understanding what it meant, as the original reference was conveniently provided in the ChEMBL_31 schema documentation. The reference paper was by Bickerton, G., Paolini, G., Besnard, J. et al. Quantifying the chemical beauty of drugs. Nature Chem 4, 90–98 (2012) (note: author’s manuscript was available to view via PubMed link, the Nature Chemistry link only provided abstract with access to article via other means as stated).\nIn short, it was a measure of druglikeness for small molecules based on the concept of desirability, which was based on a total of 8 different molecular properties. These molecular properties included molecular weight, ALogP, polar surface area, number of hydrogen bond acceptors, number of hydrogen bond donors, number of rotatable bonds, number of aromatic rings and structural alerts. Without going into too much details for this QED Weighted parameter, it was normally recorded as a number that ranged from 0 to 1, with 0 being the least druglike and 1 being the most druglike.\n\n\n\nPrepare dataframe prior to running machine learning model\nBefore I got too carried away with further EDA, I wanted to get started on preparing a dataframe for the ML model. A rough plan at this stage was to filter out Max Phase 4 and 0 compounds. Max phase 0 compounds were the ones that were not assigned with any max phase numbers yet, so they would be ideal for use as the testing set. Another main idea was to use “Max Phase” parameter as the target y variable for a LR model, because ultimately stakeholders would be more interested in knowing which candidate compounds had the most likely chance to reach the final approved phase during a drug discovery and development project or otherwise. This would also provide a chance to potentially reduce the amount of resources and time required in such a complex and sophisticated matter.\nThe goal of this ML model was to answer this question: which physicochemical parameters would be the most suitable ones to predict whether a compound would enter max phase 4 (approved) or not? (implicitly, this might also help to predict which max phase 0 compounds would likely enter max phase 4 in the end)\nI’ve then narrowed down the df_dn dataset to fulfill the following criteria:\n\nOnly small molecules present\nMax phase of 0 and 4 only\n\nAnother reason behind choosing only small molecules that had max phase of 0 and 4 was that a confusion matrix could be built in the end to see if the parameters selected would give us a reasonably good model for predicting the outcomes of these small molecules.\nFor now, I’ve chosen the following columns (or physicochemical parameters) to appear in the interim df_0 and df_4 datasets.\n\n# Selecting Max phase 0 small molecules with desired parameters\ndf_0 = df_dn.filter(\n    (pl.col(\"Type\") == \"Small molecule\") &\n    (pl.col(\"Max Phase\") == 0)\n).select([\"ChEMBL ID\", \n          \"Type\", \n          \"Max Phase\",\n          \"#RO5 Violations\", \n          \"QED Weighted\", \n          \"CX LogP\", \n          \"CX LogD\", \n          \"Heavy Atoms\"]\n        )\ndf_0\n\n\n\n\nshape: (612795, 8)\n\n\n\n\nChEMBL ID\n\n\nType\n\n\nMax Phase\n\n\n#RO5 Violations\n\n\nQED Weighted\n\n\nCX LogP\n\n\nCX LogD\n\n\nHeavy Atoms\n\n\n\n\nstr\n\n\nstr\n\n\ni64\n\n\ni64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\ni64\n\n\n\n\n\n\n\"CHEMBL539070\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.63\n\n\n2.57\n\n\n2.57\n\n\n17\n\n\n\n\n\"CHEMBL3827271\"\n\n\n\"Small molecule...\n\n\n0\n\n\n2\n\n\n0.07\n\n\n-6.88\n\n\n-8.95\n\n\n50\n\n\n\n\n\"CHEMBL3824158\"\n\n\n\"Small molecule...\n\n\n0\n\n\n1\n\n\n0.31\n\n\n2.49\n\n\n2.42\n\n\n31\n\n\n\n\n\"CHEMBL1991010\"\n\n\n\"Small molecule...\n\n\n0\n\n\n1\n\n\n0.6\n\n\n6.34\n\n\n5.22\n\n\n31\n\n\n\n\n\"CHEMBL195644\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.73\n\n\n3.92\n\n\n3.91\n\n\n28\n\n\n\n\n\"CHEMBL255263\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.72\n\n\n1.74\n\n\n1.74\n\n\n27\n\n\n\n\n\"CHEMBL504846\"\n\n\n\"Small molecule...\n\n\n0\n\n\n3\n\n\n0.23\n\n\n3.4\n\n\n2.87\n\n\n58\n\n\n\n\n\"CHEMBL85010\"\n\n\n\"Small molecule...\n\n\n0\n\n\n1\n\n\n0.22\n\n\n3.27\n\n\n2.75\n\n\n35\n\n\n\n\n\"CHEMBL1364151\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.88\n\n\n2.38\n\n\n2.14\n\n\n23\n\n\n\n\n\"CHEMBL2047203\"\n\n\n\"Small molecule...\n\n\n0\n\n\n2\n\n\n0.06\n\n\n4.35\n\n\n4.11\n\n\n61\n\n\n\n\n\"CHEMBL3798157\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.4\n\n\n3.97\n\n\n3.64\n\n\n32\n\n\n\n\n\"CHEMBL1337107\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.75\n\n\n2.35\n\n\n2.35\n\n\n22\n\n\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n\n\n\"CHEMBL255122\"\n\n\n\"Small molecule...\n\n\n0\n\n\n1\n\n\n0.47\n\n\n1.68\n\n\n1.65\n\n\n36\n\n\n\n\n\"CHEMBL2018776\"\n\n\n\"Small molecule...\n\n\n0\n\n\n2\n\n\n0.26\n\n\n5.66\n\n\n3.88\n\n\n36\n\n\n\n\n\"CHEMBL97207\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.89\n\n\n2.1\n\n\n2.1\n\n\n18\n\n\n\n\n\"CHEMBL221343\"\n\n\n\"Small molecule...\n\n\n0\n\n\n1\n\n\n0.55\n\n\n5.46\n\n\n5.46\n\n\n24\n\n\n\n\n\"CHEMBL1420018\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.52\n\n\n2.38\n\n\n2.38\n\n\n19\n\n\n\n\n\"CHEMBL2314244\"\n\n\n\"Small molecule...\n\n\n0\n\n\n1\n\n\n0.2\n\n\n-0.72\n\n\n-3.93\n\n\n34\n\n\n\n\n\"CHEMBL1420130\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.63\n\n\n2.94\n\n\n2.94\n\n\n15\n\n\n\n\n\"CHEMBL2419480\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.59\n\n\n2.14\n\n\n1.2\n\n\n32\n\n\n\n\n\"CHEMBL540121\"\n\n\n\"Small molecule...\n\n\n0\n\n\n1\n\n\n0.22\n\n\n-0.75\n\n\n-0.78\n\n\n36\n\n\n\n\n\"CHEMBL374041\"\n\n\n\"Small molecule...\n\n\n0\n\n\n1\n\n\n0.28\n\n\n2.17\n\n\n1.33\n\n\n37\n\n\n\n\n\"CHEMBL2017916\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.8\n\n\n2.17\n\n\n2.1\n\n\n22\n\n\n\n\n\"CHEMBL1416264\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.54\n\n\n2.47\n\n\n2.47\n\n\n27\n\n\n\n\n\n\n\n\n# Selecting Max phase 4 small molecules with desired parameters\ndf_4 = df_dn.filter(\n    (pl.col(\"Type\") == \"Small molecule\") &\n    (pl.col(\"Max Phase\") == 4)\n).select([\"ChEMBL ID\", \n          \"Type\", \n          \"Max Phase\",\n          \"#RO5 Violations\", \n          \"QED Weighted\", \n          \"CX LogP\", \n          \"CX LogD\", \n          \"Heavy Atoms\"]\n        )\ndf_4\n\n\n\n\nshape: (944, 8)\n\n\n\n\nChEMBL ID\n\n\nType\n\n\nMax Phase\n\n\n#RO5 Violations\n\n\nQED Weighted\n\n\nCX LogP\n\n\nCX LogD\n\n\nHeavy Atoms\n\n\n\n\nstr\n\n\nstr\n\n\ni64\n\n\ni64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\ni64\n\n\n\n\n\n\n\"CHEMBL1096882\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.31\n\n\n-1.97\n\n\n-5.12\n\n\n24\n\n\n\n\n\"CHEMBL2023898\"\n\n\n\"Small molecule...\n\n\n4\n\n\n2\n\n\n0.14\n\n\n4.18\n\n\n4.16\n\n\n54\n\n\n\n\n\"CHEMBL1029\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.46\n\n\n-1.18\n\n\n-2.3\n\n\n15\n\n\n\n\n\"CHEMBL1616\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.72\n\n\n2.88\n\n\n2.58\n\n\n20\n\n\n\n\n\"CHEMBL2146123\"\n\n\n\"Small molecule...\n\n\n4\n\n\n1\n\n\n0.33\n\n\n-3.51\n\n\n-3.81\n\n\n32\n\n\n\n\n\"CHEMBL1200773\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.75\n\n\n1.88\n\n\n1.0\n\n\n14\n\n\n\n\n\"CHEMBL1201002\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.77\n\n\n1.42\n\n\n-0.89\n\n\n21\n\n\n\n\n\"CHEMBL1086440\"\n\n\n\"Small molecule...\n\n\n4\n\n\n1\n\n\n0.58\n\n\n5.88\n\n\n5.88\n\n\n21\n\n\n\n\n\"CHEMBL2359966\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.88\n\n\n2.51\n\n\n0.86\n\n\n24\n\n\n\n\n\"CHEMBL302795\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.87\n\n\n-0.12\n\n\n-1.91\n\n\n22\n\n\n\n\n\"CHEMBL1214185\"\n\n\n\"Small molecule...\n\n\n4\n\n\n2\n\n\n0.08\n\n\n3.0\n\n\n1.32\n\n\n58\n\n\n\n\n\"CHEMBL487253\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.7\n\n\n1.8\n\n\n0.81\n\n\n23\n\n\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n\n\n\"CHEMBL2103743\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.93\n\n\n1.24\n\n\n1.19\n\n\n23\n\n\n\n\n\"CHEMBL3989931\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.46\n\n\n4.59\n\n\n4.59\n\n\n33\n\n\n\n\n\"CHEMBL1201033\"\n\n\n\"Small molecule...\n\n\n4\n\n\n1\n\n\n0.32\n\n\n3.4\n\n\n1.0\n\n\n19\n\n\n\n\n\"CHEMBL1201731\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.69\n\n\n3.21\n\n\n1.71\n\n\n29\n\n\n\n\n\"CHEMBL2105743\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.58\n\n\n1.19\n\n\n-0.18\n\n\n28\n\n\n\n\n\"CHEMBL4297513\"\n\n\n\"Small molecule...\n\n\n4\n\n\n2\n\n\n0.26\n\n\n4.9\n\n\n4.9\n\n\n53\n\n\n\n\n\"CHEMBL1201321\"\n\n\n\"Small molecule...\n\n\n4\n\n\n1\n\n\n0.58\n\n\n2.65\n\n\n2.65\n\n\n32\n\n\n\n\n\"CHEMBL3545062\"\n\n\n\"Small molecule...\n\n\n4\n\n\n2\n\n\n0.1\n\n\n5.57\n\n\n5.57\n\n\n65\n\n\n\n\n\"CHEMBL3039520\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.83\n\n\n3.3\n\n\n2.61\n\n\n27\n\n\n\n\n\"CHEMBL1198857\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.26\n\n\n3.6\n\n\n1.93\n\n\n32\n\n\n\n\n\"CHEMBL2146133\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.77\n\n\n2.43\n\n\n2.43\n\n\n24\n\n\n\n\n\"CHEMBL1619785\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.49\n\n\n2.09\n\n\n1.86\n\n\n34\n\n\n\n\n\n\n\n\n\nRe-sampling via under-sampling\nBecause of the large number of Max Phase 0 compounds present in the original dataset, I’ve randomly sampled about 950 small molecules from this group, so that there were similar amount of data in each group to avoid having an imbalanced dataset.\n\ndf_s_0 = df_0.sample(n = 950, shuffle = True, seed = 0)\ndf_s_0\n\n\n\n\nshape: (950, 8)\n\n\n\n\nChEMBL ID\n\n\nType\n\n\nMax Phase\n\n\n#RO5 Violations\n\n\nQED Weighted\n\n\nCX LogP\n\n\nCX LogD\n\n\nHeavy Atoms\n\n\n\n\nstr\n\n\nstr\n\n\ni64\n\n\ni64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\ni64\n\n\n\n\n\n\n\"CHEMBL3448290\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.91\n\n\n2.05\n\n\n0.62\n\n\n21\n\n\n\n\n\"CHEMBL3966308\"\n\n\n\"Small molecule...\n\n\n0\n\n\n2\n\n\n0.16\n\n\n1.51\n\n\n-0.41\n\n\n48\n\n\n\n\n\"CHEMBL3963545\"\n\n\n\"Small molecule...\n\n\n0\n\n\n2\n\n\n0.2\n\n\n5.05\n\n\n3.27\n\n\n46\n\n\n\n\n\"CHEMBL1649629\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.53\n\n\n3.21\n\n\n3.21\n\n\n24\n\n\n\n\n\"CHEMBL3813954\"\n\n\n\"Small molecule...\n\n\n0\n\n\n1\n\n\n0.14\n\n\n2.8\n\n\n2.8\n\n\n37\n\n\n\n\n\"CHEMBL1164717\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.42\n\n\n1.6\n\n\n1.55\n\n\n35\n\n\n\n\n\"CHEMBL1824896\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.58\n\n\n4.69\n\n\n4.13\n\n\n34\n\n\n\n\n\"CHEMBL2323807\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.88\n\n\n3.09\n\n\n2.22\n\n\n20\n\n\n\n\n\"CHEMBL3919258\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.5\n\n\n1.36\n\n\n1.36\n\n\n32\n\n\n\n\n\"CHEMBL1973768\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.61\n\n\n-1.09\n\n\n-1.09\n\n\n15\n\n\n\n\n\"CHEMBL3193130\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.32\n\n\n2.88\n\n\n2.88\n\n\n30\n\n\n\n\n\"CHEMBL157009\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.4\n\n\n-1.57\n\n\n-1.6\n\n\n20\n\n\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n\n\n\"CHEMBL1586774\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.79\n\n\n4.03\n\n\n4.02\n\n\n25\n\n\n\n\n\"CHEMBL3735848\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.62\n\n\n2.49\n\n\n2.48\n\n\n31\n\n\n\n\n\"CHEMBL2238035\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.63\n\n\n-0.89\n\n\n-0.9\n\n\n18\n\n\n\n\n\"CHEMBL2409594\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.42\n\n\n2.9\n\n\n2.9\n\n\n32\n\n\n\n\n\"CHEMBL1823603\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.51\n\n\n4.06\n\n\n4.06\n\n\n32\n\n\n\n\n\"CHEMBL1373723\"\n\n\n\"Small molecule...\n\n\n0\n\n\n2\n\n\n0.25\n\n\n4.85\n\n\n4.84\n\n\n47\n\n\n\n\n\"CHEMBL1092638\"\n\n\n\"Small molecule...\n\n\n0\n\n\n1\n\n\n0.45\n\n\n5.0\n\n\n4.78\n\n\n34\n\n\n\n\n\"CHEMBL3884327\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.23\n\n\n2.0\n\n\n1.31\n\n\n33\n\n\n\n\n\"CHEMBL3952298\"\n\n\n\"Small molecule...\n\n\n0\n\n\n2\n\n\n0.27\n\n\n4.75\n\n\n4.75\n\n\n37\n\n\n\n\n\"CHEMBL3958658\"\n\n\n\"Small molecule...\n\n\n0\n\n\n1\n\n\n0.37\n\n\n4.32\n\n\n4.32\n\n\n36\n\n\n\n\n\"CHEMBL2181572\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.32\n\n\n3.3\n\n\n3.3\n\n\n23\n\n\n\n\n\"CHEMBL603992\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.27\n\n\n3.51\n\n\n3.51\n\n\n35\n\n\n\n\n\n\n\nSince the plan was to use LR method for ML model, the y variable I was interested in was going to be a binary categorical variable - meaning it needed to be 0 (not approved) or 1 (approved). To do this, I’ve added a new column with a new name of “Max_Phase” and replace “4” as “1” by dividing the whole column by 4 to reach this new label.\n\ndf_4_f = df_4.with_columns((pl.col(\"Max Phase\") / 4).alias(\"Max_Phase\"))\ndf_4_f\n\n\n\n\nshape: (944, 9)\n\n\n\n\nChEMBL ID\n\n\nType\n\n\nMax Phase\n\n\n#RO5 Violations\n\n\nQED Weighted\n\n\nCX LogP\n\n\nCX LogD\n\n\nHeavy Atoms\n\n\nMax_Phase\n\n\n\n\nstr\n\n\nstr\n\n\ni64\n\n\ni64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\ni64\n\n\nf64\n\n\n\n\n\n\n\"CHEMBL1096882\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.31\n\n\n-1.97\n\n\n-5.12\n\n\n24\n\n\n1.0\n\n\n\n\n\"CHEMBL2023898\"\n\n\n\"Small molecule...\n\n\n4\n\n\n2\n\n\n0.14\n\n\n4.18\n\n\n4.16\n\n\n54\n\n\n1.0\n\n\n\n\n\"CHEMBL1029\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.46\n\n\n-1.18\n\n\n-2.3\n\n\n15\n\n\n1.0\n\n\n\n\n\"CHEMBL1616\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.72\n\n\n2.88\n\n\n2.58\n\n\n20\n\n\n1.0\n\n\n\n\n\"CHEMBL2146123\"\n\n\n\"Small molecule...\n\n\n4\n\n\n1\n\n\n0.33\n\n\n-3.51\n\n\n-3.81\n\n\n32\n\n\n1.0\n\n\n\n\n\"CHEMBL1200773\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.75\n\n\n1.88\n\n\n1.0\n\n\n14\n\n\n1.0\n\n\n\n\n\"CHEMBL1201002\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.77\n\n\n1.42\n\n\n-0.89\n\n\n21\n\n\n1.0\n\n\n\n\n\"CHEMBL1086440\"\n\n\n\"Small molecule...\n\n\n4\n\n\n1\n\n\n0.58\n\n\n5.88\n\n\n5.88\n\n\n21\n\n\n1.0\n\n\n\n\n\"CHEMBL2359966\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.88\n\n\n2.51\n\n\n0.86\n\n\n24\n\n\n1.0\n\n\n\n\n\"CHEMBL302795\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.87\n\n\n-0.12\n\n\n-1.91\n\n\n22\n\n\n1.0\n\n\n\n\n\"CHEMBL1214185\"\n\n\n\"Small molecule...\n\n\n4\n\n\n2\n\n\n0.08\n\n\n3.0\n\n\n1.32\n\n\n58\n\n\n1.0\n\n\n\n\n\"CHEMBL487253\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.7\n\n\n1.8\n\n\n0.81\n\n\n23\n\n\n1.0\n\n\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n\n\n\"CHEMBL2103743\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.93\n\n\n1.24\n\n\n1.19\n\n\n23\n\n\n1.0\n\n\n\n\n\"CHEMBL3989931\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.46\n\n\n4.59\n\n\n4.59\n\n\n33\n\n\n1.0\n\n\n\n\n\"CHEMBL1201033\"\n\n\n\"Small molecule...\n\n\n4\n\n\n1\n\n\n0.32\n\n\n3.4\n\n\n1.0\n\n\n19\n\n\n1.0\n\n\n\n\n\"CHEMBL1201731\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.69\n\n\n3.21\n\n\n1.71\n\n\n29\n\n\n1.0\n\n\n\n\n\"CHEMBL2105743\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.58\n\n\n1.19\n\n\n-0.18\n\n\n28\n\n\n1.0\n\n\n\n\n\"CHEMBL4297513\"\n\n\n\"Small molecule...\n\n\n4\n\n\n2\n\n\n0.26\n\n\n4.9\n\n\n4.9\n\n\n53\n\n\n1.0\n\n\n\n\n\"CHEMBL1201321\"\n\n\n\"Small molecule...\n\n\n4\n\n\n1\n\n\n0.58\n\n\n2.65\n\n\n2.65\n\n\n32\n\n\n1.0\n\n\n\n\n\"CHEMBL3545062\"\n\n\n\"Small molecule...\n\n\n4\n\n\n2\n\n\n0.1\n\n\n5.57\n\n\n5.57\n\n\n65\n\n\n1.0\n\n\n\n\n\"CHEMBL3039520\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.83\n\n\n3.3\n\n\n2.61\n\n\n27\n\n\n1.0\n\n\n\n\n\"CHEMBL1198857\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.26\n\n\n3.6\n\n\n1.93\n\n\n32\n\n\n1.0\n\n\n\n\n\"CHEMBL2146133\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.77\n\n\n2.43\n\n\n2.43\n\n\n24\n\n\n1.0\n\n\n\n\n\"CHEMBL1619785\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.49\n\n\n2.09\n\n\n1.86\n\n\n34\n\n\n1.0\n\n\n\n\n\n\n\nThen I changed the data type of “Max_Phase” from float to integer, so that the two different dataframes could be concatenated (which would only work if both were of same data types).\n\ndf_4_f = df_4_f.with_column((pl.col(\"Max_Phase\")).cast(pl.Int64, strict = False))\ndf_4_f\n\n\n\n\nshape: (944, 9)\n\n\n\n\nChEMBL ID\n\n\nType\n\n\nMax Phase\n\n\n#RO5 Violations\n\n\nQED Weighted\n\n\nCX LogP\n\n\nCX LogD\n\n\nHeavy Atoms\n\n\nMax_Phase\n\n\n\n\nstr\n\n\nstr\n\n\ni64\n\n\ni64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\ni64\n\n\ni64\n\n\n\n\n\n\n\"CHEMBL1096882\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.31\n\n\n-1.97\n\n\n-5.12\n\n\n24\n\n\n1\n\n\n\n\n\"CHEMBL2023898\"\n\n\n\"Small molecule...\n\n\n4\n\n\n2\n\n\n0.14\n\n\n4.18\n\n\n4.16\n\n\n54\n\n\n1\n\n\n\n\n\"CHEMBL1029\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.46\n\n\n-1.18\n\n\n-2.3\n\n\n15\n\n\n1\n\n\n\n\n\"CHEMBL1616\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.72\n\n\n2.88\n\n\n2.58\n\n\n20\n\n\n1\n\n\n\n\n\"CHEMBL2146123\"\n\n\n\"Small molecule...\n\n\n4\n\n\n1\n\n\n0.33\n\n\n-3.51\n\n\n-3.81\n\n\n32\n\n\n1\n\n\n\n\n\"CHEMBL1200773\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.75\n\n\n1.88\n\n\n1.0\n\n\n14\n\n\n1\n\n\n\n\n\"CHEMBL1201002\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.77\n\n\n1.42\n\n\n-0.89\n\n\n21\n\n\n1\n\n\n\n\n\"CHEMBL1086440\"\n\n\n\"Small molecule...\n\n\n4\n\n\n1\n\n\n0.58\n\n\n5.88\n\n\n5.88\n\n\n21\n\n\n1\n\n\n\n\n\"CHEMBL2359966\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.88\n\n\n2.51\n\n\n0.86\n\n\n24\n\n\n1\n\n\n\n\n\"CHEMBL302795\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.87\n\n\n-0.12\n\n\n-1.91\n\n\n22\n\n\n1\n\n\n\n\n\"CHEMBL1214185\"\n\n\n\"Small molecule...\n\n\n4\n\n\n2\n\n\n0.08\n\n\n3.0\n\n\n1.32\n\n\n58\n\n\n1\n\n\n\n\n\"CHEMBL487253\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.7\n\n\n1.8\n\n\n0.81\n\n\n23\n\n\n1\n\n\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n\n\n\"CHEMBL2103743\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.93\n\n\n1.24\n\n\n1.19\n\n\n23\n\n\n1\n\n\n\n\n\"CHEMBL3989931\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.46\n\n\n4.59\n\n\n4.59\n\n\n33\n\n\n1\n\n\n\n\n\"CHEMBL1201033\"\n\n\n\"Small molecule...\n\n\n4\n\n\n1\n\n\n0.32\n\n\n3.4\n\n\n1.0\n\n\n19\n\n\n1\n\n\n\n\n\"CHEMBL1201731\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.69\n\n\n3.21\n\n\n1.71\n\n\n29\n\n\n1\n\n\n\n\n\"CHEMBL2105743\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.58\n\n\n1.19\n\n\n-0.18\n\n\n28\n\n\n1\n\n\n\n\n\"CHEMBL4297513\"\n\n\n\"Small molecule...\n\n\n4\n\n\n2\n\n\n0.26\n\n\n4.9\n\n\n4.9\n\n\n53\n\n\n1\n\n\n\n\n\"CHEMBL1201321\"\n\n\n\"Small molecule...\n\n\n4\n\n\n1\n\n\n0.58\n\n\n2.65\n\n\n2.65\n\n\n32\n\n\n1\n\n\n\n\n\"CHEMBL3545062\"\n\n\n\"Small molecule...\n\n\n4\n\n\n2\n\n\n0.1\n\n\n5.57\n\n\n5.57\n\n\n65\n\n\n1\n\n\n\n\n\"CHEMBL3039520\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.83\n\n\n3.3\n\n\n2.61\n\n\n27\n\n\n1\n\n\n\n\n\"CHEMBL1198857\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.26\n\n\n3.6\n\n\n1.93\n\n\n32\n\n\n1\n\n\n\n\n\"CHEMBL2146133\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.77\n\n\n2.43\n\n\n2.43\n\n\n24\n\n\n1\n\n\n\n\n\"CHEMBL1619785\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.49\n\n\n2.09\n\n\n1.86\n\n\n34\n\n\n1\n\n\n\n\n\n\n\nAlso I’ve created a new column with the same name of “Max_Phase” for Max phase 0 small molecules, so that the two dataframes could be combined (also needed to have exactly the same column names for it to work).\n\ndf_s_0_f = df_s_0.with_column((pl.col(\"Max Phase\")).alias(\"Max_Phase\"))\ndf_s_0_f\n\n\n\n\nshape: (950, 9)\n\n\n\n\nChEMBL ID\n\n\nType\n\n\nMax Phase\n\n\n#RO5 Violations\n\n\nQED Weighted\n\n\nCX LogP\n\n\nCX LogD\n\n\nHeavy Atoms\n\n\nMax_Phase\n\n\n\n\nstr\n\n\nstr\n\n\ni64\n\n\ni64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\ni64\n\n\ni64\n\n\n\n\n\n\n\"CHEMBL3448290\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.91\n\n\n2.05\n\n\n0.62\n\n\n21\n\n\n0\n\n\n\n\n\"CHEMBL3966308\"\n\n\n\"Small molecule...\n\n\n0\n\n\n2\n\n\n0.16\n\n\n1.51\n\n\n-0.41\n\n\n48\n\n\n0\n\n\n\n\n\"CHEMBL3963545\"\n\n\n\"Small molecule...\n\n\n0\n\n\n2\n\n\n0.2\n\n\n5.05\n\n\n3.27\n\n\n46\n\n\n0\n\n\n\n\n\"CHEMBL1649629\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.53\n\n\n3.21\n\n\n3.21\n\n\n24\n\n\n0\n\n\n\n\n\"CHEMBL3813954\"\n\n\n\"Small molecule...\n\n\n0\n\n\n1\n\n\n0.14\n\n\n2.8\n\n\n2.8\n\n\n37\n\n\n0\n\n\n\n\n\"CHEMBL1164717\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.42\n\n\n1.6\n\n\n1.55\n\n\n35\n\n\n0\n\n\n\n\n\"CHEMBL1824896\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.58\n\n\n4.69\n\n\n4.13\n\n\n34\n\n\n0\n\n\n\n\n\"CHEMBL2323807\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.88\n\n\n3.09\n\n\n2.22\n\n\n20\n\n\n0\n\n\n\n\n\"CHEMBL3919258\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.5\n\n\n1.36\n\n\n1.36\n\n\n32\n\n\n0\n\n\n\n\n\"CHEMBL1973768\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.61\n\n\n-1.09\n\n\n-1.09\n\n\n15\n\n\n0\n\n\n\n\n\"CHEMBL3193130\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.32\n\n\n2.88\n\n\n2.88\n\n\n30\n\n\n0\n\n\n\n\n\"CHEMBL157009\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.4\n\n\n-1.57\n\n\n-1.6\n\n\n20\n\n\n0\n\n\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n\n\n\"CHEMBL1586774\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.79\n\n\n4.03\n\n\n4.02\n\n\n25\n\n\n0\n\n\n\n\n\"CHEMBL3735848\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.62\n\n\n2.49\n\n\n2.48\n\n\n31\n\n\n0\n\n\n\n\n\"CHEMBL2238035\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.63\n\n\n-0.89\n\n\n-0.9\n\n\n18\n\n\n0\n\n\n\n\n\"CHEMBL2409594\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.42\n\n\n2.9\n\n\n2.9\n\n\n32\n\n\n0\n\n\n\n\n\"CHEMBL1823603\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.51\n\n\n4.06\n\n\n4.06\n\n\n32\n\n\n0\n\n\n\n\n\"CHEMBL1373723\"\n\n\n\"Small molecule...\n\n\n0\n\n\n2\n\n\n0.25\n\n\n4.85\n\n\n4.84\n\n\n47\n\n\n0\n\n\n\n\n\"CHEMBL1092638\"\n\n\n\"Small molecule...\n\n\n0\n\n\n1\n\n\n0.45\n\n\n5.0\n\n\n4.78\n\n\n34\n\n\n0\n\n\n\n\n\"CHEMBL3884327\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.23\n\n\n2.0\n\n\n1.31\n\n\n33\n\n\n0\n\n\n\n\n\"CHEMBL3952298\"\n\n\n\"Small molecule...\n\n\n0\n\n\n2\n\n\n0.27\n\n\n4.75\n\n\n4.75\n\n\n37\n\n\n0\n\n\n\n\n\"CHEMBL3958658\"\n\n\n\"Small molecule...\n\n\n0\n\n\n1\n\n\n0.37\n\n\n4.32\n\n\n4.32\n\n\n36\n\n\n0\n\n\n\n\n\"CHEMBL2181572\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.32\n\n\n3.3\n\n\n3.3\n\n\n23\n\n\n0\n\n\n\n\n\"CHEMBL603992\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.27\n\n\n3.51\n\n\n3.51\n\n\n35\n\n\n0\n\n\n\n\n\n\n\nThen I combined df_s_0_f (dataframe with max phase 0 compounds) and df_4_f (dataframe with max phase 4 compounds).\n\ndf_concat = pl.concat([df_s_0_f, df_4_f], how = \"vertical\",)\nprint(df_concat)\n\nshape: (1894, 9)\n┌───────────┬───────────┬───────────┬────────────┬─────┬─────────┬─────────┬───────────┬───────────┐\n│ ChEMBL ID ┆ Type      ┆ Max Phase ┆ #RO5       ┆ ... ┆ CX LogP ┆ CX LogD ┆ Heavy     ┆ Max_Phase │\n│ ---       ┆ ---       ┆ ---       ┆ Violations ┆     ┆ ---     ┆ ---     ┆ Atoms     ┆ ---       │\n│ str       ┆ str       ┆ i64       ┆ ---        ┆     ┆ f64     ┆ f64     ┆ ---       ┆ i64       │\n│           ┆           ┆           ┆ i64        ┆     ┆         ┆         ┆ i64       ┆           │\n╞═══════════╪═══════════╪═══════════╪════════════╪═════╪═════════╪═════════╪═══════════╪═══════════╡\n│ CHEMBL344 ┆ Small     ┆ 0         ┆ 0          ┆ ... ┆ 2.05    ┆ 0.62    ┆ 21        ┆ 0         │\n│ 8290      ┆ molecule  ┆           ┆            ┆     ┆         ┆         ┆           ┆           │\n├╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤\n│ CHEMBL396 ┆ Small     ┆ 0         ┆ 2          ┆ ... ┆ 1.51    ┆ -0.41   ┆ 48        ┆ 0         │\n│ 6308      ┆ molecule  ┆           ┆            ┆     ┆         ┆         ┆           ┆           │\n├╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤\n│ CHEMBL396 ┆ Small     ┆ 0         ┆ 2          ┆ ... ┆ 5.05    ┆ 3.27    ┆ 46        ┆ 0         │\n│ 3545      ┆ molecule  ┆           ┆            ┆     ┆         ┆         ┆           ┆           │\n├╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤\n│ CHEMBL164 ┆ Small     ┆ 0         ┆ 0          ┆ ... ┆ 3.21    ┆ 3.21    ┆ 24        ┆ 0         │\n│ 9629      ┆ molecule  ┆           ┆            ┆     ┆         ┆         ┆           ┆           │\n├╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤\n│ ...       ┆ ...       ┆ ...       ┆ ...        ┆ ... ┆ ...     ┆ ...     ┆ ...       ┆ ...       │\n├╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤\n│ CHEMBL303 ┆ Small     ┆ 4         ┆ 0          ┆ ... ┆ 3.3     ┆ 2.61    ┆ 27        ┆ 1         │\n│ 9520      ┆ molecule  ┆           ┆            ┆     ┆         ┆         ┆           ┆           │\n├╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤\n│ CHEMBL119 ┆ Small     ┆ 4         ┆ 0          ┆ ... ┆ 3.6     ┆ 1.93    ┆ 32        ┆ 1         │\n│ 8857      ┆ molecule  ┆           ┆            ┆     ┆         ┆         ┆           ┆           │\n├╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤\n│ CHEMBL214 ┆ Small     ┆ 4         ┆ 0          ┆ ... ┆ 2.43    ┆ 2.43    ┆ 24        ┆ 1         │\n│ 6133      ┆ molecule  ┆           ┆            ┆     ┆         ┆         ┆           ┆           │\n├╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤\n│ CHEMBL161 ┆ Small     ┆ 4         ┆ 0          ┆ ... ┆ 2.09    ┆ 1.86    ┆ 34        ┆ 1         │\n│ 9785      ┆ molecule  ┆           ┆            ┆     ┆         ┆         ┆           ┆           │\n└───────────┴───────────┴───────────┴────────────┴─────┴─────────┴─────────┴───────────┴───────────┘\n\n\nThis df_concat dataset was checked to see it had all compounds in Max Phase 0 and 4 only. Note: Max Phase 4 (approved) compounds were re-labelled as Max_Phase = 1.\n\ndf_concat.groupby(\"Max_Phase\").count()\n\n\n\n\nshape: (2, 2)\n\n\n\n\nMax_Phase\n\n\ncount\n\n\n\n\ni64\n\n\nu32\n\n\n\n\n\n\n0\n\n\n950\n\n\n\n\n1\n\n\n944\n\n\n\n\n\n\n\nI then checked df_concat dataset only had small molecules to confirm what I’ve tried to achieve.\n\ndf_concat.groupby(\"Type\").count()\n\n\n\n\nshape: (1, 2)\n\n\n\n\nType\n\n\ncount\n\n\n\n\nstr\n\n\nu32\n\n\n\n\n\n\n\"Small molecule...\n\n\n1894\n\n\n\n\n\n\n\nSo here we had the final version of the dataset, which I’ve renamed to df_ml to avoid confusion from the previous dataframes, before entering the ML phase.\n\n# Leave out ChEMBL ID and Type\ndf_ml = df_concat.select([\"Max_Phase\", \n                          \"#RO5 Violations\", \n                          \"QED Weighted\", \n                          \"CX LogP\", \n                          \"CX LogD\", \n                          \"Heavy Atoms\"]\n                        )\ndf_ml\n\n\n\n\nshape: (1894, 6)\n\n\n\n\nMax_Phase\n\n\n#RO5 Violations\n\n\nQED Weighted\n\n\nCX LogP\n\n\nCX LogD\n\n\nHeavy Atoms\n\n\n\n\ni64\n\n\ni64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\ni64\n\n\n\n\n\n\n0\n\n\n0\n\n\n0.91\n\n\n2.05\n\n\n0.62\n\n\n21\n\n\n\n\n0\n\n\n2\n\n\n0.16\n\n\n1.51\n\n\n-0.41\n\n\n48\n\n\n\n\n0\n\n\n2\n\n\n0.2\n\n\n5.05\n\n\n3.27\n\n\n46\n\n\n\n\n0\n\n\n0\n\n\n0.53\n\n\n3.21\n\n\n3.21\n\n\n24\n\n\n\n\n0\n\n\n1\n\n\n0.14\n\n\n2.8\n\n\n2.8\n\n\n37\n\n\n\n\n0\n\n\n0\n\n\n0.42\n\n\n1.6\n\n\n1.55\n\n\n35\n\n\n\n\n0\n\n\n0\n\n\n0.58\n\n\n4.69\n\n\n4.13\n\n\n34\n\n\n\n\n0\n\n\n0\n\n\n0.88\n\n\n3.09\n\n\n2.22\n\n\n20\n\n\n\n\n0\n\n\n0\n\n\n0.5\n\n\n1.36\n\n\n1.36\n\n\n32\n\n\n\n\n0\n\n\n0\n\n\n0.61\n\n\n-1.09\n\n\n-1.09\n\n\n15\n\n\n\n\n0\n\n\n0\n\n\n0.32\n\n\n2.88\n\n\n2.88\n\n\n30\n\n\n\n\n0\n\n\n0\n\n\n0.4\n\n\n-1.57\n\n\n-1.6\n\n\n20\n\n\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n\n\n1\n\n\n0\n\n\n0.93\n\n\n1.24\n\n\n1.19\n\n\n23\n\n\n\n\n1\n\n\n0\n\n\n0.46\n\n\n4.59\n\n\n4.59\n\n\n33\n\n\n\n\n1\n\n\n1\n\n\n0.32\n\n\n3.4\n\n\n1.0\n\n\n19\n\n\n\n\n1\n\n\n0\n\n\n0.69\n\n\n3.21\n\n\n1.71\n\n\n29\n\n\n\n\n1\n\n\n0\n\n\n0.58\n\n\n1.19\n\n\n-0.18\n\n\n28\n\n\n\n\n1\n\n\n2\n\n\n0.26\n\n\n4.9\n\n\n4.9\n\n\n53\n\n\n\n\n1\n\n\n1\n\n\n0.58\n\n\n2.65\n\n\n2.65\n\n\n32\n\n\n\n\n1\n\n\n2\n\n\n0.1\n\n\n5.57\n\n\n5.57\n\n\n65\n\n\n\n\n1\n\n\n0\n\n\n0.83\n\n\n3.3\n\n\n2.61\n\n\n27\n\n\n\n\n1\n\n\n0\n\n\n0.26\n\n\n3.6\n\n\n1.93\n\n\n32\n\n\n\n\n1\n\n\n0\n\n\n0.77\n\n\n2.43\n\n\n2.43\n\n\n24\n\n\n\n\n1\n\n\n0\n\n\n0.49\n\n\n2.09\n\n\n1.86\n\n\n34\n\n\n\n\n\n\n\n\n# Check for any nulls in the dataset\ndf_ml.null_count()\n\n\n\n\nshape: (1, 6)\n\n\n\n\nMax_Phase\n\n\n#RO5 Violations\n\n\nQED Weighted\n\n\nCX LogP\n\n\nCX LogD\n\n\nHeavy Atoms\n\n\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\n\n\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n\n\n\n\n\n\n# Check data types in df_ml dataset\n# Needed to be integers or floats for scikit-learn algorithms to work\ndf_ml.dtypes\n\n[polars.datatypes.Int64,\n polars.datatypes.Int64,\n polars.datatypes.Float64,\n polars.datatypes.Float64,\n polars.datatypes.Float64,\n polars.datatypes.Int64]\n\n\n```{python}\n# Note: exported df_ml dataframe as csv file for ML series 2.\ndf_ml.write_csv(\"df_ml.csv\", sep = \",\")\n```\n\n\n\n\nImport libraries for machine learning\n\n# Install scikit-learn - an open-source ML library\n# Uncomment the line below if needing to install this library\n#!pip install -U scikit-learn\n\n\n# Import scikit-learn\nimport sklearn\n\n# Check version of scikit-learn \nprint(sklearn.__version__)\n\n1.2.0\n\n\nOther libraries needed to generate ML model were imported as below.\n\n# To use NumPy arrays to prepare X & y variables\nimport numpy as np\n\n# Needed for dataframe in scikit-learn ML\n# Uncomment line below if requiring to install pandas\n#!pip install pandas\nimport pandas as pd\n\n# To normalise dataset prior to running ML\nfrom sklearn import preprocessing\n# To split dataset into training & testing sets\nfrom sklearn.model_selection import train_test_split\n\n# For data visualisations\n# Uncomment line below if requiring to install matplotlib\n#!pip install matplotlib\nimport matplotlib.pyplot as plt\n\nI’ve then installed pyarrow, to convert Polars dataframe into a Pandas dataframe, which was needed to run scikit-learn.\n\n# Uncomment line below to install pyarrow\n#!pip install pyarrow\n\n\n# Convert Polars df to Pandas df \ndf_ml_pd = df_ml.to_pandas()\ntype(df_ml_pd)\n\npandas.core.frame.DataFrame\n\n\n\n\n\nLogistic regression with scikit-learn\nLR was one of the supervised methods in statistical ML realm. As the term “supervised” suggested, this type of ML was purely data-driven to allow computers to learn patterns from input data with known outcomes, in order to predict new outcomes on novel data.\n\n\nDefining X and y variables\n\n# Define X variables from df_ml_pd dataset\nX = np.asarray(df_ml_pd[[\"#RO5 Violations\", \n                         \"QED Weighted\", \n                         \"CX LogP\", \n                         \"CX LogD\", \n                         \"Heavy Atoms\"]]\n              )\nX[0:5]\n\narray([[ 0.  ,  0.91,  2.05,  0.62, 21.  ],\n       [ 2.  ,  0.16,  1.51, -0.41, 48.  ],\n       [ 2.  ,  0.2 ,  5.05,  3.27, 46.  ],\n       [ 0.  ,  0.53,  3.21,  3.21, 24.  ],\n       [ 1.  ,  0.14,  2.8 ,  2.8 , 37.  ]])\n\n\n\n# Define y variable\n# Note to use \"Max_Phase\", not the original \"Max Phase\"\ny = np.asarray(df_ml_pd[\"Max_Phase\"])\ny[0:5]\n\narray([0, 0, 0, 0, 0])\n\n\n\n\n\nTraining and testing sets\n\n# Split dataset into training & testing sets\n\n# Random number generator\n#rng = np.random.RandomState(0) - note: this may produce different result each time\n\n# Edited post to use random_state = 250 to show comparison with ML series 2\n# for reproducible result\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 250)\nprint('Training set:', X_train.shape, y_train.shape)\nprint('Testing set:', X_test.shape, y_test.shape)\n\nTraining set: (1515, 5) (1515,)\nTesting set: (379, 5) (379,)\n\n\n\n\n\nPreprocessing data\n\n# Normalise & clean the dataset\n# Fit on the training set - not on testing set as this might lead to data leakage\n# Transform on the testing set\nX = preprocessing.StandardScaler().fit(X_train).transform(X_test)\nX[0:5]\n\narray([[-0.61846489, -0.79518088,  0.57523481,  0.76170581,  0.47638078],\n       [-0.61846489, -1.24006401,  1.27389185,  1.25867492,  0.37925834],\n       [-0.61846489,  0.4949802 , -0.18352175,  0.12634023, -1.27182321],\n       [-0.61846489, -0.79518088,  0.03433905,  0.28360894, -0.68908855],\n       [-0.61846489, -0.48376269,  0.61655324,  0.79630492, -0.20347633]])\n\n\n\n\n\nFitting LR classifier on training set\n\n# Import logistic regression \nfrom sklearn.linear_model import LogisticRegression\n# Create an instance of logistic regression classifier and fit the data\nLogR = LogisticRegression().fit(X_train, y_train)\nLogR\n\nLogisticRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LogisticRegressionLogisticRegression()\n\n\n\n\n\nApplying LR classifier on testing set for prediction\n\ny_mp = LogR.predict(X_test)\ny_mp\n\narray([0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n       1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1,\n       1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n       0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n       1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n       1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n       0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n       0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n       0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n       0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n       0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n       1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n       0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n       1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n       1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n       0, 0, 1, 0, 0])\n\n\n\n\n\nConverting predicted values into a dataframe\n\n# Predicted values were based on log odds\n# Use describe() method to get characteristics of the distribution\npred = pd.DataFrame(LogR.predict_log_proba(X))\npred.describe()\n\n\n\n\n\n  \n    \n      \n      0\n      1\n    \n  \n  \n    \n      count\n      379.000000\n      379.000000\n    \n    \n      mean\n      -0.816092\n      -0.719514\n    \n    \n      std\n      0.419447\n      0.386759\n    \n    \n      min\n      -1.845917\n      -1.981267\n    \n    \n      25%\n      -1.085309\n      -0.966916\n    \n    \n      50%\n      -0.732457\n      -0.655325\n    \n    \n      75%\n      -0.478445\n      -0.412184\n    \n    \n      max\n      -0.148378\n      -0.171833\n    \n  \n\n\n\n\nAlternatively, a quicker way to get predicted probabilities was via predict_proba() method in scikit-learn.\n\ny_mp_proba = LogR.predict_proba(X_test)\n# Uncomment below to see the predicted probabilities printed\n#print(y_mp_proba)\n\n\n\n\nConverting predicted probabilities into a dataframe\n\n# Use describe() to show distributions\ny_mp_prob = pd.DataFrame(y_mp_proba)\ny_mp_prob.describe()\n\n\n\n\n\n  \n    \n      \n      0\n      1\n    \n  \n  \n    \n      count\n      379.000000\n      379.000000\n    \n    \n      mean\n      0.483444\n      0.516556\n    \n    \n      std\n      0.178763\n      0.178763\n    \n    \n      min\n      0.006530\n      0.141583\n    \n    \n      25%\n      0.354201\n      0.385328\n    \n    \n      50%\n      0.502085\n      0.497915\n    \n    \n      75%\n      0.614672\n      0.645799\n    \n    \n      max\n      0.858417\n      0.993470\n    \n  \n\n\n\n\n\n\n\nPipeline method for LR\nThis was something I thought to try when I was reading through scikit-learn documentation. One major advantage of using pipeline was that it was designed to chain all the estimators used for ML. The benefit of this was that we only had to call fit and predict once in our data to fit the whole chain of estimators. The other useful thing was that this could avoid data leakage from our testing set into the training set by making sure the same set of samples were used to train the transformers and predictors. One other key thing it also helped was that it also avoided the possibility of missing out on the transformation step.\nThe example below used the function of make_pipeline, which took in a number of estimators as inputted, and then constructed a pipeline based on them.\n\n# Test pipline from scikit-Learn\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nLR = make_pipeline(StandardScaler(), LogisticRegression())\nLR.fit(X_train, y_train)\n\nPipeline(steps=[('standardscaler', StandardScaler()),\n                ('logisticregression', LogisticRegression())])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('standardscaler', StandardScaler()),\n                ('logisticregression', LogisticRegression())])StandardScalerStandardScaler()LogisticRegressionLogisticRegression()\n\n\n\n\n\n\nEvaluation of the logistic regression model\n\nAccuracy scores\n\nfrom sklearn.metrics import accuracy_score\naccuracy_score(y_mp, y_test)\n\n0.6992084432717678\n\n\nThe accuracy score was 0.7 (after rounding up) based on the original data preprocessing method, which meant that there were around 70% of the cases (or compounds) classified correctly by using this LR classifier. Accuracy literally provided a measure of how close the predicted samples were to the true values. One caveat to note was that for imbalanced dataset, accuracy score might not be very informative, and other evaluation metrics would need to be considered instead.\nThe accuracy score shown below was from the pipeline method used previously, which showed a very similar accuracy score of 0.69656992 (close to 0.7), confirming the method was in line with the original preprocessing method.\n\nLR.score(X_test, y_test)\n\n0.6965699208443272\n\n\n\n\n\nConfusion matrix\nNext, I’ve built a confusion matrix based on the model in order to visualise the counts of correct and incorrect predictions. The function code used below was adapted from the IBM data science course I’ve taken around the end of last year. I’ve added comments to try and explain what each section of the codes meant.\n\n# Import confusion matrix from scikit-learn\nfrom sklearn.metrics import confusion_matrix\n# Import itertools - functions to create iterators for efficient looping\nimport itertools\n\n# Function to print and plot confusion matrix\ndef plot_confusion_matrix(# Sets a cm object (cm = confusion matrix)\n                          cm, \n                          # Sets classes of '1s' (Successes) & '0s' (Non-successes) for the cm\n                          classes,\n                          # If setting normalize = true, reports in ratios instead of counts\n                          normalize,\n                          title = 'Confusion matrix',\n                          # Choose colour of the cm (using colourmap recognised by matplotlib)\n                          cmap = plt.cm.Reds):\n    \n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis = 1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    # Plot the confusion matrix \n    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation = 45)\n    plt.yticks(tick_marks, classes)\n\n    # Floats to be round up to two decimal places if using normalize = True\n    # or else use integers\n    fmt = '.2f' if normalize else 'd'\n    # Sets threshold of 0.5\n    thresh = cm.max() / 2.\n    # Iterate through the results and differentiate between two text colours \n    # by using the threshold as a cut-off\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment = \"center\",\n                 color = \"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n\n# Compute confusion matrix\nmatrix = confusion_matrix(y_test, y_mp, labels = [0,1])\nnp.set_printoptions(precision = 2)\n\n# Plot confusion matrix without normalisation\nplt.figure()\nplot_confusion_matrix(matrix, \n                      # Define classes of outcomes\n                      classes = ['Max_Phase = 0','Max_Phase = 1'], \n                      # Set normalize = True if wanting ratios instead\n                      normalize = False, \n                      title = \"Confusion matrix without normalisation\"\n                     )\n\nConfusion matrix, without normalization\n[[139  63]\n [ 51 126]]\n\n\n\n\n\nA common rule of thumb for confusion matrix was that all predicted outcomes were columns and all the true outcomes were rows. However, there might be exceptions where this was the other way round. Four different categories could be seen in the confusion matrix which were:\n\nTrue positive - Predicted Max_Phase = 1 & True Max_Phase = 1 (126 out of 189 samples)\nTrue negative - Predicted Max_Phase = 0 & True Max_Phase = 0 (139 out of 190 samples)\nFalse positive - Predicted Max_Phase = 1 & True Max_Phase = 0 (63 out of 189 samples)\nFalse negative - Predicted Max_Phase = 0 & True Max_Phase = 1 (51 out of 190 samples)\n\nBy having these four categories known would then lead us to the next section about classification report, which showed all the precision, recall, f1-score and support metrics to evaluate the performance of this classifier.\n\n\n\nClassification report\n\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, y_mp))\n\n              precision    recall  f1-score   support\n\n           0       0.73      0.69      0.71       202\n           1       0.67      0.71      0.69       177\n\n    accuracy                           0.70       379\n   macro avg       0.70      0.70      0.70       379\nweighted avg       0.70      0.70      0.70       379\n\n\n\nPrecision was a measure of the accuracy of a predicted outcome, where a class label had been predicted by the classifier. So in this case, we could see that for class label 1, the precision was 0.67, which corresponded to the true positive result of 126 out of 189 samples (= 0.666). It was defined by:\n\\[\n\\text{Precision} = \\frac{\\Sigma\\ True\\ Positive}{(\\Sigma\\ True\\ Positive + \\Sigma\\ False\\ Positive)}\n\\]\nRecall, also known as sensitivity (especially widely used in biostatistics and medical diagnostic fields), was a measure of the strength of the classifier to predict a positive outcome. In simple words, it measured the true positive rate. In this example, there was a total of 126 out of 177 samples (which = 0.712, for True Max_Phase = 1 row) that had a true positive outcome of having a max phase of 1. It was defined by:\n\\[\n\\text{Recall} = \\frac{\\Sigma\\ True\\ Positive}{(\\Sigma\\ True\\ Positive + \\Sigma\\ False\\ Negative)}\n\\]\nThe precision and recall metrics could also be calculated for class label = 0, which were shown for the row 0 in the classification report.\nf1-score, or also known as balanced F-score or F-measure, denoted the harmonic average of both precision and recall metrics. This metric would also give another indication about whether this model performed well on outcome predictions. It normally ranged from 0 (worst precision and recall) to 1 (perfect precision and recall). For this particular classifier, f1-score was at 0.69 (for class label = 1), which was definitely not at its worst, but also could be further improved. It was defined as:\n\\[\n\\text{F1-score} = \\frac{2 \\times (Precision \\times Recall)}{(Precision + Recall)}\n\\]\nSupport, which some readers might have already worked out how the numbers were derived, was the total number of true samples in each class label (reading row-wise from the confusion matrix). The main purpose of showing this metric was to help clarifying whether the model or classifier had a reasonably balanced dataset for each class or otherwise.\n\n\n\nLog loss\nLog loss could be used as another gauge to show how good the classifier was at making the outcome predictions. The further the predicted probability was from the true value, the larger the log loss, which was also ranged from 0 to 1. Ideally, the smaller the log loss the better the model would be. Here, we had a log loss of 0.607 for this particular model.\n\n# Log loss\nfrom sklearn.metrics import log_loss\nlog_loss(y_test, y_mp_proba)\n\n0.606602645025058\n\n\n\n\n\nDiscussions and conclusion\nSo here I’ve completed a very basic LR classifier model for ChEMBL compound dataset. By no means was this a perfect ML model as I haven’t actually changed the default settings of scikit-learn’s LogisticRegression() classifier, with examples such as adjusting C, a regularization parameter which was set at ‘1.0’ by default, and also solvers, which could take in different algorithms for use in optimisation problems and normally set as ‘lbfgs’ by default.\nSo with this default LR model, the evaluation metrics demonstrated a LR classifer of moderate quality to predict the approval outcomes on ChEMBL small molecules, with a lot of rooms for improvements. Therefore, I could not yet confirm fully that the physicochemical parameters chosen would be the best ones to predict the approval outcomes for any small molecules. However, I might be okay to say that these molecular parameters were on the right track to help with making this prediction.\nTo further improve this model, I could possibly trial changing the C value and use different solvers to see if better outcomes could be achieved, or even add more molecular parameters in the model to test. I could have also trialled adding more class labels, e.g. making it between max phase 1, 2 and 4, or a mix-and-match between each max phase category. Other things to consider would be to use other types of ML methods such as naive Bayes, K-nearest neighbours or decision trees and so on. To tackle the problem thoroughly, I would most likely need to do an ensemble of different ML models to find out which model would be the most optimal to answer our target question.\n\n\n\nFinal words\nI’ve experienced the fun of ML after completing this project. The idea was to build on what I knew gradually and enjoy what ML could do when making critical decisions. From what I’ve learnt about ML so far (and definitely more to learn) was that the quality of data was vital for making meaningful interpretations of the results.\nHowever, jumping back to present time, I’ll need to work on my second project first, which is about using Rust interactively via Jupyter notebook. At the moment, I’m not sure how long it will take or how the content will play out. I’ll certainly do as much as I can since Rust is very new to me. If I get very stuck, I’d most likely continue on this ML series. Thanks for reading.\n\n\n\nReferences\nI’ve listed below most of the references used throughout this project. Again, huge thanks could not be forgotten for our online communities, and definitely also towards the references I’ve used here.\n\nscikit-learn documentation\nScikit-learn: Machine Learning in Python, Pedregosa et al., JMLR 12, pp. 2825-2830, 2011.\nBruce, P., Bruce, A. & Gedeck P. (2020). Practical statistics for data scientists. O’Reilly.\nStack Overflow\nPolars references:\n\nPolars - User Guide - https://pola-rs.github.io/polars-book/user-guide/introduction.html\nPolars documentation - https://pola-rs.github.io/polars/py-polars/html/index.html#\nPolars GitHub repository - https://github.com/pola-rs/polars"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data in life",
    "section": "",
    "text": "🌟Welcome to my portfolio🌟 - to quickly navigate, all of the data projects fall into one of the two main themes:\n\nCheminformatics & data science projects\n\nMachine learning projects\nRDKit\nCheminformatics\nChEMBL database\nPills dataset series\n\n\n\nHealthcare data projects\n\nData analytics projects\nRare diseases\nLong COVID\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nSmall molecules in ChEMBL database\n\n\nCross-validation & hyper-parameter tuning with scikit-learn\n\n\n\n\n\n\nMar 7, 2023\n\n\nJennifer HY Lin\n\n\n14 min\n\n\n\n\n\n\n  \n\n\n\n\nPills dataset - Part 3\n\n\nUsing Rust for data visualisation\n\n\n\n\n\n\nFeb 14, 2023\n\n\nJennifer HY Lin\n\n\n10 min\n\n\n\n\n\n\n  \n\n\n\n\nPills dataset - Part 2\n\n\nText cleaning using Polars & visualising pills with Plotly\n\n\n\n\n\n\nJan 31, 2023\n\n\nJennifer HY Lin\n\n\n13 min\n\n\n\n\n\n\n  \n\n\n\n\nPills dataset - Part 1\n\n\nWeb scraping, Polars & Pandas dataframe libraries\n\n\n\n\n\n\nJan 21, 2023\n\n\nJennifer HY Lin\n\n\n11 min\n\n\n\n\n\n\n  \n\n\n\n\nSmall molecules in ChEMBL database\n\n\nPolars dataframe library and machine learning in scikit-learn\n\n\n\n\n\n\nJan 4, 2023\n\n\nJennifer HY Lin\n\n\n28 min\n\n\n\n\n\n\n  \n\n\n\n\nMolecular similarities in selected COVID-19 antivirals\n\n\nUsing RDKit’s similarity map and fingerprint generator\n\n\n\n\n\n\nNov 19, 2022\n\n\nJennifer HY Lin\n\n\n28 min\n\n\n\n\n\n\n  \n\n\n\n\nPhD project\n\n\nA research saga that went through COVID\n\n\n\n\n\n\nOct 23, 2022\n\n\nJennifer HY Lin\n\n\n6 min\n\n\n\n\n\n\n  \n\n\n\n\nPublications\n\n\n\n\n\n\n\n\n\nOct 23, 2022\n\n\nJennifer HY Lin\n\n\n1 min\n\n\n\n\n\n\n  \n\n\n\n\nLong COVID - an update\n\n\nPDF table scraping, bar graph, interactive map & wordcloud\n\n\n\n\n\n\nSep 19, 2022\n\n\nJennifer HY Lin\n\n\n9 min\n\n\n\n\n\n\n  \n\n\n\n\nTable scraping from PDF\n\n\nUsing tabula-py in Python\n\n\n\n\n\n\nSep 15, 2022\n\n\nJennifer HY Lin\n\n\n3 min\n\n\n\n\n\n\n  \n\n\n\n\nBlog move\n\n\n\n\n\n\n\n\n\nAug 6, 2022\n\n\nJennifer HY Lin\n\n\n1 min\n\n\n\n\n\n\n  \n\n\n\n\nPhenotypes associated with rare diseases\n\n\n\n\n\n\n\n\n\nAug 2, 2022\n\n\nJennifer HY Lin\n\n\n7 min\n\n\n\n\n\n\n  \n\n\n\n\nEmbracing social network\n\n\n\n\n\n\n\n\n\nJul 15, 2022\n\n\nJennifer HY Lin\n\n\n1 min\n\n\n\n\n\n\n  \n\n\n\n\nNatural history of rare diseases - malformation syndrome\n\n\n\n\n\n\n\n\n\nJun 27, 2022\n\n\nJennifer HY Lin\n\n\n1 min\n\n\n\n\n\n\n  \n\n\n\n\nUpdate on portfolio\n\n\n\n\n\n\n\n\n\nJun 13, 2022\n\n\nJennifer HY Lin\n\n\n1 min\n\n\n\n\n\n\n  \n\n\n\n\nLong COVID data in SQL\n\n\n\n\n\n\n\n\n\nJun 5, 2022\n\n\nJennifer HY Lin\n\n\n1 min\n\n\n\n\n\n\n  \n\n\n\n\nPortfolio projects\n\n\n\n\n\n\n\n\n\nMay 31, 2022\n\n\nJennifer HY Lin\n\n\n0 min\n\n\n\n\n\n\n  \n\n\n\n\nLong COVID dashboard\n\n\n\n\n\n\n\n\n\nMay 31, 2022\n\n\nJennifer HY Lin\n\n\n1 min\n\n\n\n\n\n\n  \n\n\n\n\nDrugs in rare diseases\n\n\n\n\n\n\n\n\n\nMay 28, 2022\n\n\nJennifer HY Lin\n\n\n3 min\n\n\n\n\n\n\n  \n\n\n\n\nFocussing on data analytics\n\n\n\n\n\n\n\n\n\nApr 15, 2022\n\n\nJennifer HY Lin\n\n\n0 min\n\n\n\n\n\n\n  \n\n\n\n\nThe beginning of the data science journey\n\n\n\n\n\n\n\n\n\nJan 28, 2022\n\n\nJennifer HY Lin\n\n\n3 min\n\n\n\n\n\n\n  \n\n\n\n\nSERCA project\n\n\n\n\n\n\n\n\n\nJan 24, 2022\n\n\nJennifer HY Lin\n\n\n2 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Jennifer HY Lin",
    "section": "",
    "text": "About me & this blog\nPersonally, I was born in Taiwan but was raised in New Zealand since I was a young kid. So practically I’m more like a Kiwi, although to be more precise, I’m more like half-a-Kiwi and half-a-Taiwanese. There was always an East-meets-West fusion element in me, forever. Professionally, I started my career as a pharmacist in New Zealand, and spent several years working at community and hospital pharmacies, across metropolitan and rural areas.\nThen somehow life took me on a detour where I went down the path of doing postgraduate studies. The research mainly focussed on drug discovery and design with medicinal and computational chemistry involved, with numerous hours spent in chemistry (wet) and computer (dry) labs doing experiments. The research work happened in Australia, where I’ve also continued to work as a hospital pharmacist while working on the research projects. Reflecting back, it felt like my brain cells have gone through a major metamorphasis during those years, before I ended up with a MPhil and PhD.\nI’ve then decided to return to New Zealand and the pandemic hit within a few months after (I couldn’t even make it to my PhD graduation in 2020, because it was cancelled due to COVID), which meant most of my original plans after PhD were forced to change. Subsequently, I discovered my more recent interests in the world of data science and analytics. This then led to this blog, which is really my portfolio, on data analytics work in the healthcare and pharmaceutical fields, as I came from these backgrounds with boundless interests. It’ll also be another channel for me to write random personal blog posts detailing my journey in data analytics."
  }
]