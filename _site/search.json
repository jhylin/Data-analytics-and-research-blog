[
  {
    "objectID": "posts/2. Long COVID dashboard/Tableau_dashboard.html",
    "href": "posts/2. Long COVID dashboard/Tableau_dashboard.html",
    "title": "Long COVID dashboard",
    "section": "",
    "text": "Source of dataset\nThe source of the dataset was from a relatively recent live systemic review paper: Michelen M, Manoharan L, Elkheir N, et al. Characterising long COVID: a living systematic review. BMJ Global Health 2021;6:e005427\n\n\nProject link\nThis project can be accessed at this link from Tableau Public.\n\n\nSummary\nThe data from this paper have shown a very heterogeneous variety of long COVID-related signs and symptoms. Among them, it appeared that female gender had higher risk of suffering from long COVID than the male populations. Other factors that might have contributed to higher risk of suffering from long COVID were people who were above 60-65 years old and also people who have multiple chronic illnesses such as cardiovascular diseases and diabetes. Since this paper only focussed on dataset up until March 2021, more recent variants of COVID would not be covered in the dataset, therefore, more work would be required to look into the long COVID risk inflicted by more recent COVID variants.\n\n\n\n\n\nFootnotes\n\n\nThe published date reflected the last day I worked on the associated files for this project, prior to the blog move. This work is under CC BY-SA 4.0 International License for anyone interested in exploring the topic further.↩︎"
  },
  {
    "objectID": "posts/7. Molecular similarities in COVID-19 antivirals/Mol_sim_covid.html",
    "href": "posts/7. Molecular similarities in COVID-19 antivirals/Mol_sim_covid.html",
    "title": "Molecular similarities in selected COVID-19 antivirals",
    "section": "",
    "text": "The COVID-19 antivirals\nWithout going into too much pharmacodynamic profiles for these antivirals, as that could easily be another blog post, I’ll provide only brief overviews on how these medicines were used mainly in the New Zealand context (may vary for different countries).\n\nnirmatrelvir & ritonavir\nOne of the oral COVID-19 antivirals, marketed as Paxlovid, was indicated for mild to moderate symptoms, or at risk of severe disease. For effectiveness, it needed to be taken within 5 days of symptom onset, otherwise it might not work as expected. As a side note, ritonavir was added like an enhancer agent for nirmatrelvir, due to its known ability to inhibit CYP3A2-mediated metabolism of nirmatrelvir, therefore, by having it also inside the oral tablet, it would ensure that the plasma concentration of nirmatrelvir would be kept at an optimal therapeutic level in vivo, vital for the antiviral effect. One of the well-known downsides for this medicine was that it could cause drug interactions with several other commonly used medications such as dabigatran, or potent CYP3A inducers such as carbamazepine as one of the examples (for full drug interaction profiles, please consult local guidelines). Renal functions was also another important factor to consider when dosing.\n\n\nmolnupiravir\nThis was the other oral COVID-19 antiviral, also indicated for mild to moderate symptoms or at risk of severe disease, and also if the option of nirmatrelvir with ritonavir was unsuitable. It was often selected as an oral alternative to nirmatrelvir with ritonavir to avoid drug interactions. It also needed to be taken within 5 days of symptom onset to reach optimal effect.\n\n\nremdesivir\nThis was administered via intravenous infusion for selected adult or paediatric patients (depends on local guidelines) when they were hospitalised and at risk of developing severe disease. Current consideration for its use would be within 7 days of symptom onset. It was classed as a section 29 medicine, which meant it was unapproved, but could be prescribed on a case-by-case basis by qualified medical practitioners.\n\n\nbaricitinib\nThis was also another unapproved, section 29 medicine, indicated for use in hospitalised patients on a case-by-case basis. It was indicated for moderate to severe disease with renally-adjusted dose via oral or nasogastric route.\n\n\n\n\nSource of dataset\nThe URLs to obtain canonical simplified molecular input line entry systems (SMILES) of all 5 molecules are listed below (there are several different ways to obtain SMILES for molecules, I’ve decided to use PubChem in this case):\n\nPubChem [Internet]. Bethesda (MD): National Library of Medicine (US), National Center for Biotechnology Information; 2004-. PubChem Compound Summary for CID 155903259, Nirmatrelvir; [cited 2022 Nov. 13]. Available from: https://pubchem.ncbi.nlm.nih.gov/compound/Nirmatrelvir\nPubChem [Internet]. Bethesda (MD): National Library of Medicine (US), National Center for Biotechnology Information; 2004-. PubChem Compound Summary for CID 392622, Ritonavir; [cited 2022 Nov. 13]. Available from: https://pubchem.ncbi.nlm.nih.gov/compound/Ritonavir\nPubChem [Internet]. Bethesda (MD): National Library of Medicine (US), National Center for Biotechnology Information; 2004-. PubChem Compound Summary for CID 145996610, EIDD-2801; [cited 2022 Nov. 13]. Available from: https://pubchem.ncbi.nlm.nih.gov/compound/eidd-2801\nPubChem [Internet]. Bethesda (MD): National Library of Medicine (US), National Center for Biotechnology Information; 2004-. PubChem Compound Summary for CID 121304016, Remdesivir; [cited 2022 Nov. 13]. Available from: https://pubchem.ncbi.nlm.nih.gov/compound/Remdesivir\nPubChem [Internet]. Bethesda (MD): National Library of Medicine (US), National Center for Biotechnology Information; 2004-. PubChem Compound Summary for CID 44205240, Baricitinib; [cited 2022 Nov. 13]. Available from: https://pubchem.ncbi.nlm.nih.gov/compound/Baricitinib\n\n\n\n\nInstall modules/libraries\nInstall relevant libraries if needed.\n\n# Uncomment and install the following libraries if required \n#!pip install rdkit-pypi pandas mols2grid matplotlib\n\nImport libraries needed as shown below.\n\n# RDKit chemistry\nfrom rdkit import Chem\n# RDKit drawing\nfrom rdkit.Chem.Draw import IPythonConsole\nfrom rdkit.Chem import Draw\n# RDKit fingerprint generator\nfrom rdkit.Chem import rdFingerprintGenerator\n# RDKit functionality for basic data structures\nfrom rdkit.Chem import DataStructs\n# Settings to improve quality of structures\nfrom rdkit.Chem import rdDepictor\n# SVG = scalable vector graphics, set to false if wanting PNGs instead\nIPythonConsole.ipython_useSVG = True\nrdDepictor.SetPreferCoordGen(True)\n# Add ability to add a molecule to a dataframe\nfrom rdkit.Chem import PandasTools\n# mols2grid library provides convenient way to display molecules in a grid\nimport mols2grid\n# for dataframe manipulations\nimport pandas as pd\n# for plotting graphs\nimport matplotlib.pyplot as plt\n\n\n\n\nGenerate RDKit molecules based on SMILES\nBefore any actual molecular manipulation work could begin, the SMILES of all 5 molecules were downloaded from the source URLs. I’ve downloaded all 5 molecules’ SMILES and saved them as separate .sdf files (selected 2D structure option).\nSo I started off with nirmatrelvir with its canonical SMILES retrieved from PubChem. To display a molecule as a 2D chemical structure graphically, an open-source cheminformatics toolkit library, RDKit, was used.\n\n# Generate a RDKit molecule representing nirmatrelvir\nnmt = Chem.MolFromSmiles(\"CC1(C2C1C(N(C2)C(=O)C(C(C)(C)C)NC(=O)C(F)(F)F)C(=O)NC(CC3CCNC3=O)C#N)C\")\nnmt\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Create a RDKit molecule for ritonavir using canonical SMILES\nrit = Chem.MolFromSmiles(\"CC(C)C1=NC(=CS1)CN(C)C(=O)NC(C(C)C)C(=O)NC(CC2=CC=CC=C2)CC(C(CC3=CC=CC=C3)NC(=O)OCC4=CN=CS4)O\")\nrit\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Create a RDKit molecule for molnupiravir using canonical SMILES\nmol = Chem.MolFromSmiles(\"CC(C)C(=O)OCC1C(C(C(O1)N2C=CC(=NC2=O)NO)O)O\")\nmol\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Create a RDKit molecule for remdesivir by using canonical SMILES\nrem = Chem.MolFromSmiles(\"CCC(CC)COC(=O)C(C)NP(=O)(OCC1C(C(C(O1)(C#N)C2=CC=C3N2N=CN=C3N)O)O)OC4=CC=CC=C4\")\nrem\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Create a RDKit molecule for baricitinib by using canonical SMILES\nbar = Chem.MolFromSmiles(\"CCS(=O)(=O)N1CC(C1)(CC#N)N2C=C(C=N2)C3=C4C=CNC4=NC=N3\")\nbar\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDisplay 2D molecules in grid view\nTo display all 5 molecules in a grid view, I’ve saved all separate .sdf files into one .sdf file (e.g. covid_antivirals.sdf). A quick way to do this was via CLI by using one line of code: cat *.sdf > file_name.sdf (replace “file_name” as the actual file name wanted). One thing to be aware of was to make sure which working directory this was saved to, as it needed to be in the same directory as the .qmd file for it to work.\n\n# Save all 5 COVID-19 antivirals as a list in a cpds object\ncpds = [x for x in Chem.SDMolSupplier(\"covid_antivirals.sdf\")]\ncpds\n\n[<rdkit.Chem.rdchem.Mol at 0x15ee2ac20>,\n <rdkit.Chem.rdchem.Mol at 0x15ee2ae60>,\n <rdkit.Chem.rdchem.Mol at 0x15ee2b280>,\n <rdkit.Chem.rdchem.Mol at 0x15ee2b0a0>,\n <rdkit.Chem.rdchem.Mol at 0x15ee2b3a0>]\n\n\nWell, this flexible grid view with function to select molecules would be much more useful if there were several thousands of molecules downloaded. I was just basically trialling this as a practice, which turned out quite nicely.\n\n# Display all compounds in a flexible grid view with selection function\nmols2grid.display(cpds)\n\n\n\n\n\n\n\n\n\nThen I thought about adding drug names to each molecule, rather than listing their IUPAC3 names, for the sake of easier reading and viewing. One of the ways to do this was to add legend with the drug names in the same order.\n\n# Display compounds in grid view with drug names shown\nDraw.MolsToGridImage(cpds, \n                     molsPerRow = 3, \n                     legends = (\"baricitinib\", \"molnupiravir\", \"nirmatrelvir\", \"remdesivir\", \"ritonavir\"), \n                     subImgSize=(300, 300), \n                     useSVG = True\n                    )\n\n\n\n\n\n\n\nSimilarity maps\nNow this part was interesting to me and I’ve spent at least a day or two to just try and understand the fundamentals behind this functionality in RDKit. One of the biggest help for me to fully understand this was this paper: Riniker, S.; Landrum, G. A. “Similarity Maps - A Visualization Strategy for Molecular Fingerprints and Machine-Learning Methods” J. Cheminf. 5:43 (2013). It explained the full methodology behind generating similarity map between compounds using molecular fingerprints.\n\n# Build similarity maps between molecules\n# Import additional libraries needed\nfrom rdkit.Chem.Draw import SimilarityMaps\nimport io\nfrom PIL import Image\n\nThe following step was important to ensure a good image of the map was produced for the molecules, by creating a function for “show_png” first, which was used later.\n\n# Binary i/o keeps data as bytes in an in-memory buffer\n# A function that creates a bytes object as an image\ndef show_png(data):\n    bio = io.BytesIO(data)\n    img = Image.open(bio)\n    return img\n\nI’ve randomly set nirmatrelvir as the reference compound. The other 4 molecules were set as test or probe molecules to be compared with the reference compound. So here I’ve compared nirmatrelvir with ritonavir first.\n\n# Create a Draw2D object \"a\" and specify size of 2D image\na = Draw.MolDraw2DCairo(500, 500)\n# Produces a similarity map for nirmatrelvir and ritonavir\n# Specify which compounds to compare (reference and probe) for the similarity map\nfig, maxweight = SimilarityMaps.GetSimilarityMapForFingerprint(nmt, rit, \n                                                               # creates a lambda function (anonymous function) for use within SimilarityMaps, \n                                                               # then select fingerprint type e.g. Morgan fingerprint\n                                                               # types of Morgan fingerprint: bit vector (bv, default) & count vector (count)\n                                                               lambda b, c: SimilarityMaps.GetMorganFingerprint(b, c, radius = 2, fpType = 'bv'),\n                                                               draw2d = a)\n\n# Finish drawing Draw2D object \"a\"                                                                                       \na.FinishDrawing()\n# Display similarity map                                                             \nshow_png(a.GetDrawingText())\n\n\n\n\nTo quickly explain how to look at the contour or topographical map in different colours for the molecule:\n\nGreen shades represented a positive difference or where the similarity decreased when the bits4 were removed\nPink shades showed negative difference or where the similarity increased when the bits were removed\nGrey shades meant there was no change\n\nAnother parameter that might allow us to interpret more easily was to obtain the maximum weight (also known as “maxweight” in the code) for the structure comparison between two molecules. Maximum weight could be understood as maximum difference between the reference and probe molecules. By default, maximum weight was capped at 1.0. This function was already built in above code, so to find out the maximum weight or difference for nirmatrelvir and ritonavir, simply just use the print() function.\n\n# Max weight between nirmatrelvir and ritonavir \nprint(maxweight)\n\n0.03389096421417358\n\n\nI’ve then saved this particular maxweight result with a different label name (to clearly show which molecules were being compared), for later use.\n\nmol2_rit_maxw_mol1 = maxweight\nmol2_rit_maxw_mol1\n\n0.03389096421417358\n\n\nTo further explain and understand the parameter of maximum weight, this paper by Riniker and Landrum have included a full calculation styled as pseudocodes in Python. I have attempted to summarise them in words, along with the codes (adapted from the paper), as below:\n```{python}\n# 1. Calculate the fingerprint for reference molecule\nref_fp = calculate_fingerprint (ref_mol)\n\n# 2. Calculate the fingerprint for test molecule\nthis_fp = calculate_fingerprint (this_mol)\n\n# 3. Create an empty weights list\nweights = []\n\n# 4. Calculate original similarity for ref mol & test mol based on Dice similarity\norig_simil = dice_similarity(ref_fp, this_fp)\n\n# 5. Loop over the different atoms present in the test mol\nfor atom in this_mol.get_atoms:\n\n# 5. (cont.) Generate a new fingerprint by calculating new fingerprints without each of the atom for the test mol\n    new_fp = calculate_fingerprint_without_atom(this_mol, atom)\n    \n# 5. (cont.) Calculate new similarity for the ref fingerprint & new fingerprint based on Dice similarity\n    new_simil = dice_similarity(ref_fp, new_fp)\n    \n# 6. The atomic weight will be calculated as the difference between the original similarity and the new similarity\nweight = original_simil - new_simil\n\n# 7. The atomic weight obtained for each loop iteration (for each atom present) will be added up to contribute to the final atomic weight\nweights.append(weight)\n\n# Note: maximum absolute weight is normalised and capped at 1.0\n```\nNext one was between nirmatrelvir and molnupiravir. I’ve renamed “maxweight” to “mol3_mol_maxw_mol1” to reflect this parameter was measured between 3rd molecule (molnupiravir) and 1st molecule (nirmatrelvir).\n\n# 2. Comparing nirmatrelvir and molnupiravir\na = Draw.MolDraw2DCairo(400, 400)\n# Produces a similarity map for molecules selected\n# Specify which compounds to compare (reference and probe) for the similarity map\nfig, mol3_mol_maxw_mol1 = SimilarityMaps.GetSimilarityMapForFingerprint(nmt, mol, \n                                                               # creates a lambda function (anonymous function) for use within SimilarityMaps, \n                                                               # then select fingerprint type e.g. Morgan fingerprint\n                                                               # types of Morgan fingerprint: bit vector (bv, default) & count vector (count)\n                                                               lambda b, c: SimilarityMaps.GetMorganFingerprint(b, c, radius = 2, fpType = 'bv'),\n                                                               draw2d = a)\n\n# Finish drawing Draw2D object \"a\"                                                                                       \na.FinishDrawing()\n# Display similarity map                                                             \nshow_png(a.GetDrawingText())\n\n\n\n\nThe maximum weight between nirmatrelvir and molnupiravir was shown as below.\n\nprint(mol3_mol_maxw_mol1)\n\n0.026617250673854453\n\n\nSimilarity map was then generated for nirmatrelvir and remdesivir.\n\n# 3. Comparing nirmatrelvir and remdesivir\na = Draw.MolDraw2DCairo(400, 400)\n# Produces a similarity map for molecules selected\n# Specify which compounds to compare (reference and probe) for the similarity map\nfig, mol4_rem_maxw_mol1 = SimilarityMaps.GetSimilarityMapForFingerprint(nmt, rem, \n                                                               # creates a lambda function (anonymous function) for use within SimilarityMaps, \n                                                               # then select fingerprint type e.g. Morgan fingerprint\n                                                               # types of Morgan fingerprint: bit vector (bv, default) & count vector (count)\n                                                               lambda b, c: SimilarityMaps.GetMorganFingerprint(b, c, radius = 2, fpType = 'bv'),\n                                                               draw2d = a)\n\n# Finish drawing Draw2D object \"a\"                                                                                       \na.FinishDrawing()\n# Display similarity map                                                             \nshow_png(a.GetDrawingText())\n\n\n\n\nTheir maximum weight was found as below.\n\nprint(mol4_rem_maxw_mol1)\n\n0.021674876847290636\n\n\nLastly, the comparison was made between nirmatrelvir and baricitinib.\n\n# 4. Comparing nirmatrelvir and baricitinib\na = Draw.MolDraw2DCairo(400, 400)\n# Produces a similarity map for molecules selected\n# Specify which compounds to compare (reference and probe) for the similarity map\nfig, mol5_bar_maxw_mol1 = SimilarityMaps.GetSimilarityMapForFingerprint(nmt, bar, \n                                                               # creates a lambda function (anonymous function) for use within SimilarityMaps, \n                                                               # then select fingerprint type e.g. Morgan fingerprint\n                                                               # types of Morgan fingerprint: bit vector (bv, default) & count vector (count)\n                                                               lambda b, c: SimilarityMaps.GetMorganFingerprint(b, c, radius = 2, fpType = 'bv'),\n                                                               draw2d = a)\n\n# Finish drawing Draw2D object \"a\"                                                                                       \na.FinishDrawing()\n# Display similarity map                                                             \nshow_png(a.GetDrawingText())\n\n\n\n\nThe maximum weight was found as below.\n\nprint(mol5_bar_maxw_mol1)\n\n0.026242075777679508\n\n\nShort summary:\n\nNirmatrelvir vs. remdesivir had the smallest maximum weight or difference out of all 5 compounds\nNirmatrelvir vs. ritonavir had the biggest maximum weight or difference out of all compounds, the second biggest one would be between nirmatrelvir and molnupiravir\n\n\n\n\nFingerprint generator\nAfter using the similarity maps, I found more things to trial in RDKit, and this one was a fingerprint generator. I’ve decided to use the same 5 molecules as before, and see if I could get similar results.\n\n# Re-label molecules for later use\nmol1 = nmt\nmol2 = rit\nmol3 = mol\nmol4 = rem\nmol5 = bar\n\n# Combine all 5 molecules into a list\nmols = [mol1, mol2, mol3, mol4, mol5]\n\nBelow was the set of codes used to generate a fingerprint between compounds. I’ve changed the radius to 2 to align with the similarity map test above.\n\n# Create an object fp to generate fingerprint\n# Default radius of molecule = 3 \nfp = rdFingerprintGenerator.GetMorganGenerator(radius = 2)\n# Get fingerprints of all molecules in the list\nfp1 = [fp.GetFingerprint(x) for x in mols]\nfp1\n\n[<rdkit.DataStructs.cDataStructs.ExplicitBitVect at 0x15f0811e0>,\n <rdkit.DataStructs.cDataStructs.ExplicitBitVect at 0x15f081360>,\n <rdkit.DataStructs.cDataStructs.ExplicitBitVect at 0x15f0817e0>,\n <rdkit.DataStructs.cDataStructs.ExplicitBitVect at 0x15f081960>,\n <rdkit.DataStructs.cDataStructs.ExplicitBitVect at 0x15f0819c0>]\n\n\nA loop was created to iterate through all 5 antivirals to compare their molecular similarities by using Tanimoto coefficient (TC)5. Particularly, each molecule was compared to the other 4 molecules, with results printed as shown below.\n\nfor i in range(len(fp1)):\n    for a in range(i):\n        tc = DataStructs.TanimotoSimilarity(fp1[i], fp1[a])\n        print(f'mol{i+1}-mol{a+1}: Tanimoto coefficient {tc}')\n\nmol2-mol1: Tanimoto coefficient 0.08461538461538462\nmol3-mol1: Tanimoto coefficient 0.10891089108910891\nmol3-mol2: Tanimoto coefficient 0.14953271028037382\nmol4-mol1: Tanimoto coefficient 0.10687022900763359\nmol4-mol2: Tanimoto coefficient 0.1386861313868613\nmol4-mol3: Tanimoto coefficient 0.19811320754716982\nmol5-mol1: Tanimoto coefficient 0.11214953271028037\nmol5-mol2: Tanimoto coefficient 0.09243697478991597\nmol5-mol3: Tanimoto coefficient 0.10989010989010989\nmol5-mol4: Tanimoto coefficient 0.15517241379310345\n\n\nI then saved each TC separately between nirmatrelvir and other 4 molecules. This was to create another list of these TCs for data visualisation later.\n\n# Tanimoto coefficient between nirmatrelvir (mol1) & ritonavir (mol2)\ntc_mol1_mol2 = DataStructs.TanimotoSimilarity(fp1[0], fp1[1])\n\n# Tanimoto coefficient between nirmatrelvir (mol1) & molnupiravir (mol3)\ntc_mol1_mol3 = DataStructs.TanimotoSimilarity(fp1[0], fp1[2])\n\n# Tanimoto coefficient between nirmatrelvir (mol1) & remdesivir (mol4)\ntc_mol1_mol4 = DataStructs.TanimotoSimilarity(fp1[0], fp1[3])\n\n# Tanimoto coefficient between nirmatrelvir (mol1) & baricitinib (mol5)\ntc_mol1_mol5 = DataStructs.TanimotoSimilarity(fp1[0], fp1[4])\n\nA new list was created to save all TCs for nirmatrelvir versus other 4 molecules.\n\ntc_mols = [tc_mol1_mol2, tc_mol1_mol3, tc_mol1_mol4, tc_mol1_mol5]\ntc_mols\n\n[0.08461538461538462,\n 0.10891089108910891,\n 0.10687022900763359,\n 0.11214953271028037]\n\n\nI thought to include following codes to ensure I wasn’t losing track on which molecule was which by having them displayed as 2D structures with labels.\n\n# Display compounds to help with recognising which antivirals are being compared\nDraw.MolsToGridImage(mols, \n                     molsPerRow = 3, \n                     legends = (\"mol1 = nirmatrelvir\", \"mol2 = ritonavir\", \"mol3 = molnupiravir\", \"mol4 = remdesivir\", \"mol5 = baricitinib\"), \n                     subImgSize=(300, 300), \n                     useSVG = True\n                    )\n\n\n\n\nAnother list was generated to save all maximum weights between nirmatrelvir and the rest of the molecules.\n\nmaxw_diff = [mol2_rit_maxw_mol1, mol3_mol_maxw_mol1, mol4_rem_maxw_mol1, mol5_bar_maxw_mol1]\nmaxw_diff\n\n[0.03389096421417358,\n 0.026617250673854453,\n 0.021674876847290636,\n 0.026242075777679508]\n\n\nA new dataframe was also created to include maximum weights and TCs of all 5 molecules.\n\ndf_ms = pd.DataFrame(list(zip(maxw_diff, tc_mols)),\n                     index = ['nmt_v_rit', 'nmt_v_mol', 'nmt_v_rem', 'nmt_v_bar'],\n                     columns = ['Maxweight', 'T_coeff']\n                    )\ndf_ms\n\n\n\n\n\n  \n    \n      \n      Maxweight\n      T_coeff\n    \n  \n  \n    \n      nmt_v_rit\n      0.033891\n      0.084615\n    \n    \n      nmt_v_mol\n      0.026617\n      0.108911\n    \n    \n      nmt_v_rem\n      0.021675\n      0.106870\n    \n    \n      nmt_v_bar\n      0.026242\n      0.112150\n    \n  \n\n\n\n\nTo produce a bar graph representing these parameters, I realised I would probably need to change the index into a column instead.\n\ndf_ms.reset_index(inplace = True)\ndf_ms_new = df_ms.rename(columns = {'index': 'Molecules'})\ndf_ms_new\n\n\n\n\n\n  \n    \n      \n      Molecules\n      Maxweight\n      T_coeff\n    \n  \n  \n    \n      0\n      nmt_v_rit\n      0.033891\n      0.084615\n    \n    \n      1\n      nmt_v_mol\n      0.026617\n      0.108911\n    \n    \n      2\n      nmt_v_rem\n      0.021675\n      0.106870\n    \n    \n      3\n      nmt_v_bar\n      0.026242\n      0.112150\n    \n  \n\n\n\n\n\n\n\nData visualisation and some findings\nA side-by-side bar graph showing two different molecular similarity parameters - maximum weights from similarity map and TCs calculated from Morgan fingerprints - was plotted based on the dataframe created above. It showed similar trend between these two molecular similarity tests for these known COVID-19 antivirals. In that, nirmatrelvir versus ritonavir showed the largest molecular difference out of all 5 compounds with the highest maximum weight. This was reflected in the lowest TC as the shortest orange bar, which implied a low similarity between the two molecules. Interestingly, between nirmatrelvir and remdesivir, it appeared the maximum weight was lowest of all 5 molecules, but the TC did not quite reflect that (being lower than that for nirmatrelvir versus molnupiravir and baricitinib).\n\n# Set the overall font size to make all labels on graph easier to read\nplt.rcParams.update({'font.size': 10})\n\n# Used nirmatrelvir as reference compound (mol1) and compared it with 4 other antivirals\n# If wanting stacked bar graph:\n#df_ms_new.plot(x = 'Molecules', \n               #kind = 'bar', \n               #width = 0.3, \n               #stacked = True, \n               #title = 'Molecular similarities between 5 known COVID-19 antivirals'\n               #)\n#plt.show()\n\n# Side-by-side bar graph\ndf_ms_new.plot(x = 'Molecules', \n               y = ['Maxweight', 'T_coeff'], \n               kind = 'bar', \n               figsize = (7, 7)\n               )\n# Add title\nplt.title(label = 'Molecular similarities between 5 known COVID-19 antivirals')\n\n# Add caption for graph re. abbreviations of all the molecules compared \n# Import textwrap module\nimport textwrap\nt = \"nmt = nirmatrelvir, \"\\\n    \"rit = ritonavir, \"\\\n    \"mol = molnupiravir, \"\\\n    \"rem = remdesivir, \"\\\n    \"bar = baricitinib\"\nb = textwrap.fill(t, width = 58)\nx = 'Molecules'\ny = ['Maxweight', 'T_coeff']\nplt.text(len(x) / 2, 0, b, ha = 'left', va = 'bottom')\n\nText(4.5, 0, 'nmt = nirmatrelvir, rit = ritonavir, mol = molnupiravir,\\nrem = remdesivir, bar = baricitinib')\n\n\n\n\n\n\nOne possibility for this difference could be that the maximum weight parameter in the similarity map test was based on Dice similarity (if referring back to the pseudocodes for how to calculate atomic weight), but for the other fingerprint generator test, Tanimoto similarity (also known as Jaccard coefficient) was used instead. These two similarity coefficients were actually calculated differently, with their equivalent equations shown below.\n\nTanimoto similarity/coefficient\nTC was the ratio of the number of chemical features common to two molecules (e.g. molecule a and molecule b) to the total number of chemical features in the two molecules. The following equation summarised this.\n\\[\n\\text{Tanimoto coefficient} = \\frac{(a \\cap b)}{(a + b - (a \\cap b))}\n\\]\n\n\nDice similarity/coefficient\nOn the other hand, Dice coefficient described the number of features in common for molecules a and b, relative to the average size of the total number of chemical features present in the two molecules. The weighting factor of 0.5 was shown in the denominator (or can be 2 in the numerator). The coefficient also ranges from zero to 1. The following showed the equation of Dice similarity.\n\\[\n\\text{Dice coefficient} = \\frac{(a \\cap b)}{0.5\\times(a + b)}\n\\]\n\n\n\n\nAcknowledgement\nThe codes used in this post were heavily inspired by and adapted from the following blogs and website shown below. I’ve learnt a lot from them, and would like to thank the existence of these blogs and website, which are helping readers like me to learn in an open-source manner. I particularly like the clear and concise writing style from P. Walter’s Practical Cheminformatics blog which is easy to follow. Iwatobipen’s is life worth living? blog has shown a very diverse range of cheminformatics tools available for use, and I’m constantly surprised by how many there are from this blog and also the generous sharing of all the codes.\n\nP. Walter’s blog\nIwatobipen’s blog\nRDKit documentation by G. Landrum\n\n\n\n\nFinal words\nI have read quite a few blog posts from P. Walter and Iwatobipen, and have enjoyed them but never quite got around to write one myself, so finally I did it! Although this post itself was not written in a grand scale, and I would warmly welcome comments for improvements or corrections, I hope to project what I did here in the future, e.g. to apply them to a much larger set of compounds. My very draft thought now is to perhaps trial using ChEMBL database, which is a well-known open-source cheminformatics library.\nAs a little prelude to what other work I’m planning to do, I’ve managed to start learning Rust as well. There is a back story about why I’ve started learning Rust, which I’ll leave as a probable new post in the future if I feel it fits the context of the post. From what I’ve tried so far, only at seedling stage, it’s going to be an even steeper learning curve than Python and R, but I feel it’s going to benefit whatever I’m planning to do consciously or unconsciously in the future.\n\n\n\n\n\nFootnotes\n\n\nCommand line interface↩︎\nCytochrome P450 enzymes of 3A subfamily↩︎\nInternational Union of Pure and Applied Chemistry↩︎\nBits in a bit vector or counts in a count vector are converted from structural features in chemical structures to formulate molecular fingerprints, which subsequently allows a more efficient way to compare chemical structures computationally↩︎\nRanged from zero (lowest similarity) to 1.0 (highest similarity), more on this in the next section↩︎"
  },
  {
    "objectID": "posts/Blog-Portfolio projects/Portfolio_projects.html",
    "href": "posts/Blog-Portfolio projects/Portfolio_projects.html",
    "title": "Portfolio projects",
    "section": "",
    "text": "Photo by Joanna Kosinska on Unsplash"
  },
  {
    "objectID": "posts/Publications/Side_projects.html",
    "href": "posts/Publications/Side_projects.html",
    "title": "Publications",
    "section": "",
    "text": "Photo by Clark Young on Unsplash\n\n\n\nHsuan-Yu J. Lin, Rachana Rao Battaje, Jinlong Tan, Munikumar Doddareddy, Hemendra Pal Singh Dhaked, Shalini Srivastava, Bryson A. Hawkins, Laith Mohammad Hilal Al-Shdifat, David E. Hibbs, Dulal Panda, Paul W. Groundwater. Discovery of 20,6-Bis(4-hydroxybenzyl)-2-acetylcyclohexanone, a Novel FtsZ Inhibitor. Molecules. 2022; 27(20), 6993. (IF = 4.927)\nPalanimuthu D, Poon R, Sahni S, Anjum R, Hibbs D, Lin JHY, Bernhardt PV, Kalinowski DS, Richardson DR. A novel class of thiosemicarbazones show multi-functional activity for the treatment of Alzheimer’s disease. Eur J Med Chem. 2017; 139: 612-632. (IF = 4.816)\nPanda D, Bhattacharya D, Gao QH, Oza PM, Lin JHY, Hawkins B, Hibbs DE, Groundwater PW. Identification of agents targeting FtsZ assembly. Future Med Chem. 2016; 8(10):1111-32. (IF = 3.969)\nGao Q, Hanh J, Váradi L, Cairns R, Sjöström H, Liao VW, Wood P, Balaban S, Ong JA, Lin JHY, Lai F, Hoy AJ, Grewal T, Groundwater PW, Hibbs DE. Identification of dual PPARα/γ agonists and their effects on lipid metabolism. Bioorg Med Chem. 2015; 23(24):7676-84. (IF = 2.881)\n\n\n\n\n\nFootnotes\n\n\nNot a large number of publications there, perhaps due to the research topics I’ve chosen, they tend to require months or years to see tangible results… so here is my very humble list as some others may be more productive than me…↩︎"
  },
  {
    "objectID": "posts/PhD projects/PhD_projects.html",
    "href": "posts/PhD projects/PhD_projects.html",
    "title": "PhD project",
    "section": "",
    "text": "PhD thesis link\nPlease visit http://hdl.handle.net/2123/20236 if anyone is even remotely wanting to read the full thesis, for completeness, here it is (beware: very long).\n\n\nAbstract of the projects\nDrug discovery is one of the most challenging research fields that contributes to the birth of novel drugs for therapeutic use. Due to the complexity and intricate nature of the research, lengthy processes are involved in identifying potential hit molecules for a therapeutic target. To shorten the time required to reach the hit-to-lead stage, computer-aided drug design (CADD) has been used to expedite the process and reduce laboratory expenses. Common strategies used within CADD involve structure-based drug design (SBDD) and ligand-based drug design (LBDD). Both strategies were used extensively in two projects showing the complementarity of each strategy throughout the process. In this work, two separate drug discovery projects are detailed: Design, synthesis and molecular docking study of novel tetrahydrocurcumin analogues as potential sarcoplasmic-endoplasmic reticulum calcium ATPases (SERCA) inhibitors – details the identification, synthesis and testing of potential hit candidate(s) targeting SERCA by using SBDD Filamenting temperature-sensitive mutant Z (FtsZ) as therapeutic target in ligand-based drug design – details the identification, synthesis and testing of potential hit molecule(s) targeting FtsZ In the first project, homology modelling and virtual compound library screening were utilised as the SBDD methods to identify potential hit molecules for testing in P-type calcium ATPases such as SERCA. Preliminary results have found compound 20, an analogue of tetrahydrocurcumin, to show some SERCA inhibitory effect at 300µM based on a SERCA-specific calcium signalling assay performed via fluorometric imaging plate reader. Molecular docking study has also reflected this outcome with desirable ligand-protein binding energies found for 20 when compared with other tested ligands. Pharmacophore screening was used as the main LBDD method in the second project to identify probable hit candidates targeting FtsZ. Potential ligands were synthesised, and tested for antibacterial effect in Bacillus Subtilis strain 168 (Bs168) and Streptococcus pneumoniae strain R6 (SpnR6) cells. One of the tetrahydrocurcumin analogues, compound 4, was found to have minimum inhibitory concentration (MIC) ≤ 10 µM in Bs168 cells and ≤ 2 µM in spnR6 cells. The IC50 values for 4 were 9.1 ± 0.01 µM and 1 ± 0.01 µM in Bs168 and SpnR6 cells respectively. The MIC of 4 was found to be very similar to the MIC of compound 1, a known hit compound targeting against Bs168 cells. On the other hand, the MIC of 4 was lower than the MIC (> 64 µg/mL) of a well-known FtsZ inhibitor, PC190723, against S. pneumoniae. Subsequent molecular docking analyses were completed to evaluate the ligand-protein binding energies to correlate against the testing results. Both compounds 20 and 4 possess some structural similarities and differences that may confer their different effects in these protein targets, which render both with potentials to become the next lead molecules for future development.\n\n\nFinal update on FtsZ project\nAs time was ticking along towards the end of 2022, my last attempt to try to get this work published occurred around end of August, where I contacted one of my previous PhD advisers. After that I actually thought there was no way I could carry on in this line of research work, or even think about expanding into cheminformatics for drug discovery and design etc. So in September, I thought about leaving all of this behind and that I need to change direction completely (again), e.g. into health data science or similar. Perhaps it was the universe’s answering or for other unknown reasons, around end of September, an email was sent to me from my previous PhD adviser asking for my help to organise the draft manuscript into the journal template that we were intending to submit. Then in early October, I got another email saying our manuscript was submitted. Then it seemed things started to roll again, after 2019. So this was, indeed, a perfect example showing how a piece of research work was stalled, not only by the commonly known reasons such as delays from collaborating groups, but also by the global-scale pandemic and finally somehow, miraculously, made it to the publication stage.\nIf anyone asked me if I wanted to go through this again, I would firmly say no as it was mentally painful, but on the other hand, I’ve also gained invaluable things like grit and resilience throughout the process. This has, without doubts, influenced on how I want to approach similar research again, which will be in a different way, in a more data-informed way.\n\n\nPublished paper link\nThis will complete the story for the FtsZ project (finally): Discovery of 2′,6-Bis(4-hydroxybenzyl)-2-acetylcyclohexanone, a Novel FtsZ Inhibitor\n\n\n\n\n\nFootnotes\n\n\nI’ve attempted to communicate with both of my PhD advisers and our research collaborators to publish this work, but to no avail due to the severe restrictions imposed by the COVID-19 situation from the beginning of 2020 and basically also in 2021 (our collaborators were unable to perform any experiments during lockdowns…), a direct publication in a scientific journal is not going to happen any time soon so I thought to provide at least my part to showcase what I’ve done at least…↩︎\nUpdates on 31/1/2022 – it appeared that my supervisors are in communications with our overseas research collaborators recently about the manuscript so there is a higher chance now that we may be able to publish this work towards the end of 2022 (fingers-crossed…).↩︎"
  },
  {
    "objectID": "posts/Blog-Data analytics/Focussing_on_data_analytics.html",
    "href": "posts/Blog-Data analytics/Focussing_on_data_analytics.html",
    "title": "Focussing on data analytics",
    "section": "",
    "text": "Photo by Tobias Fischer on Unsplash\n\n\nSo I’m planning to work on other projects at the moment that are not from my certificate course, but are self-motivated ones which would be more relevant to data science and analytics and the ones that I have personal interests in. New projects will be showcased in the portfolio section when they’re ready. The most current one would be the Tableau project about characterising long COVID symptoms (more on this in portfolio section)."
  },
  {
    "objectID": "posts/Blog-Update/Update_on_portfolio.html",
    "href": "posts/Blog-Update/Update_on_portfolio.html",
    "title": "Update on portfolio",
    "section": "",
    "text": "Photo by RetroSupply on Unsplash\n\n\n\nI’ve started working on an extension project to the rare disease work (recent Python project) by delving further into the natural history of rare diseases by using Orphanet’s data source (having fun working with xml files)\nWith the turn of events lately, I’m now also learning R programming language (which is something I was planning to do much later, but… to do this now is also fine as this’ll keep me on the ball) and surprisingly it is quite similar to Python in some ways but not at all as well\nTableau project most likely needs further work apart from what the dashboard is looking like at the moment (might be still a bit bare) but at the moment, my focus is on above two projects in the meantime. I’ll try to squeeze more time to work on this soon\n\nOther than that, I’m grateful that I can still work on things of great interests and the world is somehow still functioning in its best possible ways – onwards and upwards hopefully."
  },
  {
    "objectID": "posts/4. Natural history of rare diseases – malformation syndrome/Natural_history_rare_diseases_mal_syn.html",
    "href": "posts/4. Natural history of rare diseases – malformation syndrome/Natural_history_rare_diseases_mal_syn.html",
    "title": "Natural history of rare diseases - malformation syndrome",
    "section": "",
    "text": "Project link\nThe .ipynb file can be found in my GitHub repository of Portfolio-projects at this URL: https://github.com/jhylin/Portfolio-projects or go to this link, which will take you to the Jupyter notebook for this work to show the differences in life spans for different rare diseases under this particular disorder type.\n\n\nSummary\n\nTurner syndrome and Prune belly syndrome are the only two disorders of the malformation syndrome type that have an average age of onset at antenatal period, with an average age of death in the elderly years\nThis means these two rare disorders have had relatively long life spans out of all the rare diseases present in the dataset\nOppositely, there are far more rare disorders, such as Noonan syndrome, Trisomy 13, Hydraencephaly and more, with early childhood deaths while having the same antenatal onsets as Turner syndrome and Prune belly syndrome\n\n\n\n\n\n\nFootnotes\n\n\nThis project was last committed on 27th June 2022 on GitHub so I’ve set it as the published date, prior to the blog move. This work is under CC BY-SA 4.0 International License for anyone interested in exploring the topic further.↩︎"
  },
  {
    "objectID": "posts/Blog-DS journey/Beginning_of_DS_journey.html",
    "href": "posts/Blog-DS journey/Beginning_of_DS_journey.html",
    "title": "The beginning of the data science journey",
    "section": "",
    "text": "Regarding to the postdoc job searching, this has made me ponder really hard about what sort of research I would really like to work on. As I’ve spent time preparing my CV, writing different cover letters, applying for different postdoc-related roles and also after being invited to five job interviews, I’ve decided that it was not quite enough about what I’ve done so far in Masters and PhD work… I’m still lacking some skills. I’ve also realised that I do not necessarily like the traditional academic postdoc work (discovered while and after I’ve applied for numerous postdoc posts in 2019) and also I’m more inclined to work on computational chemistry and cheminformatics side of research.\nAnother “elephant-in-the-room” issue was that it has been very difficult to publish a first-author paper from my PhD research work, due to the impact from the development of COVID-19 pandemic for the last two years (my overseas-based collaborators have been hit hard particularly and they were still working on part of the experiments until the first quarter of the year 2021) and hence probably this was the most likely the reason that I did not get final offers in some academic postdoc positions, due to the lack of first-author papers.\n\n\n\nPhoto by Sergi Kabrera on Unsplash\n\n\nBecause of all the issues and problems, I’ve still kept my old pharmacist job as my side job while I start on a new journey in learning data science. I’ve tested the water since 2019 and temporarily ceased the learning in 2020 due to the pandemic (I worked full-time in hospital which was also another unforgettable experience of course). From the last quarter of 2021, I’ve made up my mind to go full board with data science (as I can’t see my PhD research work being published any time soon so it’s time to consider a possible change in direction). I thought I’d like to learn about it systematically with some sort of logical structures in the course so that I can understand a basic full picture about it in a reasonably short time (I realise data science itself is a profound field) and if there are some sort of accreditations, this would be even better. This was also the sole reason why I started on Coursera’s IBM data science professional certificate in the last quarter of 2021. After learning more about it, I’ve realised how much it has overlapped with cheminformatics and my interests in both areas grew more and more as time goes.\nI have now completed the data science professional certificate, which consisted of a total of 10 courses with assessments, assignments and portfolios (certificates and/or IBM badges viewable from my LinkedIn profile). I have managed to finish the course within about 5 months (from mid-September 2021 till end of January 2022) while working part-time as a locum pharmacist. Although it’s not a perfect course, I think it reflects very nicely what the reality will be like when working as a data scientist or cheminformatician – imperfections in data sources, data analyses and presentations that need to be corrected or problems that need to be solved by looking for answers and working on possible solutions. I think it’s a useful course for newcomers who want to learn more about data science and also for the professionals who would like to refresh or reaffirm knowledge and skills (this is by no means a promotion about Coursera’s data science course but just a personal learning experience only, other course providers may equally provide similar experiences and I would encourage anyone who’s interested to look around and see what other courses are available)."
  },
  {
    "objectID": "posts/1. Drugs in rare diseases/Rare_diseases_drugs.html",
    "href": "posts/1. Drugs in rare diseases/Rare_diseases_drugs.html",
    "title": "Drugs in rare diseases",
    "section": "",
    "text": "Python project\nFor Python project2, there was one question in mind to answer:\nHow long did it take on average for a rare disease drug to reach marketing approval?\nPython version of the data analysis: link\nShort summary of findings from this dataset using Python:\n\nThe orphan designation for rare disease drug that had the highest counts between 1983 till present was for the treatment of multiple myeloma\nThe highest counts of final approved indication for rare disease drugs spanned across several different clinical indications – it often ended up with more indication details than the initial orphan designation phase\nThe average time required for a rare disease drug to progress from the initial designation phase to the final approval for marketing was about 1932 days (~5 years)\nThe horizontal bar graph (access from link above) showed the top ten rare disease drugs with the longest time taken to reach the market Tiopronin was the one that took the longest time of 12,215 days (~33 years)\nThe data for Tiopronin appeared to be duplicates, but note that the two were formulated differently as one of them was the enteric-coated (EC) version (marketed as delayed-release tablets under the actual trade name of “Thiola EC”, but recorded in the dataset as “Thiola” only), while the other one was the immediate-release form (Thiola)\n\n Image: Rawpixel.com\n\n\nR project\nFor R project3, there were two questions in mind to answer:\n\nWhat countries were involved in rare disease drug developments?\nHow would the time from designation to approval be displayed in timeline style for selected rare disease drugs?\n\nR versions of the data analysis:\n\nbase R methods via Jupyter notebook with link\nTidyverse version via RStudio with link - done using RMarkdown\n\nShort summary of findings from this dataset using R:\n\nUS was the country that had the most involvement in rare disease drug developments, which was followed by Ireland and the UK, and also a number of other countries\nMore work could possibly go into looking at the duplicates of brand names of the same generic drug e.g. cannabidiol with trade name as Epidiolex that had 5 repeated timelines (shown in link above), which appeared to be different clinical indications for each of these entries after further checks\nThe timelines have also implied that drug discovery and development is a very timely process, which could span many years, such as 10 – 20 years or more, before a drug actually reaches the market for public use\n\n\n\n\n\n\nFootnotes\n\n\nThis work is under CC BY-SA 4.0 International License for anyone interested in exploring the topic further.↩︎\nThe published date of this project would be based on the last day I’ve worked on associated file, prior to the blog move↩︎\nThe R versions, base R and Tidyverse projects, were done after the Python one was completed↩︎"
  },
  {
    "objectID": "posts/SERCA project/SERCA_project.html",
    "href": "posts/SERCA project/SERCA_project.html",
    "title": "SERCA project",
    "section": "",
    "text": "Reflecting back to the whole experience for this project, I’ve learned my lessons about working with collaborators whose research focus was on entirely different but related field (their one was on molecular biology, while our side was on chemistry, I’ve been spending time working in both computer and chemistry labs, trying to identify likely compound candidate from molecular modelling and then synthesise the compounds in the lab for them to test). There should have been more communications if possible and perhaps we could’ve terminated the project earlier if needed so that we could allocate more time to work on other research project that better suited to the situation of our lab group. To have a closure for this project, I’ve written up a chapter about it in my PhD thesis to show what have been done and what other future work can be added if we have all the time and money in the world.\n Image: Rawpixel.com\nLink to MPhil thesis (beware: quite long)\nAbstract of this project:\nThe goal of this research project was to discover potential chemical compounds that could be further developed to become lead compounds to target secretory pathway calcium ATPase 1 (SPCA1) and also sarcoplasmic-endoplasmic reticulum calcium ATPase (SERCA) pumps. The drug design process would need to be robust enough to ask the question; could a SERCA inhibitor be developed based on the drug design process involving molecular modelling, chemical synthesis and biological testing? If this first step was achieved then the next critical step was to design a SPCA1 inhibitor as SPCA1 was found to be highly involved in basal-like breast cancer. The potential lead compounds would then have the opportunity to become novel anti-cancer agents targeting basal-like breast cancer in this context. The ultimate aim was to widen the current therapeutic agents available for patients with basal-like subtype of breast cancer in the hope to further improve their quality of life and life expectancy.\n\n\n\n\nFootnotes\n\n\nthis was not a perfect example of drug discovery, I was a complete research newbie prior to this MPhil project and thinking back, I think I was far too ambitious…↩︎"
  },
  {
    "objectID": "posts/6. Long COVID update/ExtractTableFromPDF.html",
    "href": "posts/6. Long COVID update/ExtractTableFromPDF.html",
    "title": "Table scraping from PDF",
    "section": "",
    "text": "Installing and importing libraries\nThen we would install any libraries needed for scraping table data from PDF, which in this case, I ended up using only one library.\n\n!pip install -q tabula-py\n\n\n# import read_pdf from the tabula library\nfrom tabula import read_pdf\n\n\n\nData source\nSource of the table was from this journal paper by Healey Q, Sheikh A, Daines L, Vasileiou E. Symptoms and signs of long COVID: A rapid review and meta-analysis. J Glob Health 2022;12:05014. Creative Commons Attribution 4.0 International Public License\n\n\n\nPhoto by Steve Richey on Unsplash\n\n\n\n\nTable scraping\nFirstly, I trialled scraping the table from page 4 of the journal paper, which only really scraped about half of the table. I then went on to add in another line of code to specify the scraping area1 on the PDF page in inches (this part could be deduced by using the in-built PDF tool).\nOne thing I wasn’t too sure about was that the tabula-py documentation did state that the default = full page, but in fact, it appeared to be not the case (only half of the table showed up). Also, the journal paper I was using had the tables printed in landscape layout (rather than the more common portrait style), so it wasn’t completely clear if landscape version was making this harder or the other way.\n\n#specify the scraping area (top, left, bottom, right)\ntest_area = \"10.05,6.60,10.05,6.60\" \ndf = read_pdf(\"Journal.pdf\", pages = \"4\", area = test_area, guess = False, stream = True, pandas_options={'header':None})\ndf\n\n[                                                    0\n 0   VREIESWEAPROCINHT TSHEME 1:  Healey et al. COV...\n 1    Table 1. Characteristics of the included studies\n 2                             Author Hospital (%) Age\n 3   (country) {ICU (%)} (years) Comorbiditiestime ...\n 4   41% hypertension, 15% diabetes, Generalised/MS...\n 5   11% obesity, 11% endocrine disease, Respirator...\n 6   10% malignancy, 9% IHD, 8% Neuropsychiatric 43...\n 7    Bellan (Italy) dyslipidaemia, 7% AF, 6% COPD, 6%\n 8   100 {12} 61 107 ENT 5% gustatory dysfunction, ...\n 9             [19] CKD, 6% haematological disease, 5%\n 10             anxiety/depression, 4% cerebrovascular\n 11  disease, 3% liver disease, 3% VTE, 2% Gastroin...\n 12                         IBD, 2% autoimmune disease\n 13  Generalised/MSK Fatigue, myalgia, arthralgia, ...\n 14  Respiratory Dyspnoea, cough, chest pain, sputu...\n 15       Bliddal 28% allergy, 17% osteoarthritis, 15%\n 16  Neuropsychiatric Memory issues, concentration ...\n 17  (Denmark) 0 50 hypertension, 9% thyroid diseas...\n 18  ENT Olfactory dysfunction, gustatory dysfuncti...\n 19                                        [20] asthma\n 20  Gastrointestinal Diarrhoea, anorexia, abdomina...\n 21                              Others Red runny eyes\n 22        Chiesa- 6% hypertension, 6% hypothyroidism,\n 23  Estomba Not stated 41 6% asthma, 4% autoimmune...\n 24          (Italy) [21] 3% diabetes, 2% IHD, 1% COPD\n 25                                             Cousyn\n 26  0 35 Not stated 60 ENT 16.8% olfactory dysfunc...\n 27                                      (France) [22]\n 28  Generalised/MSK 45% fatigue, 15% myalgia, 3% f...\n 29  33% dyspnoea, 33% cough. Normal spirometry, no...\n 30                                        Respiratory\n 31                                   distance on 6MWT\n 32  Neuropsychiatric 18% cognitive issues, 15% hea...\n 33          Daher 59% hypertension, 25% diabetes, 22%\n 34  ENT 12% olfactory dysfunction, 12% rhinorrhoea...\n 35   (Germany) 100 64 CKD, 19% IHD, 13% asthma, 9% 56\n 36  9% diarrhoea, 6% nausea, 3% abdominal pain, no...\n 37  18% angina, normal left ventricular function, ...\n 38                                     Cardiovascular\n 39                                         biomarkers\n 40  Normal FBC, normal coagulation screen, raised ...\n 41                                   Other biomarkers\n 42  U&Es, normal CRP, normal procalcitonin, normal...\n 43  26% hypertension, 12% diabetes, Generalised/MS...\n 44                                         Fernandez-\n 45                 12% IHD, 7% asthma, 5% obesity, 4%\n 46                        de-Las-Penas 100 {7} 61 340\n 47  COPD, 2% cerebrovascular disease, 2% Respirato...\n 48                                       (Spain) [23]\n 49                            rheumatological disease\n 50  47% hypertension, 42% dyslipidaemia, Generalis...\n 51                                           Froidure\n 52  28% obesity, 22% diabetes, 9% Abnormal chest C...\n 53                           (Belgium) 100 {22} 60 98\n 54  asthma, 4% COPD, 2% lung cancer, Respiratory t...\n 55                                               [24]\n 56  1% ILD cough, 4% chest tightness, normal spiro...\n 57  2022  •  Vol. 12  •  05014 4 www.jogh.org •  d...]\n\n\nOnce above worked, I moved onto scraping the whole table across pages 4 to 6 of the PDF, and then saved the scraped table into a .csv file, which appeared automatically in the working directory.\n\nimport tabula\ntest_area = \"10.05,6.60,10.05,6.60\"\n# Convert and save scraped data into specified file format\ntabula.convert_into(\"Journal.pdf\", \"Full_table_scraped.csv\", output_format = \"csv\", pages = \"4-6\", area = test_area, guess = False, stream = True)\n!cat Full_table_scraped.csv\n\nVREIESWEAPROCINHT TSHEME 1:  Healey et al. COVID-19 PANDEMIC\nTable 1. Characteristics of the included studies\nAuthor Hospital (%) Age\n(country) {ICU (%)} (years) Comorbiditiestime (days) Follow-up Body system Results\n\"41% hypertension, 15% diabetes, Generalised/MSK 5.9% myalgia, 5.9% arthralgia\"\n\"11% obesity, 11% endocrine disease, Respiratory 5.5% dyspnoea, 2.5% cough, 0.4% chest pain, 51.6% reduced DLCO, normal spirometry\"\n\"10% malignancy, 9% IHD, 8% Neuropsychiatric 43% PTSD symptoms\"\n\"Bellan (Italy) dyslipidaemia, 7% AF, 6% COPD, 6%\"\n\"100 {12} 61 107 ENT 5% gustatory dysfunction, 4.6% olfactory dysfunction\"\n\"[19] CKD, 6% haematological disease, 5%\"\n\"anxiety/depression, 4% cerebrovascular\"\n\"disease, 3% liver disease, 3% VTE, 2% Gastrointestinal 1.3% diarrhoea\"\n\"IBD, 2% autoimmune disease\"\n\"Generalised/MSK Fatigue, myalgia, arthralgia, chills, fever\"\n\"Respiratory Dyspnoea, cough, chest pain, sputum production\"\n\"Bliddal 28% allergy, 17% osteoarthritis, 15%\"\n\"Neuropsychiatric Memory issues, concentration issues, headache\"\n\"(Denmark) 0 50 hypertension, 9% thyroid disease, 8% 84\"\n\"ENT Olfactory dysfunction, gustatory dysfunction, sore throat, rhinorrhoea, sneezing\"\n[20] asthma\n\"Gastrointestinal Diarrhoea, anorexia, abdominal pain, nausea\"\nOthers Red runny eyes\n\"Chiesa- 6% hypertension, 6% hypothyroidism,\"\n\"Estomba Not stated 41 6% asthma, 4% autoimmune disease, 47 ENT 51% olfactory dysfunction\"\n\"(Italy) [21] 3% diabetes, 2% IHD, 1% COPD\"\nCousyn\n\"0 35 Not stated 60 ENT 16.8% olfactory dysfunction, 9.6% gustatory dysfunction\"\n(France) [22]\n\"Generalised/MSK 45% fatigue, 15% myalgia, 3% fever, slight pain/discomfort\"\n\"33% dyspnoea, 33% cough. Normal spirometry, normal ABG, reduced DLCO, reduced\"\nRespiratory\ndistance on 6MWT\n\"Neuropsychiatric 18% cognitive issues, 15% headache, mild depression, subthreshold anxiety\"\n\"Daher 59% hypertension, 25% diabetes, 22%\"\n\"ENT 12% olfactory dysfunction, 12% rhinorrhoea, 9% gustatory dysfunction, 9% sore throat\"\n\"(Germany) 100 64 CKD, 19% IHD, 13% asthma, 9% 56\"\n\"9% diarrhoea, 6% nausea, 3% abdominal pain, normal LFTs[17] COPD, 9% AF, 9% heart failureGastrointestinal\"\n\"18% angina, normal left ventricular function, normal right ventricular function, normal cardiac\"\nCardiovascular\nbiomarkers\n\"Normal FBC, normal coagulation screen, raised ferritin, potentially raised D-dimer, normal\"\nOther biomarkers\n\"U&Es, normal CRP, normal procalcitonin, normal TFTs, normal IL-6\"\n\"26% hypertension, 12% diabetes, Generalised/MSK 61.2% fatigue\"\nFernandez-\n\"12% IHD, 7% asthma, 5% obesity, 4%\"\nde-Las-Penas 100 {7} 61 340\n\"COPD, 2% cerebrovascular disease, 2% Respiratory 23.3% dyspnoea, 6.5% chest pain, 2.5% cough\"\n(Spain) [23]\nrheumatological disease\n\"47% hypertension, 42% dyslipidaemia, Generalised/MSK 25% fatigue\"\nFroidure\n\"28% obesity, 22% diabetes, 9% Abnormal chest CT: 67% ground glass opacities, 44% reticulations, 20% fibrotic lesions/\"\n(Belgium) 100 {22} 60 98\n\"asthma, 4% COPD, 2% lung cancer, Respiratory traction bronchiectasis, 7% consolidations. 46% reduced DLCO, 35% dyspnoea, 10% dry\"\n[24]\n\"1% ILD cough, 4% chest tightness, normal spirometry\"\n2022  •  Vol. 12  •  05014 4 www.jogh.org •  doi: 10.7189/jogh.12.05014\n\"\",,,,,,,Symptoms and signs of long COVID: A rapid review\nTable 1. continued,,,,,,,\nAuthor (country) Hospital (%) {ICU (%)},Age (years),,,Comorbidities,Follow-up time (days),,Body system Results\n\"\",,,,,,,Generalised/MSK 17% fatigue\nGerhards,,,,,,,\n\"\",,,,,,,\"Neuropsychiatric Depression, concentration issues\"\n(Germany) 10,46,,,Not stated,183,,\n\"\",,,,,,,ENT 27% olfactory/gustatory dysfunction\n[25],,,,,,,\n\"\",,,,,,,Others Alopecia\n\"\",,,,,,,\"Generalised/MSK Fatigue, arthralgia, myalgia\"\n\"\",,,,\"38% hypertension, 22% obesity, 19%\",,,\nGhosn,,,,,,,\"Respiratory Dyspnoea, cough\"\n100 {29},61,,,\"diabetes, 18% IHD, 10% COPD, 7%\",194,,\n(France) [26],,,,,,,Neuropsychiatric Headache\n\"\",,,,\"CKD, 7% malignancy, 1% liver disease\",,,\n\"\",,,,,,,\"ENT Rhinorrhoea, olfactory dysfunction, gustatory dysfunction, sore throat\"\n\"\",,,,,,,\"62% abnormal chest CT: 35% fibrotic-like changes, 27% ground glass opacities/interstitial\"\nHan (China),,,,\"28% hypertension, 14% respiratory\",,,\"thickening, nodules/masses, interlobar pleural traction, pulmonary atelectasis and\"\n100,54,,,,175,,Respiratory\n[27],,,,\"disease, 11% diabetes\",,,\"bronchiectasis. 26% reduced DLCO, 14% mild dyspnoea, 10% sputum production, 6.1% dry\"\n\"\",,,,,,,cough\n\"\",,,,,,,\"Generalised/MSK 50% fatigue, 35.7% arthralgia, 21.4% myalgia\"\nHolmes,,,,,,,\"Respiratory 28.6% cough, 25% dyspnoea, 3.6% chest pain\"\n(Australia) 0,57,,,Not stated,183,,Neuropsychiatric 10.7% headache\n[28],,,,,,,\"ENT 28.6% olfactory dysfunction, 14.3% rhinorrhoea\"\n\"\",,,,,,,Gastrointestinal No abdominal pain\n\"\",,,,\"49% obesity, 48% hypertension,\",,,\"Generalised/MSK 44.8% fatigue, 21.3% myalgia, 15.8% arthralgia, 1.1% fever, 1.1% ulcer\"\n\"\",,,,\"28% diabetes, 12% IHD, 11%\",,,\"Respiratory 31.7% dyspnoea, 25.1% cough, 14.8% sputum production\"\n\"\",,,,\"dyslipidaemia, 10% asthma, 10%\",,,\"Neuropsychiatric 12.6% headache, 8.7% cognitive issues\"\nJacobs (USA),,,,\"malignancy, 5% arrhythmia, 4%\",,,\n100,57,,,,35,,\"ENT 9.8% gustatory dysfunction, 9.3% olfactory dysfunction\"\n[29],,,,\"COPD, 4% hypothyroidism, 4%\",,,\n\"\",,,,,,,Gastrointestinal 3.8% diarrhoea\n\"\",,,,\"depression, anxiety or schizophrenia,\",,,\n\"\",,,,\"3% heart failure, 3% sleep apnoea, 2%\",,,\"Others 8.2% eye irritation, 1.1% ulcer\"\n\"\",,,,VTE,,,\n\"\",,,,\"36% obesity, 29% hypertension,\",,,\"Generalised/MSK 63% fatigue, 35% myalgia\"\nLeth,,,,\"12% malignancy, 10% IHD, 8%\",,,\"Respiratory 53% dyspnoea, 24% cough, 20% chest pain, 12% sputum production\"\n(Denmark) 100 {12},58,,,\"asthma, 8% COPD, 4% diabetes, 4%\",128,,\"Neuropsychiatric 45% concentration issues, 27% headache, 27% paraesthesia\"\n[30],,,,\"hyperthyroidism, 2% cerebrovascular\",,,\"ENT 31% gustatory dysfunction, 27% olfactory dysfunction, 10% sore throat\"\n\"\",,,,disease,,,\"Gastrointestinal 10% abdominal pain, 8% diarrhoea, 8% nausea, 4% anorexia\"\n\"\",,,,,,,\"Generalised/MSK 33% fatigue, 1.4% arthralgia, 0.6% myalgia\"\n\"\",,,,,,,\"Respiratory 8.5% cough, 7% dyspnoea, 0.8% chest pain\"\nMahmud,,,,,,,\n\"\",,,,,,,\"3.9% circadian rhythm disorders, 3.4% headache, 2.3% sleep disturbance, 1.4% adjustment\"\n(Bangladesh) Not stated,40,,,\"15% hypertension, 14% diabetes\",30,,Neuropsychiatric\n\"\",,,,,,,disorder\n[18],,,,,,,\n\"\",,,,,,,\"ENT 2.3% vertigo, 2% olfactory dysfunction\"\n\"\",,,,,,,Cardiovascular 1.4% palpitation\n\"\",,,,,,,RESEARCH THEME 1:\n\"\",,,,,,,VCOIEVWIDP-O1I9N PTASNDEMIC\nwww.jogh.org • doi: 10.7189/jogh.12.05014,,,,5,,,2022  •  Vol. 12  •  05014\nRVEIESWEAPROCINHT TSHEME 1:  Healey et al. COVID-19 PANDEMIC\nTable 1. continued\nAuthor Hospital (%) Age Follow-up\n(country) {ICU (%)} (years) Comorbidities time (days) Body system Results\nOtte\n\"42.3% subjective olfactory dysfunction, 26.9% objective olfactory dysfunction (discrimination\"\n(Germany) 0 45 Not stated 201 ENT\nand identification issues)\n[31]\n\"Generalised/MSK 13.1% fatigue, 8.2% rheumatological issues\"\n\"23% hypertension, 16% obesity, 6% Respiratory 6% dyspnoea, 2% cough, 0.8% chest pain\"\n\"Peghin (Italy) diabetes, 4% respiratory disease, 1% Neuropsychiatric 9.6% neurological disorders, 4.9% psychiatric disorders, 2.7% headache\"\n26 53 191\n\"[32] IHD, 2% liver disease, 1% depression/ ENT 10.4% olfactory/gustatory dysfunction,\"\n\"anxiety, 0% CKD Gastrointestinal 1.5% gastrointestinal disorders\"\n\"Others 3.7% alopecia, 3.4% cutaneous manifestations, 0.3% ocular symptoms\"\n\"Generalised/MSK 24% night sweats, 0% fever\"\n\"63% abnormal chest CT: ground-glass opacities, reticular lesions, consolidations, bronchial\"\n\"Respiratory dilation. 36% dyspnoea, abnormal spirometry: 22% reduced FVC, 22% reduced FEV1, normal\"\n\"40% cardiovascular disease, 30% FEV1/FVC. 21% reduced DLCO, 17% cough\"\n\"hypertension, 19% dyslipidaemia,\"\nSonnweber Neuropsychiatric 22% sleep disorders\n\"75 57 17% diabetes, 7% asthma, 7% CKD, 103\"\n(Austria) [16] ENT 19% olfactory dysfunction\n\"6% COPD, 6% liver disease, 6%\"\n\"malignancy, 1% ILD Gastrointestinal 9% diarrhoea/vomiting\"\n\"97% normal LVEF, 55% diastolic dysfunction on echo, 23% raised NT-proBNP, 10%\"\nCardiovascular\n\"pulmonary hypertension, 1% pericardial effusion\"\n\"Other biomarkers Raised D-dimer, potentially raised ferritin, normal CRP, normal procalcitonin, normal IL-6\"\n\"Generalised/MSK Fatigue, myalgia, fever\"\n\"Respiratory Dyspnoea, cough, chest pain\"\n\"Sudre (UK, 26% obesity, 14% respiratory disease, Neuropsychiatric Headache, paraesthesia, numbness, concentration/ memory issues\"\n\"USA, Sweden) 14 42 10% asthma, 3% diabetes, 2% IHD, 84\"\n\"[33] 1% CKD ENT Olfactory dysfunction, sore throat, hoarse voice, tinnitus, earache\"\n\"Gastrointestinal Diarrhoea, abdominal pain\"\nCardiovascular Palpitations/tachycardia\n\"Vaira (Italy) 29% obesity, 27% IHD, 15%\"\n\"23 51 60 ENT 21% olfactory dysfunction, 7.9% gustatory dysfunction\"\n\"[34] respiratory disease, 11% diabetes\"\n\"ICU – intensive care unit, IHD – ischaemic heart disease, AF – atrial fibrillation, COPD – chronic obstructive pulmonary disease, CKD – chronic kidney disease, VTE – venous thromboembolism, IBD – inflammatory bowel\"\n\"disease, NS – not stated, ILD – interstitial lung disease, MSK – musculoskeletal, ENT – ear, nose, and throat, OGD – olfactory-gustatory dysfunction, DLCO – diffusing capacity for carbon monoxide, PTSD – posttraumatic\"\n\"stress disorder, ABG – arterial blood gas, 6MWT – 6-min walk test, LFT – liver function test, FBC – full blood count, U&E – urea and electrolyte, CRP – c-reactive protein, TFT – thyroid function test, IL-6 – interleukin-6,\"\n\"FVC – forced vital capacity, FEV1 – forced expiratory volume in one second, NT-proBNP – N-terminal pro B-type natriuretic peptide\"\n2022  •  Vol. 12  •  05014 6 www.jogh.org •  doi: 10.7189/jogh.12.05014\n\n\n\n\nShort summary\nThe PDF scraping exercise only worked to a certain degree2, as the data did not arrive in a proper tabular format. I’ve also gone on to read several online resources and looked into tabula-py and tabula-java, it was clearly shown in their GitHub repo that there were existing issues for tables that have merged cells, empty cells or no column lines (which was what I had in this case). All of them tend to result in jumbled or merged rows or columns. It tends to work better if the tables in the PDFs are already in a proper table format i.e. columns and rows marked by lines. Nevertheless, the purpose of scraping the table data was achieved as full data were there after checking, but just not in a clean and tidy state so the next post named, “Long COVID - an update” would take us into the next stage to see what this tabular data would tell us about long COVID (all done in R).\n\n\n\n\n\nFootnotes\n\n\nThanks to Stack Overflow as I’ve managed to find this solution from several different scenarios and comments.↩︎\nor it could be my ignorance to other better methods - please leave a comment as I’d like to learn!↩︎"
  },
  {
    "objectID": "posts/6. Long COVID update/Long_COVID_update.html",
    "href": "posts/6. Long COVID update/Long_COVID_update.html",
    "title": "Long COVID - an update",
    "section": "",
    "text": "Source of dataset\nJournal paper by Healey Q, Sheikh A, Daines L, Vasileiou E. Symptoms and signs of long COVID: A rapid review and meta-analysis. J Glob Health 2022;12:05014. Creative Commons Attribution 4.0 International Public License\n\n\nData scraping from PDF\nThe dataset was scraped from a PDF obtained via PubMed (journal paper source as shown above) by using tabula-py (for details please see this post, “Table scraping from PDF”). Unfortunately I had trouble installing a similar R package remotely after it was archived (tabulizer package with known issues in its GitHub repository) so I trialled tabula-py instead. It worked for scraping all the data from the target table, but the downside was that the scraped data did not inherit the original tabular format on PDF, with columns and rows all jumbled. I’ve discussed a little bit more on the likely reason for this in the blog post link above. So in short, the final scraped table was cleaned in Excel and saved as .csv file, which was then imported as shown below.\n\n\nData inspection and wrangling\n\n# Uncomment below if requiring installations of packages\n# install.packages(\"wordcloud\")\n# install.packages(\"RColorBrewer\")\n# install.packages(\"tidytext\")\n# install.packages(\"leaflet\")\n\nLoading all the required libraries below. Install libraries needed as shown in codes above.\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(knitr)\nlibrary(leaflet)\nlibrary(tidytext)\nlibrary(wordcloud)\nlibrary(RColorBrewer)\n\n\ndf <- read_csv(\"Full_table.csv\")\n\nNew names:\nRows: 75 Columns: 9\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(5): Author (country), Hospital (%) {ICU (%)}, Comorbidities, Body syste... dbl\n(2): Age (years), Follow-up time (days) lgl (2): ...8, ...9\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -> `...8`\n• `` -> `...9`\n\n\n\n\n\nHere’s a quick overview on the hospitalisation rates across all the studies from this paper.\n\ndf_hosp <- df %>% \n  select(`Author (country)`, `Hospital (%) {ICU (%)}`)\ndf_hosp\n\n# A tibble: 75 × 2\n   `Author (country)` `Hospital (%) {ICU (%)}`\n   <chr>              <chr>                   \n 1 Bellan (Italy)     100 {12}                \n 2 Bellan (Italy)     <NA>                    \n 3 Bellan (Italy)     <NA>                    \n 4 Bellan (Italy)     <NA>                    \n 5 Bellan (Italy)     <NA>                    \n 6 Bliddal (Denmark)  0                       \n 7 Bliddal (Denmark)  <NA>                    \n 8 Bliddal (Denmark)  <NA>                    \n 9 Bliddal (Denmark)  <NA>                    \n10 Bliddal (Denmark)  <NA>                    \n# … with 65 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\n\nSeparating columns and change column type\nThe table column of Hospital (%) {ICU (%)} was separated into two separate columns to allow clearer differentiation between hospital and ICU rates within each study. The data type for Hospital (%) column was also changed from character to numeric so we can plot a bar graph later on (otherwise the x-axis may not be accurate or properly shown).\n\ndf_hosp_icu <- df_hosp %>% \n  # separate column into two columns\n  separate(`Hospital (%) {ICU (%)}`, c(\"Hospital (%)\", \"ICU (%)\"))%>% \n  # change column type\n  mutate(across(`Hospital (%)`, as.numeric))\n# show the first 10 rows as example\nc <- head(df_hosp_icu, 10)\nkable(c)\n\n\n\n\nAuthor (country)\nHospital (%)\nICU (%)\n\n\n\n\nBellan (Italy)\n100\n12\n\n\nBellan (Italy)\nNA\nNA\n\n\nBellan (Italy)\nNA\nNA\n\n\nBellan (Italy)\nNA\nNA\n\n\nBellan (Italy)\nNA\nNA\n\n\nBliddal (Denmark)\n0\nNA\n\n\nBliddal (Denmark)\nNA\nNA\n\n\nBliddal (Denmark)\nNA\nNA\n\n\nBliddal (Denmark)\nNA\nNA\n\n\nBliddal (Denmark)\nNA\nNA\n\n\n\n\n\n\n\nSeparating rows\nThe listed co-morbidities for each study were separated into separate rows, rather than into columns, to avoid adding too many columns all at once.\n\ndf_new <- df %>% \n  separate_rows(Comorbidities, sep = \", \")\n# Show the first 10 rows as example\ne <- head(df_new, 10)\nkable(e)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAuthor (country)\nHospital (%) {ICU (%)}\nAge (years)\nComorbidities\nFollow-up time (days)\nBody system\nResults\n…8\n…9\n\n\n\n\nBellan (Italy)\n100 {12}\n61\n41% hypertension\n107\nGeneralised/MSK\n5.9% myalgia, 5.9% arthralgia\nNA\nNA\n\n\nBellan (Italy)\n100 {12}\n61\n15% diabetes\n107\nGeneralised/MSK\n5.9% myalgia, 5.9% arthralgia\nNA\nNA\n\n\nBellan (Italy)\n100 {12}\n61\n11% obesity\n107\nGeneralised/MSK\n5.9% myalgia, 5.9% arthralgia\nNA\nNA\n\n\nBellan (Italy)\n100 {12}\n61\n11% endocrine disease\n107\nGeneralised/MSK\n5.9% myalgia, 5.9% arthralgia\nNA\nNA\n\n\nBellan (Italy)\n100 {12}\n61\n10% malignancy\n107\nGeneralised/MSK\n5.9% myalgia, 5.9% arthralgia\nNA\nNA\n\n\nBellan (Italy)\n100 {12}\n61\n9% IHD\n107\nGeneralised/MSK\n5.9% myalgia, 5.9% arthralgia\nNA\nNA\n\n\nBellan (Italy)\n100 {12}\n61\n8% dyslipidaemia\n107\nGeneralised/MSK\n5.9% myalgia, 5.9% arthralgia\nNA\nNA\n\n\nBellan (Italy)\n100 {12}\n61\n7% AF\n107\nGeneralised/MSK\n5.9% myalgia, 5.9% arthralgia\nNA\nNA\n\n\nBellan (Italy)\n100 {12}\n61\n6% COPD\n107\nGeneralised/MSK\n5.9% myalgia, 5.9% arthralgia\nNA\nNA\n\n\nBellan (Italy)\n100 {12}\n61\n6% CKD\n107\nGeneralised/MSK\n5.9% myalgia, 5.9% arthralgia\nNA\nNA\n\n\n\n\n\n\n\nA frequency count showing types of comorbidities in long COVID\nI then noticed how the comorbidities for each study were listed with different percentages and to gather a quick initial overall picture of the data, I started by removing these digits and percentage symbols. Obviously since I was still quite new to R (started using R in July), I soon ran into a problem as I kept on getting stuck with not having the count() function to actually count unique elements under the co-morbidities column.\nBy looking at the magnified circle on the right in the image below, you would notice a subtle difference in spacing, so yes the culprit was the space1 and once it was removed, count() worked nicely as how it should be. One small downside was that it would also remove the space between the co-morbidity terms e.g. “liver disease” became “liverdisease”, but since it achieved the aim intended to do unique counts on all the co-morbidities, I left it as it was.\n\n\n\nScreenshot of the extra space(s) in dataframe\n\n\n\ndf_new %>% \n  # Remove % symbol, numbers and don't forget to remove spaces as well in the column! \n  mutate(Comorbidities = str_remove_all(Comorbidities, \"[:digit:]|[%]|[ ]\")) %>%\n  # Add this line to filter out all the \"NA\"s\n  filter(!is.na(Comorbidities)) %>% \n  # Count the comorbidities in descending order\n  count(Comorbidities, sort = TRUE) \n\n# A tibble: 37 × 2\n   Comorbidities     n\n   <chr>         <int>\n 1 diabetes         14\n 2 hypertension     13\n 3 IHD              10\n 4 asthma            9\n 5 COPD              9\n 6 obesity           9\n 7 CKD               6\n 8 malignancy        5\n 9 dyslipidaemia     4\n10 liverdisease      4\n# … with 27 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\nNow we could observe the top 3 frequency of all co-morbidities listed were: diabetes, hypertension and IHD2. These were followed by, unsurprisingly, common respiratory illnesses such as asthma, COPD3, then obesity, and also CKD4, malignancy, dyslipidaemia and so on. These would be considered as high risk factors of developing long COVID symptoms if someone had these co-morbidities present before being infected by the coronoviruses.\n\n\n\nData visualisations\n\nBar graph for hospitalisation rate\nThen a line of code to filter out the results of “NA” under the column of Hospital (%) was added. Most of the cells with “NA” were there to fill the multiple empty row entries for other variables and not for the Hospital (%) column, therefore these “NA”s were removed in this instance. The horizontal bar graph below showed the COVID-19 hospitalisation rate for studies in different countries, presenting a very diverse results between 0% and 100% hospitalisations across all 19 cohort studies.\n\ndf_hosp_icu %>% \n  # filter out all NAs\n  filter(!is.na(`Hospital (%)`)) %>% \n  # plot the bar graph\n  ggplot(aes(x = `Author (country)`, y = `Hospital (%)`)) + \n  geom_bar(stat = \"identity\") +\n  coord_flip()\n\n\n\n\nCOVID-19 hospitalisation rate across different countries\n\n\n\n\nNote: two of the studies were removed from above, these studies were by Chiesa-Estomba (Italy) and Mahmud (Bangladesh), which had “Not stated” recorded under Hospital (%) {ICU (%)} column. When the Hospital (%) column was converted from character to numeric, these two rows were converted to “NA” automatically.\n\n\nInteractive map for long COVID results\n\nPreparing dataframe for map\n\ndf_new_a <- df %>% \n  # separate Author (country) column into two columns \n  # note: rename country as region - needed for joining data later on\n  separate(`Author (country)`, c(\"Author\", \"region\")) %>% \n  # print only the columns as selected\n  select(`region`, Results)\n\n# The study author name, Fernandez-de-Las-Penas (Spain), got separated as above\n# so replace \"de\" under Country column with the actual country name of Spain\ndf_new_a[df_new_a == \"de\"] <- \"Spain\" \n# Show first 10 rows as example\nd <- head(df_new_a, 10)\nkable(d)\n\n\n\n\n\n\n\n\nregion\nResults\n\n\n\n\nItaly\n5.9% myalgia, 5.9% arthralgia\n\n\nItaly\n5.5% dyspnoea, 2.5% cough, 0.4% chest pain, 51.6% reduced DLCO, normal spirometry\n\n\nItaly\n43% PTSD symptoms\n\n\nItaly\n5% gustatory dysfunction, 4.6% olfactory dysfunction\n\n\nItaly\n1.3% diarrhoea\n\n\nDenmark\nfatigue, myalgia, arthralgia, chills, fever\n\n\nDenmark\ndyspnoea, cough, chest pain, sputum production\n\n\nDenmark\nmemory issues, concentration issues, headache\n\n\nDenmark\nolfactory dysfunction, gustatory dysfunction, sore throat, rhinorrhoea, sneezing\n\n\nDenmark\ndiarrhoea, anorexia, abdominal pain, nausea\n\n\n\n\n\n\ndf1 <- df_new_a %>% \n  # re-group dataframe based on region column\n  group_by(`region`) %>%\n  # merge all rows under Results column into one string\n  summarise(across(everything(), ~toString(.)))\ndf1\n\n# A tibble: 13 × 2\n   region     Results                                                           \n   <chr>      <chr>                                                             \n 1 Australia  50% fatigue, 35.7% arthralgia, 21.4% myalgia, 28.6% cough, 25% dy…\n 2 Austria    24% night sweats, 0% fever, 63% abnormal chest CT: ground-glass o…\n 3 Bangladesh 33% fatigue, 1.4% arthralgia, 0.6% myalgia, 8.5% cough, 7% dyspno…\n 4 Belgium    25% fatigue, abnormal chest CT: 67% ground glass opacities, 44% r…\n 5 China      62% abnormal chest CT: 35% fibrotic-like changes, 27% ground glas…\n 6 Denmark    fatigue, myalgia, arthralgia, chills, fever, dyspnoea, cough, che…\n 7 Estomba    51% olfactory dysfunction                                         \n 8 France     16.8% olfactory dysfunction, 9.6% gustatory dysfunction, fatigue,…\n 9 Germany    45% fatigue, 15% myalgia, 3% fever, slight pain/discomfort, 33% d…\n10 Italy      5.9% myalgia, 5.9% arthralgia, 5.5% dyspnoea, 2.5% cough, 0.4% ch…\n11 Spain      61.2% fatigue, 23.3% dyspnoea, 6.5% chest pain, 2.5% cough        \n12 UK         fatigue, myalgia, fever, dyspnoea, cough, chest pain, headache, p…\n13 USA        44.8% fatigue, 21.3% myalgia, 15.8% arthralgia, 1.1% fever, 1.1% …\n\n\n\n# grab the world map data from ggplot\nmapdata <- map_data(\"world\") \n# view full dataset in separate tab \nview(mapdata)\n\n\n# combine mapdata dataframe (contains longitudes & latitudes of each country) \n# with df_new_a dataframe (contains country info)\nmapdata <- left_join(mapdata, df1, by = \"region\")\nhead(mapdata)\n\n       long      lat group order region subregion Results\n1 -69.89912 12.45200     1     1  Aruba      <NA>    <NA>\n2 -69.89571 12.42300     1     2  Aruba      <NA>    <NA>\n3 -69.94219 12.43853     1     3  Aruba      <NA>    <NA>\n4 -70.00415 12.50049     1     4  Aruba      <NA>    <NA>\n5 -70.06612 12.54697     1     5  Aruba      <NA>    <NA>\n6 -70.05088 12.59707     1     6  Aruba      <NA>    <NA>\n\n\n\n# filter out all the empty or \"NA\" cells\nmapdata_new <- mapdata %>% filter(!is.na(mapdata$Results))\nhead(mapdata_new)\n\n      long       lat group order    region                   subregion\n1 123.5945 -12.42568   133  7115 Australia Ashmore and Cartier Islands\n2 123.5952 -12.43594   133  7116 Australia Ashmore and Cartier Islands\n3 123.5732 -12.43418   133  7117 Australia Ashmore and Cartier Islands\n4 123.5725 -12.42393   133  7118 Australia Ashmore and Cartier Islands\n5 123.5945 -12.42568   133  7119 Australia Ashmore and Cartier Islands\n6 158.8788 -54.70976   139  7267 Australia            Macquarie Island\n                                                                                                                                                                      Results\n1 50% fatigue, 35.7% arthralgia, 21.4% myalgia, 28.6% cough, 25% dyspnoea, 3.6% chest pain, 10.7% headache, 28.6% olfactory dysfunction, 14.3% rhinorrhoea, no abdominal pain\n2 50% fatigue, 35.7% arthralgia, 21.4% myalgia, 28.6% cough, 25% dyspnoea, 3.6% chest pain, 10.7% headache, 28.6% olfactory dysfunction, 14.3% rhinorrhoea, no abdominal pain\n3 50% fatigue, 35.7% arthralgia, 21.4% myalgia, 28.6% cough, 25% dyspnoea, 3.6% chest pain, 10.7% headache, 28.6% olfactory dysfunction, 14.3% rhinorrhoea, no abdominal pain\n4 50% fatigue, 35.7% arthralgia, 21.4% myalgia, 28.6% cough, 25% dyspnoea, 3.6% chest pain, 10.7% headache, 28.6% olfactory dysfunction, 14.3% rhinorrhoea, no abdominal pain\n5 50% fatigue, 35.7% arthralgia, 21.4% myalgia, 28.6% cough, 25% dyspnoea, 3.6% chest pain, 10.7% headache, 28.6% olfactory dysfunction, 14.3% rhinorrhoea, no abdominal pain\n6 50% fatigue, 35.7% arthralgia, 21.4% myalgia, 28.6% cough, 25% dyspnoea, 3.6% chest pain, 10.7% headache, 28.6% olfactory dysfunction, 14.3% rhinorrhoea, no abdominal pain\n\n\nI realised that map_data(“world”) showed all the longitudes and latitudes for subregions of each country, which might not be required for the map I wanted. So after trialling the map visualisation several times, I opted to use centroids of each country instead, to leave the map in a cleaner and easy-to-see state. Otherwise one of the maps I tested before ended up with countless blobs of circles marking the boundaries of each country, looking like a 5-year-old’s map drawing!\n\nmapdata_final <- mapdata_new %>% \n  group_by(region) %>% \n  # Using centroids of countries = means of longitudes and latitudes for each country\n  summarise(long = mean(long), lat = mean(lat))\nkable(mapdata_final)\n\n\n\n\nregion\nlong\nlat\n\n\n\n\nAustralia\n136.998543\n-25.18300\n\n\nAustria\n13.473366\n47.57973\n\n\nBangladesh\n90.506118\n23.50905\n\n\nBelgium\n4.732104\n50.59063\n\n\nChina\n106.847575\n35.08244\n\n\nDenmark\n10.731255\n55.70473\n\n\nFrance\n3.226979\n46.16686\n\n\nGermany\n10.401156\n51.20461\n\n\nItaly\n11.752853\n42.16598\n\n\nSpain\n-2.906821\n40.67995\n\n\nUK\n-4.098750\n55.55813\n\n\nUSA\n-121.625310\n48.74333\n\n\n\n\n\n\n# join above mapdata_final with the df1 which contains countries and long COVID results\ndf1_mapdata <- left_join(mapdata_final, df1, by = \"region\")\nkable(df1_mapdata)\n\n\n\n\n\n\n\n\n\n\nregion\nlong\nlat\nResults\n\n\n\n\nAustralia\n136.998543\n-25.18300\n50% fatigue, 35.7% arthralgia, 21.4% myalgia, 28.6% cough, 25% dyspnoea, 3.6% chest pain, 10.7% headache, 28.6% olfactory dysfunction, 14.3% rhinorrhoea, no abdominal pain\n\n\nAustria\n13.473366\n47.57973\n24% night sweats, 0% fever, 63% abnormal chest CT: ground-glass opacities, reticular lesions, consolidations, bronchial dilation. 36% dyspnoea, abnormal spirometry: 22% reduced FVC, 22% reduced FEV1, normal FEV1/FVC. 21% reduced DLCO, 17% cough, 22% sleep disorders, 19% olfactory dysfunction, 9% diarrhoea/vomiting, 97% normal LVEF, 55% diastolic dysfunction on echo, 23% raised NT-proBNP, 10% pulmonary hypertension, 1% pericardial effusion, raised D-dimer, potentially raised ferritin, normal CRP, normal procalcitonin, normal IL-6\n\n\nBangladesh\n90.506118\n23.50905\n33% fatigue, 1.4% arthralgia, 0.6% myalgia, 8.5% cough, 7% dyspnoea, 0.8% chest pain, 3.9% circadian rhythm disorders, 3.4% headache, 2.3% sleep disturbance, 1.4% adjustment disorder, 2.3% vertigo, 2% olfactory dysfunction, 1.4% palpitation\n\n\nBelgium\n4.732104\n50.59063\n25% fatigue, abnormal chest CT: 67% ground glass opacities, 44% reticulations, 20% fibrotic lesions/traction bronchiectasis, 7% consolidations. 46% reduced DLCO, 35% dyspnoea, 10% dry cough, 4% chest tightness, normal spirometry\n\n\nChina\n106.847575\n35.08244\n62% abnormal chest CT: 35% fibrotic-like changes, 27% ground glass opacities/interstitial thickening, nodules/masses, interlobar pleural traction, pulmonary atelectasis and bronchiectasis. 26% reduced DLCO, 14% mild dyspnoea, 10% sputum production, 6.1% dry cough\n\n\nDenmark\n10.731255\n55.70473\nfatigue, myalgia, arthralgia, chills, fever, dyspnoea, cough, chest pain, sputum production, memory issues, concentration issues, headache, olfactory dysfunction, gustatory dysfunction, sore throat, rhinorrhoea, sneezing, diarrhoea, anorexia, abdominal pain, nausea, red runny eyes, 63% fatigue, 35% myalgia, 53% dyspnoea, 24% cough, 20% chest pain, 12% sputum production, 45% concentration issues, 27% headache, 27% paraesthesia, 31% gustatory dysfunction, 27% olfactory dysfunction, 10% sore throat, 10% abdominal pain, 8% diarrhoea, 8% nausea, 4% anorexia\n\n\nFrance\n3.226979\n46.16686\n16.8% olfactory dysfunction, 9.6% gustatory dysfunction, fatigue, arthralgia, myalgia, dyspnoea, cough, headache, rhinorrhoea, olfactory dysfunction, gustatory dysfunction, sore throat\n\n\nGermany\n10.401156\n51.20461\n45% fatigue, 15% myalgia, 3% fever, slight pain/discomfort, 33% dyspnoea, 33% cough. Normal spirometry, normal ABG, reduced DLCO, reduced distance on 6MWT, 18% cognitive issues, 15% headache, mild depression, subthreshold anxiety, 12% olfactory dysfunction, 12% rhinorrhoea, 9% gustatory dysfunction, 9% sore throat, 9% diarrhoea, 6% nausea, 3% abdominal pain, normal LFTs, 18% angina, normal left ventricular function, normal right ventricular function, normal cardiac biomarkers, normal FBC, normal coagulation screen, raised ferritin, potentially raised D-dimer, normal U&Es, normal CRP, normal procalcitonin, normal TFTs, normal IL-6, 17% fatigue, depression, concentration issues, 27% olfactory/gustatory dysfunction, alopecia, 42.3% subjective olfactory dysfunction, 26.9% objective olfactory dysfunction (discrimination and identification issues)\n\n\nItaly\n11.752853\n42.16598\n5.9% myalgia, 5.9% arthralgia, 5.5% dyspnoea, 2.5% cough, 0.4% chest pain, 51.6% reduced DLCO, normal spirometry, 43% PTSD symptoms, 5% gustatory dysfunction, 4.6% olfactory dysfunction, 1.3% diarrhoea, 13.1% fatigue, 8.2% rheumatological issues, 6% dyspnoea, 2% cough, 0.8% chest pain, 9.6% neurological disorders, 4.9% psychiatric disorders, 2.7% headache, 10.4% olfactory/gustatory dysfunction, 1.5% gastrointestinal disorders, 3.7% alopecia, 3.4% cutaneous manifestations, 0.3% ocular symptoms, 21% olfactory dysfunction, 7.9% gustatory dysfunction\n\n\nSpain\n-2.906821\n40.67995\n61.2% fatigue, 23.3% dyspnoea, 6.5% chest pain, 2.5% cough\n\n\nUK\n-4.098750\n55.55813\nfatigue, myalgia, fever, dyspnoea, cough, chest pain, headache, paraesthesia, numbness, concentration/ memory issues, olfactory dysfunction, sore throat, hoarse voice, tinnitus, earache, diarrhoea, abdominal pain, palpitations/tachycardia\n\n\nUSA\n-121.625310\n48.74333\n44.8% fatigue, 21.3% myalgia, 15.8% arthralgia, 1.1% fever, 1.1% ulcer, 31.7% dyspnoea, 25.1% cough, 14.8% sputum production, 12.6% headache, 8.7% cognitive issues, 9.8% gustatory dysfunction, 9.3% olfactory dysfunction, 3.8% diarrhoea, 8.2% eye irritation, 1.1% ulcer\n\n\n\n\n\n\n# Prepare pop up information\ndf1_mapdata <- df1_mapdata %>% \n  # paste region and Results columns into popup_info and add it as a new column into dataset\n  # bold texts and add break lines by using html tags as shown\n  mutate(popup_info = paste(\"<b>\",region,\"</b>\",\"<br/>\",\"<b>\",\"Long COVID symptoms:\",\"</b>\",\"<br/>\", Results))\ndf1_mapdata\n\n# A tibble: 12 × 5\n   region        long   lat Results                                      popup…¹\n   <chr>        <dbl> <dbl> <chr>                                        <chr>  \n 1 Australia   137.   -25.2 50% fatigue, 35.7% arthralgia, 21.4% myalgi… <b> Au…\n 2 Austria      13.5   47.6 24% night sweats, 0% fever, 63% abnormal ch… <b> Au…\n 3 Bangladesh   90.5   23.5 33% fatigue, 1.4% arthralgia, 0.6% myalgia,… <b> Ba…\n 4 Belgium       4.73  50.6 25% fatigue, abnormal chest CT: 67% ground … <b> Be…\n 5 China       107.    35.1 62% abnormal chest CT: 35% fibrotic-like ch… <b> Ch…\n 6 Denmark      10.7   55.7 fatigue, myalgia, arthralgia, chills, fever… <b> De…\n 7 France        3.23  46.2 16.8% olfactory dysfunction, 9.6% gustatory… <b> Fr…\n 8 Germany      10.4   51.2 45% fatigue, 15% myalgia, 3% fever, slight … <b> Ge…\n 9 Italy        11.8   42.2 5.9% myalgia, 5.9% arthralgia, 5.5% dyspnoe… <b> It…\n10 Spain        -2.91  40.7 61.2% fatigue, 23.3% dyspnoea, 6.5% chest p… <b> Sp…\n11 UK           -4.10  55.6 fatigue, myalgia, fever, dyspnoea, cough, c… <b> UK…\n12 USA        -122.    48.7 44.8% fatigue, 21.3% myalgia, 15.8% arthral… <b> US…\n# … with abbreviated variable name ¹​popup_info\n\n\n\nleaflet() %>% \n  # initialising the graphics environment for map\n  addTiles() %>% \n  # add circle markers to map\n  # use the df1_mapdata dataset containing countries, longitudes, latitudes and long COVID results\n  # add data, latitudes, longitudes, radius of circles, pop up information\n  addCircleMarkers(data = df1_mapdata, lat = ~lat, lng = ~long, radius = ~3, popup = ~popup_info)\n\n\n\nInteractive map for long COVID symptoms\n\n\nABG = arterial blood gas, CT = computed tomography, CRP = c-reactive protein, DLCO = diffusing capacity for carbon monoxide, FBC = full blood count, FEV1 = forced expiratory volume in one second, FVC = forced vital capacity, IL-6 = interleukin-6, LFT = liver function test, LVEF = left ventricular ejection fraction, NT-proBNP = N-terminal pro B-type natriuretic peptide, PTSD = posttraumatic stress disorder, 6MWT = 6-min walk test, U&E = urea and electrolyte, TFT = thyroid function test\n\n\n\nText mining for word cloud\nWhen skimming through the Results column, it appeared some of the terms recorded were repetitive, so a wordcloud might be another interesting way to see if it could highlight any particular long COVID symptoms from this meta-analysis.\n\n# Select the results column\ntext <- df$Results\n# Remove numbers from the texts so that the digits won't appear in the wordcloud\ntext1 <- str_replace_all(text, \"[:digit:]\", \"\")\ntext1\n\n [1] \".% myalgia, .% arthralgia\"                                                                                                                                                                                                                                \n [2] \".% dyspnoea, .% cough, .% chest pain, .% reduced DLCO, normal spirometry\"                                                                                                                                                                                 \n [3] \"% PTSD symptoms\"                                                                                                                                                                                                                                          \n [4] \"% gustatory dysfunction, .% olfactory dysfunction\"                                                                                                                                                                                                        \n [5] \".% diarrhoea\"                                                                                                                                                                                                                                             \n [6] \"fatigue, myalgia, arthralgia, chills, fever\"                                                                                                                                                                                                              \n [7] \"dyspnoea, cough, chest pain, sputum production\"                                                                                                                                                                                                           \n [8] \"memory issues, concentration issues, headache\"                                                                                                                                                                                                            \n [9] \"olfactory dysfunction, gustatory dysfunction, sore throat, rhinorrhoea, sneezing\"                                                                                                                                                                         \n[10] \"diarrhoea, anorexia, abdominal pain, nausea\"                                                                                                                                                                                                              \n[11] \"red runny eyes\"                                                                                                                                                                                                                                           \n[12] \"% olfactory dysfunction\"                                                                                                                                                                                                                                  \n[13] \".% olfactory dysfunction, .% gustatory dysfunction\"                                                                                                                                                                                                       \n[14] \"% fatigue, % myalgia, % fever, slight pain/discomfort\"                                                                                                                                                                                                    \n[15] \"% dyspnoea, % cough. Normal spirometry, normal ABG, reduced DLCO, reduced distance on MWT\"                                                                                                                                                                \n[16] \"% cognitive issues, % headache, mild depression, subthreshold anxiety\"                                                                                                                                                                                    \n[17] \"% olfactory dysfunction, % rhinorrhoea, % gustatory dysfunction, % sore throat\"                                                                                                                                                                           \n[18] \"% diarrhoea, % nausea, % abdominal pain, normal LFTs\"                                                                                                                                                                                                     \n[19] \"% angina, normal left ventricular function, normal right ventricular function, normal cardiac biomarkers\"                                                                                                                                                 \n[20] \"normal FBC, normal coagulation screen, raised ferritin, potentially raised D-dimer, normal U&Es, normal CRP, normal procalcitonin, normal TFTs, normal IL-\"                                                                                               \n[21] \".% fatigue\"                                                                                                                                                                                                                                               \n[22] \".% dyspnoea, .% chest pain, .% cough\"                                                                                                                                                                                                                     \n[23] \"% fatigue\"                                                                                                                                                                                                                                                \n[24] \"abnormal chest CT: % ground glass opacities, % reticulations, % fibrotic lesions/traction bronchiectasis, % consolidations. % reduced DLCO, % dyspnoea, % dry cough, % chest tightness, normal spirometry\"                                                \n[25] \"% fatigue\"                                                                                                                                                                                                                                                \n[26] \"depression, concentration issues\"                                                                                                                                                                                                                         \n[27] \"% olfactory/gustatory dysfunction\"                                                                                                                                                                                                                        \n[28] \"alopecia\"                                                                                                                                                                                                                                                 \n[29] \"fatigue, arthralgia, myalgia\"                                                                                                                                                                                                                             \n[30] \"dyspnoea, cough\"                                                                                                                                                                                                                                          \n[31] \"headache\"                                                                                                                                                                                                                                                 \n[32] \"rhinorrhoea, olfactory dysfunction, gustatory dysfunction, sore throat\"                                                                                                                                                                                   \n[33] \"% abnormal chest CT: % fibrotic-like changes, % ground glass opacities/interstitial thickening, nodules/masses, interlobar pleural traction, pulmonary atelectasis and bronchiectasis. % reduced DLCO, % mild dyspnoea, % sputum production, .% dry cough\"\n[34] \"% fatigue, .% arthralgia, .% myalgia\"                                                                                                                                                                                                                     \n[35] \".% cough, % dyspnoea, .% chest pain\"                                                                                                                                                                                                                      \n[36] \".% headache\"                                                                                                                                                                                                                                              \n[37] \".% olfactory dysfunction, .% rhinorrhoea\"                                                                                                                                                                                                                 \n[38] \"no abdominal pain\"                                                                                                                                                                                                                                        \n[39] \".% fatigue, .% myalgia, .% arthralgia, .% fever, .% ulcer\"                                                                                                                                                                                                \n[40] \".% dyspnoea, .% cough, .% sputum production\"                                                                                                                                                                                                              \n[41] \".% headache, .% cognitive issues\"                                                                                                                                                                                                                         \n[42] \".% gustatory dysfunction, .% olfactory dysfunction\"                                                                                                                                                                                                       \n[43] \".% diarrhoea\"                                                                                                                                                                                                                                             \n[44] \".% eye irritation, .% ulcer\"                                                                                                                                                                                                                              \n[45] \"% fatigue, % myalgia\"                                                                                                                                                                                                                                     \n[46] \"% dyspnoea, % cough, % chest pain, % sputum production\"                                                                                                                                                                                                   \n[47] \"% concentration issues, % headache, % paraesthesia\"                                                                                                                                                                                                       \n[48] \"% gustatory dysfunction, % olfactory dysfunction, % sore throat\"                                                                                                                                                                                          \n[49] \"% abdominal pain, % diarrhoea, % nausea, % anorexia\"                                                                                                                                                                                                      \n[50] \"% fatigue, .% arthralgia, .% myalgia\"                                                                                                                                                                                                                     \n[51] \".% cough, % dyspnoea, .% chest pain\"                                                                                                                                                                                                                      \n[52] \".% circadian rhythm disorders, .% headache, .% sleep disturbance, .% adjustment disorder\"                                                                                                                                                                 \n[53] \".% vertigo, % olfactory dysfunction\"                                                                                                                                                                                                                      \n[54] \".% palpitation\"                                                                                                                                                                                                                                           \n[55] \".% subjective olfactory dysfunction, .% objective olfactory  dysfunction (discrimination and identification issues)\"                                                                                                                                      \n[56] \".% fatigue, .% rheumatological issues\"                                                                                                                                                                                                                    \n[57] \"% dyspnoea, % cough, .% chest pain\"                                                                                                                                                                                                                       \n[58] \".% neurological disorders, .% psychiatric disorders, .% headache\"                                                                                                                                                                                         \n[59] \".% olfactory/gustatory dysfunction\"                                                                                                                                                                                                                       \n[60] \".% gastrointestinal disorders\"                                                                                                                                                                                                                            \n[61] \".% alopecia, .% cutaneous manifestations, .% ocular symptoms\"                                                                                                                                                                                             \n[62] \"% night sweats, % fever\"                                                                                                                                                                                                                                  \n[63] \"% abnormal chest CT: ground-glass opacities, reticular lesions, consolidations, bronchial dilation. % dyspnoea, abnormal spirometry: % reduced FVC, % reduced FEV, normal FEV/FVC. % reduced DLCO, % cough\"                                               \n[64] \"% sleep disorders\"                                                                                                                                                                                                                                        \n[65] \"% olfactory dysfunction\"                                                                                                                                                                                                                                  \n[66] \"% diarrhoea/vomiting\"                                                                                                                                                                                                                                     \n[67] \"% normal LVEF, % diastolic dysfunction on echo, % raised NT-proBNP, % pulmonary hypertension, % pericardial effusion\"                                                                                                                                     \n[68] \"raised D-dimer, potentially raised ferritin, normal CRP, normal procalcitonin, normal IL-\"                                                                                                                                                                \n[69] \"fatigue, myalgia, fever\"                                                                                                                                                                                                                                  \n[70] \"dyspnoea, cough, chest pain\"                                                                                                                                                                                                                              \n[71] \"headache, paraesthesia, numbness, concentration/ memory issues\"                                                                                                                                                                                           \n[72] \"olfactory dysfunction, sore throat, hoarse voice, tinnitus, earache\"                                                                                                                                                                                      \n[73] \"diarrhoea, abdominal pain\"                                                                                                                                                                                                                                \n[74] \"palpitations/tachycardia\"                                                                                                                                                                                                                                 \n[75] \"% olfactory dysfunction, .% gustatory dysfunction\"                                                                                                                                                                                                        \n\n\n\n# Change the text into a tibble\ntext_df <- tibble(line = 1:75, text = text1)\ntext_df\n\n# A tibble: 75 × 2\n    line text                                                                   \n   <int> <chr>                                                                  \n 1     1 .% myalgia, .% arthralgia                                              \n 2     2 .% dyspnoea, .% cough, .% chest pain, .% reduced DLCO, normal spiromet…\n 3     3 % PTSD symptoms                                                        \n 4     4 % gustatory dysfunction, .% olfactory dysfunction                      \n 5     5 .% diarrhoea                                                           \n 6     6 fatigue, myalgia, arthralgia, chills, fever                            \n 7     7 dyspnoea, cough, chest pain, sputum production                         \n 8     8 memory issues, concentration issues, headache                          \n 9     9 olfactory dysfunction, gustatory dysfunction, sore throat, rhinorrhoea…\n10    10 diarrhoea, anorexia, abdominal pain, nausea                            \n# … with 65 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\n\n# Tokenise the texts in the selected column\ntext_df1 <- text_df %>% \n  unnest_tokens(word, text)\ntext_df1\n\n# A tibble: 399 × 2\n    line word      \n   <int> <chr>     \n 1     1 myalgia   \n 2     1 arthralgia\n 3     2 dyspnoea  \n 4     2 cough     \n 5     2 chest     \n 6     2 pain      \n 7     2 reduced   \n 8     2 dlco      \n 9     2 normal    \n10     2 spirometry\n# … with 389 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\n\ntext_df1 %>% \n  # Remove stop_words\n  anti_join(stop_words) %>% \n  # Count the frequency of appearance of each word\n  count(word) %>% \n  # Then create a wordcloud\n  with(wordcloud(word, n, colors = brewer.pal(8,\"Dark2\")))\n\n\n\n# display.brewer.all to display all colour palettes if wanting to use different colours\n\nA known drawback of wordcloud was that the length of a word might influence how big it might appear in the wordcloud, so it was not completely dependent on the word frequencies in a set of texts. Nevertheless, it was one of the ways to get a rough idea about the most common terms cropping up in collected texts. This last part was more like a small exercise for me and also for anyone who might want to try this but did not where to start.\n\n\n\nSummary\nLong COVID had shown a very versatile and diverse range of signs and symptoms, often resembling other known post-viral illnesses such as myalgic encephalomyelitis and chronic fatigue syndrome, the interactive map above would enable readers to see specific long COVID symptoms for selected countries. People with diabetes, hypertension and IHD might have higher risk of suffering from long COVID if they were infected with the coronoviruses. The types of co-morbidities were not limited to these three unfortunately and several other chronic illnesses mentioned above might also contribute to similar risk. The most affected body systems in long COVID were in respiratory tract, ear, nose and throat areas, musculoskeletal parts, gastrointestinal tract and last, but not the least, neuropsychiatric systems which could bring fatigue and memory/concentration issue, or more widely known as the “brain fog”. All of these outcomes also did not vary widely from earlier meta-analyses on long COVID, reiterating the wide health ramifications that COVID-19 could inflict upon global populations.\n\nAcknowledgement\nI have to thank several online resources when I was trying to build the interactive map. Most notably, I’ve adapted my codes based on these two useful online resources:\n\nR tutorial: Creating Maps and mapping data with ggplot2 by Dr Paul Christiansen\nCreating interactive maps in R by A&G Statworks\n\nI also have to thank all the package creators for all the packages used here and all the authors of the journal paper (as mentioned under “Source of dataset”) which provided the long COVID data.\n\nsessionInfo()\n\nR version 4.2.0 (2022-04-22)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Catalina 10.15.7\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_NZ.UTF-8/en_NZ.UTF-8/en_NZ.UTF-8/C/en_NZ.UTF-8/en_NZ.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] wordcloud_2.6      RColorBrewer_1.1-3 tidytext_0.3.4     leaflet_2.1.1     \n [5] knitr_1.39         forcats_0.5.1      stringr_1.4.0      dplyr_1.0.9       \n [9] purrr_0.3.4        readr_2.1.2        tidyr_1.2.0        tibble_3.1.8      \n[13] ggplot2_3.3.6      tidyverse_1.3.2   \n\nloaded via a namespace (and not attached):\n [1] httr_1.4.3          maps_3.4.0          bit64_4.0.5        \n [4] vroom_1.5.7         jsonlite_1.8.0      modelr_0.1.8       \n [7] assertthat_0.2.1    highr_0.9           googlesheets4_1.0.0\n[10] cellranger_1.1.0    yaml_2.3.5          pillar_1.8.0       \n[13] backports_1.4.1     lattice_0.20-45     glue_1.6.2         \n[16] digest_0.6.29       rvest_1.0.2         colorspace_2.0-3   \n[19] htmltools_0.5.3     Matrix_1.4-1        pkgconfig_2.0.3    \n[22] broom_1.0.0         haven_2.5.0         scales_1.2.0       \n[25] tzdb_0.3.0          googledrive_2.0.0   farver_2.1.1       \n[28] generics_0.1.3      ellipsis_0.3.2      withr_2.5.0        \n[31] cli_3.4.1           magrittr_2.0.3      crayon_1.5.1       \n[34] readxl_1.4.0        evaluate_0.15       tokenizers_0.2.1   \n[37] janeaustenr_1.0.0   fs_1.5.2            fansi_1.0.3        \n[40] SnowballC_0.7.0     xml2_1.3.3          tools_4.2.0        \n[43] hms_1.1.1           gargle_1.2.0        lifecycle_1.0.1    \n[46] munsell_0.5.0       reprex_2.0.1        compiler_4.2.0     \n[49] rlang_1.0.4         grid_4.2.0          rstudioapi_0.13    \n[52] htmlwidgets_1.5.4   crosstalk_1.2.0     labeling_0.4.2     \n[55] rmarkdown_2.14      gtable_0.3.0        DBI_1.1.3          \n[58] R6_2.5.1            lubridate_1.8.0     fastmap_1.1.0      \n[61] bit_4.0.4           utf8_1.2.2          stringi_1.7.8      \n[64] parallel_4.2.0      Rcpp_1.0.9          vctrs_0.4.1        \n[67] dbplyr_2.2.1        tidyselect_1.1.2    xfun_0.31          \n\n\n\n\n\n\n\n\nFootnotes\n\n\nIt took probably at least half an hour to figure this out… eventually I thought to look at the column itself long enough to see if I’d missed anything… then voila!↩︎\nischaemic heart disease↩︎\nchronic obstructive pulmonary disease↩︎\nchronic kidney disease↩︎"
  },
  {
    "objectID": "posts/Blog-Social network/Embracing_social_network.html",
    "href": "posts/Blog-Social network/Embracing_social_network.html",
    "title": "Embracing social network",
    "section": "",
    "text": "Photo by visuals on Unsplash\n\n\nOne of the reasons that I’ve finally decided to post on Twitter is that I’ve heard about the active and friendly R community on Twitter and thought if I could get any feedbacks on my short piece of work in R then that’ll be helpful for me to see if I’ve missed or done anything incorrectly since there’s not really a mentor person around that is able to do this at the moment (I’ve dreadfully taken the self-learning route, rather than attending data science bootcamps or get “another” degree, which is something I’m not really fancied at doing again, after already having MPhil and PhD already…). Luckily, I did get one helpful response and with a small number of likes so perhaps I’m not doing it entirely wrong (hopefully). My future plans will likely be trying to do a #TidyTuesday data visualisation and post whenever I can to learn and grow.\nI’ve also recently edited my rare disease drug projects in R and Python to add summaries of findings from these two projects so it’s easier for anyone to read, especially if there’s not really much time to go through long threads of codes in GitHub. I’m also currently working on another project in the rare diseases series on phenotypes associated with rare diseases from Orphanet. My plan at the moment is to use Python to clean the data (I’ve tried to load it in RStudio via a URL with XML file, it’s >4000 rows and taking quite a long time to run on my laptop, so will stick to Python on Anaconda as it has loaded a lot faster than RStudio, then perhaps once it’s cleaned, I’ll re-import it back into RStudio for analysis and visualisations)."
  },
  {
    "objectID": "posts/3. Long COVID data in SQL/Long_COVID_SQL.html",
    "href": "posts/3. Long COVID data in SQL/Long_COVID_SQL.html",
    "title": "Long COVID data in SQL",
    "section": "",
    "text": "The process\nMySQL server was installed with DBeaver used as the GUI. Four tables (Continents, Countries, Risk factors and Hospitalisation) in .csv file formats were imported into the newly created database named LongCovid. A series of SQL queries were written and performed. Two views were created so that selected data were stored for future use, such as for data visualisations in Tableau.\n\n\nProject link\nSQL file can be found in my GitHub repository of Portfolio-projects at this URL: https://github.com/jhylin/Portfolio-projects or directly here to view.\n\n\n\n\n\nFootnotes\n\n\nThe published date reflected the most recent date I worked on associated file with the project, prior to the blog move. This work is under CC BY-SA 4.0 International License for anyone interested in exploring the area further.↩︎"
  },
  {
    "objectID": "posts/Blog-Blog move/Blog_move.html",
    "href": "posts/Blog-Blog move/Blog_move.html",
    "title": "Blog move",
    "section": "",
    "text": "Photo by Lia Trevarthen on Unsplash\n\n\nSo here is my very first Quarto blog, deployed using Netlify initially and then I also figured out how to deploy it on GitHub Pages, so now I’ve actually got two extra sites running. The process to deploy on Netlify was quite simple as many people have already mentioned (GitHub Pages were also not too complicated as well once I’ve grasped the deployment workflow). I’m still pondering if I should write something on how I started Quarto blogs, but considering so many talented people have already talked about it, I may not go down this route (consider visiting Bea Milz’s lovely post on “Creating a blog with Quarto in 10 steps” - this was what I followed to get my Quarto blog up and running).\nI will be slowly moving my current posts and portfolio projects from WordPress to Quarto blogs. Who knows, maybe I may end up working on building websites, or doing other things that I’ve never imagined I would do before!"
  },
  {
    "objectID": "posts/5. Phenotypes associated with rare diseases/Phenotypes_rare_diseases.html",
    "href": "posts/5. Phenotypes associated with rare diseases/Phenotypes_rare_diseases.html",
    "title": "Phenotypes associated with rare diseases",
    "section": "",
    "text": "Source of dataset\nOrphadata: Free access data from Orphanet. © INSERM 1999. Available on http://www.orphadata.org. Data version (XML data version). Dataset (.xml file) from http://www.orphadata.org/cgi-bin/epidemio.html. Latest date of update for the dataset: 14/6/2022 (last accessed 24/7/2022). Creative Commons Attribution 4.0 International.\n\nPhoto by Sangharsh Lohakare on Unsplash\nThe following libraries were used for the exploratory data analysis:\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(ggplot2)\nlibrary(knitr)\n\nRead imported .csv file after data cleaning in Python.\n\ndf <- read_csv(\"rare_disease_phenotypes.csv\")\n\nRows: 112243 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (10): Disorder group, Disorder type, Diagnostic criteria, HPO frequency...\ndbl   (2): HPO disorder & clinical entity association count, Disorder Orphacode\ndttm  (1): Validation date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nNote: HPO = human phenotype ontology\n\nspec(df)\n\ncols(\n  `Disorder group` = col_character(),\n  `Disorder type` = col_character(),\n  `HPO disorder & clinical entity association count` = col_double(),\n  `Diagnostic criteria` = col_character(),\n  `HPO frequency` = col_character(),\n  `HPO ID` = col_character(),\n  `Preferred HPO term` = col_character(),\n  `Disorder name` = col_character(),\n  `Disorder Orphacode` = col_double(),\n  Online = col_character(),\n  Source = col_character(),\n  `Validation date` = col_datetime(format = \"\"),\n  `Validation status` = col_character()\n)\n\n\n\n\nExploratory data analysis\nSince I wasn’t intending for this project2 to be extremely long (as most people would likely lose interests by then), I’d like to first ask a question about the dataset, in order to keep it at a reasonably short but informative length. So, here’s the question: what are the most common rare disorders and their associated phenotypic features?\nTo answer it, let’s observe the spread of the disorder groups and types first by formulating a contingency table.\n\ndf_type <- df %>% \n  group_by(`Disorder group`,`Disorder type`) %>% \n  summarise(Number = n())\ndf_type\n\n# A tibble: 11 × 3\n# Groups:   Disorder group [3]\n   `Disorder group`    `Disorder type`                                    Number\n   <chr>               <chr>                                               <int>\n 1 Disorder            Biological anomaly                                     41\n 2 Disorder            Clinical syndrome                                     661\n 3 Disorder            Disease                                             57920\n 4 Disorder            Malformation syndrome                               37634\n 5 Disorder            Morphological anomaly                                2644\n 6 Disorder            Particular clinical situation in a disease or syn…    418\n 7 Group of disorders  Category                                              479\n 8 Group of disorders  Clinical group                                        952\n 9 Subtype of disorder Clinical subtype                                     7394\n10 Subtype of disorder Etiological subtype                                  4060\n11 Subtype of disorder Histopathological subtype                              40\n\n\nAfter a quick view on the column of “Disorder group”, it mainly provided different disorder types a group label for each, which to a certain extent, was not necessary at this early stage. So this column was removed for now from the contingency table, in order to focus solely on, “Disorder type” with the number of counts (or times it appeared in the dataset).\n\ndf_type <- df %>% \n  group_by(`Disorder type`) %>% \n  summarise(Number = n())\ndf_type\n\n# A tibble: 11 × 2\n   `Disorder type`                                        Number\n   <chr>                                                   <int>\n 1 Biological anomaly                                         41\n 2 Category                                                  479\n 3 Clinical group                                            952\n 4 Clinical subtype                                         7394\n 5 Clinical syndrome                                         661\n 6 Disease                                                 57920\n 7 Etiological subtype                                      4060\n 8 Histopathological subtype                                  40\n 9 Malformation syndrome                                   37634\n10 Morphological anomaly                                    2644\n11 Particular clinical situation in a disease or syndrome    418\n\n\nThen to visualise this in a graphic way, a lollypop chart was built horizontally, with different types of rare disorders on the y-axis and the number of each type on the x-axis.\n\nggplot(data = df_type, aes(x = `Disorder type`, y = `Number`)) +\n  geom_segment(aes(x = `Disorder type`, xend = `Disorder type`, y = 0, yend = `Number`), colour = \"dark blue\") +\n  geom_point(colour = \"dark green\", size = 2, alpha = 0.6) +\n  theme_light() +\n  coord_flip() \n\n\n\n\nTwo disorder types stood out the most, with “Disease” type appeared 57,920 times and “Malformation syndrome” at 37,634 times. To understand further what each of these two disorder types were, a direct reference3 was used. According to the source of the dataset:\nThe definition of “Disease” in the rare disorder context was “a disorder with homogeneous therapeutic possibilities and an identified physiopathological mechanism…”, one thing also worth noting was that this type did not include any developmental anomalies.\nFor “Malformation syndrome”, this was defined as, “A disorder resulting from a developmental anomaly involving more than one morphogenetic field. Malformative sequences and associations are included.”\nTo demonstrate this in a tabular form, with corresponding proportions of each disorder type in the dataset, the following codes were used:\n\ndf1 <- df %>% \n  group_by(`Disorder type`) %>% \n  summarise(n = n()) %>% \n  mutate(prop = n/sum(n))\ndf1\n\n# A tibble: 11 × 3\n   `Disorder type`                                            n     prop\n   <chr>                                                  <int>    <dbl>\n 1 Biological anomaly                                        41 0.000365\n 2 Category                                                 479 0.00427 \n 3 Clinical group                                           952 0.00848 \n 4 Clinical subtype                                        7394 0.0659  \n 5 Clinical syndrome                                        661 0.00589 \n 6 Disease                                                57920 0.516   \n 7 Etiological subtype                                     4060 0.0362  \n 8 Histopathological subtype                                 40 0.000356\n 9 Malformation syndrome                                  37634 0.335   \n10 Morphological anomaly                                   2644 0.0236  \n11 Particular clinical situation in a disease or syndrome   418 0.00372 \n\n\nThe table was then rearranged with proportions in descending order (from highest to lowest). It also showed the top two were “Disease” (51.6%) and “Malformation syndrome” (33.5%).\n\ndf1 %>% arrange(desc(prop))\n\n# A tibble: 11 × 3\n   `Disorder type`                                            n     prop\n   <chr>                                                  <int>    <dbl>\n 1 Disease                                                57920 0.516   \n 2 Malformation syndrome                                  37634 0.335   \n 3 Clinical subtype                                        7394 0.0659  \n 4 Etiological subtype                                     4060 0.0362  \n 5 Morphological anomaly                                   2644 0.0236  \n 6 Clinical group                                           952 0.00848 \n 7 Clinical syndrome                                        661 0.00589 \n 8 Category                                                 479 0.00427 \n 9 Particular clinical situation in a disease or syndrome   418 0.00372 \n10 Biological anomaly                                        41 0.000365\n11 Histopathological subtype                                 40 0.000356\n\n\n\nDistributions of HPO frequency\nThis was followed by checking out the distributions of HPO frequency to see which categories had the most and least number of counts.\n\ndf_freq <- df %>% \n  count(`HPO frequency`) %>% \n  arrange(desc(n))\ndf_freq\n\n# A tibble: 7 × 2\n  `HPO frequency`            n\n  <chr>                  <int>\n1 Occasional (29-5%)     41140\n2 Frequent (79-30%)      37480\n3 Very frequent (99-80%) 25892\n4 Very rare (<4-1%)       6414\n5 Excluded (0%)            705\n6 Obligate (100%)          610\n7 <NA>                       2\n\n\nResults for rare disorders with obligate or 100% frequency in patient’s populations were then filtered, showing disorder type, HPO frequency and disorder name. Specifically, I wanted to find out the disorder names associated with the “Disease” disorder type with HPO frequency of “Obligate (100%)”.\n\ndf_freq_ob <- df %>% \n  filter(`Disorder type` == \"Disease\", `HPO frequency` == \"Obligate (100%)\") %>% \n  select(`Disorder type`, `HPO frequency`, `Disorder name`)\ndf_freq_ob\n\n# A tibble: 404 × 3\n   `Disorder type` `HPO frequency` `Disorder name`                              \n   <chr>           <chr>           <chr>                                        \n 1 Disease         Obligate (100%) Retinoblastoma                               \n 2 Disease         Obligate (100%) Parathyroid carcinoma                        \n 3 Disease         Obligate (100%) Pituitary carcinoma                          \n 4 Disease         Obligate (100%) Familial hypocalciuric hypercalcemia         \n 5 Disease         Obligate (100%) Familial hypocalciuric hypercalcemia         \n 6 Disease         Obligate (100%) Ravine syndrome                              \n 7 Disease         Obligate (100%) Ravine syndrome                              \n 8 Disease         Obligate (100%) Interstitial granulomatous dermatitis with a…\n 9 Disease         Obligate (100%) Interstitial granulomatous dermatitis with a…\n10 Disease         Obligate (100%) PLIN1-related familial partial lipodystrophy \n# … with 394 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\nI’d then like to look into associated counts of appearance of each disorder name. When I cross-checked with the full dataset in table view, I’ve noted that the number of appearance of each disorder name is linked to the number of preferred HPO phenotype terms for each of these disorder types.\n\ndf2 <- df_freq_ob %>% \n  count(`Disorder name`) \ndf2 %>% arrange(desc(n))\n\n# A tibble: 239 × 2\n   `Disorder name`                                                             n\n   <chr>                                                                   <int>\n 1 Autosomal recessive complex spastic paraplegia due to Kennedy pathway …    10\n 2 STT3A-CDG                                                                   9\n 3 STT3B-CDG                                                                   9\n 4 Spastic paraplegia-Paget disease of bone syndrome                           8\n 5 Oculocutaneous albinism type 5                                              7\n 6 PLIN1-related familial partial lipodystrophy                                7\n 7 Plummer-Vinson syndrome                                                     5\n 8 SSR4-CDG                                                                    5\n 9 Cholesterol-ester transfer protein deficiency                               4\n10 Isolated follicle stimulating hormone deficiency                            4\n# … with 229 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\nTo show this, let’s link preferred HPO terms to a disorder name such as this one, “Autosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction”, which had the “Disease” disorder type with obligate or 100% HPO frequency.\n\ndf_disease <- df %>% \n  filter(`Disorder type` == \"Disease\", `HPO frequency` == \"Obligate (100%)\", `Disorder name` == \"Autosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction\") %>% \n  select(`Disorder type`, `HPO frequency`, `Disorder name`, `Preferred HPO term`)\nkable(df_disease)\n\n\n\n\n\n\n\n\n\n\nDisorder type\nHPO frequency\nDisorder name\nPreferred HPO term\n\n\n\n\nDisease\nObligate (100%)\nAutosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction\nProgressive spastic paraplegia\n\n\nDisease\nObligate (100%)\nAutosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction\nMicrocephaly\n\n\nDisease\nObligate (100%)\nAutosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction\nModerately short stature\n\n\nDisease\nObligate (100%)\nAutosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction\nNasal, dysarthic speech\n\n\nDisease\nObligate (100%)\nAutosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction\nDelayed gross motor development\n\n\nDisease\nObligate (100%)\nAutosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction\nProgressive spasticity\n\n\nDisease\nObligate (100%)\nAutosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction\nLower limb hyperreflexia\n\n\nDisease\nObligate (100%)\nAutosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction\nAnkle clonus\n\n\nDisease\nObligate (100%)\nAutosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction\nRetinal pigment epithelial mottling\n\n\nDisease\nObligate (100%)\nAutosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction\nProgressive spastic paraparesis\n\n\n\n\n\nAs shown in the dataframe above, under the column name, “Preferred HPO term”, there were a total of ten different HPO phenotype terms associated with this particular rare disease with 100% HPO frequency within the patient population for this specific type of spastic paraplegia.\nBy using similar filtering method, we could quickly narrow down any particular rare disease of interest to find out specific phenotype or clinical features, along with associated HPO phenotype frequency, for further investigations.\nFor “Malformation syndrome”, a similar search process was used to find out what was the most common phenotypes associated with it.\n\ndf_freq_ma <- df %>% \n  filter(`Disorder type` == \"Malformation syndrome\", `HPO frequency` == \"Obligate (100%)\") %>%\n  select(`Disorder type`, `HPO frequency`, `Disorder name`)\ndf_freq_ma\n\n# A tibble: 125 × 3\n   `Disorder type`       `HPO frequency` `Disorder name`                  \n   <chr>                 <chr>           <chr>                            \n 1 Malformation syndrome Obligate (100%) CLAPO syndrome                   \n 2 Malformation syndrome Obligate (100%) CLAPO syndrome                   \n 3 Malformation syndrome Obligate (100%) Weaver-Williams syndrome         \n 4 Malformation syndrome Obligate (100%) Weaver-Williams syndrome         \n 5 Malformation syndrome Obligate (100%) Weaver-Williams syndrome         \n 6 Malformation syndrome Obligate (100%) Weaver-Williams syndrome         \n 7 Malformation syndrome Obligate (100%) Weaver-Williams syndrome         \n 8 Malformation syndrome Obligate (100%) Weaver-Williams syndrome         \n 9 Malformation syndrome Obligate (100%) Lethal recessive chondrodysplasia\n10 Malformation syndrome Obligate (100%) Lethal recessive chondrodysplasia\n# … with 115 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\nCount() was used to find out the number of appearance of each disorder name in descending order.\n\ndf3 <- df_freq_ma %>% \n  count(`Disorder name`)\ndf3 %>% arrange(desc(n))\n\n# A tibble: 40 × 2\n   `Disorder name`                                                             n\n   <chr>                                                                   <int>\n 1 Hydrocephalus-obesity-hypogonadism syndrome                                12\n 2 Pelviscapular dysplasia                                                    11\n 3 46,XX disorder of sex development-skeletal anomalies syndrome               9\n 4 X-linked microcephaly-growth retardation-prognathism-cryptorchidism sy…     9\n 5 Severe intellectual disability-hypotonia-strabismus-coarse face-planov…     7\n 6 Lethal recessive chondrodysplasia                                           6\n 7 Weaver-Williams syndrome                                                    6\n 8 SERKAL syndrome                                                             5\n 9 Patent ductus arteriosus-bicuspid aortic valve-hand anomalies syndrome      4\n10 46,XX gonadal dysgenesis                                                    3\n# … with 30 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\nTo show one of the examples of the most common malformation syndrome with the most associated phenotypic features (with a total of 12 different phenotypic descriptions):\n\ndf_mal_syn <- df %>%\n  filter(`Disorder type` == \"Malformation syndrome\", `HPO frequency` == \"Obligate (100%)\", `Disorder name` == \"Hydrocephalus-obesity-hypogonadism syndrome\") %>% \n  select(`Disorder type`, `HPO frequency`, `Disorder name`, `Preferred HPO term`)\nkable(df_mal_syn)\n\n\n\n\n\n\n\n\n\n\nDisorder type\nHPO frequency\nDisorder name\nPreferred HPO term\n\n\n\n\nMalformation syndrome\nObligate (100%)\nHydrocephalus-obesity-hypogonadism syndrome\nHydrocephalus\n\n\nMalformation syndrome\nObligate (100%)\nHydrocephalus-obesity-hypogonadism syndrome\nShort neck\n\n\nMalformation syndrome\nObligate (100%)\nHydrocephalus-obesity-hypogonadism syndrome\nGynecomastia\n\n\nMalformation syndrome\nObligate (100%)\nHydrocephalus-obesity-hypogonadism syndrome\nHypergonadotropic hypogonadism\n\n\nMalformation syndrome\nObligate (100%)\nHydrocephalus-obesity-hypogonadism syndrome\nIntellectual disability, mild\n\n\nMalformation syndrome\nObligate (100%)\nHydrocephalus-obesity-hypogonadism syndrome\nObesity\n\n\nMalformation syndrome\nObligate (100%)\nHydrocephalus-obesity-hypogonadism syndrome\nMitral valve prolapse\n\n\nMalformation syndrome\nObligate (100%)\nHydrocephalus-obesity-hypogonadism syndrome\nLow posterior hairline\n\n\nMalformation syndrome\nObligate (100%)\nHydrocephalus-obesity-hypogonadism syndrome\nHigh, narrow palate\n\n\nMalformation syndrome\nObligate (100%)\nHydrocephalus-obesity-hypogonadism syndrome\nCubitus valgus\n\n\nMalformation syndrome\nObligate (100%)\nHydrocephalus-obesity-hypogonadism syndrome\nShort stature\n\n\nMalformation syndrome\nObligate (100%)\nHydrocephalus-obesity-hypogonadism syndrome\nShort 4th metacarpal\n\n\n\n\n\n\n\nExplore rare disease validation date\nNow, to add one more piece of work towards this exploratory data analysis, I thought to check out the Validation date column. “Validation date” in this context meant the dates when the annotations of HPO terms were made for each rare disorder, which were based on the source articles listed (as shown in the Source column).\nFirstly, I started with the “Disease” disorder type and singled out the year component from the Validation date column.\n\ndf_val_date <- df %>% \n  mutate(year = year(`Validation date`), label = TRUE, abbr = FALSE)\ndf_val_date\n\n# A tibble: 112,243 × 16\n   Disorder gr…¹ Disor…² HPO d…³ Diagn…⁴ HPO f…⁵ HPO I…⁶ Prefe…⁷ Disor…⁸ Disor…⁹\n   <chr>         <chr>     <dbl> <chr>   <chr>   <chr>   <chr>   <chr>     <dbl>\n 1 Disorder      Disease      59 Diagno… Very f… HP:000… Pectus… Marfan…     558\n 2 Disorder      Disease      59 Diagno… Very f… HP:000… Striae… Marfan…     558\n 3 Disorder      Disease      59 Diagno… Very f… HP:000… Arachn… Marfan…     558\n 4 Disorder      Disease      59 Diagno… Very f… HP:000… Dispro… Marfan…     558\n 5 Disorder      Disease      59 Diagno… Very f… HP:000… Pes pl… Marfan…     558\n 6 Disorder      Disease      59 Diagno… Very f… HP:000… Sponta… Marfan…     558\n 7 Disorder      Disease      59 Diagno… Very f… HP:000… Dilata… Marfan…     558\n 8 Disorder      Disease      59 Diagno… Freque… HP:000… Myopia  Marfan…     558\n 9 Disorder      Disease      59 Diagno… Freque… HP:000… Dental… Marfan…     558\n10 Disorder      Disease      59 Diagno… Freque… HP:000… Pectus… Marfan…     558\n# … with 112,233 more rows, 7 more variables: Online <chr>, Source <chr>,\n#   `Validation date` <dttm>, `Validation status` <chr>, year <dbl>,\n#   label <lgl>, abbr <lgl>, and abbreviated variable names ¹​`Disorder group`,\n#   ²​`Disorder type`, ³​`HPO disorder & clinical entity association count`,\n#   ⁴​`Diagnostic criteria`, ⁵​`HPO frequency`, ⁶​`HPO ID`, ⁷​`Preferred HPO term`,\n#   ⁸​`Disorder name`, ⁹​`Disorder Orphacode`\n# ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\n\n\nTo show this in a dataframe, observations for “Disease” disorder type were shown by using a filter:\n\ndf_val_date_d <- df_val_date %>% \n  select(`Disorder type`, year) %>% \n  filter(`Disorder type` == \"Disease\")\ndf_val_date_d\n\n# A tibble: 57,920 × 2\n   `Disorder type`  year\n   <chr>           <dbl>\n 1 Disease          2016\n 2 Disease          2016\n 3 Disease          2016\n 4 Disease          2016\n 5 Disease          2016\n 6 Disease          2016\n 7 Disease          2016\n 8 Disease          2016\n 9 Disease          2016\n10 Disease          2016\n# … with 57,910 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\nThen to make it easier to visualise, the year counts were plotted in a bar graph. Interestingly, 2016 seemed to be the year for rare disorders to be annotated with the most phenotypic features (if referring back to the original dataset, each observation or row was present for a unique “Preferred HPO term” or phenotypic abnormality).\n\ndf_val_date_d %>% \n  ggplot(aes(x = year)) +\n  geom_bar()\n\nWarning: Removed 49 rows containing non-finite values (stat_count).\n\n\n\n\n\nIt was also worth noting that there were 49 rows of non-finite values excluded from the bar graph above. To look into this, a count on the year column of the dataframe df_val_date_d was done, which confirmed that these were the “NA” or missing values in the validation date column.\n\ndf_val_date_d %>% \n  count(year)\n\n# A tibble: 8 × 2\n   year     n\n  <dbl> <int>\n1  2015   567\n2  2016 14193\n3  2017  5419\n4  2018  6297\n5  2019 10525\n6  2020  9402\n7  2021 11468\n8    NA    49\n\n\n\n\n\nSummary\nTo quickly summarise key findings from this work4 regarding phenotypes associated with rare diseases:\n\nAutosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction was one of the most common rare diseases under the Disease disorder type with the most phenotypic abnormalities recorded, which were:\n\n\nprogressive spastic paraplegia\nmicrocephaly\nmoderately short stature\nnasal, dysarthic speech\ndelayed gross motor development\nprogressive spasticity\nlower limb hyperreflexia\nankle clonus\nretinal pigment epithelial mottling\nprogressive spastic paraparesis\n\n\nFor malformation syndrome of the rare disorder type, Hydrocephalus-obesity-hypogonadism syndrome was found to be one of the most common rare diseases with the most phenotypic abnormalities recorded, which were:\n\n\nhydrocephalus\nshort neck\ngynecomastia\nhypergonadotropic hypogonadism\nintellectual disability, mild\nobesity\nmitral valve prolapse\nlow posterior hairline\nhigh, narrow palate\ncubitus valgus\nshort stature\nshort 4th metacarpal\n\n\nThe year of 2016 had the highest number of HPO terms or phenotypic abnormalities annotated to rare disorders from specific named source articles, and on the contrary, 2015 had the lowest counts from the dataset\n\n\n\n\n\n\nFootnotes\n\n\nUsed only for initial data cleaning stage - please see this GitHub link for details. R was used for the rest of the analysis↩︎\nThis work is under CC BY-SA 4.0 International License if anyone is interested in exploring the dataset further↩︎\n“Orphadata: Free access products description” - April 2020. http://www.orphadata.org/cgi-bin/img/PDF/OrphadataFreeAccessProductsDescription.pdf. Version 2↩︎\nIt’s possible to dig further into the dataset e.g. diagnostic criterion and perhaps even bring back some of the columns removed initially, however due to time constraints (due to being a one-person team and also I’d like to start on the COVID-19 antiviral work soon), I’ll leave some room here for the interested to work on the data↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data in life",
    "section": "",
    "text": "Small molecules in ChEMBL database\n\n\n\nData analytics projects\n\n\nPolars\n\n\nRust\n\n\nPython\n\n\nJupyter\n\n\nCheminformatics\n\n\n\n\n\n\n\nJennifer HY Lin\n\n\nDec 22, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMolecular similarities in selected COVID-19 antivirals\n\n\n\nData analytics projects\n\n\nCheminformatics\n\n\nPython\n\n\nRDKit\n\n\n\n\n\n\n\nJennifer HY Lin\n\n\nNov 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPublications\n\n\n\nResearch\n\n\n\n\n\n\n\nJennifer HY Lin\n\n\nOct 23, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPhD project\n\n\n\nResearch\n\n\nDrug discovery & design\n\n\n\n\n\n\n\nJennifer HY Lin\n\n\nOct 23, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLong COVID - an update\n\n\n\nData analytics projects\n\n\nR\n\n\nPython\n\n\nLong COVID\n\n\n\n\n\n\n\nJennifer HY Lin\n\n\nSep 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable scraping from PDF\n\n\n\nData analytics projects\n\n\nPython\n\n\nLong COVID\n\n\n\n\n\n\n\n\nJennifer HY Lin\n\n\nSep 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBlog move\n\n\n\nBlog\n\n\n\n\n\n\n\nJennifer HY Lin\n\n\nAug 6, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPhenotypes associated with rare diseases\n\n\n\nData analytics projects\n\n\nR\n\n\nPython\n\n\nRare diseases\n\n\n\n\n\n\n\nJennifer HY Lin\n\n\nAug 2, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEmbracing social network\n\n\n\nBlog\n\n\n\n\n\n\n\nJennifer HY Lin\n\n\nJul 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNatural history of rare diseases - malformation syndrome\n\n\n\nData analytics projects\n\n\nPython\n\n\nRare diseases\n\n\n\n\n\n\n\nJennifer HY Lin\n\n\nJun 27, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUpdate on portfolio\n\n\n\nBlog\n\n\n\n\n\n\n\nJennifer HY Lin\n\n\nJun 13, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLong COVID data in SQL\n\n\n\nData analytics projects\n\n\nSQL\n\n\nLong COVID\n\n\n\n\n\n\n\nJennifer HY Lin\n\n\nJun 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLong COVID dashboard\n\n\n\nData analytics projects\n\n\nTableau\n\n\nLong COVID\n\n\n\n\n\n\n\n\nJennifer HY Lin\n\n\nMay 31, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPortfolio projects\n\n\n\nBlog\n\n\n\n\n\n\n\nJennifer HY Lin\n\n\nMay 31, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDrugs in rare diseases\n\n\n\nData analytics projects\n\n\nR\n\n\nPython\n\n\nRare diseases\n\n\n\n\n\n\n\nJennifer HY Lin\n\n\nMay 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFocussing on data analytics\n\n\n\nBlog\n\n\n\n\n\n\n\nJennifer HY Lin\n\n\nApr 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe beginning of the data science journey\n\n\n\nBlog\n\n\n\n\n\n\n\nJennifer HY Lin\n\n\nJan 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSERCA project\n\n\n\nResearch\n\n\n\n\n\n\n\nJennifer HY Lin\n\n\nJan 24, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Jennifer HY Lin",
    "section": "",
    "text": "I was initially trained as a pharmacist in New Zealand, and spent several years working at community and hospital pharmacies. Somehow life took me on a detour where I went down the path of doing postgraduate studies. The research mainly focussed on drug discovery and design with medicinal and computational chemistry involved, with numerous hours spent in chemistry (wet) and computer (dry) labs doing experiments. The research work happened in Australia, where I’ve also continued to work as a hospital pharmacist while working on the research projects. Reflecting back, it felt like my brain cells have gone through a major metamorphasis during those years, before I ended up with a MPhil and PhD.\nI’ve then decided to return to New Zealand and the pandemic hit within a few months after, which meant most of my original plans after PhD were forced to change. Subsequently, I discovered my more recent interests in the world of data science and analytics. This then led to this blog, which is really my portfolio, on data analytics work in the healthcare and pharmaceutical fields, as I came from these backgrounds with boundless interests. It’ll also be another channel for me to write personal blog posts detailing my journey in data analytics."
  },
  {
    "objectID": "Test.html",
    "href": "Test.html",
    "title": "Test",
    "section": "",
    "text": "Code\nimport polars as pl\n\ndf = pl.read_csv(\"https://j.mp/iriscsv\")\nprint(df.filter(pl.col(\"sepal_length\") > 5)\n      .groupby(\"species\")\n      .agg(pl.all().sum())\n)"
  },
  {
    "objectID": "test.html",
    "href": "test.html",
    "title": "Test",
    "section": "",
    "text": "Code\nimport polars as pl\n\ndf = pl.read_csv(\"https://j.mp/iriscsv\")\nprint(df.filter(pl.col(\"sepal_length\") > 5)\n      .groupby(\"species\")\n      .agg(pl.all().sum())\n)\n\n\nshape: (3, 5)\n┌────────────┬──────────────┬─────────────┬──────────────┬─────────────┐\n│ species    ┆ sepal_length ┆ sepal_width ┆ petal_length ┆ petal_width │\n│ ---        ┆ ---          ┆ ---         ┆ ---          ┆ ---         │\n│ str        ┆ f64          ┆ f64         ┆ f64          ┆ f64         │\n╞════════════╪══════════════╪═════════════╪══════════════╪═════════════╡\n│ virginica  ┆ 324.5        ┆ 146.2       ┆ 273.1        ┆ 99.6        │\n├╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n│ versicolor ┆ 281.9        ┆ 131.8       ┆ 202.9        ┆ 63.3        │\n├╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n│ setosa     ┆ 116.9        ┆ 81.7        ┆ 33.2         ┆ 6.1         │\n└────────────┴──────────────┴─────────────┴──────────────┴─────────────┘"
  },
  {
    "objectID": "posts/8. Test/test.html",
    "href": "posts/8. Test/test.html",
    "title": "Test",
    "section": "",
    "text": "Code\nimport polars as pl\n\ndf = pl.read_csv(\"https://j.mp/iriscsv\")\nprint(df.filter(pl.col(\"sepal_length\") > 5)\n      .groupby(\"species\")\n      .agg(pl.all().sum())\n)\n\n\nshape: (3, 5)\n┌────────────┬──────────────┬─────────────┬──────────────┬─────────────┐\n│ species    ┆ sepal_length ┆ sepal_width ┆ petal_length ┆ petal_width │\n│ ---        ┆ ---          ┆ ---         ┆ ---          ┆ ---         │\n│ str        ┆ f64          ┆ f64         ┆ f64          ┆ f64         │\n╞════════════╪══════════════╪═════════════╪══════════════╪═════════════╡\n│ versicolor ┆ 281.9        ┆ 131.8       ┆ 202.9        ┆ 63.3        │\n├╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n│ setosa     ┆ 116.9        ┆ 81.7        ┆ 33.2         ┆ 6.1         │\n├╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n│ virginica  ┆ 324.5        ┆ 146.2       ┆ 273.1        ┆ 99.6        │\n└────────────┴──────────────┴─────────────┴──────────────┴─────────────┘"
  },
  {
    "objectID": "posts/8. Small molecules in ChEMBL database/Rust_pl_chembl_cpds.html",
    "href": "posts/8. Small molecules in ChEMBL database/Rust_pl_chembl_cpds.html",
    "title": "Small molecules in ChEMBL database",
    "section": "",
    "text": "Background\nAs my interests gradually grew for Rust, I realised why so many people said it might be a hard programming language to learn. My head was spinning after reading the Rust programming language book and watching a few online teaching videos about it. I then decided to start from something I was more familiar with, and somehow through various online ventures and searching, I’ve managed to start two projects in parallel. The first one was where I used Polars dataframe library, and the second one would be about using Rust through an interactive user interface such as Jupyter notebook. I’ve anticipated that the second project would take much longer time for me to finish, so I would be tackling the first project for now.\nThis project was about using Polars, a blazingly fast dataframe library that was written completely in Rust with a very light Python binding that was available for use via Python or Rust, so I started using Polars via Python on Jupyter Lab initially, which involved data wrangling, some exploratory data analysis (EDA), and a reasonably larger section on using machine learning (ML) through scikit-learn. The editing and publishing of this post was mainly achieved via RStudio IDE.\n\n\n\nInstall Polars\n\n# To install Polars dataframe library\n# Uncomment below to download and install Polars\n#!pip install polars\n\n# Update Polars version\n# Uncomment the line below to update Polars\n#!pip install --upgrade polars\n\nOnce Polars was installed, the next step was to import it for use.\n\nimport polars as pl\n\n\n# Show version of Polars\n# Uncomment line below to check version of Polars installed/updated\n#pl.show_versions()\n\n\n\n\nDownload dataset\nThe dataset, which was purely about small molecules and their physicochemical properties, was downloaded from ChEMBL database and saved as a .csv file. As a side note, if anyone was curious about why the “chembl_mols.csv” file was not uploaded onto my GitHub repository was because I was still figuring out how to add it into my repository due to the file size (it was approximately 0.6GB). I was testing Git large file system, but haven’t quite figured it out yet (would be on my to-do list…).\nFor anyone who would like to reproduce this work, the file I used would be equivalent to a straight download from the home page of ChEMBL database, via clicking on the “Distinct compounds” (please see the circled area in the image below). Options were available to download the files as .csv, .tsv or .sdf formats (located at the top right of the page).\n\n\n\n\nImage adapted from ChEMBL database website\n\n\n\nOnce we’ve had the file ready, it would be read via the usual read_csv() method.\n\ndf = pl.read_csv(\"chembl_mols.csv\")\ndf.head() #read first 5 rows\n#df #read full dataset\n\n\n\n\nshape: (5, 1)\n\n\n\n\nChEMBL ID\";\"Name\";\"Synonyms\";\"Type\";\"Max Phase\";\"Molecular Weight\";\"Targets\";\"Bioactivities\";\"AlogP\";\"Polar Surface Area\";\"HBA\";\"HBD\";\"#RO5 Violations\";\"#Rotatable Bonds\";\"Passes Ro3\";\"QED Weighted\";\"CX Acidic pKa\";\"CX Basic pKa\";\"CX LogP\";\"CX LogD\";\"Aromatic Rings\";\"Structure Type\";\"Inorganic Flag\";\"Heavy Atoms\";\"HBA (Lipinski)\";\"HBD (Lipinski)\";\"#RO5 Violations (Lipinski)\";\"Molecular Weight (Monoisotopic)\";\"Molecular Species\";\"Molecular Formula\";\"Smiles\";\"Inchi Key\n\n\n\n\nstr\n\n\n\n\n\n\n\"CHEMBL1206185;...\n\n\n\n\n\"CHEMBL539070;\"...\n\n\n\n\n\"CHEMBL3335528;...\n\n\n\n\n\"CHEMBL2419030;...\n\n\n\n\n\"CHEMBL4301448;...\n\n\n\n\n\n\n\n\n\n\nData wrangling\nNow an obvious issue appeared without surprises as this dataset was downloaded as .csv file, which meant it was likely to have a certain delimiter between each variable. The dataset showed all data were packed as strings for each compound in each row. Each variable was separated or delimited by semicolons. To read the dataframe properly, I’ve added a delimiter term into the code to transform the dataframe into a more readable format.\n\n# By referring to Polars documentation, \n# use \"sep\" to set the delimiter of the file\n# which in this case was semicolons\ndf = pl.read_csv(\"chembl_mols.csv\", sep = \";\")\n# Show the first 10 rows of data\n#df.head(10)\n\n# or full dataset\ndf\n\n\n\n\nshape: (2331700, 32)\n\n\n\n\nChEMBL ID\n\n\nName\n\n\nSynonyms\n\n\nType\n\n\nMax Phase\n\n\nMolecular Weight\n\n\nTargets\n\n\nBioactivities\n\n\nAlogP\n\n\nPolar Surface Area\n\n\nHBA\n\n\nHBD\n\n\n#RO5 Violations\n\n\n#Rotatable Bonds\n\n\nPasses Ro3\n\n\nQED Weighted\n\n\nCX Acidic pKa\n\n\nCX Basic pKa\n\n\nCX LogP\n\n\nCX LogD\n\n\nAromatic Rings\n\n\nStructure Type\n\n\nInorganic Flag\n\n\nHeavy Atoms\n\n\nHBA (Lipinski)\n\n\nHBD (Lipinski)\n\n\n#RO5 Violations (Lipinski)\n\n\nMolecular Weight (Monoisotopic)\n\n\nMolecular Species\n\n\nMolecular Formula\n\n\nSmiles\n\n\nInchi Key\n\n\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\ni64\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\ni64\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n\"CHEMBL1206185\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"607.88\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"9.46\"\n\n\n\"89.62\"\n\n\n\"5\"\n\n\n\"2\"\n\n\n\"2\"\n\n\n\"17\"\n\n\n\"N\"\n\n\n\"0.09\"\n\n\n\"-1.91\"\n\n\n\"8.38\"\n\n\n\"9.40\"\n\n\n\"9.36\"\n\n\n\"3\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"42\"\n\n\n\"5\"\n\n\n\"3\"\n\n\n\"2\"\n\n\n\"607.2790\"\n\n\n\"ACID\"\n\n\n\"C35H45NO4S2\"\n\n\n\"CCCCCCCCCCC#CC...\n\n\n\"UFBLKYIDZFRLPR...\n\n\n\n\n\"CHEMBL539070\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"286.79\"\n\n\n\"1\"\n\n\n\"1\"\n\n\n\"2.28\"\n\n\n\"73.06\"\n\n\n\"6\"\n\n\n\"2\"\n\n\n\"0\"\n\n\n\"5\"\n\n\n\"N\"\n\n\n\"0.63\"\n\n\n\"13.84\"\n\n\n\"3.64\"\n\n\n\"2.57\"\n\n\n\"2.57\"\n\n\n\"2\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"17\"\n\n\n\"5\"\n\n\n\"3\"\n\n\n\"0\"\n\n\n\"250.0888\"\n\n\n\"NEUTRAL\"\n\n\n\"C11H15ClN4OS\"\n\n\n\"CCCOc1ccccc1-c...\n\n\n\"WPEWNRKLKLNLSO...\n\n\n\n\n\"CHEMBL3335528\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"842.80\"\n\n\n\"2\"\n\n\n\"6\"\n\n\n\"0.18\"\n\n\n\"269.57\"\n\n\n\"18\"\n\n\n\"5\"\n\n\n\"2\"\n\n\n\"17\"\n\n\n\"N\"\n\n\n\"0.09\"\n\n\n\"3.20\"\n\n\n\"None\"\n\n\n\"3.31\"\n\n\n\"-0.14\"\n\n\n\"3\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"60\"\n\n\n\"19\"\n\n\n\"5\"\n\n\n\"2\"\n\n\n\"842.2633\"\n\n\n\"ACID\"\n\n\n\"C41H46O19\"\n\n\n\"COC(=O)[C@H](O...\n\n\n\"KGUJQZWYZPYYRZ...\n\n\n\n\n\"CHEMBL2419030\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"359.33\"\n\n\n\"4\"\n\n\n\"4\"\n\n\n\"3.94\"\n\n\n\"85.13\"\n\n\n\"6\"\n\n\n\"1\"\n\n\n\"0\"\n\n\n\"3\"\n\n\n\"N\"\n\n\n\"0.66\"\n\n\n\"None\"\n\n\n\"None\"\n\n\n\"3.66\"\n\n\n\"3.66\"\n\n\n\"2\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"24\"\n\n\n\"6\"\n\n\n\"1\"\n\n\n\"0\"\n\n\n\"359.0551\"\n\n\n\"NEUTRAL\"\n\n\n\"C14H12F3N3O3S\"\n\n\n\"O=c1nc(NC2CCCC...\n\n\n\"QGDMYSDFCXOKML...\n\n\n\n\n\"CHEMBL4301448\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"465.55\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"5.09\"\n\n\n\"105.28\"\n\n\n\"6\"\n\n\n\"4\"\n\n\n\"1\"\n\n\n\"10\"\n\n\n\"N\"\n\n\n\"0.15\"\n\n\n\"None\"\n\n\n\"12.14\"\n\n\n\"4.41\"\n\n\n\"2.00\"\n\n\n\"4\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"33\"\n\n\n\"7\"\n\n\n\"5\"\n\n\n\"1\"\n\n\n\"465.1635\"\n\n\n\"BASE\"\n\n\n\"C24H24FN5O2S\"\n\n\n\"N=C(N)NCCCOc1c...\n\n\n\"RXTJPHLPHOZLFS...\n\n\n\n\n\"CHEMBL3827271\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"712.85\"\n\n\n\"1\"\n\n\n\"1\"\n\n\n\"-2.84\"\n\n\n\"319.06\"\n\n\n\"10\"\n\n\n\"11\"\n\n\n\"2\"\n\n\n\"16\"\n\n\n\"N\"\n\n\n\"0.07\"\n\n\n\"4.08\"\n\n\n\"10.49\"\n\n\n\"-6.88\"\n\n\n\"-8.95\"\n\n\n\"0\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"50\"\n\n\n\"19\"\n\n\n\"14\"\n\n\n\"3\"\n\n\n\"712.4232\"\n\n\n\"ZWITTERION\"\n\n\n\"C31H56N10O9\"\n\n\n\"CC(C)C[C@@H]1N...\n\n\n\"QJQNNLICZLLPMB...\n\n\n\n\n\"CHEMBL1969944\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"\"\n\n\n\"56\"\n\n\n\"56\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"NONE\"\n\n\n-1\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\n\n\"CHEMBL3465961\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"319.42\"\n\n\n\"16\"\n\n\n\"22\"\n\n\n\"2.22\"\n\n\n\"50.50\"\n\n\n\"4\"\n\n\n\"1\"\n\n\n\"0\"\n\n\n\"6\"\n\n\n\"N\"\n\n\n\"0.87\"\n\n\n\"None\"\n\n\n\"9.38\"\n\n\n\"2.13\"\n\n\n\"-0.44\"\n\n\n\"1\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"23\"\n\n\n\"4\"\n\n\n\"1\"\n\n\n\"0\"\n\n\n\"319.2060\"\n\n\n\"BASE\"\n\n\n\"C18H26FN3O\"\n\n\n\"CC(O)CN1CCC(CN...\n\n\n\"FZEVYCHTADTXPM...\n\n\n\n\n\"CHEMBL587495\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"478.54\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"6.85\"\n\n\n\"66.73\"\n\n\n\"4\"\n\n\n\"3\"\n\n\n\"1\"\n\n\n\"6\"\n\n\n\"N\"\n\n\n\"0.23\"\n\n\n\"10.67\"\n\n\n\"8.47\"\n\n\n\"6.04\"\n\n\n\"4.93\"\n\n\n\"5\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"34\"\n\n\n\"4\"\n\n\n\"4\"\n\n\n\"1\"\n\n\n\"478.1439\"\n\n\n\"NEUTRAL\"\n\n\n\"C26H21F3N4S\"\n\n\n\"Nc1cccc(CNCc2c...\n\n\n\"KZOHKPSNJBXTRJ...\n\n\n\n\n\"CHEMBL3824158\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"422.48\"\n\n\n\"2\"\n\n\n\"4\"\n\n\n\"5.09\"\n\n\n\"109.54\"\n\n\n\"6\"\n\n\n\"2\"\n\n\n\"1\"\n\n\n\"10\"\n\n\n\"N\"\n\n\n\"0.31\"\n\n\n\"4.59\"\n\n\n\"7.99\"\n\n\n\"2.49\"\n\n\n\"2.42\"\n\n\n\"2\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"31\"\n\n\n\"7\"\n\n\n\"2\"\n\n\n\"1\"\n\n\n\"422.1842\"\n\n\n\"ACID\"\n\n\n\"C24H26N2O5\"\n\n\n\"CCCCCCCNC(C1=C...\n\n\n\"AXOVDUYYBUYLPC...\n\n\n\n\n\"CHEMBL194112\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"366.38\"\n\n\n\"2\"\n\n\n\"3\"\n\n\n\"4.80\"\n\n\n\"57.53\"\n\n\n\"3\"\n\n\n\"2\"\n\n\n\"0\"\n\n\n\"1\"\n\n\n\"N\"\n\n\n\"0.75\"\n\n\n\"8.98\"\n\n\n\"None\"\n\n\n\"4.84\"\n\n\n\"4.83\"\n\n\n\"1\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"26\"\n\n\n\"3\"\n\n\n\"2\"\n\n\n\"0\"\n\n\n\"366.1443\"\n\n\n\"NEUTRAL\"\n\n\n\"C20H21F3O3\"\n\n\n\"C[C@]12CCC3c4c...\n\n\n\"FIBOSLUEJGPVMK...\n\n\n\n\n\"CHEMBL2047226\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"452.40\"\n\n\n\"4\"\n\n\n\"8\"\n\n\n\"4.93\"\n\n\n\"53.08\"\n\n\n\"5\"\n\n\n\"2\"\n\n\n\"0\"\n\n\n\"7\"\n\n\n\"N\"\n\n\n\"0.53\"\n\n\n\"None\"\n\n\n\"8.47\"\n\n\n\"4.51\"\n\n\n\"3.29\"\n\n\n\"3\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"29\"\n\n\n\"5\"\n\n\n\"2\"\n\n\n\"0\"\n\n\n\"451.1372\"\n\n\n\"NEUTRAL\"\n\n\n\"C23H26BrN5\"\n\n\n\"Brc1ccc(CNc2cc...\n\n\n\"WOAVNWHCIXCOIZ...\n\n\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n\n\n\"CHEMBL387315\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"673.99\"\n\n\n\"2\"\n\n\n\"2\"\n\n\n\"9.83\"\n\n\n\"43.86\"\n\n\n\"3\"\n\n\n\"0\"\n\n\n\"2\"\n\n\n\"21\"\n\n\n\"N\"\n\n\n\"0.08\"\n\n\n\"None\"\n\n\n\"9.57\"\n\n\n\"10.60\"\n\n\n\"8.45\"\n\n\n\"4\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"50\"\n\n\n\"5\"\n\n\n\"0\"\n\n\n\"2\"\n\n\n\"673.4607\"\n\n\n\"BASE\"\n\n\n\"C45H59N3O2\"\n\n\n\"CCCCCc1ccc(C(=...\n\n\n\"HVSKDFHVTFRADD...\n\n\n\n\n\"CHEMBL540121\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"540.05\"\n\n\n\"2\"\n\n\n\"3\"\n\n\n\"2.39\"\n\n\n\"147.14\"\n\n\n\"6\"\n\n\n\"4\"\n\n\n\"1\"\n\n\n\"8\"\n\n\n\"N\"\n\n\n\"0.22\"\n\n\n\"5.02\"\n\n\n\"11.48\"\n\n\n\"-0.75\"\n\n\n\"-0.78\"\n\n\n\"4\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"36\"\n\n\n\"9\"\n\n\n\"5\"\n\n\n\"1\"\n\n\n\"503.1627\"\n\n\n\"ZWITTERION\"\n\n\n\"C26H26ClN5O4S\"\n\n\n\"Cc1ccn(NS(=O)(...\n\n\n\"TZLGWENJAJXWGA...\n\n\n\n\n\"CHEMBL2387650\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"496.01\"\n\n\n\"2\"\n\n\n\"13\"\n\n\n\"6.03\"\n\n\n\"66.84\"\n\n\n\"5\"\n\n\n\"1\"\n\n\n\"1\"\n\n\n\"7\"\n\n\n\"N\"\n\n\n\"0.32\"\n\n\n\"3.57\"\n\n\n\"None\"\n\n\n\"6.77\"\n\n\n\"3.42\"\n\n\n\"3\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"33\"\n\n\n\"5\"\n\n\n\"1\"\n\n\n\"1\"\n\n\n\"495.0366\"\n\n\n\"ACID\"\n\n\n\"C25H18ClNO4S2\"\n\n\n\"O=C(O)[C@@H](C...\n\n\n\"LSYQEQADGPAMNF...\n\n\n\n\n\"CHEMBL374041\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"504.50\"\n\n\n\"2\"\n\n\n\"4\"\n\n\n\"3.04\"\n\n\n\"144.95\"\n\n\n\"8\"\n\n\n\"3\"\n\n\n\"1\"\n\n\n\"10\"\n\n\n\"N\"\n\n\n\"0.28\"\n\n\n\"6.59\"\n\n\n\"4.37\"\n\n\n\"2.17\"\n\n\n\"1.33\"\n\n\n\"3\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"37\"\n\n\n\"11\"\n\n\n\"3\"\n\n\n\"2\"\n\n\n\"504.1645\"\n\n\n\"NEUTRAL\"\n\n\n\"C26H24N4O7\"\n\n\n\"CCOCCC1(Oc2ccc...\n\n\n\"ABCSNHDQYHOLOO...\n\n\n\n\n\"CHEMBL394794\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"707.86\"\n\n\n\"1\"\n\n\n\"2\"\n\n\n\"4.31\"\n\n\n\"183.99\"\n\n\n\"12\"\n\n\n\"3\"\n\n\n\"2\"\n\n\n\"9\"\n\n\n\"N\"\n\n\n\"0.18\"\n\n\n\"12.10\"\n\n\n\"None\"\n\n\n\"3.09\"\n\n\n\"3.09\"\n\n\n\"0\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"50\"\n\n\n\"13\"\n\n\n\"3\"\n\n\n\"2\"\n\n\n\"707.3881\"\n\n\n\"NEUTRAL\"\n\n\n\"C37H57NO12\"\n\n\n\"C=C1[C@@H](O)C...\n\n\n\"CFMSPOHWBQUTHN...\n\n\n\n\n\"CHEMBL2035815\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"534.89\"\n\n\n\"10\"\n\n\n\"10\"\n\n\n\"4.46\"\n\n\n\"146.01\"\n\n\n\"10\"\n\n\n\"3\"\n\n\n\"1\"\n\n\n\"8\"\n\n\n\"N\"\n\n\n\"0.28\"\n\n\n\"None\"\n\n\n\"6.22\"\n\n\n\"3.48\"\n\n\n\"3.48\"\n\n\n\"4\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"37\"\n\n\n\"11\"\n\n\n\"4\"\n\n\n\"2\"\n\n\n\"534.1142\"\n\n\n\"NEUTRAL\"\n\n\n\"C22H18ClF3N8O3...\n\n\n\"C=CC(=O)NCc1co...\n\n\n\"ZRZKVZZVULTROL...\n\n\n\n\n\"CHEMBL1586325\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"425.47\"\n\n\n\"6\"\n\n\n\"7\"\n\n\n\"3.11\"\n\n\n\"109.62\"\n\n\n\"5\"\n\n\n\"1\"\n\n\n\"0\"\n\n\n\"8\"\n\n\n\"N\"\n\n\n\"0.44\"\n\n\n\"13.84\"\n\n\n\"None\"\n\n\n\"3.24\"\n\n\n\"3.24\"\n\n\n\"3\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"30\"\n\n\n\"8\"\n\n\n\"1\"\n\n\n\"0\"\n\n\n\"425.1045\"\n\n\n\"NEUTRAL\"\n\n\n\"C21H19N3O5S\"\n\n\n\"O=C(CN(c1cccc(...\n\n\n\"XVDMUGUIAWGPNU...\n\n\n\n\n\"CHEMBL2017916\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"312.35\"\n\n\n\"3\"\n\n\n\"3\"\n\n\n\"2.86\"\n\n\n\"77.00\"\n\n\n\"6\"\n\n\n\"1\"\n\n\n\"0\"\n\n\n\"4\"\n\n\n\"N\"\n\n\n\"0.80\"\n\n\n\"8.13\"\n\n\n\"3.49\"\n\n\n\"2.17\"\n\n\n\"2.10\"\n\n\n\"3\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"22\"\n\n\n\"6\"\n\n\n\"1\"\n\n\n\"0\"\n\n\n\"312.0681\"\n\n\n\"NEUTRAL\"\n\n\n\"C15H12N4O2S\"\n\n\n\"COc1ccc(-c2nnc...\n\n\n\"XIZUJGDKNPVNQA...\n\n\n\n\n\"CHEMBL374652\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"403.83\"\n\n\n\"1\"\n\n\n\"1\"\n\n\n\"5.98\"\n\n\n\"36.02\"\n\n\n\"2\"\n\n\n\"2\"\n\n\n\"1\"\n\n\n\"4\"\n\n\n\"N\"\n\n\n\"0.42\"\n\n\n\"13.65\"\n\n\n\"None\"\n\n\n\"5.36\"\n\n\n\"5.36\"\n\n\n\"3\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"26\"\n\n\n\"2\"\n\n\n\"2\"\n\n\n\"1\"\n\n\n\"403.0421\"\n\n\n\"NEUTRAL\"\n\n\n\"C18H14ClF4NOS\"\n\n\n\"CC(O)(CSc1ccc(...\n\n\n\"CRPQTBRTHURKII...\n\n\n\n\n\"CHEMBL1416264\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"380.41\"\n\n\n\"6\"\n\n\n\"8\"\n\n\n\"3.06\"\n\n\n\"85.07\"\n\n\n\"7\"\n\n\n\"1\"\n\n\n\"0\"\n\n\n\"5\"\n\n\n\"N\"\n\n\n\"0.54\"\n\n\n\"13.85\"\n\n\n\"3.86\"\n\n\n\"2.47\"\n\n\n\"2.47\"\n\n\n\"4\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"27\"\n\n\n\"7\"\n\n\n\"1\"\n\n\n\"0\"\n\n\n\"380.0856\"\n\n\n\"NEUTRAL\"\n\n\n\"C18H13FN6OS\"\n\n\n\"O=C(CSc1ccc2nn...\n\n\n\"QVYIEKHEJKFNAT...\n\n\n\n\n\"CHEMBL213734\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"288.26\"\n\n\n\"2\"\n\n\n\"3\"\n\n\n\"2.32\"\n\n\n\"101.70\"\n\n\n\"5\"\n\n\n\"2\"\n\n\n\"0\"\n\n\n\"5\"\n\n\n\"N\"\n\n\n\"0.50\"\n\n\n\"7.20\"\n\n\n\"None\"\n\n\n\"2.36\"\n\n\n\"1.95\"\n\n\n\"2\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"21\"\n\n\n\"7\"\n\n\n\"2\"\n\n\n\"0\"\n\n\n\"288.0746\"\n\n\n\"NEUTRAL\"\n\n\n\"C14H12N2O5\"\n\n\n\"O=C(COc1ccccc1...\n\n\n\"PZTWAHGBGTWVEB...\n\n\n\n\n\"CHEMBL1531634\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n\"320.16\"\n\n\n\"19\"\n\n\n\"21\"\n\n\n\"4.40\"\n\n\n\"29.10\"\n\n\n\"2\"\n\n\n\"1\"\n\n\n\"0\"\n\n\n\"4\"\n\n\n\"N\"\n\n\n\"0.67\"\n\n\n\"None\"\n\n\n\"None\"\n\n\n\"4.04\"\n\n\n\"4.04\"\n\n\n\"2\"\n\n\n\"MOL\"\n\n\n-1\n\n\n\"19\"\n\n\n\"2\"\n\n\n\"1\"\n\n\n\"0\"\n\n\n\"319.0008\"\n\n\n\"NEUTRAL\"\n\n\n\"C15H11BrFNO\"\n\n\n\"O=C(/C=C/Nc1cc...\n\n\n\"DKPWCCDDKFLKEC...\n\n\n\n\n\n\n\nInitially, I only wanted to download about 24 compounds from ChEMBL database to trial first. Unknowingly, I ended up downloading the whole curated set of 2,331,700 small molecules (!), and I found this out when I loaded the dataframe after setting the delimiter for the csv file, which later led to the problem of uploading the .csv file into GitHub repo mentioned earlier.\nLoading these 2,331,700 rows of data was fast, which occurred within a few seconds without exaggeration. This echoed many users’ experiences with Polars, so this was another nice surprise, and once again confirmed that Rust (and also Apache arrow, which was used as Polars’ foundation) were solid in speed.\nNow I had the full dataframe, and I wanted to find out what types of physicochemical properties were there for the compounds.\n\n# Print all column names and data types \nprint(df.glimpse())\n\nRows: 2331700\nColumns: 32\n$ ChEMBL ID                        <Utf8> CHEMBL1206185, CHEMBL539070, CHEMBL3335528, CHEMBL2419030, CHEMBL4301448, CHEMBL3827271, CHEMBL1969944, CHEMBL3465961, CHEMBL587495, CHEMBL3824158\n$ Name                             <Utf8> , , , , , , , , ,                                             \n$ Synonyms                         <Utf8> , , , , , , , , ,                                             \n$ Type                             <Utf8> Small molecule, Small molecule, Small molecule, Small molecule, Small molecule, Small molecule, Small molecule, Small molecule, Small molecule, Small molecule\n$ Max Phase                       <Int64> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0                                  \n$ Molecular Weight                 <Utf8> 607.88, 286.79, 842.80, 359.33, 465.55, 712.85, , 319.42, 478.54, 422.48\n$ Targets                          <Utf8> , 1, 2, 4, , 1, 56, 16, , 2                                   \n$ Bioactivities                    <Utf8> , 1, 6, 4, , 1, 56, 22, , 4                                   \n$ AlogP                            <Utf8> 9.46, 2.28, 0.18, 3.94, 5.09, -2.84, , 2.22, 6.85, 5.09       \n$ Polar Surface Area               <Utf8> 89.62, 73.06, 269.57, 85.13, 105.28, 319.06, , 50.50, 66.73, 109.54\n$ HBA                              <Utf8> 5, 6, 18, 6, 6, 10, , 4, 4, 6                                 \n$ HBD                              <Utf8> 2, 2, 5, 1, 4, 11, , 1, 3, 2                                  \n$ #RO5 Violations                  <Utf8> 2, 0, 2, 0, 1, 2, , 0, 1, 1                                   \n$ #Rotatable Bonds                 <Utf8> 17, 5, 17, 3, 10, 16, , 6, 6, 10                              \n$ Passes Ro3                       <Utf8> N, N, N, N, N, N, , N, N, N                                   \n$ QED Weighted                     <Utf8> 0.09, 0.63, 0.09, 0.66, 0.15, 0.07, , 0.87, 0.23, 0.31        \n$ CX Acidic pKa                    <Utf8> -1.91, 13.84, 3.20, None, None, 4.08, , None, 10.67, 4.59     \n$ CX Basic pKa                     <Utf8> 8.38, 3.64, None, None, 12.14, 10.49, , 9.38, 8.47, 7.99      \n$ CX LogP                          <Utf8> 9.40, 2.57, 3.31, 3.66, 4.41, -6.88, , 2.13, 6.04, 2.49       \n$ CX LogD                          <Utf8> 9.36, 2.57, -0.14, 3.66, 2.00, -8.95, , -0.44, 4.93, 2.42     \n$ Aromatic Rings                   <Utf8> 3, 2, 3, 2, 4, 0, , 1, 5, 2                                   \n$ Structure Type                   <Utf8> MOL, MOL, MOL, MOL, MOL, MOL, NONE, MOL, MOL, MOL             \n$ Inorganic Flag                  <Int64> -1, -1, -1, -1, -1, -1, -1, -1, -1, -1                        \n$ Heavy Atoms                      <Utf8> 42, 17, 60, 24, 33, 50, , 23, 34, 31                          \n$ HBA (Lipinski)                   <Utf8> 5, 5, 19, 6, 7, 19, , 4, 4, 7                                 \n$ HBD (Lipinski)                   <Utf8> 3, 3, 5, 1, 5, 14, , 1, 4, 2                                  \n$ #RO5 Violations (Lipinski)       <Utf8> 2, 0, 2, 0, 1, 3, , 0, 1, 1                                   \n$ Molecular Weight (Monoisotopic)  <Utf8> 607.2790, 250.0888, 842.2633, 359.0551, 465.1635, 712.4232, , 319.2060, 478.1439, 422.1842\n$ Molecular Species                <Utf8> ACID, NEUTRAL, ACID, NEUTRAL, BASE, ZWITTERION, , BASE, NEUTRAL, ACID\n$ Molecular Formula                <Utf8> C35H45NO4S2, C11H15ClN4OS, C41H46O19, C14H12F3N3O3S, C24H24FN5O2S, C31H56N10O9, , C18H26FN3O, C26H21F3N4S, C24H26N2O5\n$ Smiles                           <Utf8> CCCCCCCCCCC#CC(N)c1ccccc1-c1ccc(Sc2ccc(OCCCC)cc2)c(S(=O)(=O)O)c1, CCCOc1ccccc1-c1nnc(NN)s1.Cl, COC(=O)[C@H](O[C@@H]1O[C@@H](C)[C@@H](O)[C@@H](O)[C@@H]1O)[C@@H](O[C@@H]1O[C@H](CO)[C@H](OC(=O)c2ccccc2)[C@H](O[C@H](Cc2ccccc2)C(=O)O)[C@H]1OC(=O)c1ccccc1)C(=O)OC, O=c1nc(NC2CCCC2)sc2c([N+](=O)[O-])cc(C(F)(F)F)cc12, N=C(N)NCCCOc1ccc(CNc2nc3ccc(Oc4ccc(F)cc4)cc3s2)cc1, CC(C)C[C@@H]1NC(=O)[C@H](CCCNC(N)=O)NC(=O)[C@H](CCCCN)NC(=O)[C@H](CC(=O)O)NC(=O)[C@H](CCCCN)NC(=O)CCNC1=O, , CC(O)CN1CCC(CN(C)Cc2cc(C#N)ccc2F)CC1, Nc1cccc(CNCc2ccc(-c3ccc(-c4nc5cc(C(F)(F)F)ccc5[nH]4)s3)cc2)c1, CCCCCCCNC(C1=C(O)C(=O)c2ccccc2C1=O)c1ccc([N+](=O)[O-])cc1\n$ Inchi Key                        <Utf8> UFBLKYIDZFRLPR-UHFFFAOYSA-N, WPEWNRKLKLNLSO-UHFFFAOYSA-N, KGUJQZWYZPYYRZ-LWEWUKDVSA-N, QGDMYSDFCXOKML-UHFFFAOYSA-N, RXTJPHLPHOZLFS-UHFFFAOYSA-N, QJQNNLICZLLPMB-VUBDRERZSA-N, , FZEVYCHTADTXPM-UHFFFAOYSA-N, KZOHKPSNJBXTRJ-UHFFFAOYSA-N, AXOVDUYYBUYLPC-UHFFFAOYSA-N\n\n\n\nThere were a few terms where I wasn’t sure of their exact meanings, so I went through the ChEMBL_31 schema documentation and ChEMBL database website to find out. This took a while and was an important step so that I would be interpreting the results or meanings of these data appropriately later on.\nI have selected a few physicochemical properties down below so that readers and I could gather reasonable understandings of each term. The explanations for each term were adapted from ChEMBL_31 schema documentation (available as “Release notes” on the website), or if definitions for certain terms were not available from the documentation, I resorted to interpret them myself by going into “Dinstict compounds” section on the ChEMBL database, where I would click on, e.g. bioactivities, for a random compound in there to see what results showed up and then described them below.\nThe definitions for these physicochemical properties were listed as below:\nMax Phase - Maximum phase of development reached for the compound (where 4 = approved). Null was where max phase has not yet been assigned.\nBioactivities - Various biological assays used for the compounds e.g. IC50, GI50, potency tests etc.\nAlogP - Calculated partition coefficient\nHBA - Number of hydrogen bond acceptors\nHBD - Number of hydrogen bond donors\n#RO5 Violations - Number of violations of Lipinski’s rule-of-five, using HBA and HBD definitions\nPasses Ro3 - Indicated whether the compound passes the rule-of-three (MW < 300, logP < 3 etc)\nQED Weighted - Weighted quantitative estimate of drug likeness (as defined by Bickerton et al., Nature Chem 2012)\nInorganic flag - Indicated whether the molecule was inorganic (i.e., containing only metal atoms and <2 carbon atoms), where 1 = inorganic compound and -1 = not inorganic compound (assuming 0 meant it was neither case or yet to be assigned)\nHeavy Atoms - Number of heavy (non-hydrogen) atoms\nCX Acidic pKa - The most acidic pKa calculated using ChemAxon v17.29.0\nCX Basic pKa - The most basic pKa calculated using ChemAxon v17.29.0\nCX LogP - The calculated octanol/water partition coefficient using ChemAxon v17.29.0\nCX LogD - The calculated octanol/water distribution coefficient at pH = 7.4 using ChemAxon v17.29.0\nStructure Type - based on compound_structures table, where SEQ indicated an entry in the protein_therapeutics table instead, NONE indicated an entry in neither tables, e.g. structure unknown\nInchi Key - the IUPAC international chemical identifier key\nFrom the df.glimpse() method previously, there were a lot of columns with the data type of “Utf8”, which meant they were strings. There were only two columns that had “Int64”, which meant they were integers. A lot of these columns were actually storing numbers as strings. So to make my life easier, I went on to convert these data types into the more appropriate ones for selected columns.\n\n# Convert data types for multiple selected columns\n# Note: only takes two positional arguments, \n# so needed to use [] in code to change \n\n# Multiple columns all at once - with_columns()\n# Single column - with_column()\n\n# Use alias if wanting to keep original data type in column, \n# as it adds a new column under an alias name to dataframe\ndf_new = df.with_columns(\n    [\n        (pl.col(\"Molecular Weight\")).cast(pl.Float64, strict = False),\n        (pl.col(\"Targets\")).cast(pl.Int64, strict = False),\n        (pl.col(\"Bioactivities\")).cast(pl.Int64, strict = False),\n        (pl.col(\"AlogP\")).cast(pl.Float64, strict = False),\n        (pl.col(\"Polar Surface Area\")).cast(pl.Float64, strict = False),\n        (pl.col(\"HBA\")).cast(pl.Int64, strict = False),\n        (pl.col(\"HBD\")).cast(pl.Int64, strict = False),\n        (pl.col(\"#RO5 Violations\")).cast(pl.Int64, strict = False),\n        (pl.col(\"#Rotatable Bonds\")).cast(pl.Int64, strict = False),\n        (pl.col(\"QED Weighted\")).cast(pl.Float64, strict = False),\n        (pl.col(\"CX Acidic pKa\")).cast(pl.Float64, strict = False),\n        (pl.col(\"CX Basic pKa\")).cast(pl.Float64, strict = False),\n        (pl.col(\"CX LogP\")).cast(pl.Float64, strict = False),\n        (pl.col(\"CX LogD\")).cast(pl.Float64, strict = False),\n        (pl.col(\"Aromatic Rings\")).cast(pl.Int64, strict = False),\n        (pl.col(\"Heavy Atoms\")).cast(pl.Int64, strict = False),\n        (pl.col(\"HBA (Lipinski)\")).cast(pl.Int64, strict = False),\n        (pl.col(\"HBD (Lipinski)\")).cast(pl.Int64, strict = False),\n        (pl.col(\"#RO5 Violations (Lipinski)\")).cast(pl.Int64, strict = False),\n        (pl.col(\"Molecular Weight (Monoisotopic)\")).cast(pl.Float64, strict = False)\n    ]\n)\ndf_new.head()\n\n\n\n\nshape: (5, 32)\n\n\n\n\nChEMBL ID\n\n\nName\n\n\nSynonyms\n\n\nType\n\n\nMax Phase\n\n\nMolecular Weight\n\n\nTargets\n\n\nBioactivities\n\n\nAlogP\n\n\nPolar Surface Area\n\n\nHBA\n\n\nHBD\n\n\n#RO5 Violations\n\n\n#Rotatable Bonds\n\n\nPasses Ro3\n\n\nQED Weighted\n\n\nCX Acidic pKa\n\n\nCX Basic pKa\n\n\nCX LogP\n\n\nCX LogD\n\n\nAromatic Rings\n\n\nStructure Type\n\n\nInorganic Flag\n\n\nHeavy Atoms\n\n\nHBA (Lipinski)\n\n\nHBD (Lipinski)\n\n\n#RO5 Violations (Lipinski)\n\n\nMolecular Weight (Monoisotopic)\n\n\nMolecular Species\n\n\nMolecular Formula\n\n\nSmiles\n\n\nInchi Key\n\n\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\ni64\n\n\nf64\n\n\ni64\n\n\ni64\n\n\nf64\n\n\nf64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\nstr\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\ni64\n\n\nstr\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\nf64\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n\"CHEMBL1206185\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n607.88\n\n\nnull\n\n\nnull\n\n\n9.46\n\n\n89.62\n\n\n5\n\n\n2\n\n\n2\n\n\n17\n\n\n\"N\"\n\n\n0.09\n\n\n-1.91\n\n\n8.38\n\n\n9.4\n\n\n9.36\n\n\n3\n\n\n\"MOL\"\n\n\n-1\n\n\n42\n\n\n5\n\n\n3\n\n\n2\n\n\n607.279\n\n\n\"ACID\"\n\n\n\"C35H45NO4S2\"\n\n\n\"CCCCCCCCCCC#CC...\n\n\n\"UFBLKYIDZFRLPR...\n\n\n\n\n\"CHEMBL539070\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n286.79\n\n\n1\n\n\n1\n\n\n2.28\n\n\n73.06\n\n\n6\n\n\n2\n\n\n0\n\n\n5\n\n\n\"N\"\n\n\n0.63\n\n\n13.84\n\n\n3.64\n\n\n2.57\n\n\n2.57\n\n\n2\n\n\n\"MOL\"\n\n\n-1\n\n\n17\n\n\n5\n\n\n3\n\n\n0\n\n\n250.0888\n\n\n\"NEUTRAL\"\n\n\n\"C11H15ClN4OS\"\n\n\n\"CCCOc1ccccc1-c...\n\n\n\"WPEWNRKLKLNLSO...\n\n\n\n\n\"CHEMBL3335528\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n842.8\n\n\n2\n\n\n6\n\n\n0.18\n\n\n269.57\n\n\n18\n\n\n5\n\n\n2\n\n\n17\n\n\n\"N\"\n\n\n0.09\n\n\n3.2\n\n\nnull\n\n\n3.31\n\n\n-0.14\n\n\n3\n\n\n\"MOL\"\n\n\n-1\n\n\n60\n\n\n19\n\n\n5\n\n\n2\n\n\n842.2633\n\n\n\"ACID\"\n\n\n\"C41H46O19\"\n\n\n\"COC(=O)[C@H](O...\n\n\n\"KGUJQZWYZPYYRZ...\n\n\n\n\n\"CHEMBL2419030\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n359.33\n\n\n4\n\n\n4\n\n\n3.94\n\n\n85.13\n\n\n6\n\n\n1\n\n\n0\n\n\n3\n\n\n\"N\"\n\n\n0.66\n\n\nnull\n\n\nnull\n\n\n3.66\n\n\n3.66\n\n\n2\n\n\n\"MOL\"\n\n\n-1\n\n\n24\n\n\n6\n\n\n1\n\n\n0\n\n\n359.0551\n\n\n\"NEUTRAL\"\n\n\n\"C14H12F3N3O3S\"\n\n\n\"O=c1nc(NC2CCCC...\n\n\n\"QGDMYSDFCXOKML...\n\n\n\n\n\"CHEMBL4301448\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n465.55\n\n\nnull\n\n\nnull\n\n\n5.09\n\n\n105.28\n\n\n6\n\n\n4\n\n\n1\n\n\n10\n\n\n\"N\"\n\n\n0.15\n\n\nnull\n\n\n12.14\n\n\n4.41\n\n\n2.0\n\n\n4\n\n\n\"MOL\"\n\n\n-1\n\n\n33\n\n\n7\n\n\n5\n\n\n1\n\n\n465.1635\n\n\n\"BASE\"\n\n\n\"C24H24FN5O2S\"\n\n\n\"N=C(N)NCCCOc1c...\n\n\n\"RXTJPHLPHOZLFS...\n\n\n\n\n\n\n\nOnce all the columns’ data types have been checked and converted to appropriate types accordingly, I used null_count() to see the distributions of all null entries in the dataset.\n\n# Check for any null or NA or \"\" entries in the dataset\n# Alternative code that worked similarly was df.select(pl.all().null_count())\ndf_new.null_count()\n\n\n\n\nshape: (1, 32)\n\n\n\n\nChEMBL ID\n\n\nName\n\n\nSynonyms\n\n\nType\n\n\nMax Phase\n\n\nMolecular Weight\n\n\nTargets\n\n\nBioactivities\n\n\nAlogP\n\n\nPolar Surface Area\n\n\nHBA\n\n\nHBD\n\n\n#RO5 Violations\n\n\n#Rotatable Bonds\n\n\nPasses Ro3\n\n\nQED Weighted\n\n\nCX Acidic pKa\n\n\nCX Basic pKa\n\n\nCX LogP\n\n\nCX LogD\n\n\nAromatic Rings\n\n\nStructure Type\n\n\nInorganic Flag\n\n\nHeavy Atoms\n\n\nHBA (Lipinski)\n\n\nHBD (Lipinski)\n\n\n#RO5 Violations (Lipinski)\n\n\nMolecular Weight (Monoisotopic)\n\n\nMolecular Species\n\n\nMolecular Formula\n\n\nSmiles\n\n\nInchi Key\n\n\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\n\n\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n23249\n\n\n96223\n\n\n96223\n\n\n83571\n\n\n83571\n\n\n83571\n\n\n83571\n\n\n83571\n\n\n83571\n\n\n0\n\n\n83571\n\n\n1052439\n\n\n882168\n\n\n83795\n\n\n83795\n\n\n83571\n\n\n0\n\n\n0\n\n\n83571\n\n\n83571\n\n\n83571\n\n\n83571\n\n\n23252\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n\n\n\n\n\n\n# Drop rows with null entries\ndf_dn = df_new.drop_nulls()\ndf_dn \n# Number of rows reduced to 736,570\n\n\n\n\nshape: (736570, 32)\n\n\n\n\nChEMBL ID\n\n\nName\n\n\nSynonyms\n\n\nType\n\n\nMax Phase\n\n\nMolecular Weight\n\n\nTargets\n\n\nBioactivities\n\n\nAlogP\n\n\nPolar Surface Area\n\n\nHBA\n\n\nHBD\n\n\n#RO5 Violations\n\n\n#Rotatable Bonds\n\n\nPasses Ro3\n\n\nQED Weighted\n\n\nCX Acidic pKa\n\n\nCX Basic pKa\n\n\nCX LogP\n\n\nCX LogD\n\n\nAromatic Rings\n\n\nStructure Type\n\n\nInorganic Flag\n\n\nHeavy Atoms\n\n\nHBA (Lipinski)\n\n\nHBD (Lipinski)\n\n\n#RO5 Violations (Lipinski)\n\n\nMolecular Weight (Monoisotopic)\n\n\nMolecular Species\n\n\nMolecular Formula\n\n\nSmiles\n\n\nInchi Key\n\n\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\ni64\n\n\nf64\n\n\ni64\n\n\ni64\n\n\nf64\n\n\nf64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\nstr\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\ni64\n\n\nstr\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\nf64\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n\"CHEMBL539070\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n286.79\n\n\n1\n\n\n1\n\n\n2.28\n\n\n73.06\n\n\n6\n\n\n2\n\n\n0\n\n\n5\n\n\n\"N\"\n\n\n0.63\n\n\n13.84\n\n\n3.64\n\n\n2.57\n\n\n2.57\n\n\n2\n\n\n\"MOL\"\n\n\n-1\n\n\n17\n\n\n5\n\n\n3\n\n\n0\n\n\n250.0888\n\n\n\"NEUTRAL\"\n\n\n\"C11H15ClN4OS\"\n\n\n\"CCCOc1ccccc1-c...\n\n\n\"WPEWNRKLKLNLSO...\n\n\n\n\n\"CHEMBL3827271\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n712.85\n\n\n1\n\n\n1\n\n\n-2.84\n\n\n319.06\n\n\n10\n\n\n11\n\n\n2\n\n\n16\n\n\n\"N\"\n\n\n0.07\n\n\n4.08\n\n\n10.49\n\n\n-6.88\n\n\n-8.95\n\n\n0\n\n\n\"MOL\"\n\n\n-1\n\n\n50\n\n\n19\n\n\n14\n\n\n3\n\n\n712.4232\n\n\n\"ZWITTERION\"\n\n\n\"C31H56N10O9\"\n\n\n\"CC(C)C[C@@H]1N...\n\n\n\"QJQNNLICZLLPMB...\n\n\n\n\n\"CHEMBL3824158\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n422.48\n\n\n2\n\n\n4\n\n\n5.09\n\n\n109.54\n\n\n6\n\n\n2\n\n\n1\n\n\n10\n\n\n\"N\"\n\n\n0.31\n\n\n4.59\n\n\n7.99\n\n\n2.49\n\n\n2.42\n\n\n2\n\n\n\"MOL\"\n\n\n-1\n\n\n31\n\n\n7\n\n\n2\n\n\n1\n\n\n422.1842\n\n\n\"ACID\"\n\n\n\"C24H26N2O5\"\n\n\n\"CCCCCCCNC(C1=C...\n\n\n\"AXOVDUYYBUYLPC...\n\n\n\n\n\"CHEMBL1991010\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n454.05\n\n\n60\n\n\n60\n\n\n5.18\n\n\n40.54\n\n\n3\n\n\n1\n\n\n1\n\n\n8\n\n\n\"N\"\n\n\n0.6\n\n\n13.88\n\n\n8.48\n\n\n6.34\n\n\n5.22\n\n\n2\n\n\n\"MOL\"\n\n\n-1\n\n\n31\n\n\n3\n\n\n1\n\n\n1\n\n\n417.2668\n\n\n\"NEUTRAL\"\n\n\n\"C28H36ClNO2\"\n\n\n\"CCc1ccc(/C=C/C...\n\n\n\"XJDPAUYFONOZBC...\n\n\n\n\n\"CHEMBL195644\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n375.47\n\n\n2\n\n\n3\n\n\n4.95\n\n\n70.42\n\n\n4\n\n\n2\n\n\n0\n\n\n2\n\n\n\"N\"\n\n\n0.73\n\n\n9.52\n\n\n3.73\n\n\n3.92\n\n\n3.91\n\n\n2\n\n\n\"MOL\"\n\n\n-1\n\n\n28\n\n\n4\n\n\n2\n\n\n0\n\n\n375.1834\n\n\n\"NEUTRAL\"\n\n\n\"C24H25NO3\"\n\n\n\"C[C@]12CCC3c4c...\n\n\n\"MOBPUUUBXAHZBM...\n\n\n\n\n\"CHEMBL255263\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n388.42\n\n\n4\n\n\n4\n\n\n2.42\n\n\n95.16\n\n\n4\n\n\n2\n\n\n0\n\n\n4\n\n\n\"N\"\n\n\n0.72\n\n\n11.24\n\n\n1.02\n\n\n1.74\n\n\n1.74\n\n\n3\n\n\n\"MOL\"\n\n\n-1\n\n\n27\n\n\n7\n\n\n2\n\n\n0\n\n\n388.1005\n\n\n\"NEUTRAL\"\n\n\n\"C18H17FN4O3S\"\n\n\n\"O=C(Cc1ccc(F)c...\n\n\n\"JXSGQHRSUUOSAF...\n\n\n\n\n\"CHEMBL504846\"\n\n\n\"\"\n\n\n\"25-Deacetyl-Ri...\n\n\n\"Small molecule...\n\n\n0\n\n\n807.0\n\n\n3\n\n\n21\n\n\n3.9\n\n\n202.64\n\n\n13\n\n\n7\n\n\n3\n\n\n3\n\n\n\"N\"\n\n\n0.23\n\n\n8.61\n\n\n8.27\n\n\n3.4\n\n\n2.87\n\n\n1\n\n\n\"MOL\"\n\n\n-1\n\n\n58\n\n\n14\n\n\n7\n\n\n3\n\n\n806.4466\n\n\n\"NEUTRAL\"\n\n\n\"C44H62N4O10\"\n\n\n\"CO[C@H]1/C=C/O...\n\n\n\"MVUYPJALSSDCQB...\n\n\n\n\n\"CHEMBL85010\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n508.96\n\n\n4\n\n\n5\n\n\n2.65\n\n\n139.21\n\n\n9\n\n\n3\n\n\n1\n\n\n7\n\n\n\"N\"\n\n\n0.22\n\n\n7.03\n\n\n2.71\n\n\n3.27\n\n\n2.75\n\n\n1\n\n\n\"MOL\"\n\n\n-1\n\n\n35\n\n\n10\n\n\n3\n\n\n1\n\n\n508.1612\n\n\n\"NEUTRAL\"\n\n\n\"C24H29ClN2O8\"\n\n\n\"CCOCCNC(=O)CO/...\n\n\n\"PHPBXALSGRFDIK...\n\n\n\n\n\"CHEMBL1364151\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n314.39\n\n\n5\n\n\n6\n\n\n2.5\n\n\n54.56\n\n\n4\n\n\n1\n\n\n0\n\n\n3\n\n\n\"N\"\n\n\n0.88\n\n\n13.45\n\n\n7.28\n\n\n2.38\n\n\n2.14\n\n\n2\n\n\n\"MOL\"\n\n\n-1\n\n\n23\n\n\n5\n\n\n1\n\n\n0\n\n\n314.163\n\n\n\"NEUTRAL\"\n\n\n\"C18H22N2O3\"\n\n\n\"Cc1[nH]c2ccccc...\n\n\n\"OKIWVYPITFJCJI...\n\n\n\n\n\"CHEMBL2047203\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n855.36\n\n\n5\n\n\n6\n\n\n7.45\n\n\n272.16\n\n\n10\n\n\n4\n\n\n2\n\n\n13\n\n\n\"N\"\n\n\n0.06\n\n\n-10.58\n\n\n5.78\n\n\n4.35\n\n\n4.11\n\n\n4\n\n\n\"MOL\"\n\n\n-1\n\n\n61\n\n\n20\n\n\n4\n\n\n3\n\n\n854.3492\n\n\n\"ACID\"\n\n\n\"C40H47ClN14O6\"\n\n\n\"COC(=O)N[C@H](...\n\n\n\"QDXJQBSKIKHCKU...\n\n\n\n\n\"CHEMBL3798157\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n455.45\n\n\n28\n\n\n64\n\n\n4.77\n\n\n105.24\n\n\n6\n\n\n3\n\n\n0\n\n\n5\n\n\n\"N\"\n\n\n0.4\n\n\n7.29\n\n\n3.02\n\n\n3.97\n\n\n3.64\n\n\n4\n\n\n\"MOL\"\n\n\n-1\n\n\n32\n\n\n8\n\n\n3\n\n\n0\n\n\n455.0864\n\n\n\"NEUTRAL\"\n\n\n\"C21H15F2N5O3S\"\n\n\n\"CNC(=O)c1cc(Oc...\n\n\n\"LADWERPDOVRXBZ...\n\n\n\n\n\"CHEMBL1337107\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n296.33\n\n\n2\n\n\n2\n\n\n2.29\n\n\n64.35\n\n\n5\n\n\n1\n\n\n0\n\n\n4\n\n\n\"N\"\n\n\n0.75\n\n\n12.82\n\n\n4.35\n\n\n2.35\n\n\n2.35\n\n\n3\n\n\n\"MOL\"\n\n\n-1\n\n\n22\n\n\n5\n\n\n1\n\n\n0\n\n\n296.1161\n\n\n\"NEUTRAL\"\n\n\n\"C17H16N2O3\"\n\n\n\"COC(=O)Cn1c(C(...\n\n\n\"SBCXFZQMSVPTPA...\n\n\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n\n\n\"CHEMBL255122\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n529.07\n\n\n1\n\n\n2\n\n\n2.81\n\n\n110.43\n\n\n6\n\n\n3\n\n\n1\n\n\n5\n\n\n\"N\"\n\n\n0.47\n\n\n12.29\n\n\n6.33\n\n\n1.68\n\n\n1.65\n\n\n3\n\n\n\"MOL\"\n\n\n-1\n\n\n36\n\n\n9\n\n\n3\n\n\n1\n\n\n528.171\n\n\n\"NEUTRAL\"\n\n\n\"C25H29ClN6O3S\"\n\n\n\"CCC(=O)N1CCC(N...\n\n\n\"RAMXCQDJYLSGRA...\n\n\n\n\n\"CHEMBL2018776\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n516.04\n\n\n5\n\n\n5\n\n\n6.1\n\n\n97.84\n\n\n8\n\n\n2\n\n\n2\n\n\n13\n\n\n\"N\"\n\n\n0.26\n\n\n12.76\n\n\n9.18\n\n\n5.66\n\n\n3.88\n\n\n3\n\n\n\"MOL\"\n\n\n-1\n\n\n36\n\n\n9\n\n\n2\n\n\n2\n\n\n515.2299\n\n\n\"BASE\"\n\n\n\"C26H34ClN5O4\"\n\n\n\"CCCCOc1cc2c(Nc...\n\n\n\"FARPVPMCEBTTDI...\n\n\n\n\n\"CHEMBL97207\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n286.12\n\n\n2\n\n\n2\n\n\n1.31\n\n\n99.82\n\n\n5\n\n\n2\n\n\n0\n\n\n3\n\n\n\"N\"\n\n\n0.89\n\n\n13.08\n\n\n0.38\n\n\n2.1\n\n\n2.1\n\n\n2\n\n\n\"MOL\"\n\n\n-1\n\n\n18\n\n\n6\n\n\n4\n\n\n0\n\n\n285.0184\n\n\n\"NEUTRAL\"\n\n\n\"C10H9Cl2N5O\"\n\n\n\"NC(=O)c1nnn(Cc...\n\n\n\"HULYRQSWFVUVSF...\n\n\n\n\n\"CHEMBL221343\"\n\n\n\"\"\n\n\n\"LUF-5980\"\n\n\n\"Small molecule...\n\n\n0\n\n\n313.4\n\n\n5\n\n\n7\n\n\n5.42\n\n\n41.57\n\n\n2\n\n\n1\n\n\n1\n\n\n3\n\n\n\"N\"\n\n\n0.55\n\n\n11.75\n\n\n3.12\n\n\n5.46\n\n\n5.46\n\n\n4\n\n\n\"MOL\"\n\n\n-1\n\n\n24\n\n\n3\n\n\n1\n\n\n1\n\n\n313.1579\n\n\n\"NEUTRAL\"\n\n\n\"C21H19N3\"\n\n\n\"CC(C)c1nc2c(-c...\n\n\n\"REXYMDQLBZWOMA...\n\n\n\n\n\"CHEMBL1420018\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n255.27\n\n\n15\n\n\n20\n\n\n2.31\n\n\n69.39\n\n\n4\n\n\n1\n\n\n0\n\n\n4\n\n\n\"N\"\n\n\n0.52\n\n\n13.72\n\n\n2.76\n\n\n2.38\n\n\n2.38\n\n\n2\n\n\n\"MOL\"\n\n\n-1\n\n\n19\n\n\n4\n\n\n2\n\n\n0\n\n\n255.0895\n\n\n\"NEUTRAL\"\n\n\n\"C15H13NO3\"\n\n\n\"Nc1cccc(C(=O)O...\n\n\n\"UTIDKUVFKVXYLT...\n\n\n\n\n\"CHEMBL2314244\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n470.61\n\n\n7\n\n\n9\n\n\n1.86\n\n\n122.72\n\n\n6\n\n\n6\n\n\n1\n\n\n17\n\n\n\"N\"\n\n\n0.2\n\n\n8.96\n\n\n10.81\n\n\n-0.72\n\n\n-3.93\n\n\n2\n\n\n\"MOL\"\n\n\n-1\n\n\n34\n\n\n8\n\n\n6\n\n\n1\n\n\n470.2893\n\n\n\"BASE\"\n\n\n\"C26H38N4O4\"\n\n\n\"O=C(Cc1ccccc1O...\n\n\n\"SUKXUTUXGGJIBX...\n\n\n\n\n\"CHEMBL1420130\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n226.3\n\n\n2\n\n\n2\n\n\n1.89\n\n\n63.08\n\n\n5\n\n\n1\n\n\n0\n\n\n3\n\n\n\"N\"\n\n\n0.63\n\n\n12.05\n\n\n1.31\n\n\n2.94\n\n\n2.94\n\n\n1\n\n\n\"MOL\"\n\n\n-1\n\n\n15\n\n\n4\n\n\n1\n\n\n0\n\n\n226.0776\n\n\n\"NEUTRAL\"\n\n\n\"C10H14N2O2S\"\n\n\n\"CC(C)(C)C(=O)C...\n\n\n\"LCGAKQAOOABKRG...\n\n\n\n\n\"CHEMBL2419480\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n456.52\n\n\n3\n\n\n3\n\n\n1.56\n\n\n129.46\n\n\n8\n\n\n1\n\n\n0\n\n\n8\n\n\n\"N\"\n\n\n0.59\n\n\n3.99\n\n\n1.9\n\n\n2.14\n\n\n1.2\n\n\n2\n\n\n\"MOL\"\n\n\n-1\n\n\n32\n\n\n9\n\n\n1\n\n\n0\n\n\n456.1467\n\n\n\"ACID\"\n\n\n\"C22H24N4O5S\"\n\n\n\"CCOC(=O)c1cc(C...\n\n\n\"TXYSLOQUANFYQS...\n\n\n\n\n\"CHEMBL540121\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n540.05\n\n\n2\n\n\n3\n\n\n2.39\n\n\n147.14\n\n\n6\n\n\n4\n\n\n1\n\n\n8\n\n\n\"N\"\n\n\n0.22\n\n\n5.02\n\n\n11.48\n\n\n-0.75\n\n\n-0.78\n\n\n4\n\n\n\"MOL\"\n\n\n-1\n\n\n36\n\n\n9\n\n\n5\n\n\n1\n\n\n503.1627\n\n\n\"ZWITTERION\"\n\n\n\"C26H26ClN5O4S\"\n\n\n\"Cc1ccn(NS(=O)(...\n\n\n\"TZLGWENJAJXWGA...\n\n\n\n\n\"CHEMBL374041\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n504.5\n\n\n2\n\n\n4\n\n\n3.04\n\n\n144.95\n\n\n8\n\n\n3\n\n\n1\n\n\n10\n\n\n\"N\"\n\n\n0.28\n\n\n6.59\n\n\n4.37\n\n\n2.17\n\n\n1.33\n\n\n3\n\n\n\"MOL\"\n\n\n-1\n\n\n37\n\n\n11\n\n\n3\n\n\n2\n\n\n504.1645\n\n\n\"NEUTRAL\"\n\n\n\"C26H24N4O7\"\n\n\n\"CCOCCC1(Oc2ccc...\n\n\n\"ABCSNHDQYHOLOO...\n\n\n\n\n\"CHEMBL2017916\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n312.35\n\n\n3\n\n\n3\n\n\n2.86\n\n\n77.0\n\n\n6\n\n\n1\n\n\n0\n\n\n4\n\n\n\"N\"\n\n\n0.8\n\n\n8.13\n\n\n3.49\n\n\n2.17\n\n\n2.1\n\n\n3\n\n\n\"MOL\"\n\n\n-1\n\n\n22\n\n\n6\n\n\n1\n\n\n0\n\n\n312.0681\n\n\n\"NEUTRAL\"\n\n\n\"C15H12N4O2S\"\n\n\n\"COc1ccc(-c2nnc...\n\n\n\"XIZUJGDKNPVNQA...\n\n\n\n\n\"CHEMBL1416264\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"Small molecule...\n\n\n0\n\n\n380.41\n\n\n6\n\n\n8\n\n\n3.06\n\n\n85.07\n\n\n7\n\n\n1\n\n\n0\n\n\n5\n\n\n\"N\"\n\n\n0.54\n\n\n13.85\n\n\n3.86\n\n\n2.47\n\n\n2.47\n\n\n4\n\n\n\"MOL\"\n\n\n-1\n\n\n27\n\n\n7\n\n\n1\n\n\n0\n\n\n380.0856\n\n\n\"NEUTRAL\"\n\n\n\"C18H13FN6OS\"\n\n\n\"O=C(CSc1ccc2nn...\n\n\n\"QVYIEKHEJKFNAT...\n\n\n\n\n\n\n\n\n# Check that all rows with null values were dropped\ndf_dn.null_count()\n\n\n\n\nshape: (1, 32)\n\n\n\n\nChEMBL ID\n\n\nName\n\n\nSynonyms\n\n\nType\n\n\nMax Phase\n\n\nMolecular Weight\n\n\nTargets\n\n\nBioactivities\n\n\nAlogP\n\n\nPolar Surface Area\n\n\nHBA\n\n\nHBD\n\n\n#RO5 Violations\n\n\n#Rotatable Bonds\n\n\nPasses Ro3\n\n\nQED Weighted\n\n\nCX Acidic pKa\n\n\nCX Basic pKa\n\n\nCX LogP\n\n\nCX LogD\n\n\nAromatic Rings\n\n\nStructure Type\n\n\nInorganic Flag\n\n\nHeavy Atoms\n\n\nHBA (Lipinski)\n\n\nHBD (Lipinski)\n\n\n#RO5 Violations (Lipinski)\n\n\nMolecular Weight (Monoisotopic)\n\n\nMolecular Species\n\n\nMolecular Formula\n\n\nSmiles\n\n\nInchi Key\n\n\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\n\n\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n\n\n\n\n\n\n# To see summary statistics for df_dn dataset\ndf_dn.describe()\n\n\n\n\nshape: (7, 33)\n\n\n\n\ndescribe\n\n\nChEMBL ID\n\n\nName\n\n\nSynonyms\n\n\nType\n\n\nMax Phase\n\n\nMolecular Weight\n\n\nTargets\n\n\nBioactivities\n\n\nAlogP\n\n\nPolar Surface Area\n\n\nHBA\n\n\nHBD\n\n\n#RO5 Violations\n\n\n#Rotatable Bonds\n\n\nPasses Ro3\n\n\nQED Weighted\n\n\nCX Acidic pKa\n\n\nCX Basic pKa\n\n\nCX LogP\n\n\nCX LogD\n\n\nAromatic Rings\n\n\nStructure Type\n\n\nInorganic Flag\n\n\nHeavy Atoms\n\n\nHBA (Lipinski)\n\n\nHBD (Lipinski)\n\n\n#RO5 Violations (Lipinski)\n\n\nMolecular Weight (Monoisotopic)\n\n\nMolecular Species\n\n\nMolecular Formula\n\n\nSmiles\n\n\nInchi Key\n\n\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nstr\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nstr\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n\"count\"\n\n\n\"736570\"\n\n\n\"736570\"\n\n\n\"736570\"\n\n\n\"736570\"\n\n\n736570.0\n\n\n736570.0\n\n\n736570.0\n\n\n736570.0\n\n\n736570.0\n\n\n736570.0\n\n\n736570.0\n\n\n736570.0\n\n\n736570.0\n\n\n736570.0\n\n\n\"736570\"\n\n\n736570.0\n\n\n736570.0\n\n\n736570.0\n\n\n736570.0\n\n\n736570.0\n\n\n736570.0\n\n\n\"736570\"\n\n\n736570.0\n\n\n736570.0\n\n\n736570.0\n\n\n736570.0\n\n\n736570.0\n\n\n736570.0\n\n\n\"736570\"\n\n\n\"736570\"\n\n\n\"736570\"\n\n\n\"736570\"\n\n\n\n\n\"null_count\"\n\n\n\"0\"\n\n\n\"0\"\n\n\n\"0\"\n\n\n\"0\"\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n\"0\"\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n\"0\"\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n\"0\"\n\n\n\"0\"\n\n\n\"0\"\n\n\n\"0\"\n\n\n\n\n\"mean\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n0.007937\n\n\n431.880042\n\n\n5.520715\n\n\n8.705471\n\n\n3.325204\n\n\n97.58116\n\n\n5.890221\n\n\n2.274721\n\n\n0.489124\n\n\n6.216262\n\n\nnull\n\n\n0.510936\n\n\n9.59944\n\n\n5.074377\n\n\n2.815115\n\n\n2.17363\n\n\n2.754412\n\n\nnull\n\n\n-0.929521\n\n\n30.266113\n\n\n7.276555\n\n\n2.497847\n\n\n0.576319\n\n\n428.334452\n\n\nnull\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\n\n\"std\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n0.164565\n\n\n135.637543\n\n\n14.784793\n\n\n55.537836\n\n\n1.980414\n\n\n47.40847\n\n\n2.459106\n\n\n1.681943\n\n\n0.794171\n\n\n3.894505\n\n\nnull\n\n\n0.229039\n\n\n3.583639\n\n\n3.234099\n\n\n2.286325\n\n\n2.645694\n\n\n1.2009\n\n\nnull\n\n\n0.255953\n\n\n9.54406\n\n\n3.067158\n\n\n2.081485\n\n\n0.908719\n\n\n133.755653\n\n\nnull\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\n\n\"min\"\n\n\n\"CHEMBL10\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n0.0\n\n\n45.04\n\n\n1.0\n\n\n1.0\n\n\n-12.92\n\n\n3.24\n\n\n1.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n\"N\"\n\n\n0.01\n\n\n-20.03\n\n\n0.0\n\n\n-16.71\n\n\n-26.04\n\n\n0.0\n\n\n\"BOTH\"\n\n\n-1.0\n\n\n3.0\n\n\n1.0\n\n\n0.0\n\n\n0.0\n\n\n45.0215\n\n\n\"ACID\"\n\n\n\"C10H10Br2N2O\"\n\n\n\"Br.Br.C/C(=N/N...\n\n\n\"AAAADVYFXUUVEO...\n\n\n\n\n\"max\"\n\n\n\"CHEMBL99998\"\n\n\n\"t-4-AMINOCROTO...\n\n\n\"trovafloxacin9...\n\n\n\"Unknown\"\n\n\n4.0\n\n\n1901.51\n\n\n1334.0\n\n\n17911.0\n\n\n16.83\n\n\n595.22\n\n\n32.0\n\n\n25.0\n\n\n4.0\n\n\n59.0\n\n\n\"Y\"\n\n\n0.95\n\n\n14.0\n\n\n38.8\n\n\n18.31\n\n\n18.31\n\n\n28.0\n\n\n\"MOL\"\n\n\n0.0\n\n\n76.0\n\n\n34.0\n\n\n32.0\n\n\n4.0\n\n\n999.4063\n\n\n\"ZWITTERION\"\n\n\n\"HNNa2O8S2\"\n\n\n\"n1nc2c([nH]1)c...\n\n\n\"ZZZZEJJXQQRZBH...\n\n\n\n\n\"median\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n0.0\n\n\n413.46\n\n\n2.0\n\n\n3.0\n\n\n3.37\n\n\n88.32\n\n\n5.0\n\n\n2.0\n\n\n0.0\n\n\n5.0\n\n\nnull\n\n\n0.51\n\n\n10.51\n\n\n4.7\n\n\n2.97\n\n\n2.46\n\n\n3.0\n\n\nnull\n\n\n-1.0\n\n\n29.0\n\n\n7.0\n\n\n2.0\n\n\n0.0\n\n\n410.2066\n\n\nnull\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\n\n\n\n\n\n\n\nSome exploratory data analysis\nOne of the columns that jumped out from the summary statistics of the df_dn dataset was the “Targets” column. It ranged from 1 to 1334 targets. Out of curiosity, I went through several places on ChEMBL website to find out the exact definition of “Target”. Eventually I settled on an answer which explained that the “Target” column represented the number of targets associated with the particular ChEMBL compound listed. I then singled out the ChEMBL compound with 1334 targets recorded, it turned out to be imatinib, which was marketed as Gleevec, and was a well-known prescription medicine for leukaemia and other selected oncological disorders with many well-documented drug interactions.\n\n# This was confirmed via a filter function, which brought up CHEMBL1421, or also known as dasatinib\ndf_dn.filter(pl.col(\"Targets\") == 1334)\n\n\n\n\nshape: (1, 32)\n\n\n\n\nChEMBL ID\n\n\nName\n\n\nSynonyms\n\n\nType\n\n\nMax Phase\n\n\nMolecular Weight\n\n\nTargets\n\n\nBioactivities\n\n\nAlogP\n\n\nPolar Surface Area\n\n\nHBA\n\n\nHBD\n\n\n#RO5 Violations\n\n\n#Rotatable Bonds\n\n\nPasses Ro3\n\n\nQED Weighted\n\n\nCX Acidic pKa\n\n\nCX Basic pKa\n\n\nCX LogP\n\n\nCX LogD\n\n\nAromatic Rings\n\n\nStructure Type\n\n\nInorganic Flag\n\n\nHeavy Atoms\n\n\nHBA (Lipinski)\n\n\nHBD (Lipinski)\n\n\n#RO5 Violations (Lipinski)\n\n\nMolecular Weight (Monoisotopic)\n\n\nMolecular Species\n\n\nMolecular Formula\n\n\nSmiles\n\n\nInchi Key\n\n\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\ni64\n\n\nf64\n\n\ni64\n\n\ni64\n\n\nf64\n\n\nf64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\nstr\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\ni64\n\n\nstr\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\nf64\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n\"CHEMBL941\"\n\n\n\"IMATINIB\"\n\n\n\"GLAMOX|Gleevec...\n\n\n\"Small molecule...\n\n\n4\n\n\n493.62\n\n\n1334\n\n\n4359\n\n\n4.59\n\n\n86.28\n\n\n7\n\n\n2\n\n\n0\n\n\n7\n\n\n\"N\"\n\n\n0.39\n\n\n12.69\n\n\n7.84\n\n\n4.38\n\n\n3.8\n\n\n4\n\n\n\"MOL\"\n\n\n0\n\n\n37\n\n\n8\n\n\n2\n\n\n0\n\n\n493.259\n\n\n\"NEUTRAL\"\n\n\n\"C29H31N7O\"\n\n\n\"Cc1ccc(NC(=O)c...\n\n\n\"KTUFNOKKBVMGRW...\n\n\n\n\n\n\n\nTo explore other physicochemical and molecular properties in the dataframe, “Max Phase” was one of the first few that drew my interests. So it tagged each ChEMBL compound with a max phase number from 0 to 4, where 4 meant the compound was approved (usually also meant it was already a prescription medicine). Thinking along this line, I thought what about those compounds that had max phase as 0, because they were the ones still pending associations with max phase numbers. So I thought this might be a good opportunity to introduce some ML into this project, to predict whether these zero max phase compounds would enter the approved max phase.\nFirstly, I had a look at the overall distribution of the max phase compounds in this dataframe df_dn.\n\n# Interested in what types of \"Max Phase\" were recorded \n# for the curated small molecules in ChEMBL database\ndf_dn.groupby(\"Max Phase\", maintain_order = True).agg(pl.count())\n\n\n\n\nshape: (5, 2)\n\n\n\n\nMax Phase\n\n\ncount\n\n\n\n\ni64\n\n\nu32\n\n\n\n\n\n\n0\n\n\n734633\n\n\n\n\n3\n\n\n303\n\n\n\n\n4\n\n\n954\n\n\n\n\n2\n\n\n441\n\n\n\n\n1\n\n\n239\n\n\n\n\n\n\n\nA quick groupby function showed that there were only 954 small molecules approved. Phase 3 recorded a total of 303 small molecules. For phase 2, there were 441 small molecules, followed by 239 compounds in phase 1. There were, however, a total amount of 734,633 small molecules that had zero as phase number (as per ChEMBL_31 schema documentation). Note: these figures were only for ChEMBL compounds with full documentations in the dataset (excluding entries or compounds with N/A or “” (empty) string cells).\nOne of the other parameters I was interested in was “QED Weighted”. So I went further into understanding what it meant, as the original reference was conveniently provided in the ChEMBL_31 schema documentation. The reference paper was by Bickerton, G., Paolini, G., Besnard, J. et al. Quantifying the chemical beauty of drugs. Nature Chem 4, 90–98 (2012)(note: author’s manuscript was available to view via PubMed link, the Nature Chemistry link only provided abstract with access to article via other means as stated).\nIn short, it was a measure of druglikeness for small molecules based on the concept of desirability, which was based on a total of 8 different molecular properties. These molecular properties included molecular weight, ALogP, polar surface area, number of hydrogen bond acceptors, number of hydrogen bond donors, number of rotatable bonds, number of aromatic rings and structural alerts. Without going into too much details for this QED Weighted parameter, it was normally recorded as a number that ranged from 0 to 1, with 0 being the least druglike and 1 being the most druglike.\n\n\n\nPrepare dataframe prior to running machine learning model\nBefore I got too carried away with further EDA, I wanted to get started on preparing a dataframe for the ML model. A rough plan at this stage was to filter out Max Phase 4 and 0 compounds. Max phase 0 compounds were the ones that were not assigned with any max phase numbers yet, so I thought they would be ideal for use as the testing set. The main idea was to use “Max Phase” parameter as the target y variable for a LR model, because ultimately stakeholders would be more interested in knowing which candidate compounds had the most likely chance to reach the final approved phase during a drug discovery and development project, with also a chance to potentially reduce resources and time required in such a complex matter.\nThe goal of this ML model was to answer the question: which physicochemical parameters would be the most suitable ones to predict whether a compound would enter max phase 4 (approved) or not? (implicitly, this might also help indicate whether if we could predict if any of the max phase 0 compounds would likely enter max phase 4 in the end)\nI’ve then narrowed down the df_dn dataset to fulfill the following criteria:\n* Only small molecules present * Max phase of 0 and 4 only\nAnother reason behind choosing only small molecules that had max phase of 0 and 4 was that a confusion matrix could be built in the end to see if the parameters selected would give us a reasonably good model for predicting the outcomes of these small molecules. For now, I’ve chosen the following columns (or physicochemical parameters) to appear in this interim df_f dataset.\n\n# Selecting Max phase 0 small molecules with desired parameters\ndf_0 = df_dn.filter(\n    (pl.col(\"Type\") == \"Small molecule\") &\n    (pl.col(\"Max Phase\") == 0)\n).select([\"ChEMBL ID\", \n          \"Type\", \n          \"Max Phase\",\n          \"#RO5 Violations\", \n          \"QED Weighted\", \n          \"CX LogP\", \n          \"CX LogD\", \n          \"Heavy Atoms\"]\n        )\ndf_0\n\n\n\n\nshape: (612795, 8)\n\n\n\n\nChEMBL ID\n\n\nType\n\n\nMax Phase\n\n\n#RO5 Violations\n\n\nQED Weighted\n\n\nCX LogP\n\n\nCX LogD\n\n\nHeavy Atoms\n\n\n\n\nstr\n\n\nstr\n\n\ni64\n\n\ni64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\ni64\n\n\n\n\n\n\n\"CHEMBL539070\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.63\n\n\n2.57\n\n\n2.57\n\n\n17\n\n\n\n\n\"CHEMBL3827271\"\n\n\n\"Small molecule...\n\n\n0\n\n\n2\n\n\n0.07\n\n\n-6.88\n\n\n-8.95\n\n\n50\n\n\n\n\n\"CHEMBL3824158\"\n\n\n\"Small molecule...\n\n\n0\n\n\n1\n\n\n0.31\n\n\n2.49\n\n\n2.42\n\n\n31\n\n\n\n\n\"CHEMBL1991010\"\n\n\n\"Small molecule...\n\n\n0\n\n\n1\n\n\n0.6\n\n\n6.34\n\n\n5.22\n\n\n31\n\n\n\n\n\"CHEMBL195644\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.73\n\n\n3.92\n\n\n3.91\n\n\n28\n\n\n\n\n\"CHEMBL255263\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.72\n\n\n1.74\n\n\n1.74\n\n\n27\n\n\n\n\n\"CHEMBL504846\"\n\n\n\"Small molecule...\n\n\n0\n\n\n3\n\n\n0.23\n\n\n3.4\n\n\n2.87\n\n\n58\n\n\n\n\n\"CHEMBL85010\"\n\n\n\"Small molecule...\n\n\n0\n\n\n1\n\n\n0.22\n\n\n3.27\n\n\n2.75\n\n\n35\n\n\n\n\n\"CHEMBL1364151\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.88\n\n\n2.38\n\n\n2.14\n\n\n23\n\n\n\n\n\"CHEMBL2047203\"\n\n\n\"Small molecule...\n\n\n0\n\n\n2\n\n\n0.06\n\n\n4.35\n\n\n4.11\n\n\n61\n\n\n\n\n\"CHEMBL3798157\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.4\n\n\n3.97\n\n\n3.64\n\n\n32\n\n\n\n\n\"CHEMBL1337107\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.75\n\n\n2.35\n\n\n2.35\n\n\n22\n\n\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n\n\n\"CHEMBL255122\"\n\n\n\"Small molecule...\n\n\n0\n\n\n1\n\n\n0.47\n\n\n1.68\n\n\n1.65\n\n\n36\n\n\n\n\n\"CHEMBL2018776\"\n\n\n\"Small molecule...\n\n\n0\n\n\n2\n\n\n0.26\n\n\n5.66\n\n\n3.88\n\n\n36\n\n\n\n\n\"CHEMBL97207\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.89\n\n\n2.1\n\n\n2.1\n\n\n18\n\n\n\n\n\"CHEMBL221343\"\n\n\n\"Small molecule...\n\n\n0\n\n\n1\n\n\n0.55\n\n\n5.46\n\n\n5.46\n\n\n24\n\n\n\n\n\"CHEMBL1420018\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.52\n\n\n2.38\n\n\n2.38\n\n\n19\n\n\n\n\n\"CHEMBL2314244\"\n\n\n\"Small molecule...\n\n\n0\n\n\n1\n\n\n0.2\n\n\n-0.72\n\n\n-3.93\n\n\n34\n\n\n\n\n\"CHEMBL1420130\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.63\n\n\n2.94\n\n\n2.94\n\n\n15\n\n\n\n\n\"CHEMBL2419480\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.59\n\n\n2.14\n\n\n1.2\n\n\n32\n\n\n\n\n\"CHEMBL540121\"\n\n\n\"Small molecule...\n\n\n0\n\n\n1\n\n\n0.22\n\n\n-0.75\n\n\n-0.78\n\n\n36\n\n\n\n\n\"CHEMBL374041\"\n\n\n\"Small molecule...\n\n\n0\n\n\n1\n\n\n0.28\n\n\n2.17\n\n\n1.33\n\n\n37\n\n\n\n\n\"CHEMBL2017916\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.8\n\n\n2.17\n\n\n2.1\n\n\n22\n\n\n\n\n\"CHEMBL1416264\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.54\n\n\n2.47\n\n\n2.47\n\n\n27\n\n\n\n\n\n\n\n\n# Selecting Max phase 4 small molecules with desired parameters\ndf_4 = df_dn.filter(\n    (pl.col(\"Type\") == \"Small molecule\") &\n    (pl.col(\"Max Phase\") == 4)\n).select([\"ChEMBL ID\", \n          \"Type\", \n          \"Max Phase\",\n          \"#RO5 Violations\", \n          \"QED Weighted\", \n          \"CX LogP\", \n          \"CX LogD\", \n          \"Heavy Atoms\"]\n        )\ndf_4\n\n\n\n\nshape: (944, 8)\n\n\n\n\nChEMBL ID\n\n\nType\n\n\nMax Phase\n\n\n#RO5 Violations\n\n\nQED Weighted\n\n\nCX LogP\n\n\nCX LogD\n\n\nHeavy Atoms\n\n\n\n\nstr\n\n\nstr\n\n\ni64\n\n\ni64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\ni64\n\n\n\n\n\n\n\"CHEMBL1096882\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.31\n\n\n-1.97\n\n\n-5.12\n\n\n24\n\n\n\n\n\"CHEMBL2023898\"\n\n\n\"Small molecule...\n\n\n4\n\n\n2\n\n\n0.14\n\n\n4.18\n\n\n4.16\n\n\n54\n\n\n\n\n\"CHEMBL1029\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.46\n\n\n-1.18\n\n\n-2.3\n\n\n15\n\n\n\n\n\"CHEMBL1616\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.72\n\n\n2.88\n\n\n2.58\n\n\n20\n\n\n\n\n\"CHEMBL2146123\"\n\n\n\"Small molecule...\n\n\n4\n\n\n1\n\n\n0.33\n\n\n-3.51\n\n\n-3.81\n\n\n32\n\n\n\n\n\"CHEMBL1200773\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.75\n\n\n1.88\n\n\n1.0\n\n\n14\n\n\n\n\n\"CHEMBL1201002\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.77\n\n\n1.42\n\n\n-0.89\n\n\n21\n\n\n\n\n\"CHEMBL1086440\"\n\n\n\"Small molecule...\n\n\n4\n\n\n1\n\n\n0.58\n\n\n5.88\n\n\n5.88\n\n\n21\n\n\n\n\n\"CHEMBL2359966\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.88\n\n\n2.51\n\n\n0.86\n\n\n24\n\n\n\n\n\"CHEMBL302795\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.87\n\n\n-0.12\n\n\n-1.91\n\n\n22\n\n\n\n\n\"CHEMBL1214185\"\n\n\n\"Small molecule...\n\n\n4\n\n\n2\n\n\n0.08\n\n\n3.0\n\n\n1.32\n\n\n58\n\n\n\n\n\"CHEMBL487253\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.7\n\n\n1.8\n\n\n0.81\n\n\n23\n\n\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n\n\n\"CHEMBL2103743\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.93\n\n\n1.24\n\n\n1.19\n\n\n23\n\n\n\n\n\"CHEMBL3989931\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.46\n\n\n4.59\n\n\n4.59\n\n\n33\n\n\n\n\n\"CHEMBL1201033\"\n\n\n\"Small molecule...\n\n\n4\n\n\n1\n\n\n0.32\n\n\n3.4\n\n\n1.0\n\n\n19\n\n\n\n\n\"CHEMBL1201731\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.69\n\n\n3.21\n\n\n1.71\n\n\n29\n\n\n\n\n\"CHEMBL2105743\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.58\n\n\n1.19\n\n\n-0.18\n\n\n28\n\n\n\n\n\"CHEMBL4297513\"\n\n\n\"Small molecule...\n\n\n4\n\n\n2\n\n\n0.26\n\n\n4.9\n\n\n4.9\n\n\n53\n\n\n\n\n\"CHEMBL1201321\"\n\n\n\"Small molecule...\n\n\n4\n\n\n1\n\n\n0.58\n\n\n2.65\n\n\n2.65\n\n\n32\n\n\n\n\n\"CHEMBL3545062\"\n\n\n\"Small molecule...\n\n\n4\n\n\n2\n\n\n0.1\n\n\n5.57\n\n\n5.57\n\n\n65\n\n\n\n\n\"CHEMBL3039520\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.83\n\n\n3.3\n\n\n2.61\n\n\n27\n\n\n\n\n\"CHEMBL1198857\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.26\n\n\n3.6\n\n\n1.93\n\n\n32\n\n\n\n\n\"CHEMBL2146133\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.77\n\n\n2.43\n\n\n2.43\n\n\n24\n\n\n\n\n\"CHEMBL1619785\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.49\n\n\n2.09\n\n\n1.86\n\n\n34\n\n\n\n\n\n\n\n\n\nRe-sampling via under-sampling\nBecause of the large number of Max Phase 0 compounds present in the original dataset, I’ve randomly sampled about 950 small molecules from this group, so that there were similar amount of data in each group to avoid having an imbalanced dataset.\n\ndf_s_0 = df_0.sample(n = 950, shuffle = True, seed = 0)\ndf_s_0\n\n\n\n\nshape: (950, 8)\n\n\n\n\nChEMBL ID\n\n\nType\n\n\nMax Phase\n\n\n#RO5 Violations\n\n\nQED Weighted\n\n\nCX LogP\n\n\nCX LogD\n\n\nHeavy Atoms\n\n\n\n\nstr\n\n\nstr\n\n\ni64\n\n\ni64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\ni64\n\n\n\n\n\n\n\"CHEMBL3448290\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.91\n\n\n2.05\n\n\n0.62\n\n\n21\n\n\n\n\n\"CHEMBL3966308\"\n\n\n\"Small molecule...\n\n\n0\n\n\n2\n\n\n0.16\n\n\n1.51\n\n\n-0.41\n\n\n48\n\n\n\n\n\"CHEMBL3963545\"\n\n\n\"Small molecule...\n\n\n0\n\n\n2\n\n\n0.2\n\n\n5.05\n\n\n3.27\n\n\n46\n\n\n\n\n\"CHEMBL1649629\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.53\n\n\n3.21\n\n\n3.21\n\n\n24\n\n\n\n\n\"CHEMBL3813954\"\n\n\n\"Small molecule...\n\n\n0\n\n\n1\n\n\n0.14\n\n\n2.8\n\n\n2.8\n\n\n37\n\n\n\n\n\"CHEMBL1164717\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.42\n\n\n1.6\n\n\n1.55\n\n\n35\n\n\n\n\n\"CHEMBL1824896\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.58\n\n\n4.69\n\n\n4.13\n\n\n34\n\n\n\n\n\"CHEMBL2323807\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.88\n\n\n3.09\n\n\n2.22\n\n\n20\n\n\n\n\n\"CHEMBL3919258\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.5\n\n\n1.36\n\n\n1.36\n\n\n32\n\n\n\n\n\"CHEMBL1973768\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.61\n\n\n-1.09\n\n\n-1.09\n\n\n15\n\n\n\n\n\"CHEMBL3193130\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.32\n\n\n2.88\n\n\n2.88\n\n\n30\n\n\n\n\n\"CHEMBL157009\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.4\n\n\n-1.57\n\n\n-1.6\n\n\n20\n\n\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n\n\n\"CHEMBL1586774\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.79\n\n\n4.03\n\n\n4.02\n\n\n25\n\n\n\n\n\"CHEMBL3735848\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.62\n\n\n2.49\n\n\n2.48\n\n\n31\n\n\n\n\n\"CHEMBL2238035\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.63\n\n\n-0.89\n\n\n-0.9\n\n\n18\n\n\n\n\n\"CHEMBL2409594\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.42\n\n\n2.9\n\n\n2.9\n\n\n32\n\n\n\n\n\"CHEMBL1823603\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.51\n\n\n4.06\n\n\n4.06\n\n\n32\n\n\n\n\n\"CHEMBL1373723\"\n\n\n\"Small molecule...\n\n\n0\n\n\n2\n\n\n0.25\n\n\n4.85\n\n\n4.84\n\n\n47\n\n\n\n\n\"CHEMBL1092638\"\n\n\n\"Small molecule...\n\n\n0\n\n\n1\n\n\n0.45\n\n\n5.0\n\n\n4.78\n\n\n34\n\n\n\n\n\"CHEMBL3884327\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.23\n\n\n2.0\n\n\n1.31\n\n\n33\n\n\n\n\n\"CHEMBL3952298\"\n\n\n\"Small molecule...\n\n\n0\n\n\n2\n\n\n0.27\n\n\n4.75\n\n\n4.75\n\n\n37\n\n\n\n\n\"CHEMBL3958658\"\n\n\n\"Small molecule...\n\n\n0\n\n\n1\n\n\n0.37\n\n\n4.32\n\n\n4.32\n\n\n36\n\n\n\n\n\"CHEMBL2181572\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.32\n\n\n3.3\n\n\n3.3\n\n\n23\n\n\n\n\n\"CHEMBL603992\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.27\n\n\n3.51\n\n\n3.51\n\n\n35\n\n\n\n\n\n\n\nSince the plan was to use LR method for ML model, the y variable I was interested in was whether a small molecule would be approved or not, so it was going to be a binary categorical variable - meaning it needed to be 0 (not approved) or 1 (approved). To do this, I’ve added a new column with a new name of “Max_Phase” and replace “4” as “1” by dividing the whole column by 4 to reach this new label.\n\ndf_4_f = df_4.with_columns((pl.col(\"Max Phase\") / 4).alias(\"Max_Phase\"))\ndf_4_f\n\n\n\n\nshape: (944, 9)\n\n\n\n\nChEMBL ID\n\n\nType\n\n\nMax Phase\n\n\n#RO5 Violations\n\n\nQED Weighted\n\n\nCX LogP\n\n\nCX LogD\n\n\nHeavy Atoms\n\n\nMax_Phase\n\n\n\n\nstr\n\n\nstr\n\n\ni64\n\n\ni64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\ni64\n\n\nf64\n\n\n\n\n\n\n\"CHEMBL1096882\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.31\n\n\n-1.97\n\n\n-5.12\n\n\n24\n\n\n1.0\n\n\n\n\n\"CHEMBL2023898\"\n\n\n\"Small molecule...\n\n\n4\n\n\n2\n\n\n0.14\n\n\n4.18\n\n\n4.16\n\n\n54\n\n\n1.0\n\n\n\n\n\"CHEMBL1029\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.46\n\n\n-1.18\n\n\n-2.3\n\n\n15\n\n\n1.0\n\n\n\n\n\"CHEMBL1616\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.72\n\n\n2.88\n\n\n2.58\n\n\n20\n\n\n1.0\n\n\n\n\n\"CHEMBL2146123\"\n\n\n\"Small molecule...\n\n\n4\n\n\n1\n\n\n0.33\n\n\n-3.51\n\n\n-3.81\n\n\n32\n\n\n1.0\n\n\n\n\n\"CHEMBL1200773\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.75\n\n\n1.88\n\n\n1.0\n\n\n14\n\n\n1.0\n\n\n\n\n\"CHEMBL1201002\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.77\n\n\n1.42\n\n\n-0.89\n\n\n21\n\n\n1.0\n\n\n\n\n\"CHEMBL1086440\"\n\n\n\"Small molecule...\n\n\n4\n\n\n1\n\n\n0.58\n\n\n5.88\n\n\n5.88\n\n\n21\n\n\n1.0\n\n\n\n\n\"CHEMBL2359966\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.88\n\n\n2.51\n\n\n0.86\n\n\n24\n\n\n1.0\n\n\n\n\n\"CHEMBL302795\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.87\n\n\n-0.12\n\n\n-1.91\n\n\n22\n\n\n1.0\n\n\n\n\n\"CHEMBL1214185\"\n\n\n\"Small molecule...\n\n\n4\n\n\n2\n\n\n0.08\n\n\n3.0\n\n\n1.32\n\n\n58\n\n\n1.0\n\n\n\n\n\"CHEMBL487253\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.7\n\n\n1.8\n\n\n0.81\n\n\n23\n\n\n1.0\n\n\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n\n\n\"CHEMBL2103743\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.93\n\n\n1.24\n\n\n1.19\n\n\n23\n\n\n1.0\n\n\n\n\n\"CHEMBL3989931\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.46\n\n\n4.59\n\n\n4.59\n\n\n33\n\n\n1.0\n\n\n\n\n\"CHEMBL1201033\"\n\n\n\"Small molecule...\n\n\n4\n\n\n1\n\n\n0.32\n\n\n3.4\n\n\n1.0\n\n\n19\n\n\n1.0\n\n\n\n\n\"CHEMBL1201731\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.69\n\n\n3.21\n\n\n1.71\n\n\n29\n\n\n1.0\n\n\n\n\n\"CHEMBL2105743\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.58\n\n\n1.19\n\n\n-0.18\n\n\n28\n\n\n1.0\n\n\n\n\n\"CHEMBL4297513\"\n\n\n\"Small molecule...\n\n\n4\n\n\n2\n\n\n0.26\n\n\n4.9\n\n\n4.9\n\n\n53\n\n\n1.0\n\n\n\n\n\"CHEMBL1201321\"\n\n\n\"Small molecule...\n\n\n4\n\n\n1\n\n\n0.58\n\n\n2.65\n\n\n2.65\n\n\n32\n\n\n1.0\n\n\n\n\n\"CHEMBL3545062\"\n\n\n\"Small molecule...\n\n\n4\n\n\n2\n\n\n0.1\n\n\n5.57\n\n\n5.57\n\n\n65\n\n\n1.0\n\n\n\n\n\"CHEMBL3039520\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.83\n\n\n3.3\n\n\n2.61\n\n\n27\n\n\n1.0\n\n\n\n\n\"CHEMBL1198857\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.26\n\n\n3.6\n\n\n1.93\n\n\n32\n\n\n1.0\n\n\n\n\n\"CHEMBL2146133\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.77\n\n\n2.43\n\n\n2.43\n\n\n24\n\n\n1.0\n\n\n\n\n\"CHEMBL1619785\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.49\n\n\n2.09\n\n\n1.86\n\n\n34\n\n\n1.0\n\n\n\n\n\n\n\nThen I changed the data type of “Max_Phase” from float to integer, so that the two different dataframes could be concatenated (which would only work if both were of same data types).\n\ndf_4_f = df_4_f.with_column((pl.col(\"Max_Phase\")).cast(pl.Int64, strict = False))\ndf_4_f\n\n\n\n\nshape: (944, 9)\n\n\n\n\nChEMBL ID\n\n\nType\n\n\nMax Phase\n\n\n#RO5 Violations\n\n\nQED Weighted\n\n\nCX LogP\n\n\nCX LogD\n\n\nHeavy Atoms\n\n\nMax_Phase\n\n\n\n\nstr\n\n\nstr\n\n\ni64\n\n\ni64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\ni64\n\n\ni64\n\n\n\n\n\n\n\"CHEMBL1096882\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.31\n\n\n-1.97\n\n\n-5.12\n\n\n24\n\n\n1\n\n\n\n\n\"CHEMBL2023898\"\n\n\n\"Small molecule...\n\n\n4\n\n\n2\n\n\n0.14\n\n\n4.18\n\n\n4.16\n\n\n54\n\n\n1\n\n\n\n\n\"CHEMBL1029\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.46\n\n\n-1.18\n\n\n-2.3\n\n\n15\n\n\n1\n\n\n\n\n\"CHEMBL1616\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.72\n\n\n2.88\n\n\n2.58\n\n\n20\n\n\n1\n\n\n\n\n\"CHEMBL2146123\"\n\n\n\"Small molecule...\n\n\n4\n\n\n1\n\n\n0.33\n\n\n-3.51\n\n\n-3.81\n\n\n32\n\n\n1\n\n\n\n\n\"CHEMBL1200773\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.75\n\n\n1.88\n\n\n1.0\n\n\n14\n\n\n1\n\n\n\n\n\"CHEMBL1201002\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.77\n\n\n1.42\n\n\n-0.89\n\n\n21\n\n\n1\n\n\n\n\n\"CHEMBL1086440\"\n\n\n\"Small molecule...\n\n\n4\n\n\n1\n\n\n0.58\n\n\n5.88\n\n\n5.88\n\n\n21\n\n\n1\n\n\n\n\n\"CHEMBL2359966\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.88\n\n\n2.51\n\n\n0.86\n\n\n24\n\n\n1\n\n\n\n\n\"CHEMBL302795\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.87\n\n\n-0.12\n\n\n-1.91\n\n\n22\n\n\n1\n\n\n\n\n\"CHEMBL1214185\"\n\n\n\"Small molecule...\n\n\n4\n\n\n2\n\n\n0.08\n\n\n3.0\n\n\n1.32\n\n\n58\n\n\n1\n\n\n\n\n\"CHEMBL487253\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.7\n\n\n1.8\n\n\n0.81\n\n\n23\n\n\n1\n\n\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n\n\n\"CHEMBL2103743\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.93\n\n\n1.24\n\n\n1.19\n\n\n23\n\n\n1\n\n\n\n\n\"CHEMBL3989931\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.46\n\n\n4.59\n\n\n4.59\n\n\n33\n\n\n1\n\n\n\n\n\"CHEMBL1201033\"\n\n\n\"Small molecule...\n\n\n4\n\n\n1\n\n\n0.32\n\n\n3.4\n\n\n1.0\n\n\n19\n\n\n1\n\n\n\n\n\"CHEMBL1201731\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.69\n\n\n3.21\n\n\n1.71\n\n\n29\n\n\n1\n\n\n\n\n\"CHEMBL2105743\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.58\n\n\n1.19\n\n\n-0.18\n\n\n28\n\n\n1\n\n\n\n\n\"CHEMBL4297513\"\n\n\n\"Small molecule...\n\n\n4\n\n\n2\n\n\n0.26\n\n\n4.9\n\n\n4.9\n\n\n53\n\n\n1\n\n\n\n\n\"CHEMBL1201321\"\n\n\n\"Small molecule...\n\n\n4\n\n\n1\n\n\n0.58\n\n\n2.65\n\n\n2.65\n\n\n32\n\n\n1\n\n\n\n\n\"CHEMBL3545062\"\n\n\n\"Small molecule...\n\n\n4\n\n\n2\n\n\n0.1\n\n\n5.57\n\n\n5.57\n\n\n65\n\n\n1\n\n\n\n\n\"CHEMBL3039520\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.83\n\n\n3.3\n\n\n2.61\n\n\n27\n\n\n1\n\n\n\n\n\"CHEMBL1198857\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.26\n\n\n3.6\n\n\n1.93\n\n\n32\n\n\n1\n\n\n\n\n\"CHEMBL2146133\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.77\n\n\n2.43\n\n\n2.43\n\n\n24\n\n\n1\n\n\n\n\n\"CHEMBL1619785\"\n\n\n\"Small molecule...\n\n\n4\n\n\n0\n\n\n0.49\n\n\n2.09\n\n\n1.86\n\n\n34\n\n\n1\n\n\n\n\n\n\n\nAlso I’ve created a new column with the same name of “Max_Phase” for Max phase 0 small molecules, so that the two dataframes could be combined (also needed to have exactly the same column names for it to work).\n\ndf_s_0_f = df_s_0.with_column((pl.col(\"Max Phase\")).alias(\"Max_Phase\"))\ndf_s_0_f\n\n\n\n\nshape: (950, 9)\n\n\n\n\nChEMBL ID\n\n\nType\n\n\nMax Phase\n\n\n#RO5 Violations\n\n\nQED Weighted\n\n\nCX LogP\n\n\nCX LogD\n\n\nHeavy Atoms\n\n\nMax_Phase\n\n\n\n\nstr\n\n\nstr\n\n\ni64\n\n\ni64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\ni64\n\n\ni64\n\n\n\n\n\n\n\"CHEMBL3448290\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.91\n\n\n2.05\n\n\n0.62\n\n\n21\n\n\n0\n\n\n\n\n\"CHEMBL3966308\"\n\n\n\"Small molecule...\n\n\n0\n\n\n2\n\n\n0.16\n\n\n1.51\n\n\n-0.41\n\n\n48\n\n\n0\n\n\n\n\n\"CHEMBL3963545\"\n\n\n\"Small molecule...\n\n\n0\n\n\n2\n\n\n0.2\n\n\n5.05\n\n\n3.27\n\n\n46\n\n\n0\n\n\n\n\n\"CHEMBL1649629\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.53\n\n\n3.21\n\n\n3.21\n\n\n24\n\n\n0\n\n\n\n\n\"CHEMBL3813954\"\n\n\n\"Small molecule...\n\n\n0\n\n\n1\n\n\n0.14\n\n\n2.8\n\n\n2.8\n\n\n37\n\n\n0\n\n\n\n\n\"CHEMBL1164717\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.42\n\n\n1.6\n\n\n1.55\n\n\n35\n\n\n0\n\n\n\n\n\"CHEMBL1824896\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.58\n\n\n4.69\n\n\n4.13\n\n\n34\n\n\n0\n\n\n\n\n\"CHEMBL2323807\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.88\n\n\n3.09\n\n\n2.22\n\n\n20\n\n\n0\n\n\n\n\n\"CHEMBL3919258\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.5\n\n\n1.36\n\n\n1.36\n\n\n32\n\n\n0\n\n\n\n\n\"CHEMBL1973768\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.61\n\n\n-1.09\n\n\n-1.09\n\n\n15\n\n\n0\n\n\n\n\n\"CHEMBL3193130\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.32\n\n\n2.88\n\n\n2.88\n\n\n30\n\n\n0\n\n\n\n\n\"CHEMBL157009\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.4\n\n\n-1.57\n\n\n-1.6\n\n\n20\n\n\n0\n\n\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n\n\n\"CHEMBL1586774\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.79\n\n\n4.03\n\n\n4.02\n\n\n25\n\n\n0\n\n\n\n\n\"CHEMBL3735848\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.62\n\n\n2.49\n\n\n2.48\n\n\n31\n\n\n0\n\n\n\n\n\"CHEMBL2238035\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.63\n\n\n-0.89\n\n\n-0.9\n\n\n18\n\n\n0\n\n\n\n\n\"CHEMBL2409594\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.42\n\n\n2.9\n\n\n2.9\n\n\n32\n\n\n0\n\n\n\n\n\"CHEMBL1823603\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.51\n\n\n4.06\n\n\n4.06\n\n\n32\n\n\n0\n\n\n\n\n\"CHEMBL1373723\"\n\n\n\"Small molecule...\n\n\n0\n\n\n2\n\n\n0.25\n\n\n4.85\n\n\n4.84\n\n\n47\n\n\n0\n\n\n\n\n\"CHEMBL1092638\"\n\n\n\"Small molecule...\n\n\n0\n\n\n1\n\n\n0.45\n\n\n5.0\n\n\n4.78\n\n\n34\n\n\n0\n\n\n\n\n\"CHEMBL3884327\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.23\n\n\n2.0\n\n\n1.31\n\n\n33\n\n\n0\n\n\n\n\n\"CHEMBL3952298\"\n\n\n\"Small molecule...\n\n\n0\n\n\n2\n\n\n0.27\n\n\n4.75\n\n\n4.75\n\n\n37\n\n\n0\n\n\n\n\n\"CHEMBL3958658\"\n\n\n\"Small molecule...\n\n\n0\n\n\n1\n\n\n0.37\n\n\n4.32\n\n\n4.32\n\n\n36\n\n\n0\n\n\n\n\n\"CHEMBL2181572\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.32\n\n\n3.3\n\n\n3.3\n\n\n23\n\n\n0\n\n\n\n\n\"CHEMBL603992\"\n\n\n\"Small molecule...\n\n\n0\n\n\n0\n\n\n0.27\n\n\n3.51\n\n\n3.51\n\n\n35\n\n\n0\n\n\n\n\n\n\n\nThen I combined df_s_0_f (dataframe with max phase 0 compounds) and df_4_f (dataframe with max phase 4 compounds).\n\ndf_concat = pl.concat([df_s_0_f, df_4_f], how = \"vertical\",)\nprint(df_concat)\n\nshape: (1894, 9)\n┌───────────┬───────────┬───────────┬────────────┬─────┬─────────┬─────────┬───────────┬───────────┐\n│ ChEMBL ID ┆ Type      ┆ Max Phase ┆ #RO5       ┆ ... ┆ CX LogP ┆ CX LogD ┆ Heavy     ┆ Max_Phase │\n│ ---       ┆ ---       ┆ ---       ┆ Violations ┆     ┆ ---     ┆ ---     ┆ Atoms     ┆ ---       │\n│ str       ┆ str       ┆ i64       ┆ ---        ┆     ┆ f64     ┆ f64     ┆ ---       ┆ i64       │\n│           ┆           ┆           ┆ i64        ┆     ┆         ┆         ┆ i64       ┆           │\n╞═══════════╪═══════════╪═══════════╪════════════╪═════╪═════════╪═════════╪═══════════╪═══════════╡\n│ CHEMBL344 ┆ Small     ┆ 0         ┆ 0          ┆ ... ┆ 2.05    ┆ 0.62    ┆ 21        ┆ 0         │\n│ 8290      ┆ molecule  ┆           ┆            ┆     ┆         ┆         ┆           ┆           │\n├╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤\n│ CHEMBL396 ┆ Small     ┆ 0         ┆ 2          ┆ ... ┆ 1.51    ┆ -0.41   ┆ 48        ┆ 0         │\n│ 6308      ┆ molecule  ┆           ┆            ┆     ┆         ┆         ┆           ┆           │\n├╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤\n│ CHEMBL396 ┆ Small     ┆ 0         ┆ 2          ┆ ... ┆ 5.05    ┆ 3.27    ┆ 46        ┆ 0         │\n│ 3545      ┆ molecule  ┆           ┆            ┆     ┆         ┆         ┆           ┆           │\n├╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤\n│ CHEMBL164 ┆ Small     ┆ 0         ┆ 0          ┆ ... ┆ 3.21    ┆ 3.21    ┆ 24        ┆ 0         │\n│ 9629      ┆ molecule  ┆           ┆            ┆     ┆         ┆         ┆           ┆           │\n├╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤\n│ ...       ┆ ...       ┆ ...       ┆ ...        ┆ ... ┆ ...     ┆ ...     ┆ ...       ┆ ...       │\n├╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤\n│ CHEMBL303 ┆ Small     ┆ 4         ┆ 0          ┆ ... ┆ 3.3     ┆ 2.61    ┆ 27        ┆ 1         │\n│ 9520      ┆ molecule  ┆           ┆            ┆     ┆         ┆         ┆           ┆           │\n├╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤\n│ CHEMBL119 ┆ Small     ┆ 4         ┆ 0          ┆ ... ┆ 3.6     ┆ 1.93    ┆ 32        ┆ 1         │\n│ 8857      ┆ molecule  ┆           ┆            ┆     ┆         ┆         ┆           ┆           │\n├╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤\n│ CHEMBL214 ┆ Small     ┆ 4         ┆ 0          ┆ ... ┆ 2.43    ┆ 2.43    ┆ 24        ┆ 1         │\n│ 6133      ┆ molecule  ┆           ┆            ┆     ┆         ┆         ┆           ┆           │\n├╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤\n│ CHEMBL161 ┆ Small     ┆ 4         ┆ 0          ┆ ... ┆ 2.09    ┆ 1.86    ┆ 34        ┆ 1         │\n│ 9785      ┆ molecule  ┆           ┆            ┆     ┆         ┆         ┆           ┆           │\n└───────────┴───────────┴───────────┴────────────┴─────┴─────────┴─────────┴───────────┴───────────┘\n\n\nThis df_concat dataset was checked to see it had all compounds in Max Phase 0 and 4 only. Note: Max Phase 4 (approved) compounds were re-labelled as Max_Phase = 1.\n\ndf_concat.groupby(\"Max_Phase\").count()\n\n\n\n\nshape: (2, 2)\n\n\n\n\nMax_Phase\n\n\ncount\n\n\n\n\ni64\n\n\nu32\n\n\n\n\n\n\n0\n\n\n950\n\n\n\n\n1\n\n\n944\n\n\n\n\n\n\n\nI then checked df_concat dataset only had small molecules to confirm what I’ve tried to achieve.\n\ndf_concat.groupby(\"Type\").count()\n\n\n\n\nshape: (1, 2)\n\n\n\n\nType\n\n\ncount\n\n\n\n\nstr\n\n\nu32\n\n\n\n\n\n\n\"Small molecule...\n\n\n1894\n\n\n\n\n\n\n\nSo here we had the final version of the dataset, which I’ve renamed to df_ml to avoid confusion from the previous dataframes, before entering the ML phase.\n\n# Leave out ChEMBL ID and Type\ndf_ml = df_concat.select([\"Max_Phase\", \n                          \"#RO5 Violations\", \n                          \"QED Weighted\", \n                          \"CX LogP\", \n                          \"CX LogD\", \n                          \"Heavy Atoms\"]\n                        )\ndf_ml\n\n\n\n\nshape: (1894, 6)\n\n\n\n\nMax_Phase\n\n\n#RO5 Violations\n\n\nQED Weighted\n\n\nCX LogP\n\n\nCX LogD\n\n\nHeavy Atoms\n\n\n\n\ni64\n\n\ni64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\ni64\n\n\n\n\n\n\n0\n\n\n0\n\n\n0.91\n\n\n2.05\n\n\n0.62\n\n\n21\n\n\n\n\n0\n\n\n2\n\n\n0.16\n\n\n1.51\n\n\n-0.41\n\n\n48\n\n\n\n\n0\n\n\n2\n\n\n0.2\n\n\n5.05\n\n\n3.27\n\n\n46\n\n\n\n\n0\n\n\n0\n\n\n0.53\n\n\n3.21\n\n\n3.21\n\n\n24\n\n\n\n\n0\n\n\n1\n\n\n0.14\n\n\n2.8\n\n\n2.8\n\n\n37\n\n\n\n\n0\n\n\n0\n\n\n0.42\n\n\n1.6\n\n\n1.55\n\n\n35\n\n\n\n\n0\n\n\n0\n\n\n0.58\n\n\n4.69\n\n\n4.13\n\n\n34\n\n\n\n\n0\n\n\n0\n\n\n0.88\n\n\n3.09\n\n\n2.22\n\n\n20\n\n\n\n\n0\n\n\n0\n\n\n0.5\n\n\n1.36\n\n\n1.36\n\n\n32\n\n\n\n\n0\n\n\n0\n\n\n0.61\n\n\n-1.09\n\n\n-1.09\n\n\n15\n\n\n\n\n0\n\n\n0\n\n\n0.32\n\n\n2.88\n\n\n2.88\n\n\n30\n\n\n\n\n0\n\n\n0\n\n\n0.4\n\n\n-1.57\n\n\n-1.6\n\n\n20\n\n\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n\n\n1\n\n\n0\n\n\n0.93\n\n\n1.24\n\n\n1.19\n\n\n23\n\n\n\n\n1\n\n\n0\n\n\n0.46\n\n\n4.59\n\n\n4.59\n\n\n33\n\n\n\n\n1\n\n\n1\n\n\n0.32\n\n\n3.4\n\n\n1.0\n\n\n19\n\n\n\n\n1\n\n\n0\n\n\n0.69\n\n\n3.21\n\n\n1.71\n\n\n29\n\n\n\n\n1\n\n\n0\n\n\n0.58\n\n\n1.19\n\n\n-0.18\n\n\n28\n\n\n\n\n1\n\n\n2\n\n\n0.26\n\n\n4.9\n\n\n4.9\n\n\n53\n\n\n\n\n1\n\n\n1\n\n\n0.58\n\n\n2.65\n\n\n2.65\n\n\n32\n\n\n\n\n1\n\n\n2\n\n\n0.1\n\n\n5.57\n\n\n5.57\n\n\n65\n\n\n\n\n1\n\n\n0\n\n\n0.83\n\n\n3.3\n\n\n2.61\n\n\n27\n\n\n\n\n1\n\n\n0\n\n\n0.26\n\n\n3.6\n\n\n1.93\n\n\n32\n\n\n\n\n1\n\n\n0\n\n\n0.77\n\n\n2.43\n\n\n2.43\n\n\n24\n\n\n\n\n1\n\n\n0\n\n\n0.49\n\n\n2.09\n\n\n1.86\n\n\n34\n\n\n\n\n\n\n\n\n# Check for any nulls in the dataset\ndf_ml.null_count()\n\n\n\n\nshape: (1, 6)\n\n\n\n\nMax_Phase\n\n\n#RO5 Violations\n\n\nQED Weighted\n\n\nCX LogP\n\n\nCX LogD\n\n\nHeavy Atoms\n\n\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\n\n\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n\n\n\n\n\n\n# Check data types in df_ml dataset\n# Needed to be integers or floats for scikit-learn algorithms to work\ndf_ml.dtypes\n\n[polars.datatypes.Int64,\n polars.datatypes.Int64,\n polars.datatypes.Float64,\n polars.datatypes.Float64,\n polars.datatypes.Float64,\n polars.datatypes.Int64]\n\n\n\n\n\n\nImport libraries for machine learning\n\n# Install scikit-learn - an open-source ML library\n# Uncomment the line below if needing to install this library\n#!pip install -U scikit-learn\n\n\n# Import scikit-learn\nimport sklearn\n\n# Check version of scikit-learn \nprint(sklearn.__version__)\n\n1.2.0\n\n\nOther libraries needed to generate ML model were imported as below.\n\n# To use NumPy arrays to prepare X & y variables\nimport numpy as np\n\n# Needed for dataframe in scikit-learn ML\n# Uncomment line below if requiring to install pandas\n#!pip install pandas\nimport pandas as pd\n\n# To normalise dataset prior to running ML\nfrom sklearn import preprocessing\n# To split dataset into training & testing sets\nfrom sklearn.model_selection import train_test_split\n\n# For data visualisations\n# Uncomment line below if requiring to install matplotlib\n#!pip install matplotlib\nimport matplotlib.pyplot as plt\n\nI’ve then installed pyarrow, to convert Polars dataframe into a Pandas dataframe, which was needed to run scikit-learn.\n\n# Uncomment line below to install pyarrow\n#!pip install pyarrow\n\n\n# Convert Polars df to Pandas df \ndf_ml_pd = df_ml.to_pandas()\ntype(df_ml_pd)\n\npandas.core.frame.DataFrame\n\n\n\n\n\nLogistic regression with scikit-learn\nLR was one of the supervised methods in statistical ML realm. As the term “supervised” suggested, this type of ML was purely data-driven to allow computers to learn patterns from input data with known outcomes, in order to predict new outcomes on novel data.\n\n\nDefining X and y variables\n\n# Define X variables from df_ml_pd dataset\nX = np.asarray(df_ml_pd[[\"#RO5 Violations\", \n                         \"QED Weighted\", \n                         \"CX LogP\", \n                         \"CX LogD\", \n                         \"Heavy Atoms\"]]\n              )\nX[0:5]\n\narray([[ 0.  ,  0.91,  2.05,  0.62, 21.  ],\n       [ 2.  ,  0.16,  1.51, -0.41, 48.  ],\n       [ 2.  ,  0.2 ,  5.05,  3.27, 46.  ],\n       [ 0.  ,  0.53,  3.21,  3.21, 24.  ],\n       [ 1.  ,  0.14,  2.8 ,  2.8 , 37.  ]])\n\n\n\n# Define y variable\n# Note to use \"Max_Phase\", not the original \"Max Phase\"\ny = np.asarray(df_ml_pd[\"Max_Phase\"])\ny[0:5]\n\narray([0, 0, 0, 0, 0])\n\n\n\n\n\nTraining and testing sets\n\n# Split dataset into training & testing sets\nrng = np.random.RandomState(0)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = rng)\nprint('Training set:', X_train.shape, y_train.shape)\nprint('Testing set:', X_test.shape, y_test.shape)\n\nTraining set: (1515, 5) (1515,)\nTesting set: (379, 5) (379,)\n\n\n\n\n\nPreprocessing data\n\n# Normalise & clean the dataset\n# Fit on the training set - not on testing set as this might lead to data leakage\n# Transform on the testing set\nX = preprocessing.StandardScaler().fit(X_train).transform(X_test)\nX[0:5]\n\narray([[-0.61683613,  0.76594864,  0.29675851,  0.52596937, -0.79684902],\n       [ 0.61602236,  0.45724627,  1.96615599,  1.92002856, -0.11325544],\n       [ 1.84888085, -1.43906824, -2.1393532 , -3.75082759,  0.37502569],\n       [ 0.61602236, -0.73346284, -2.1166917 , -1.56196543,  0.27736946],\n       [-0.61683613, -0.07195778, -1.5954771 , -1.05417464, -0.99216147]])\n\n\n\n\n\nFitting LR classifier on training set\n\n# Import logistic regression \nfrom sklearn.linear_model import LogisticRegression\n# Create an instance of logistic regression classifier and fit the data\nLogR = LogisticRegression().fit(X_train, y_train)\nLogR\n\nLogisticRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LogisticRegressionLogisticRegression()\n\n\n\n\n\nApplying LR classifier on testing set for prediction\n\ny_mp = LogR.predict(X_test)\ny_mp\n\narray([0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n       0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n       0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n       1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n       0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n       1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n       1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n       0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n       1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n       0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n       0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n       0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n       0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n       0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0,\n       0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n       0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n       0, 0, 0, 0, 1])\n\n\n\n\n\nConverting predicted values into a dataframe\n\n# Predicted values were based on log odds\n# Use describe() method to get characteristics of the distribution\npred = pd.DataFrame(LogR.predict_log_proba(X))\npred.describe()\n\n\n\n\n\n  \n    \n      \n      0\n      1\n    \n  \n  \n    \n      count\n      379.000000\n      379.000000\n    \n    \n      mean\n      -0.834407\n      -0.674677\n    \n    \n      std\n      0.383863\n      0.332967\n    \n    \n      min\n      -1.818149\n      -2.239351\n    \n    \n      25%\n      -1.058584\n      -0.887024\n    \n    \n      50%\n      -0.779455\n      -0.613700\n    \n    \n      75%\n      -0.530824\n      -0.426098\n    \n    \n      max\n      -0.112640\n      -0.177126\n    \n  \n\n\n\n\nAlternatively, a quicker way to get predicted probabilities was via predict_proba() method in scikit-learn.\n\ny_mp_proba = LogR.predict_proba(X_test)\n# Uncomment below to see the predicted probabilities printed\n#print(y_mp_proba)\n\n\n\n\nConverting predicted probabilities into a dataframe\n\n# Use describe() to show distributions\ny_mp_prob = pd.DataFrame(y_mp_proba)\ny_mp_prob.describe()\n\n\n\n\n\n  \n    \n      \n      0\n      1\n    \n  \n  \n    \n      count\n      379.000000\n      379.000000\n    \n    \n      mean\n      0.496784\n      0.503216\n    \n    \n      std\n      0.174218\n      0.174218\n    \n    \n      min\n      0.004315\n      0.143818\n    \n    \n      25%\n      0.382057\n      0.375627\n    \n    \n      50%\n      0.517089\n      0.482911\n    \n    \n      75%\n      0.624373\n      0.617943\n    \n    \n      max\n      0.856182\n      0.995685\n    \n  \n\n\n\n\n\n\n\nPipeline method for LR\nThis was something I thought to try when I was reading through scikit-learn documentation. One major advantage of using pipeline was that it was designed to chain all the estimators used for ML. The benefit of this was that we only had to call fit and predict once in our data to fit the whole chain of estimators. The other useful thing was that this could avoid data leakage from our testing set into the training set by making sure the same set of samples were used to train the transformers and predictors. One other key thing it also helped was that it also avoided the possibility of missing out on the transformation step.\nThe example below used the function of make_pipeline, which took in a number of estimators as inputted, and then constructed a pipeline based on them.\n\n# Test pipline from scikit-Learn\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nLR = make_pipeline(StandardScaler(), LogisticRegression())\nLR.fit(X_train, y_train)\n\nPipeline(steps=[('standardscaler', StandardScaler()),\n                ('logisticregression', LogisticRegression())])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('standardscaler', StandardScaler()),\n                ('logisticregression', LogisticRegression())])StandardScalerStandardScaler()LogisticRegressionLogisticRegression()\n\n\n\n\n\n\nEvaluation of the logistic regression model\n\nAccuracy scores\n\nfrom sklearn.metrics import accuracy_score\naccuracy_score(y_mp, y_test)\n\n0.7018469656992085\n\n\nThe accuracy score was 0.7 based on the original data preprocessing method, which meant that there were around 70% of the cases (or compounds) classified correctly by using this LR classifier. Accuracy literally provided a measure of how close the predicted samples were to the true values. One caveat to note was that for imbalanced dataset, accuracy score might not be very informative, and other evaluation metrics would need to be considered instead.\nThe accuracy score shown below was from the pipeline method used previously, which showed a very similar accuracy score of 0.6965699 (close to 0.7), confirming the method was in line with the original preprocessing method.\n\nLR.score(X_test, y_test)\n\n0.6965699208443272\n\n\n\n\n\nConfusion matrix\nNext I’ve built a confusion matrix based on the model in order to visualise the counts of correct and incorrect predictions. The function code used below was adapted from the IBM data science course I’ve taken around the end of last year. I’ve added comments to try and explain what each section of the codes meant.\n\n# Import confusion matrix from scikit-learn\nfrom sklearn.metrics import confusion_matrix\n# Import itertools - functions to create iterators for efficient looping\nimport itertools\n\n# Function to print and plot confusion matrix\ndef plot_confusion_matrix(# Sets a cm object (cm = confusion matrix)\n                          cm, \n                          # Sets classes of '1s' (Successes) & '0s' (Non-successes) for the cm\n                          classes,\n                          # If setting normalize = true, reports in ratios instead of counts\n                          normalize,\n                          title = 'Confusion matrix',\n                          # Choose colour of the cm (using colourmap recognised by matplotlib)\n                          cmap = plt.cm.Reds):\n    \n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis = 1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    # Plot the confusion matrix \n    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation = 45)\n    plt.yticks(tick_marks, classes)\n\n    # Floats to be round up to two decimal places if using normalize = True\n    # or else use integers\n    fmt = '.2f' if normalize else 'd'\n    # Sets threshold of 0.5\n    thresh = cm.max() / 2.\n    # Iterate through the results and differentiate between two text colours \n    # by using the threshold as a cut-off\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment = \"center\",\n                 color = \"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n\n# Compute confusion matrix\nmatrix = confusion_matrix(y_test, y_mp, labels = [0,1])\nnp.set_printoptions(precision = 2)\n\n# Plot confusion matrix without normalisation\nplt.figure()\nplot_confusion_matrix(matrix, \n                      # Define classes of outcomes\n                      classes = ['Max_Phase = 0','Max_Phase = 1'], \n                      # Set normalize = True if wanting ratios instead\n                      normalize = False, \n                      title = \"Confusion matrix without normalisation\"\n                     )\n\nConfusion matrix, without normalization\n[[138  51]\n [ 62 128]]\n\n\n\n\n\nA common rule of thumb for confusion matrix was that all predicted outcomes were columns and all the true outcomes were rows. However, there might be exceptions where this was the other way round. Four different categories could be seen in the confusion matrix which were:\n\nTrue positive - Predicted Max_Phase = 1 & True Max_Phase = 1 (128 out of 179 samples)\nTrue negative - Predicted Max_Phase = 0 & True Max_Phase = 0 (138 out of 200 samples)\nFalse positive - Predicted Max_Phase = 1 & True Max_Phase = 0 (51 out of 179 samples)\nFalse negative - Predicted Max_Phase = 0 & True Max_Phase = 1 (62 out of 200 samples)\n\nBy having these four categories known would then lead us to the next section about classification report, which showed all the precision, recall, f1-score and support metrics to evaluate the performance of this classifier.\n\n\n\nClassification report\n\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, y_mp))\n\n              precision    recall  f1-score   support\n\n           0       0.69      0.73      0.71       189\n           1       0.72      0.67      0.69       190\n\n    accuracy                           0.70       379\n   macro avg       0.70      0.70      0.70       379\nweighted avg       0.70      0.70      0.70       379\n\n\n\nPrecision was a measure of the accuracy of a predicted outcome, where a class label had been predicted by the classifier. So in this case, we could see that for class label 1, the precision was 0.72, which corresponded to the true positive result of 128 out of 179 samples (= 0.715). It was defined by:\n\\[\n\\text{Precision} = \\frac{\\Sigma\\ True\\ Positive}{(\\Sigma\\ True\\ Positive + \\Sigma\\ False\\ Positive)}\n\\]\nRecall, also known as sensitivity (especially widely used in biostatistics and medical diagnostic fields), was a measure of the strength of the classifier to predict a positive outcome. In simple words, it measured the true positive rate. In this example, there was a total of 128 out of 190 samples (which = 0.674, for True Max_Phase = 1 row) that had a true positive outcome of having a max phase of 1. It was defined by:\n\\[\n\\text{Recall} = \\frac{\\Sigma\\ True\\ Positive}{(\\Sigma\\ True\\ Positive + \\Sigma\\ False\\ Negative)}\n\\]\nThe precision and recall metrics could also be calculated for class label = 0, which were shown for the row 0 in the classification report.\nf1-score, or also known as balanced F-score or F-measure, denoted the harmonic average of both precision and recall metrics. This metric would also give another indication about whether this model performed well on outcome predictions. It normally ranged from 0 (worst precision and recall) to 1 (perfect precision and recall). For this particular classifier, f1-score was at 0.7, which was definitely not at its worst, but also could be further improved. It was defined as:\n\\[\n\\text{F1-score} = \\frac{2 \\times (Precision \\times Recall)}{(Precision + Recall)}\n\\]\nSupport, which some readers might have already worked out how the numbers were derived, was the total number of true samples in each class label (read row-wise from the confusion matrix). The main purpose of showing this metric was to help clarifying whether the model or classifier had a reasonably balanced dataset for each class or otherwise.\n\n\n\nLog loss\nLog loss could be used as another gauge to show how good the classifier was at making the outcome predictions. The further the predicted probability was from the true value, the larger the log loss, which was also ranged from 0 to 1. Ideally, the smaller the log loss the better the model would be. Here, we had a log loss of 0.61 for this particular model.\n\n# Log loss\nfrom sklearn.metrics import log_loss\nlog_loss(y_test, y_mp_proba)\n\n0.6149705820831467\n\n\n\n\n\nDiscussions and conclusion\nSo here I’ve completed a very basic LR classifier model for ChEMBL compound dataset. By no means was this a perfect ML model as I haven’t actually changed the default settings of scikit-learn’s LogisticRegression() classifier, with examples such as adjusting C, a regularization parameter which was set at ‘1.0’ by default, and also solvers, which could take in different algorithms for use in optimisation problems and normally set as ‘lbfgs’ by default.\nSo with this default LR model, the evaluation metrics demonstrated a LR classifer of moderate quality to make the approval outcomes on ChEMBL small molecules, with a lot of rooms for improvements. Therefore, I could not yet confirm fully that the physicochemical parameters chosen would be the best ones to predict the approval outcomes of any small molecules. However, I might be okay to say that these molecular parameters were on the right track to help with making this prediction.\nTo further improve this model, I could possibly trial changing the C value and use different solvers to see if better outcomes could be achieved. Other things to consider would be to use other types of ML methods such as naive Bayes, K-nearest neighbours or decision trees and so on. To tackle the problem thoroughly, I would most likely need to do an ensemble of different ML models to find out which model would be the most optimal to answer our target question.\n\n\n\nFinal words\nI’ve experienced the fun of ML after completing this project. The idea is to build on what I know gradually and enjoy what ML can do when we’re making critical decisions. I think from what I’ve got from previous readings about ML is that the quality of data needs to be high or well enough to a point that we can interpret meaningful or significant results out of them.\nHowever, before jumping too far, I’ll need to work on my second project first, which is about using Rust interactively via Jupyter notebook. At the moment, I’m not sure how long it will take or how the content will play out. I’ll certainly do as much as I can since Rust is very new to me. If I get bored or very stuck on it, I’d most likely continue on this ML series. Thanks for reading.\n\n\n\nReferences\nI’ve listed below some references used throughout this project. Again, huge thanks to our online communities in any forms or ways.\n\nscikit-learn documentation\nScikit-learn: Machine Learning in Python, Pedregosa et al., JMLR 12, pp. 2825-2830, 2011.\nBruce, P., Bruce, A. & Gedeck P. (2020). Practical statistics for data scientists. O’Reilly.\nStack Overflow\nPolars references:\n\nPolars - User Guide - https://pola-rs.github.io/polars-book/user-guide/introduction.html\nPolars documentation - https://pola-rs.github.io/polars/py-polars/html/index.html#\nPolars GitHub repository - https://github.com/pola-rs/polars"
  }
]